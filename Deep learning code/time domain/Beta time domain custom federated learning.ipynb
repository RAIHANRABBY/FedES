{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717497594033,"user_tz":-360,"elapsed":1349,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717497597198,"user_tz":-360,"elapsed":679,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717497603668,"user_tz":-360,"elapsed":4866,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717497608390,"user_tz":-360,"elapsed":3976,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1717497632325,"user_tz":-360,"elapsed":23951,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"e52cad86-51a0-4b73-c618-749982737856"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time domain /RAW/Beta_time.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717497632326,"user_tz":-360,"elapsed":7,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"fxwgRS-C1tES","executionInfo":{"status":"ok","timestamp":1717497693769,"user_tz":-360,"elapsed":10494,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Beta/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Beta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"-kPJ3TCp9vdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717497693770,"user_tz":-360,"elapsed":13,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"42699b8b-bb7d-4ab5-a269-0e73b6a43b54"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"f95e8735-4660-415e-bbb8-4250a3db5208","executionInfo":{"status":"ok","timestamp":1717498993619,"user_tz":-360,"elapsed":1299857,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.4049 - accuracy: 0.5294"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 33s 256ms/step - loss: 1.4049 - accuracy: 0.5294 - val_loss: 1.3749 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 49ms/step - loss: 1.3375 - accuracy: 0.6215 - val_loss: 1.3197 - val_accuracy: 0.6573\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.2323 - accuracy: 0.6668 - val_loss: 1.2717 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 1s 40ms/step - loss: 1.1428 - accuracy: 0.7002 - val_loss: 1.2239 - val_accuracy: 0.6853\n","Epoch 5/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.0880 - accuracy: 0.7209 - val_loss: 1.1829 - val_accuracy: 0.7209\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0524 - accuracy: 0.7223 - val_loss: 1.1458 - val_accuracy: 0.7209\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0063 - accuracy: 0.7322 - val_loss: 1.1108 - val_accuracy: 0.6530\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9774 - accuracy: 0.7346 - val_loss: 1.0812 - val_accuracy: 0.6703\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9485 - accuracy: 0.7317 - val_loss: 1.0427 - val_accuracy: 0.7144\n","Epoch 10/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9166 - accuracy: 0.7384 - val_loss: 1.0109 - val_accuracy: 0.7252\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8943 - accuracy: 0.7392 - val_loss: 0.9846 - val_accuracy: 0.7177\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8620 - accuracy: 0.7524 - val_loss: 0.9609 - val_accuracy: 0.6724\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8477 - accuracy: 0.7484 - val_loss: 0.9416 - val_accuracy: 0.6595\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8279 - accuracy: 0.7470 - val_loss: 0.9155 - val_accuracy: 0.6778\n","Epoch 15/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.7980 - accuracy: 0.7600 - val_loss: 0.8903 - val_accuracy: 0.6778\n","Epoch 16/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.7852 - accuracy: 0.7570 - val_loss: 0.8470 - val_accuracy: 0.7101\n","Epoch 17/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.7548 - accuracy: 0.7732 - val_loss: 0.8232 - val_accuracy: 0.7134\n","Epoch 18/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.7475 - accuracy: 0.7608 - val_loss: 0.8283 - val_accuracy: 0.6886\n","Epoch 19/100\n","29/29 [==============================] - 1s 41ms/step - loss: 0.7193 - accuracy: 0.7829 - val_loss: 0.7883 - val_accuracy: 0.7166\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7011 - accuracy: 0.7861 - val_loss: 0.7835 - val_accuracy: 0.7037\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6929 - accuracy: 0.7858 - val_loss: 0.7369 - val_accuracy: 0.7381\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6774 - accuracy: 0.7821 - val_loss: 0.7537 - val_accuracy: 0.7123\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6587 - accuracy: 0.7872 - val_loss: 0.7301 - val_accuracy: 0.7263\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6467 - accuracy: 0.7923 - val_loss: 0.6942 - val_accuracy: 0.7414\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6181 - accuracy: 0.8063 - val_loss: 0.7102 - val_accuracy: 0.7349\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6121 - accuracy: 0.7974 - val_loss: 0.6614 - val_accuracy: 0.7629\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5920 - accuracy: 0.8128 - val_loss: 0.6635 - val_accuracy: 0.7489\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5843 - accuracy: 0.8109 - val_loss: 0.6607 - val_accuracy: 0.7662\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5904 - accuracy: 0.8004 - val_loss: 0.6411 - val_accuracy: 0.7608\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5549 - accuracy: 0.8192 - val_loss: 0.6459 - val_accuracy: 0.7522\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5534 - accuracy: 0.8155 - val_loss: 0.6526 - val_accuracy: 0.7500\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5228 - accuracy: 0.8324 - val_loss: 0.6733 - val_accuracy: 0.7392\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5145 - accuracy: 0.8349 - val_loss: 0.7131 - val_accuracy: 0.7565\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5057 - accuracy: 0.8341 - val_loss: 0.6591 - val_accuracy: 0.7619\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4888 - accuracy: 0.8411 - val_loss: 0.6371 - val_accuracy: 0.7619\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4679 - accuracy: 0.8540 - val_loss: 0.6795 - val_accuracy: 0.7575\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4633 - accuracy: 0.8454 - val_loss: 0.6401 - val_accuracy: 0.7575\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4536 - accuracy: 0.8537 - val_loss: 0.6536 - val_accuracy: 0.7575\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4335 - accuracy: 0.8586 - val_loss: 0.6821 - val_accuracy: 0.7586\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4638 - accuracy: 0.8343 - val_loss: 0.6943 - val_accuracy: 0.7608\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4085 - accuracy: 0.8763 - val_loss: 0.6819 - val_accuracy: 0.7489\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3897 - accuracy: 0.8772 - val_loss: 0.7474 - val_accuracy: 0.7489\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8863 - val_loss: 0.7137 - val_accuracy: 0.7489\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.8798 - val_loss: 0.7571 - val_accuracy: 0.7532\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3739 - accuracy: 0.8769 - val_loss: 0.8892 - val_accuracy: 0.7047\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3902 - accuracy: 0.8685 - val_loss: 0.7327 - val_accuracy: 0.7435\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3566 - accuracy: 0.8887 - val_loss: 0.6974 - val_accuracy: 0.7554\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3317 - accuracy: 0.8995 - val_loss: 0.9117 - val_accuracy: 0.7381\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3323 - accuracy: 0.8925 - val_loss: 0.8032 - val_accuracy: 0.7468\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3165 - accuracy: 0.9025 - val_loss: 0.8901 - val_accuracy: 0.7586\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3055 - accuracy: 0.9071 - val_loss: 0.8994 - val_accuracy: 0.7565\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3441 - accuracy: 0.8804 - val_loss: 0.8285 - val_accuracy: 0.7403\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3110 - accuracy: 0.9027 - val_loss: 0.9892 - val_accuracy: 0.7371\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2927 - accuracy: 0.9079 - val_loss: 0.8935 - val_accuracy: 0.7619\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2595 - accuracy: 0.9259 - val_loss: 0.9386 - val_accuracy: 0.7489\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2537 - accuracy: 0.9240 - val_loss: 0.8674 - val_accuracy: 0.7489\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3252 - accuracy: 0.8879 - val_loss: 0.7364 - val_accuracy: 0.7446\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3351 - accuracy: 0.8887 - val_loss: 0.8339 - val_accuracy: 0.7284\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2530 - accuracy: 0.9294 - val_loss: 0.9206 - val_accuracy: 0.7543\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2551 - accuracy: 0.9195 - val_loss: 0.9390 - val_accuracy: 0.7446\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2497 - accuracy: 0.9219 - val_loss: 0.9805 - val_accuracy: 0.7511\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2277 - accuracy: 0.9359 - val_loss: 1.0236 - val_accuracy: 0.7543\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1962 - accuracy: 0.9507 - val_loss: 1.0802 - val_accuracy: 0.7468\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2039 - accuracy: 0.9423 - val_loss: 1.0156 - val_accuracy: 0.7500\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2151 - accuracy: 0.9375 - val_loss: 1.0957 - val_accuracy: 0.7489\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2138 - accuracy: 0.9335 - val_loss: 1.2060 - val_accuracy: 0.7338\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2029 - accuracy: 0.9445 - val_loss: 1.2201 - val_accuracy: 0.7554\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2215 - accuracy: 0.9356 - val_loss: 1.1077 - val_accuracy: 0.7532\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2055 - accuracy: 0.9432 - val_loss: 1.0227 - val_accuracy: 0.7543\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1910 - accuracy: 0.9445 - val_loss: 1.0044 - val_accuracy: 0.7274\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2087 - accuracy: 0.9321 - val_loss: 0.9620 - val_accuracy: 0.7543\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2229 - accuracy: 0.9308 - val_loss: 0.9744 - val_accuracy: 0.7554\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1991 - accuracy: 0.9461 - val_loss: 1.3142 - val_accuracy: 0.7220\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1733 - accuracy: 0.9502 - val_loss: 1.3524 - val_accuracy: 0.6929\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1663 - accuracy: 0.9555 - val_loss: 1.3826 - val_accuracy: 0.7069\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1558 - accuracy: 0.9604 - val_loss: 1.4266 - val_accuracy: 0.7252\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1508 - accuracy: 0.9615 - val_loss: 1.3040 - val_accuracy: 0.7177\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1724 - accuracy: 0.9547 - val_loss: 1.2268 - val_accuracy: 0.7198\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2140 - accuracy: 0.9335 - val_loss: 1.1747 - val_accuracy: 0.7468\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1572 - accuracy: 0.9601 - val_loss: 1.3468 - val_accuracy: 0.6983\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1452 - accuracy: 0.9639 - val_loss: 1.4039 - val_accuracy: 0.7425\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1337 - accuracy: 0.9682 - val_loss: 1.5628 - val_accuracy: 0.7080\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1365 - accuracy: 0.9658 - val_loss: 1.4077 - val_accuracy: 0.7392\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1705 - accuracy: 0.9512 - val_loss: 1.2988 - val_accuracy: 0.7123\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1624 - accuracy: 0.9569 - val_loss: 1.2949 - val_accuracy: 0.7231\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1456 - accuracy: 0.9628 - val_loss: 1.2790 - val_accuracy: 0.7349\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1221 - accuracy: 0.9736 - val_loss: 1.5569 - val_accuracy: 0.7403\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1100 - accuracy: 0.9784 - val_loss: 1.7385 - val_accuracy: 0.7381\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1440 - accuracy: 0.9626 - val_loss: 1.4660 - val_accuracy: 0.7144\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1234 - accuracy: 0.9693 - val_loss: 1.4675 - val_accuracy: 0.7144\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1270 - accuracy: 0.9698 - val_loss: 1.4998 - val_accuracy: 0.7360\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1243 - accuracy: 0.9693 - val_loss: 1.3735 - val_accuracy: 0.7306\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1283 - accuracy: 0.9685 - val_loss: 1.3993 - val_accuracy: 0.7338\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1101 - accuracy: 0.9752 - val_loss: 1.6848 - val_accuracy: 0.6897\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1278 - accuracy: 0.9690 - val_loss: 1.5876 - val_accuracy: 0.7112\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1183 - accuracy: 0.9744 - val_loss: 1.5355 - val_accuracy: 0.7188\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1281 - accuracy: 0.9666 - val_loss: 1.4624 - val_accuracy: 0.7381\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1467 - accuracy: 0.9566 - val_loss: 1.3321 - val_accuracy: 0.7457\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1113 - accuracy: 0.9776 - val_loss: 1.5323 - val_accuracy: 0.7123\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0982 - accuracy: 0.9803 - val_loss: 1.5136 - val_accuracy: 0.7263\n","{'loss': [1.4048717021942139, 1.3374801874160767, 1.23225998878479, 1.1427576541900635, 1.0879968404769897, 1.0523841381072998, 1.006304383277893, 0.9774011969566345, 0.9484676718711853, 0.9165742993354797, 0.8942550420761108, 0.8620165586471558, 0.8477198481559753, 0.8279232382774353, 0.7980490326881409, 0.7851735353469849, 0.7547690272331238, 0.747503936290741, 0.7193349003791809, 0.7011049389839172, 0.692931056022644, 0.6774226427078247, 0.6586992144584656, 0.646683394908905, 0.6180727481842041, 0.6120997071266174, 0.592017650604248, 0.5842641592025757, 0.5903670787811279, 0.5548580884933472, 0.5534176230430603, 0.522845983505249, 0.5145361423492432, 0.5056923031806946, 0.48883408308029175, 0.46789097785949707, 0.46332818269729614, 0.45356297492980957, 0.43352338671684265, 0.4637775719165802, 0.4085383117198944, 0.3896717131137848, 0.3682226538658142, 0.37452399730682373, 0.37390729784965515, 0.39020106196403503, 0.35658544301986694, 0.33165282011032104, 0.3322949707508087, 0.3164544701576233, 0.3054501414299011, 0.34406980872154236, 0.31102871894836426, 0.2927201986312866, 0.2594764232635498, 0.25366437435150146, 0.3252471089363098, 0.3350702226161957, 0.25295040011405945, 0.25505104660987854, 0.2497190535068512, 0.22765055298805237, 0.19619892537593842, 0.2038804590702057, 0.21509002149105072, 0.2137858271598816, 0.20289407670497894, 0.2214619517326355, 0.20551757514476776, 0.1910133808851242, 0.20872372388839722, 0.22294102609157562, 0.19908758997917175, 0.1733211874961853, 0.1662912666797638, 0.15577714145183563, 0.15080341696739197, 0.17242857813835144, 0.21399134397506714, 0.1571933478116989, 0.14516732096672058, 0.13371503353118896, 0.1365225911140442, 0.17051081359386444, 0.16236446797847748, 0.14556984603405, 0.12207508832216263, 0.10995728522539139, 0.14402401447296143, 0.12339966744184494, 0.12704655528068542, 0.12430252879858017, 0.12834860384464264, 0.11014794558286667, 0.12783174216747284, 0.1182841807603836, 0.12805989384651184, 0.14672666788101196, 0.11125455796718597, 0.0981711819767952], 'accuracy': [0.5293642282485962, 0.6214978694915771, 0.6667564511299133, 0.7001616358757019, 0.7209051847457886, 0.7222521305084229, 0.7322198152542114, 0.7346444129943848, 0.7316810488700867, 0.7384159564971924, 0.7392241358757019, 0.7524245977401733, 0.748383641242981, 0.7470366358757019, 0.7599676847457886, 0.7570043206214905, 0.7731680870056152, 0.7607758641242981, 0.782866358757019, 0.7860991358757019, 0.7858297228813171, 0.7820581793785095, 0.7871767282485962, 0.7922952771186829, 0.806303858757019, 0.7974137663841248, 0.8127694129943848, 0.810883641242981, 0.8003771305084229, 0.8192349076271057, 0.8154633641242981, 0.8324353694915771, 0.8348599076271057, 0.8340517282485962, 0.8410560488700867, 0.8539870977401733, 0.845366358757019, 0.8537176847457886, 0.8585668206214905, 0.834321141242981, 0.876347005367279, 0.8771551847457886, 0.8863146305084229, 0.8798491358757019, 0.8768857717514038, 0.868534505367279, 0.8887392282485962, 0.8995150923728943, 0.8925107717514038, 0.9024784564971924, 0.9070581793785095, 0.8803879022598267, 0.9027478694915771, 0.907866358757019, 0.9259159564971924, 0.9240301847457886, 0.8879310488700867, 0.8887392282485962, 0.9294180870056152, 0.9194504022598267, 0.921875, 0.935883641242981, 0.9507004022598267, 0.9423491358757019, 0.9375, 0.9334590435028076, 0.9445043206214905, 0.9356142282485962, 0.9431573152542114, 0.9445043206214905, 0.9321120977401733, 0.9307650923728943, 0.9461206793785095, 0.9501616358757019, 0.9555495977401733, 0.9603987336158752, 0.9614762663841248, 0.954741358757019, 0.9334590435028076, 0.9601293206214905, 0.9639008641242981, 0.9682112336158752, 0.9657866358757019, 0.9512392282485962, 0.9568965435028076, 0.9628232717514038, 0.9735991358757019, 0.9784482717514038, 0.962553858757019, 0.9692887663841248, 0.9698275923728943, 0.9692887663841248, 0.9684805870056152, 0.975215494632721, 0.9690194129943848, 0.9744073152542114, 0.9665948152542114, 0.9566271305084229, 0.9776400923728943, 0.9803340435028076], 'val_loss': [1.3748830556869507, 1.3196563720703125, 1.2716938257217407, 1.2239433526992798, 1.1829135417938232, 1.1457709074020386, 1.1108410358428955, 1.0812492370605469, 1.0427072048187256, 1.0108637809753418, 0.9846070408821106, 0.9608834385871887, 0.9415631890296936, 0.915524959564209, 0.8903350234031677, 0.8470104336738586, 0.8231989741325378, 0.8282945156097412, 0.7883131504058838, 0.7835214138031006, 0.736875057220459, 0.7537020444869995, 0.730085015296936, 0.6942039728164673, 0.710210382938385, 0.6614172458648682, 0.6635040044784546, 0.6607457995414734, 0.6410998106002808, 0.6458937525749207, 0.652580201625824, 0.6732712984085083, 0.713056743144989, 0.6590748429298401, 0.6370577216148376, 0.6795392036437988, 0.6400676369667053, 0.6535918116569519, 0.6821225881576538, 0.6942896246910095, 0.6819435358047485, 0.7474308013916016, 0.7137130498886108, 0.7571029663085938, 0.889194130897522, 0.7326939105987549, 0.6973737478256226, 0.9117039442062378, 0.8032175302505493, 0.8900867700576782, 0.8994022607803345, 0.8284505605697632, 0.9892274141311646, 0.8935450911521912, 0.938572108745575, 0.8673813939094543, 0.7364330887794495, 0.8338615298271179, 0.9206181168556213, 0.9389519095420837, 0.9804805517196655, 1.0236440896987915, 1.0802291631698608, 1.0155863761901855, 1.0957177877426147, 1.2059687376022339, 1.2200886011123657, 1.1076778173446655, 1.0227348804473877, 1.0043551921844482, 0.962030827999115, 0.9743845462799072, 1.3142173290252686, 1.3523972034454346, 1.3826065063476562, 1.4266202449798584, 1.3039507865905762, 1.226757287979126, 1.174716591835022, 1.3467639684677124, 1.4039372205734253, 1.5627703666687012, 1.4076688289642334, 1.2987802028656006, 1.2948988676071167, 1.2790099382400513, 1.5569281578063965, 1.7384865283966064, 1.4659878015518188, 1.4675004482269287, 1.4997771978378296, 1.3735136985778809, 1.3993425369262695, 1.684805154800415, 1.5875613689422607, 1.5354937314987183, 1.4624152183532715, 1.3321444988250732, 1.5322859287261963, 1.5136444568634033], 'val_accuracy': [0.48491379618644714, 0.6573275923728943, 0.48599138855934143, 0.6853448152542114, 0.7209051847457886, 0.7209051847457886, 0.6530172228813171, 0.670258641242981, 0.7144396305084229, 0.725215494632721, 0.7176724076271057, 0.6724137663841248, 0.6594827771186829, 0.6778017282485962, 0.6778017282485962, 0.7101293206214905, 0.7133620977401733, 0.6885775923728943, 0.7165948152542114, 0.7036637663841248, 0.7381465435028076, 0.712284505367279, 0.7262930870056152, 0.7413793206214905, 0.7349137663841248, 0.7629310488700867, 0.7489224076271057, 0.7661637663841248, 0.7607758641242981, 0.7521551847457886, 0.75, 0.7392241358757019, 0.756465494632721, 0.7618534564971924, 0.7618534564971924, 0.7575430870056152, 0.7575430870056152, 0.7575430870056152, 0.7586206793785095, 0.7607758641242981, 0.7489224076271057, 0.7489224076271057, 0.7489224076271057, 0.7532327771186829, 0.704741358757019, 0.743534505367279, 0.7553879022598267, 0.7381465435028076, 0.7467672228813171, 0.7586206793785095, 0.756465494632721, 0.7403017282485962, 0.7370689511299133, 0.7618534564971924, 0.7489224076271057, 0.7489224076271057, 0.7446120977401733, 0.7284482717514038, 0.7543103694915771, 0.7446120977401733, 0.7510775923728943, 0.7543103694915771, 0.7467672228813171, 0.75, 0.7489224076271057, 0.7338362336158752, 0.7553879022598267, 0.7532327771186829, 0.7543103694915771, 0.7273706793785095, 0.7543103694915771, 0.7553879022598267, 0.7219827771186829, 0.6928879022598267, 0.7068965435028076, 0.725215494632721, 0.7176724076271057, 0.7198275923728943, 0.7467672228813171, 0.6982758641242981, 0.7424569129943848, 0.7079741358757019, 0.7392241358757019, 0.712284505367279, 0.7230603694915771, 0.7349137663841248, 0.7403017282485962, 0.7381465435028076, 0.7144396305084229, 0.7144396305084229, 0.735991358757019, 0.7306034564971924, 0.7338362336158752, 0.6896551847457886, 0.7112069129943848, 0.71875, 0.7381465435028076, 0.7456896305084229, 0.712284505367279, 0.7262930870056152]}\n","38/38 [==============================] - 1s 12ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.4068 - accuracy: 0.4901"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 80ms/step - loss: 1.4068 - accuracy: 0.4901 - val_loss: 1.3770 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3507 - accuracy: 0.5396 - val_loss: 1.3238 - val_accuracy: 0.5441\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.2900 - accuracy: 0.6293 - val_loss: 1.2735 - val_accuracy: 0.6629\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1994 - accuracy: 0.6619 - val_loss: 1.2246 - val_accuracy: 0.6403\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1307 - accuracy: 0.6825 - val_loss: 1.1837 - val_accuracy: 0.7048\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0683 - accuracy: 0.7066 - val_loss: 1.1466 - val_accuracy: 0.6980\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0111 - accuracy: 0.7250 - val_loss: 1.1111 - val_accuracy: 0.7104\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9772 - accuracy: 0.7317 - val_loss: 1.0797 - val_accuracy: 0.6425\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9623 - accuracy: 0.7136 - val_loss: 1.0527 - val_accuracy: 0.6787\n","Epoch 10/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9101 - accuracy: 0.7459 - val_loss: 1.0107 - val_accuracy: 0.7274\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8847 - accuracy: 0.7436 - val_loss: 0.9902 - val_accuracy: 0.6629\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8496 - accuracy: 0.7595 - val_loss: 0.9494 - val_accuracy: 0.6889\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8289 - accuracy: 0.7555 - val_loss: 0.9280 - val_accuracy: 0.7014\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8126 - accuracy: 0.7550 - val_loss: 0.8995 - val_accuracy: 0.6912\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7783 - accuracy: 0.7697 - val_loss: 0.8858 - val_accuracy: 0.6708\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7600 - accuracy: 0.7776 - val_loss: 0.8625 - val_accuracy: 0.6753\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7349 - accuracy: 0.7861 - val_loss: 0.8225 - val_accuracy: 0.7070\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7246 - accuracy: 0.7745 - val_loss: 0.8095 - val_accuracy: 0.7025\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7048 - accuracy: 0.7835 - val_loss: 0.8092 - val_accuracy: 0.6855\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6832 - accuracy: 0.7926 - val_loss: 0.7786 - val_accuracy: 0.7070\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6850 - accuracy: 0.7767 - val_loss: 0.7536 - val_accuracy: 0.7285\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6494 - accuracy: 0.8008 - val_loss: 0.7442 - val_accuracy: 0.7195\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6281 - accuracy: 0.8028 - val_loss: 0.7072 - val_accuracy: 0.7251\n","Epoch 24/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6596 - accuracy: 0.7731 - val_loss: 0.6840 - val_accuracy: 0.7511\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6040 - accuracy: 0.8144 - val_loss: 0.7122 - val_accuracy: 0.7398\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5877 - accuracy: 0.8189 - val_loss: 0.7067 - val_accuracy: 0.7353\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5765 - accuracy: 0.8144 - val_loss: 0.6651 - val_accuracy: 0.7523\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5586 - accuracy: 0.8192 - val_loss: 0.6755 - val_accuracy: 0.7455\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5460 - accuracy: 0.8260 - val_loss: 0.6774 - val_accuracy: 0.7217\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5325 - accuracy: 0.8251 - val_loss: 0.7111 - val_accuracy: 0.7262\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5485 - accuracy: 0.8155 - val_loss: 0.6497 - val_accuracy: 0.7523\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4987 - accuracy: 0.8469 - val_loss: 0.6641 - val_accuracy: 0.7579\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4872 - accuracy: 0.8418 - val_loss: 0.6653 - val_accuracy: 0.7455\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4911 - accuracy: 0.8331 - val_loss: 0.6422 - val_accuracy: 0.7443\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4803 - accuracy: 0.8415 - val_loss: 0.6430 - val_accuracy: 0.7421\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4468 - accuracy: 0.8596 - val_loss: 0.7114 - val_accuracy: 0.7296\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.8724 - val_loss: 0.7436 - val_accuracy: 0.7410\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4224 - accuracy: 0.8721 - val_loss: 0.7048 - val_accuracy: 0.7330\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4248 - accuracy: 0.8611 - val_loss: 0.6566 - val_accuracy: 0.7443\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3946 - accuracy: 0.8778 - val_loss: 0.7083 - val_accuracy: 0.7477\n","Epoch 41/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3864 - accuracy: 0.8800 - val_loss: 0.6903 - val_accuracy: 0.7466\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3642 - accuracy: 0.8896 - val_loss: 0.7365 - val_accuracy: 0.7285\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3711 - accuracy: 0.8874 - val_loss: 0.6923 - val_accuracy: 0.7410\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3570 - accuracy: 0.8939 - val_loss: 0.7836 - val_accuracy: 0.7410\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3383 - accuracy: 0.9001 - val_loss: 0.9036 - val_accuracy: 0.7093\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4061 - accuracy: 0.8630 - val_loss: 0.7207 - val_accuracy: 0.7240\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3082 - accuracy: 0.9117 - val_loss: 0.8066 - val_accuracy: 0.7421\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3109 - accuracy: 0.9061 - val_loss: 0.7434 - val_accuracy: 0.7240\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2894 - accuracy: 0.9216 - val_loss: 0.9490 - val_accuracy: 0.7014\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3252 - accuracy: 0.9015 - val_loss: 0.7754 - val_accuracy: 0.7421\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2799 - accuracy: 0.9230 - val_loss: 0.8689 - val_accuracy: 0.7353\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2637 - accuracy: 0.9233 - val_loss: 0.8732 - val_accuracy: 0.7410\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2514 - accuracy: 0.9298 - val_loss: 0.8877 - val_accuracy: 0.7421\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2711 - accuracy: 0.9242 - val_loss: 1.0007 - val_accuracy: 0.7432\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2579 - accuracy: 0.9290 - val_loss: 0.8670 - val_accuracy: 0.7330\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2672 - accuracy: 0.9242 - val_loss: 0.9889 - val_accuracy: 0.7319\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2365 - accuracy: 0.9358 - val_loss: 0.9195 - val_accuracy: 0.7104\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2230 - accuracy: 0.9460 - val_loss: 1.0768 - val_accuracy: 0.7342\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2089 - accuracy: 0.9482 - val_loss: 0.9240 - val_accuracy: 0.7398\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2084 - accuracy: 0.9488 - val_loss: 0.9134 - val_accuracy: 0.7421\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2053 - accuracy: 0.9491 - val_loss: 1.0520 - val_accuracy: 0.7251\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2157 - accuracy: 0.9428 - val_loss: 0.9956 - val_accuracy: 0.7342\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1855 - accuracy: 0.9561 - val_loss: 1.2510 - val_accuracy: 0.7330\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1918 - accuracy: 0.9505 - val_loss: 1.2326 - val_accuracy: 0.7036\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2552 - accuracy: 0.9216 - val_loss: 0.9452 - val_accuracy: 0.7127\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2393 - accuracy: 0.9293 - val_loss: 1.0099 - val_accuracy: 0.7262\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1729 - accuracy: 0.9610 - val_loss: 0.9976 - val_accuracy: 0.7229\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1612 - accuracy: 0.9672 - val_loss: 1.1357 - val_accuracy: 0.7195\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1554 - accuracy: 0.9672 - val_loss: 1.3368 - val_accuracy: 0.7138\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1571 - accuracy: 0.9697 - val_loss: 1.2662 - val_accuracy: 0.7421\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1492 - accuracy: 0.9675 - val_loss: 1.4141 - val_accuracy: 0.7342\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1505 - accuracy: 0.9697 - val_loss: 1.2496 - val_accuracy: 0.7330\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1582 - accuracy: 0.9652 - val_loss: 1.2920 - val_accuracy: 0.7172\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1376 - accuracy: 0.9728 - val_loss: 1.3445 - val_accuracy: 0.7229\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1342 - accuracy: 0.9734 - val_loss: 1.4044 - val_accuracy: 0.7443\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1393 - accuracy: 0.9743 - val_loss: 1.2791 - val_accuracy: 0.7410\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1285 - accuracy: 0.9782 - val_loss: 1.3774 - val_accuracy: 0.7398\n","Epoch 78/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1329 - accuracy: 0.9757 - val_loss: 1.2525 - val_accuracy: 0.7251\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1343 - accuracy: 0.9740 - val_loss: 1.4580 - val_accuracy: 0.7285\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1526 - accuracy: 0.9652 - val_loss: 1.1974 - val_accuracy: 0.7443\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1629 - accuracy: 0.9576 - val_loss: 1.2026 - val_accuracy: 0.7353\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1149 - accuracy: 0.9810 - val_loss: 1.2775 - val_accuracy: 0.7443\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1105 - accuracy: 0.9805 - val_loss: 1.3526 - val_accuracy: 0.7364\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1244 - accuracy: 0.9754 - val_loss: 1.3641 - val_accuracy: 0.7455\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1313 - accuracy: 0.9714 - val_loss: 1.2802 - val_accuracy: 0.7319\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1183 - accuracy: 0.9791 - val_loss: 1.3035 - val_accuracy: 0.7364\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1073 - accuracy: 0.9833 - val_loss: 1.5319 - val_accuracy: 0.7387\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1382 - accuracy: 0.9683 - val_loss: 1.4803 - val_accuracy: 0.6980\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1489 - accuracy: 0.9649 - val_loss: 1.2593 - val_accuracy: 0.7432\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1025 - accuracy: 0.9850 - val_loss: 1.4496 - val_accuracy: 0.7466\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1437 - accuracy: 0.9652 - val_loss: 1.2707 - val_accuracy: 0.7387\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1203 - accuracy: 0.9748 - val_loss: 1.4182 - val_accuracy: 0.7296\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0887 - accuracy: 0.9909 - val_loss: 1.6695 - val_accuracy: 0.7364\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0839 - accuracy: 0.9912 - val_loss: 1.6035 - val_accuracy: 0.7376\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0753 - accuracy: 0.9960 - val_loss: 1.7651 - val_accuracy: 0.7262\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0793 - accuracy: 0.9924 - val_loss: 1.6348 - val_accuracy: 0.7376\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0881 - accuracy: 0.9887 - val_loss: 1.7271 - val_accuracy: 0.7104\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0830 - accuracy: 0.9898 - val_loss: 1.7786 - val_accuracy: 0.7240\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0744 - accuracy: 0.9938 - val_loss: 1.7812 - val_accuracy: 0.7296\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1003 - accuracy: 0.9833 - val_loss: 1.5665 - val_accuracy: 0.7398\n","{'loss': [1.4068310260772705, 1.3506720066070557, 1.2899556159973145, 1.1993987560272217, 1.1307240724563599, 1.06834876537323, 1.0111384391784668, 0.977232813835144, 0.9623390436172485, 0.9101102948188782, 0.8847335577011108, 0.8496321439743042, 0.8288560509681702, 0.8126308917999268, 0.778257429599762, 0.7600392699241638, 0.734851598739624, 0.7245664596557617, 0.7047697901725769, 0.6831527948379517, 0.6849860548973083, 0.6494219899177551, 0.6281273365020752, 0.6595615744590759, 0.6039803624153137, 0.5877377986907959, 0.5764716863632202, 0.5585890412330627, 0.545979917049408, 0.5324658751487732, 0.5485489368438721, 0.4986734688282013, 0.48721450567245483, 0.49112817645072937, 0.4803311228752136, 0.44678232073783875, 0.41984453797340393, 0.4224204123020172, 0.4248376190662384, 0.39455679059028625, 0.38643813133239746, 0.3642345368862152, 0.37105074524879456, 0.35699787735939026, 0.3383190929889679, 0.406139075756073, 0.30817991495132446, 0.3108798563480377, 0.28939706087112427, 0.32520002126693726, 0.2799037992954254, 0.26371169090270996, 0.2513792812824249, 0.2711006999015808, 0.2578720152378082, 0.2672487497329712, 0.23650535941123962, 0.22304667532444, 0.20890182256698608, 0.20843014121055603, 0.20530067384243011, 0.21570782363414764, 0.1854589432477951, 0.19183136522769928, 0.2551857829093933, 0.2392706573009491, 0.17289800941944122, 0.16120974719524384, 0.15541961789131165, 0.157070130109787, 0.1491764485836029, 0.15046784281730652, 0.15817920863628387, 0.13764028251171112, 0.1342000812292099, 0.13927322626113892, 0.12849363684654236, 0.13292671740055084, 0.1342952400445938, 0.1526077687740326, 0.16287295520305634, 0.11489009857177734, 0.11046256870031357, 0.12437459826469421, 0.1313055008649826, 0.11829309165477753, 0.10734125226736069, 0.13819484412670135, 0.14890392124652863, 0.10252384841442108, 0.14373883605003357, 0.12034197896718979, 0.08873316645622253, 0.08388395607471466, 0.07531999051570892, 0.07933218032121658, 0.08807683736085892, 0.08299348503351212, 0.0743955746293068, 0.1002972275018692], 'accuracy': [0.49009621143341064, 0.5396151542663574, 0.629315197467804, 0.6618562340736389, 0.6825127601623535, 0.7065647840499878, 0.7249575257301331, 0.7317487001419067, 0.713638961315155, 0.7458969950675964, 0.7436332702636719, 0.7594793438911438, 0.755517840385437, 0.7549518942832947, 0.7696660757064819, 0.7775891423225403, 0.7860780954360962, 0.7744765281677246, 0.7835314273834229, 0.7925863265991211, 0.7767402529716492, 0.8007922768592834, 0.8027730584144592, 0.7730616927146912, 0.8143746256828308, 0.8189020752906799, 0.8143746256828308, 0.8191850781440735, 0.8259762525558472, 0.825127363204956, 0.8155065178871155, 0.8469156622886658, 0.8418223261833191, 0.8330503702163696, 0.8415393233299255, 0.859649121761322, 0.8723825812339783, 0.8720995783805847, 0.8610639572143555, 0.8777589201927185, 0.8800226449966431, 0.8896434903144836, 0.8873797655105591, 0.8938879370689392, 0.9001131653785706, 0.8630446791648865, 0.9117147922515869, 0.9060554504394531, 0.9216185808181763, 0.901528000831604, 0.9230334162712097, 0.9233163595199585, 0.9298245906829834, 0.9241652488708496, 0.9289756417274475, 0.9241652488708496, 0.9357668161392212, 0.9459536075592041, 0.9482173323631287, 0.9487832188606262, 0.9490662217140198, 0.9428409934043884, 0.9561403393745422, 0.9504810571670532, 0.9216185808181763, 0.9292586445808411, 0.9609507918357849, 0.9671760201454163, 0.9671760201454163, 0.9697226881980896, 0.967458963394165, 0.9697226881980896, 0.9651952385902405, 0.9728353023529053, 0.9734012484550476, 0.9742501378059387, 0.9782116413116455, 0.9756649732589722, 0.9739671945571899, 0.9651952385902405, 0.9575551748275757, 0.9810413122177124, 0.9804753661155701, 0.9753820300102234, 0.9714204668998718, 0.9790605306625366, 0.983305037021637, 0.9683078527450562, 0.9649122953414917, 0.9850028157234192, 0.9651952385902405, 0.974816083908081, 0.9909451007843018, 0.9912280440330505, 0.9960384964942932, 0.9923599362373352, 0.9886813759803772, 0.9898132681846619, 0.9937747716903687, 0.983305037021637], 'val_loss': [1.377024531364441, 1.3237892389297485, 1.273458480834961, 1.2245525121688843, 1.1837078332901, 1.1465779542922974, 1.111100435256958, 1.079666256904602, 1.0526833534240723, 1.010748267173767, 0.9902235269546509, 0.9493774175643921, 0.9280291199684143, 0.8995088338851929, 0.8858126401901245, 0.8624978065490723, 0.822502851486206, 0.8095189929008484, 0.809163510799408, 0.7786045074462891, 0.7535606622695923, 0.7441877722740173, 0.7071799039840698, 0.6840075850486755, 0.7122038006782532, 0.7066980004310608, 0.6650930643081665, 0.675457239151001, 0.6774235963821411, 0.7110734581947327, 0.6497459411621094, 0.6641317009925842, 0.6652680039405823, 0.6422302722930908, 0.6429888010025024, 0.7113747596740723, 0.7435805201530457, 0.7048112154006958, 0.6566017270088196, 0.7082814574241638, 0.6903244853019714, 0.7365436553955078, 0.6923328042030334, 0.7835770845413208, 0.9035841226577759, 0.7207030057907104, 0.8066281080245972, 0.7434106469154358, 0.9490004777908325, 0.7754271626472473, 0.8689216375350952, 0.8732308149337769, 0.88768470287323, 1.0007309913635254, 0.8669887185096741, 0.9889208078384399, 0.9194986820220947, 1.0768178701400757, 0.9240196347236633, 0.9133992791175842, 1.0520168542861938, 0.9956455826759338, 1.251049280166626, 1.232559084892273, 0.9452496767044067, 1.0099167823791504, 0.9975621104240417, 1.135729432106018, 1.3367712497711182, 1.2661926746368408, 1.4140818119049072, 1.2495628595352173, 1.292047142982483, 1.3444782495498657, 1.4044419527053833, 1.2791483402252197, 1.3774362802505493, 1.2525266408920288, 1.4579575061798096, 1.197375774383545, 1.2026273012161255, 1.2774930000305176, 1.3526434898376465, 1.364123821258545, 1.2801806926727295, 1.3034865856170654, 1.5319489240646362, 1.480308175086975, 1.2593458890914917, 1.4496474266052246, 1.270661473274231, 1.4182078838348389, 1.669535517692566, 1.6035370826721191, 1.7650800943374634, 1.6348172426223755, 1.727097511291504, 1.7786060571670532, 1.7812097072601318, 1.5664993524551392], 'val_accuracy': [0.4954751133918762, 0.5441176295280457, 0.662895917892456, 0.6402714848518372, 0.7047511339187622, 0.6979637742042542, 0.7104072570800781, 0.6425339579582214, 0.6787330508232117, 0.7273755669593811, 0.662895917892456, 0.6889140009880066, 0.7013574838638306, 0.6911764740943909, 0.6708144545555115, 0.6753393411636353, 0.7070135474205017, 0.7024886608123779, 0.685520350933075, 0.7070135474205017, 0.7285068035125732, 0.7194570302963257, 0.7251130938529968, 0.7511312365531921, 0.7398189902305603, 0.7352941036224365, 0.7522624731063843, 0.7454751133918762, 0.7217194437980652, 0.726244330406189, 0.7522624731063843, 0.7579185366630554, 0.7454751133918762, 0.7443438768386841, 0.7420814633369446, 0.7296379804611206, 0.7409502267837524, 0.733031690120697, 0.7443438768386841, 0.7477375268936157, 0.7466063499450684, 0.7285068035125732, 0.7409502267837524, 0.7409502267837524, 0.709276020526886, 0.7239819169044495, 0.7420814633369446, 0.7239819169044495, 0.7013574838638306, 0.7420814633369446, 0.7352941036224365, 0.7409502267837524, 0.7420814633369446, 0.7432126402854919, 0.733031690120697, 0.7319004535675049, 0.7104072570800781, 0.7341628670692444, 0.7398189902305603, 0.7420814633369446, 0.7251130938529968, 0.7341628670692444, 0.733031690120697, 0.7036198973655701, 0.7126696705818176, 0.726244330406189, 0.7228506803512573, 0.7194570302963257, 0.7138009071350098, 0.7420814633369446, 0.7341628670692444, 0.733031690120697, 0.7171945571899414, 0.7228506803512573, 0.7443438768386841, 0.7409502267837524, 0.7398189902305603, 0.7251130938529968, 0.7285068035125732, 0.7443438768386841, 0.7352941036224365, 0.7443438768386841, 0.7364253401756287, 0.7454751133918762, 0.7319004535675049, 0.7364253401756287, 0.7386877536773682, 0.6979637742042542, 0.7432126402854919, 0.7466063499450684, 0.7386877536773682, 0.7296379804611206, 0.7364253401756287, 0.7375565767288208, 0.726244330406189, 0.7375565767288208, 0.7104072570800781, 0.7239819169044495, 0.7296379804611206, 0.7398189902305603]}\n","45/45 [==============================] - 1s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.4037 - accuracy: 0.5235"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 87ms/step - loss: 1.4037 - accuracy: 0.5235 - val_loss: 1.3706 - val_accuracy: 0.5062\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3384 - accuracy: 0.6010 - val_loss: 1.3123 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2446 - accuracy: 0.6618 - val_loss: 1.2562 - val_accuracy: 0.6684\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1325 - accuracy: 0.6917 - val_loss: 1.2107 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0675 - accuracy: 0.7202 - val_loss: 1.1643 - val_accuracy: 0.6942\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0205 - accuracy: 0.7245 - val_loss: 1.1270 - val_accuracy: 0.7076\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9726 - accuracy: 0.7380 - val_loss: 1.0863 - val_accuracy: 0.6952\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9445 - accuracy: 0.7349 - val_loss: 1.0518 - val_accuracy: 0.7386\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9040 - accuracy: 0.7452 - val_loss: 1.0276 - val_accuracy: 0.6167\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9003 - accuracy: 0.7328 - val_loss: 0.9896 - val_accuracy: 0.6932\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8488 - accuracy: 0.7566 - val_loss: 0.9557 - val_accuracy: 0.6880\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8171 - accuracy: 0.7610 - val_loss: 0.9248 - val_accuracy: 0.6849\n","Epoch 13/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7950 - accuracy: 0.7587 - val_loss: 0.9145 - val_accuracy: 0.6384\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7770 - accuracy: 0.7630 - val_loss: 0.8515 - val_accuracy: 0.7345\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7582 - accuracy: 0.7623 - val_loss: 0.8550 - val_accuracy: 0.6715\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7460 - accuracy: 0.7602 - val_loss: 0.8453 - val_accuracy: 0.6643\n","Epoch 17/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7199 - accuracy: 0.7700 - val_loss: 0.7946 - val_accuracy: 0.7087\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7066 - accuracy: 0.7721 - val_loss: 0.7999 - val_accuracy: 0.6870\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6774 - accuracy: 0.7840 - val_loss: 0.7511 - val_accuracy: 0.7376\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6634 - accuracy: 0.7853 - val_loss: 0.7649 - val_accuracy: 0.7025\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6461 - accuracy: 0.7879 - val_loss: 0.7240 - val_accuracy: 0.7407\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6442 - accuracy: 0.7783 - val_loss: 0.8061 - val_accuracy: 0.6570\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6323 - accuracy: 0.7798 - val_loss: 0.7835 - val_accuracy: 0.6508\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6132 - accuracy: 0.7907 - val_loss: 0.7309 - val_accuracy: 0.7293\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6007 - accuracy: 0.7953 - val_loss: 0.8763 - val_accuracy: 0.6322\n","Epoch 26/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5990 - accuracy: 0.7873 - val_loss: 0.6794 - val_accuracy: 0.7417\n","Epoch 27/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5828 - accuracy: 0.7969 - val_loss: 0.6752 - val_accuracy: 0.7438\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5667 - accuracy: 0.8028 - val_loss: 0.6822 - val_accuracy: 0.7397\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5592 - accuracy: 0.7964 - val_loss: 0.7030 - val_accuracy: 0.6994\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5593 - accuracy: 0.7928 - val_loss: 0.7150 - val_accuracy: 0.7283\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5395 - accuracy: 0.8010 - val_loss: 0.6576 - val_accuracy: 0.7324\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5176 - accuracy: 0.8142 - val_loss: 0.7023 - val_accuracy: 0.7283\n","Epoch 33/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5062 - accuracy: 0.8181 - val_loss: 0.6647 - val_accuracy: 0.7448\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4916 - accuracy: 0.8264 - val_loss: 0.6890 - val_accuracy: 0.7355\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4780 - accuracy: 0.8245 - val_loss: 0.6470 - val_accuracy: 0.7345\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4788 - accuracy: 0.8302 - val_loss: 0.7598 - val_accuracy: 0.6921\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4735 - accuracy: 0.8214 - val_loss: 0.6530 - val_accuracy: 0.7428\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4359 - accuracy: 0.8478 - val_loss: 0.6736 - val_accuracy: 0.7324\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4364 - accuracy: 0.8447 - val_loss: 0.6915 - val_accuracy: 0.7376\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.8501 - val_loss: 0.7122 - val_accuracy: 0.7252\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3996 - accuracy: 0.8646 - val_loss: 0.7358 - val_accuracy: 0.6983\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4135 - accuracy: 0.8463 - val_loss: 0.7237 - val_accuracy: 0.7273\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3853 - accuracy: 0.8693 - val_loss: 0.6888 - val_accuracy: 0.7304\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3585 - accuracy: 0.8829 - val_loss: 0.7450 - val_accuracy: 0.7314\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3987 - accuracy: 0.8506 - val_loss: 0.6940 - val_accuracy: 0.7324\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3709 - accuracy: 0.8672 - val_loss: 0.7942 - val_accuracy: 0.7097\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3413 - accuracy: 0.8845 - val_loss: 0.8212 - val_accuracy: 0.6973\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3924 - accuracy: 0.8548 - val_loss: 0.7677 - val_accuracy: 0.7448\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3453 - accuracy: 0.8814 - val_loss: 0.8468 - val_accuracy: 0.7087\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3065 - accuracy: 0.9021 - val_loss: 0.9137 - val_accuracy: 0.7211\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3313 - accuracy: 0.8832 - val_loss: 0.7820 - val_accuracy: 0.7314\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 0.9036 - val_loss: 0.8961 - val_accuracy: 0.7283\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2978 - accuracy: 0.8992 - val_loss: 1.0938 - val_accuracy: 0.7014\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2868 - accuracy: 0.9075 - val_loss: 1.0412 - val_accuracy: 0.7252\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2656 - accuracy: 0.9168 - val_loss: 0.8367 - val_accuracy: 0.7314\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2863 - accuracy: 0.9016 - val_loss: 0.8379 - val_accuracy: 0.7190\n","Epoch 57/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2829 - accuracy: 0.9018 - val_loss: 0.9313 - val_accuracy: 0.7221\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2487 - accuracy: 0.9230 - val_loss: 0.9606 - val_accuracy: 0.7128\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2497 - accuracy: 0.9209 - val_loss: 1.0481 - val_accuracy: 0.7169\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3235 - accuracy: 0.8848 - val_loss: 0.8672 - val_accuracy: 0.7004\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2558 - accuracy: 0.9155 - val_loss: 0.9577 - val_accuracy: 0.7211\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2400 - accuracy: 0.9220 - val_loss: 1.1314 - val_accuracy: 0.7045\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2473 - accuracy: 0.9152 - val_loss: 0.9653 - val_accuracy: 0.7262\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2177 - accuracy: 0.9315 - val_loss: 1.0015 - val_accuracy: 0.7273\n","Epoch 65/100\n","31/31 [==============================] - 2s 63ms/step - loss: 0.2364 - accuracy: 0.9279 - val_loss: 0.9818 - val_accuracy: 0.7469\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2274 - accuracy: 0.9271 - val_loss: 1.0256 - val_accuracy: 0.7211\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1966 - accuracy: 0.9426 - val_loss: 1.0755 - val_accuracy: 0.7242\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1858 - accuracy: 0.9470 - val_loss: 1.2420 - val_accuracy: 0.7376\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2085 - accuracy: 0.9359 - val_loss: 1.0993 - val_accuracy: 0.7252\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1908 - accuracy: 0.9413 - val_loss: 1.2392 - val_accuracy: 0.7066\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1838 - accuracy: 0.9468 - val_loss: 1.1673 - val_accuracy: 0.7035\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2416 - accuracy: 0.9217 - val_loss: 1.2400 - val_accuracy: 0.7386\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1743 - accuracy: 0.9509 - val_loss: 1.1507 - val_accuracy: 0.7324\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1658 - accuracy: 0.9553 - val_loss: 1.1929 - val_accuracy: 0.7386\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1677 - accuracy: 0.9522 - val_loss: 1.3472 - val_accuracy: 0.7014\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1743 - accuracy: 0.9506 - val_loss: 1.3316 - val_accuracy: 0.7376\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1665 - accuracy: 0.9514 - val_loss: 1.3583 - val_accuracy: 0.7066\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1649 - accuracy: 0.9553 - val_loss: 1.0351 - val_accuracy: 0.6963\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2134 - accuracy: 0.9310 - val_loss: 1.0057 - val_accuracy: 0.6860\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2131 - accuracy: 0.9328 - val_loss: 1.3512 - val_accuracy: 0.7045\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1624 - accuracy: 0.9548 - val_loss: 1.3476 - val_accuracy: 0.7417\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1395 - accuracy: 0.9630 - val_loss: 1.3442 - val_accuracy: 0.7159\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1315 - accuracy: 0.9680 - val_loss: 1.4354 - val_accuracy: 0.7097\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1338 - accuracy: 0.9672 - val_loss: 1.4313 - val_accuracy: 0.7242\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1243 - accuracy: 0.9713 - val_loss: 1.5250 - val_accuracy: 0.7180\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1682 - accuracy: 0.9499 - val_loss: 1.5431 - val_accuracy: 0.6973\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1760 - accuracy: 0.9494 - val_loss: 1.2771 - val_accuracy: 0.7138\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1918 - accuracy: 0.9380 - val_loss: 1.3081 - val_accuracy: 0.7190\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1463 - accuracy: 0.9597 - val_loss: 1.2970 - val_accuracy: 0.7314\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1207 - accuracy: 0.9711 - val_loss: 1.2822 - val_accuracy: 0.7180\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1079 - accuracy: 0.9760 - val_loss: 1.4747 - val_accuracy: 0.7231\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1052 - accuracy: 0.9762 - val_loss: 1.5071 - val_accuracy: 0.7056\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1061 - accuracy: 0.9765 - val_loss: 1.4791 - val_accuracy: 0.7025\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1126 - accuracy: 0.9760 - val_loss: 1.4021 - val_accuracy: 0.6849\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1110 - accuracy: 0.9760 - val_loss: 1.6977 - val_accuracy: 0.7231\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1122 - accuracy: 0.9721 - val_loss: 1.7421 - val_accuracy: 0.6994\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2180 - accuracy: 0.9274 - val_loss: 1.3163 - val_accuracy: 0.6756\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1834 - accuracy: 0.9429 - val_loss: 1.3914 - val_accuracy: 0.7118\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1266 - accuracy: 0.9661 - val_loss: 1.1672 - val_accuracy: 0.7128\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1146 - accuracy: 0.9729 - val_loss: 1.3855 - val_accuracy: 0.7242\n","{'loss': [1.4037142992019653, 1.3383853435516357, 1.2445884943008423, 1.1324691772460938, 1.0674771070480347, 1.0205471515655518, 0.9725605249404907, 0.9444547891616821, 0.904049813747406, 0.9003288745880127, 0.8488243818283081, 0.817122757434845, 0.7950361967086792, 0.777033269405365, 0.758179783821106, 0.7460409998893738, 0.7198692560195923, 0.7065600752830505, 0.6774309277534485, 0.663385272026062, 0.6460833549499512, 0.6442223787307739, 0.6322780251502991, 0.6132058501243591, 0.6007254719734192, 0.5990120768547058, 0.5828302502632141, 0.5666684508323669, 0.5592206120491028, 0.5593142509460449, 0.5395443439483643, 0.5176383256912231, 0.506203830242157, 0.49159762263298035, 0.47797784209251404, 0.4787523150444031, 0.4735442101955414, 0.4359285831451416, 0.4364309310913086, 0.41090211272239685, 0.3996242582798004, 0.41346725821495056, 0.38532036542892456, 0.35852912068367004, 0.3986818194389343, 0.3708746135234833, 0.3413292169570923, 0.39240923523902893, 0.34526342153549194, 0.30650633573532104, 0.331295371055603, 0.29704606533050537, 0.29783692955970764, 0.2868218421936035, 0.26564088463783264, 0.28625157475471497, 0.2829156816005707, 0.24869152903556824, 0.24967102706432343, 0.3235040605068207, 0.25577765703201294, 0.23999141156673431, 0.24728021025657654, 0.21774113178253174, 0.23643262684345245, 0.2274458259344101, 0.19664709270000458, 0.18577301502227783, 0.20854875445365906, 0.19079038500785828, 0.1838020235300064, 0.24160869419574738, 0.1743183434009552, 0.16575679183006287, 0.1676967293024063, 0.17433393001556396, 0.16647377610206604, 0.16491304337978363, 0.21342328190803528, 0.21313536167144775, 0.1624099761247635, 0.13946032524108887, 0.13146214187145233, 0.13378728926181793, 0.12429331243038177, 0.1681888997554779, 0.17599375545978546, 0.19176946580410004, 0.146326944231987, 0.12065377086400986, 0.107880137860775, 0.10519453138113022, 0.10611973702907562, 0.1125945970416069, 0.11101870983839035, 0.11219986528158188, 0.21803709864616394, 0.18335972726345062, 0.12656055390834808, 0.11458244174718857], 'accuracy': [0.5235142111778259, 0.6010335683822632, 0.6617571115493774, 0.6917312741279602, 0.7201550602912903, 0.724547803401947, 0.7379844784736633, 0.734883725643158, 0.7452196478843689, 0.7328165173530579, 0.7565891742706299, 0.7609819173812866, 0.7586563229560852, 0.7630490660667419, 0.762273907661438, 0.7602066993713379, 0.7700258493423462, 0.7720929980278015, 0.7839793562889099, 0.7852713465690613, 0.7878552675247192, 0.778294563293457, 0.7798449397087097, 0.7906976938247681, 0.7953488230705261, 0.7873384952545166, 0.7968991994857788, 0.802842378616333, 0.7963824272155762, 0.7927648425102234, 0.801033616065979, 0.814211905002594, 0.8180878758430481, 0.8263565897941589, 0.8245478272438049, 0.830232560634613, 0.8214470148086548, 0.8478035926818848, 0.8447028398513794, 0.8501291871070862, 0.8645994663238525, 0.8462532162666321, 0.8692506551742554, 0.882945716381073, 0.8506460189819336, 0.8671834468841553, 0.8844961524009705, 0.854780375957489, 0.8813953399658203, 0.9020671844482422, 0.8832041621208191, 0.9036175608634949, 0.8992248177528381, 0.907493531703949, 0.9167958498001099, 0.9015504121780396, 0.9018087983131409, 0.9229974150657654, 0.9209302067756653, 0.8847545385360718, 0.9155038595199585, 0.9219638109207153, 0.9152454733848572, 0.9315245747566223, 0.9279069900512695, 0.9271317720413208, 0.9426356554031372, 0.947028398513794, 0.935917317867279, 0.9413436651229858, 0.9467700123786926, 0.921705424785614, 0.950904369354248, 0.9552971720695496, 0.9521963596343994, 0.9506459832191467, 0.9514212012290955, 0.9552971720695496, 0.9310077428817749, 0.9328165650367737, 0.9547803401947021, 0.9630491137504578, 0.9679586291313171, 0.9671834707260132, 0.9713178277015686, 0.9498708248138428, 0.9493539929389954, 0.9379844665527344, 0.9596899151802063, 0.9710594415664673, 0.9759690165519714, 0.9762274026870728, 0.9764857888221741, 0.9759690165519714, 0.9759690165519714, 0.9720930457115173, 0.9273901581764221, 0.9428940415382385, 0.9661498665809631, 0.9728682041168213], 'val_loss': [1.3706104755401611, 1.3123424053192139, 1.256213665008545, 1.2107213735580444, 1.1643270254135132, 1.1270251274108887, 1.086341142654419, 1.0518039464950562, 1.0275943279266357, 0.9896483421325684, 0.955722987651825, 0.9248383045196533, 0.9145287275314331, 0.8514814972877502, 0.8549928069114685, 0.8453476428985596, 0.7946319580078125, 0.799892246723175, 0.7511407136917114, 0.7649293541908264, 0.7240174412727356, 0.8061075806617737, 0.7834745645523071, 0.7308783531188965, 0.8762592077255249, 0.6793773174285889, 0.675180971622467, 0.6821977496147156, 0.7030094265937805, 0.7149896621704102, 0.6575568914413452, 0.7023383975028992, 0.6646950244903564, 0.6889981627464294, 0.6469785571098328, 0.7597619295120239, 0.6530311703681946, 0.6736301779747009, 0.6914745569229126, 0.7121612429618835, 0.7357988953590393, 0.7236979007720947, 0.6888453960418701, 0.7450088858604431, 0.6940369606018066, 0.7941815257072449, 0.821168839931488, 0.7677261233329773, 0.8467895984649658, 0.913668692111969, 0.78199303150177, 0.8961359858512878, 1.0938266515731812, 1.041187047958374, 0.8366752862930298, 0.8379290699958801, 0.931287407875061, 0.9605798721313477, 1.0480914115905762, 0.867189347743988, 0.9576517343521118, 1.131361722946167, 0.9652985334396362, 1.001488447189331, 0.9817824959754944, 1.0255838632583618, 1.0754737854003906, 1.2420470714569092, 1.0992997884750366, 1.2392487525939941, 1.167263150215149, 1.239957571029663, 1.150721549987793, 1.1929339170455933, 1.347213625907898, 1.3315874338150024, 1.358254313468933, 1.0350892543792725, 1.0057380199432373, 1.3512016534805298, 1.3475751876831055, 1.3441730737686157, 1.4354478120803833, 1.4313236474990845, 1.525038480758667, 1.543052077293396, 1.2771122455596924, 1.308063268661499, 1.2969797849655151, 1.2822332382202148, 1.4747148752212524, 1.5071402788162231, 1.479051113128662, 1.4020665884017944, 1.6977314949035645, 1.7420732975006104, 1.316324234008789, 1.3913593292236328, 1.1672146320343018, 1.3855336904525757], 'val_accuracy': [0.5061983466148376, 0.48553720116615295, 0.6683884263038635, 0.4886363744735718, 0.6942148804664612, 0.7076446413993835, 0.6952479481697083, 0.7386363744735718, 0.6167355179786682, 0.6931818127632141, 0.6880165338516235, 0.6849173307418823, 0.6384297609329224, 0.7345041036605835, 0.6714876294136047, 0.66425621509552, 0.7086777091026306, 0.6869834661483765, 0.7376033067703247, 0.702479362487793, 0.7407024502754211, 0.6570248007774353, 0.6508264541625977, 0.7293388247489929, 0.6322314143180847, 0.7417355179786682, 0.7438016533851624, 0.7396694421768188, 0.6993801593780518, 0.7283057570457458, 0.7324380278587341, 0.7283057570457458, 0.7448347210884094, 0.7355371713638306, 0.7345041036605835, 0.692148745059967, 0.7427685856819153, 0.7324380278587341, 0.7376033067703247, 0.7252066135406494, 0.6983470916748047, 0.7272727489471436, 0.73037189245224, 0.7314049601554871, 0.7324380278587341, 0.7097107172012329, 0.6973140239715576, 0.7448347210884094, 0.7086777091026306, 0.7210744023323059, 0.7314049601554871, 0.7283057570457458, 0.7014462947845459, 0.7252066135406494, 0.7314049601554871, 0.7190082669258118, 0.7221074104309082, 0.7128099203109741, 0.7169421315193176, 0.7004132270812988, 0.7210744023323059, 0.7045454382896423, 0.7262396812438965, 0.7272727489471436, 0.7469007968902588, 0.7210744023323059, 0.7241735458374023, 0.7376033067703247, 0.7252066135406494, 0.7066115736961365, 0.7035123705863953, 0.7386363744735718, 0.7324380278587341, 0.7386363744735718, 0.7014462947845459, 0.7376033067703247, 0.7066115736961365, 0.6962810158729553, 0.6859503984451294, 0.7045454382896423, 0.7417355179786682, 0.7159090638160706, 0.7097107172012329, 0.7241735458374023, 0.7179751992225647, 0.6973140239715576, 0.7138429880142212, 0.7190082669258118, 0.7314049601554871, 0.7179751992225647, 0.7231404781341553, 0.7055785059928894, 0.702479362487793, 0.6849173307418823, 0.7231404781341553, 0.6993801593780518, 0.6756198406219482, 0.711776852607727, 0.7128099203109741, 0.7241735458374023]}\n","32/32 [==============================] - 1s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.4557 - accuracy: 0.8062"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 55ms/step - loss: 0.4529 - accuracy: 0.8066 - val_loss: 0.7251 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3848 - accuracy: 0.8386 - val_loss: 0.7240 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3294 - accuracy: 0.8731 - val_loss: 0.7163 - val_accuracy: 0.5259\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2943 - accuracy: 0.8866 - val_loss: 0.7087 - val_accuracy: 0.5312\n","Epoch 5/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2670 - accuracy: 0.8990 - val_loss: 0.6980 - val_accuracy: 0.6002\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2266 - accuracy: 0.9162 - val_loss: 0.6841 - val_accuracy: 0.6282\n","Epoch 7/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2057 - accuracy: 0.9262 - val_loss: 0.6747 - val_accuracy: 0.6304\n","Epoch 8/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.1978 - accuracy: 0.9340 - val_loss: 0.6543 - val_accuracy: 0.6616\n","Epoch 9/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.2166 - accuracy: 0.9243 - val_loss: 0.6501 - val_accuracy: 0.6789\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1835 - accuracy: 0.9391 - val_loss: 0.6172 - val_accuracy: 0.6832\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1640 - accuracy: 0.9453 - val_loss: 0.5917 - val_accuracy: 0.7134\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1614 - accuracy: 0.9450 - val_loss: 0.5605 - val_accuracy: 0.7608\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1512 - accuracy: 0.9526 - val_loss: 0.5561 - val_accuracy: 0.7392\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1424 - accuracy: 0.9566 - val_loss: 0.5235 - val_accuracy: 0.7662\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1498 - accuracy: 0.9526 - val_loss: 0.5148 - val_accuracy: 0.7662\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1302 - accuracy: 0.9596 - val_loss: 0.5241 - val_accuracy: 0.7586\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1153 - accuracy: 0.9688 - val_loss: 0.5411 - val_accuracy: 0.7522\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1253 - accuracy: 0.9623 - val_loss: 0.5252 - val_accuracy: 0.7640\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1151 - accuracy: 0.9688 - val_loss: 0.5706 - val_accuracy: 0.7575\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0984 - accuracy: 0.9766 - val_loss: 0.6201 - val_accuracy: 0.7651\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0915 - accuracy: 0.9779 - val_loss: 0.6856 - val_accuracy: 0.7414\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0901 - accuracy: 0.9784 - val_loss: 0.7462 - val_accuracy: 0.7672\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0911 - accuracy: 0.9793 - val_loss: 0.7525 - val_accuracy: 0.7759\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0953 - accuracy: 0.9739 - val_loss: 0.8244 - val_accuracy: 0.7812\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1492 - accuracy: 0.9558 - val_loss: 0.6843 - val_accuracy: 0.7845\n","Epoch 26/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1170 - accuracy: 0.9658 - val_loss: 0.7444 - val_accuracy: 0.7899\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1340 - accuracy: 0.9577 - val_loss: 0.6901 - val_accuracy: 0.7834\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0953 - accuracy: 0.9741 - val_loss: 0.8721 - val_accuracy: 0.7845\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0818 - accuracy: 0.9820 - val_loss: 0.9669 - val_accuracy: 0.7791\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9803 - val_loss: 0.9870 - val_accuracy: 0.7802\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0878 - accuracy: 0.9784 - val_loss: 1.1140 - val_accuracy: 0.7748\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1127 - accuracy: 0.9679 - val_loss: 0.9165 - val_accuracy: 0.7532\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0920 - accuracy: 0.9774 - val_loss: 0.9337 - val_accuracy: 0.7791\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0894 - accuracy: 0.9758 - val_loss: 1.2332 - val_accuracy: 0.7069\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0969 - accuracy: 0.9739 - val_loss: 0.9627 - val_accuracy: 0.7812\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0689 - accuracy: 0.9884 - val_loss: 1.0305 - val_accuracy: 0.7802\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0666 - accuracy: 0.9876 - val_loss: 1.1493 - val_accuracy: 0.7726\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0779 - accuracy: 0.9801 - val_loss: 1.0452 - val_accuracy: 0.7716\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1064 - accuracy: 0.9685 - val_loss: 0.9336 - val_accuracy: 0.7759\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0755 - accuracy: 0.9849 - val_loss: 0.9569 - val_accuracy: 0.7748\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0642 - accuracy: 0.9871 - val_loss: 1.0363 - val_accuracy: 0.7694\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9898 - val_loss: 1.1726 - val_accuracy: 0.7511\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0764 - accuracy: 0.9811 - val_loss: 1.1846 - val_accuracy: 0.7435\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0914 - accuracy: 0.9760 - val_loss: 0.8789 - val_accuracy: 0.7769\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0590 - accuracy: 0.9895 - val_loss: 1.0567 - val_accuracy: 0.7823\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0595 - accuracy: 0.9887 - val_loss: 1.1023 - val_accuracy: 0.7845\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0670 - accuracy: 0.9833 - val_loss: 1.2111 - val_accuracy: 0.7812\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0706 - accuracy: 0.9846 - val_loss: 1.1310 - val_accuracy: 0.7791\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0773 - accuracy: 0.9814 - val_loss: 0.8821 - val_accuracy: 0.7888\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0642 - accuracy: 0.9873 - val_loss: 1.0145 - val_accuracy: 0.7888\n","Epoch 51/100\n","29/29 [==============================] - 2s 64ms/step - loss: 0.0500 - accuracy: 0.9927 - val_loss: 1.2054 - val_accuracy: 0.7931\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0544 - accuracy: 0.9911 - val_loss: 1.3567 - val_accuracy: 0.7791\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0510 - accuracy: 0.9911 - val_loss: 1.1433 - val_accuracy: 0.7866\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0507 - accuracy: 0.9916 - val_loss: 1.2310 - val_accuracy: 0.7726\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0613 - accuracy: 0.9881 - val_loss: 1.1914 - val_accuracy: 0.7791\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1084 - accuracy: 0.9634 - val_loss: 1.0145 - val_accuracy: 0.7565\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9841 - val_loss: 1.0847 - val_accuracy: 0.7694\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0551 - accuracy: 0.9884 - val_loss: 1.2507 - val_accuracy: 0.7575\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0557 - accuracy: 0.9906 - val_loss: 1.2675 - val_accuracy: 0.7381\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0579 - accuracy: 0.9879 - val_loss: 1.1504 - val_accuracy: 0.7522\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0457 - accuracy: 0.9927 - val_loss: 1.1475 - val_accuracy: 0.7802\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 0.9965 - val_loss: 1.3048 - val_accuracy: 0.7791\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0379 - accuracy: 0.9954 - val_loss: 1.2023 - val_accuracy: 0.7759\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 0.9911 - val_loss: 1.3549 - val_accuracy: 0.7888\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1021 - accuracy: 0.9679 - val_loss: 1.0255 - val_accuracy: 0.7500\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0697 - accuracy: 0.9852 - val_loss: 1.0425 - val_accuracy: 0.7748\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0483 - accuracy: 0.9930 - val_loss: 1.0924 - val_accuracy: 0.7823\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0483 - accuracy: 0.9914 - val_loss: 1.3174 - val_accuracy: 0.7457\n","Epoch 69/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0505 - accuracy: 0.9876 - val_loss: 1.1751 - val_accuracy: 0.7769\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 0.9941 - val_loss: 1.2162 - val_accuracy: 0.7694\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0406 - accuracy: 0.9952 - val_loss: 1.1931 - val_accuracy: 0.7791\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0320 - accuracy: 0.9981 - val_loss: 1.2189 - val_accuracy: 0.7694\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 0.9992 - val_loss: 1.2340 - val_accuracy: 0.7845\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0337 - accuracy: 0.9970 - val_loss: 1.3234 - val_accuracy: 0.7575\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0405 - accuracy: 0.9946 - val_loss: 1.1982 - val_accuracy: 0.7694\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0474 - accuracy: 0.9903 - val_loss: 1.1914 - val_accuracy: 0.7909\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0442 - accuracy: 0.9935 - val_loss: 1.1678 - val_accuracy: 0.7651\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0735 - accuracy: 0.9806 - val_loss: 1.0462 - val_accuracy: 0.7694\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0903 - accuracy: 0.9731 - val_loss: 0.9254 - val_accuracy: 0.7737\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.9873 - val_loss: 1.0319 - val_accuracy: 0.7597\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9925 - val_loss: 1.1320 - val_accuracy: 0.7554\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9954 - val_loss: 1.1211 - val_accuracy: 0.7597\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.9981 - val_loss: 1.1852 - val_accuracy: 0.7619\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9995 - val_loss: 1.2377 - val_accuracy: 0.7694\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0260 - accuracy: 0.9995 - val_loss: 1.2553 - val_accuracy: 0.7780\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9995 - val_loss: 1.2922 - val_accuracy: 0.7651\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 0.9992 - val_loss: 1.2836 - val_accuracy: 0.7726\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0246 - accuracy: 0.9997 - val_loss: 1.2691 - val_accuracy: 0.7802\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9997 - val_loss: 1.3135 - val_accuracy: 0.7759\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9995 - val_loss: 1.2873 - val_accuracy: 0.7748\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9997 - val_loss: 1.3360 - val_accuracy: 0.7640\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.7737\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9987 - val_loss: 1.3056 - val_accuracy: 0.7640\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9970 - val_loss: 1.2701 - val_accuracy: 0.7662\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9906 - val_loss: 1.1834 - val_accuracy: 0.7619\n","Epoch 96/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0465 - accuracy: 0.9890 - val_loss: 1.2503 - val_accuracy: 0.7640\n","Epoch 97/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0483 - accuracy: 0.9879 - val_loss: 1.1457 - val_accuracy: 0.7672\n","Epoch 98/100\n","29/29 [==============================] - 1s 43ms/step - loss: 0.0432 - accuracy: 0.9916 - val_loss: 1.3150 - val_accuracy: 0.7608\n","Epoch 99/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.0398 - accuracy: 0.9935 - val_loss: 1.2289 - val_accuracy: 0.7759\n","Epoch 100/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0591 - accuracy: 0.9852 - val_loss: 1.2512 - val_accuracy: 0.7274\n","{'loss': [0.4528793394565582, 0.38476264476776123, 0.3294277489185333, 0.29426100850105286, 0.26696696877479553, 0.22658418118953705, 0.20567013323307037, 0.19776175916194916, 0.21664327383041382, 0.18352346122264862, 0.16396555304527283, 0.16140003502368927, 0.1511608362197876, 0.14239467680454254, 0.14977756142616272, 0.1301974654197693, 0.11530420184135437, 0.12532775104045868, 0.11513620615005493, 0.09844665974378586, 0.09152484685182571, 0.09014637023210526, 0.09110642969608307, 0.0953281968832016, 0.1491614431142807, 0.1169930025935173, 0.13401339948177338, 0.09534438699483871, 0.08183145523071289, 0.08061650395393372, 0.08782891929149628, 0.11269212514162064, 0.09195254743099213, 0.0894230455160141, 0.09686003625392914, 0.06888077408075333, 0.06659328192472458, 0.07789336144924164, 0.10639700293540955, 0.07545361667871475, 0.06422530859708786, 0.06037463992834091, 0.07640306651592255, 0.09141159802675247, 0.05898118391633034, 0.059537336230278015, 0.06700768321752548, 0.07056507468223572, 0.07729144394397736, 0.06415056437253952, 0.0500127375125885, 0.05442194268107414, 0.051048167049884796, 0.05067480355501175, 0.06131932884454727, 0.10842487215995789, 0.06798983365297318, 0.05513095483183861, 0.05570822209119797, 0.05789816752076149, 0.045686546713113785, 0.038553230464458466, 0.03787558525800705, 0.048855654895305634, 0.10214657336473465, 0.06971900910139084, 0.04834263399243355, 0.04829544201493263, 0.05053252354264259, 0.04010758548974991, 0.04063402861356735, 0.03203312307596207, 0.02883557789027691, 0.03366958722472191, 0.04053153097629547, 0.04743377864360809, 0.044227998703718185, 0.07347795367240906, 0.09031961113214493, 0.05971884727478027, 0.042141951620578766, 0.03627123683691025, 0.029867801815271378, 0.02669328637421131, 0.026021048426628113, 0.0264153853058815, 0.0261454526335001, 0.024564163759350777, 0.024229014292359352, 0.025216247886419296, 0.023564685136079788, 0.023627037182450294, 0.02449406497180462, 0.03013678453862667, 0.044783513993024826, 0.04652125760912895, 0.04826320335268974, 0.043244414031505585, 0.03982501104474068, 0.05906050279736519], 'accuracy': [0.8065732717514038, 0.8386314511299133, 0.8731142282485962, 0.8865840435028076, 0.8989762663841248, 0.9162176847457886, 0.9261853694915771, 0.9339978694915771, 0.9242995977401733, 0.939116358757019, 0.9453125, 0.9450430870056152, 0.9525862336158752, 0.9566271305084229, 0.9525862336158752, 0.959590494632721, 0.96875, 0.962284505367279, 0.96875, 0.9765625, 0.977909505367279, 0.9784482717514038, 0.9792564511299133, 0.9738685488700867, 0.9558189511299133, 0.9657866358757019, 0.9577047228813171, 0.9741379022598267, 0.9819504022598267, 0.9803340435028076, 0.9784482717514038, 0.9679418206214905, 0.9773706793785095, 0.9757543206214905, 0.9738685488700867, 0.9884159564971924, 0.9876077771186829, 0.9800646305084229, 0.9684805870056152, 0.9849137663841248, 0.9870689511299133, 0.9897629022598267, 0.9811422228813171, 0.9760237336158752, 0.9894935488700867, 0.9886853694915771, 0.9832974076271057, 0.9846444129943848, 0.9814116358757019, 0.9873383641242981, 0.9927262663841248, 0.9911099076271057, 0.9911099076271057, 0.9916487336158752, 0.9881465435028076, 0.9633620977401733, 0.9841055870056152, 0.9884159564971924, 0.990571141242981, 0.9878771305084229, 0.9927262663841248, 0.9964978694915771, 0.9954202771186829, 0.9911099076271057, 0.9679418206214905, 0.9851831793785095, 0.9929956793785095, 0.9913793206214905, 0.9876077771186829, 0.9940732717514038, 0.9951508641242981, 0.9981142282485962, 0.9991918206214905, 0.9970366358757019, 0.9946120977401733, 0.9903017282485962, 0.993534505367279, 0.9806034564971924, 0.9730603694915771, 0.9873383641242981, 0.9924569129943848, 0.9954202771186829, 0.9981142282485962, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 1.0, 0.998652994632721, 0.9970366358757019, 0.990571141242981, 0.9889547228813171, 0.9878771305084229, 0.9916487336158752, 0.993534505367279, 0.9851831793785095], 'val_loss': [0.7250897884368896, 0.7239964008331299, 0.7163279056549072, 0.708709180355072, 0.6979697942733765, 0.684120237827301, 0.6746525168418884, 0.6543319821357727, 0.6501494646072388, 0.6171751618385315, 0.5916973352432251, 0.560533881187439, 0.5560526251792908, 0.5234607458114624, 0.5147606730461121, 0.5241379141807556, 0.5410775542259216, 0.5251936316490173, 0.5706368088722229, 0.620132327079773, 0.6856136322021484, 0.7461658716201782, 0.7525009512901306, 0.8243786096572876, 0.6842577457427979, 0.7444139719009399, 0.6901214122772217, 0.8721109628677368, 0.9668906927108765, 0.9869751334190369, 1.1139781475067139, 0.9164848923683167, 0.9337344765663147, 1.2332340478897095, 0.9626662135124207, 1.0304739475250244, 1.1492810249328613, 1.045213222503662, 0.9335809946060181, 0.9568803310394287, 1.0363019704818726, 1.1725908517837524, 1.1846262216567993, 0.8788745999336243, 1.0567419528961182, 1.1022793054580688, 1.2111469507217407, 1.131036400794983, 0.882071316242218, 1.0145211219787598, 1.2053806781768799, 1.3566781282424927, 1.1433409452438354, 1.2310473918914795, 1.1914241313934326, 1.0144827365875244, 1.084715723991394, 1.2506637573242188, 1.267468810081482, 1.1504260301589966, 1.1474939584732056, 1.3048382997512817, 1.20232355594635, 1.3549199104309082, 1.0254857540130615, 1.042544960975647, 1.092437505722046, 1.3173744678497314, 1.175137996673584, 1.2162246704101562, 1.1930681467056274, 1.218904733657837, 1.233960509300232, 1.3233691453933716, 1.1981523036956787, 1.1913812160491943, 1.1677958965301514, 1.0461608171463013, 0.9254245162010193, 1.0318752527236938, 1.1319743394851685, 1.1211432218551636, 1.1851654052734375, 1.2376536130905151, 1.2553012371063232, 1.2922388315200806, 1.2835897207260132, 1.269096851348877, 1.313462257385254, 1.2873094081878662, 1.336043357849121, 1.3352230787277222, 1.3056254386901855, 1.2701362371444702, 1.1833866834640503, 1.2503031492233276, 1.1456727981567383, 1.3150254487991333, 1.2288604974746704, 1.2512104511260986], 'val_accuracy': [0.48491379618644714, 0.48599138855934143, 0.5258620977401733, 0.53125, 0.600215494632721, 0.6282327771186829, 0.6303879022598267, 0.6616379022598267, 0.6788793206214905, 0.6831896305084229, 0.7133620977401733, 0.7607758641242981, 0.7392241358757019, 0.7661637663841248, 0.7661637663841248, 0.7586206793785095, 0.7521551847457886, 0.764008641242981, 0.7575430870056152, 0.7650862336158752, 0.7413793206214905, 0.767241358757019, 0.7758620977401733, 0.78125, 0.7844827771186829, 0.7898706793785095, 0.7834051847457886, 0.7844827771186829, 0.7790948152542114, 0.7801724076271057, 0.774784505367279, 0.7532327771186829, 0.7790948152542114, 0.7068965435028076, 0.78125, 0.7801724076271057, 0.7726293206214905, 0.7715517282485962, 0.7758620977401733, 0.774784505367279, 0.7693965435028076, 0.7510775923728943, 0.743534505367279, 0.7769396305084229, 0.7823275923728943, 0.7844827771186829, 0.78125, 0.7790948152542114, 0.7887930870056152, 0.7887930870056152, 0.7931034564971924, 0.7790948152542114, 0.7866379022598267, 0.7726293206214905, 0.7790948152542114, 0.756465494632721, 0.7693965435028076, 0.7575430870056152, 0.7381465435028076, 0.7521551847457886, 0.7801724076271057, 0.7790948152542114, 0.7758620977401733, 0.7887930870056152, 0.75, 0.774784505367279, 0.7823275923728943, 0.7456896305084229, 0.7769396305084229, 0.7693965435028076, 0.7790948152542114, 0.7693965435028076, 0.7844827771186829, 0.7575430870056152, 0.7693965435028076, 0.7909482717514038, 0.7650862336158752, 0.7693965435028076, 0.7737069129943848, 0.7596982717514038, 0.7553879022598267, 0.7596982717514038, 0.7618534564971924, 0.7693965435028076, 0.7780172228813171, 0.7650862336158752, 0.7726293206214905, 0.7801724076271057, 0.7758620977401733, 0.774784505367279, 0.764008641242981, 0.7737069129943848, 0.764008641242981, 0.7661637663841248, 0.7618534564971924, 0.764008641242981, 0.767241358757019, 0.7607758641242981, 0.7758620977401733, 0.7273706793785095]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 54ms/step - loss: 0.4424 - accuracy: 0.8121 - val_loss: 0.7238 - val_accuracy: 0.4955\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3636 - accuracy: 0.8529 - val_loss: 0.7232 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3257 - accuracy: 0.8673 - val_loss: 0.7167 - val_accuracy: 0.5124\n","Epoch 4/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2945 - accuracy: 0.8894 - val_loss: 0.7116 - val_accuracy: 0.5147\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2606 - accuracy: 0.9021 - val_loss: 0.7045 - val_accuracy: 0.5249\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2290 - accuracy: 0.9177 - val_loss: 0.6929 - val_accuracy: 0.5486\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2038 - accuracy: 0.9284 - val_loss: 0.6776 - val_accuracy: 0.5848\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2008 - accuracy: 0.9256 - val_loss: 0.6645 - val_accuracy: 0.6143\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1850 - accuracy: 0.9372 - val_loss: 0.6468 - val_accuracy: 0.6516\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1775 - accuracy: 0.9417 - val_loss: 0.6242 - val_accuracy: 0.6640\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1626 - accuracy: 0.9479 - val_loss: 0.5928 - val_accuracy: 0.7014\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1971 - accuracy: 0.9295 - val_loss: 0.6002 - val_accuracy: 0.7025\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1495 - accuracy: 0.9533 - val_loss: 0.5515 - val_accuracy: 0.7466\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1304 - accuracy: 0.9643 - val_loss: 0.5367 - val_accuracy: 0.7443\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1192 - accuracy: 0.9666 - val_loss: 0.5407 - val_accuracy: 0.7217\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1046 - accuracy: 0.9748 - val_loss: 0.5272 - val_accuracy: 0.7500\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1352 - accuracy: 0.9598 - val_loss: 0.5271 - val_accuracy: 0.7319\n","Epoch 18/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1083 - accuracy: 0.9717 - val_loss: 0.5282 - val_accuracy: 0.7794\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1173 - accuracy: 0.9658 - val_loss: 0.7246 - val_accuracy: 0.7251\n","Epoch 20/100\n","28/28 [==============================] - 1s 51ms/step - loss: 0.1424 - accuracy: 0.9559 - val_loss: 0.5053 - val_accuracy: 0.7805\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1017 - accuracy: 0.9726 - val_loss: 0.5910 - val_accuracy: 0.7794\n","Epoch 22/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0942 - accuracy: 0.9788 - val_loss: 0.5944 - val_accuracy: 0.7839\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0955 - accuracy: 0.9779 - val_loss: 0.6440 - val_accuracy: 0.7839\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1170 - accuracy: 0.9709 - val_loss: 0.7185 - val_accuracy: 0.7557\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0882 - accuracy: 0.9816 - val_loss: 0.6360 - val_accuracy: 0.8066\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0827 - accuracy: 0.9799 - val_loss: 0.7617 - val_accuracy: 0.7964\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0706 - accuracy: 0.9875 - val_loss: 0.9418 - val_accuracy: 0.7817\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0785 - accuracy: 0.9839 - val_loss: 0.8947 - val_accuracy: 0.8054\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1398 - accuracy: 0.9607 - val_loss: 0.7639 - val_accuracy: 0.7885\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1520 - accuracy: 0.9499 - val_loss: 0.7495 - val_accuracy: 0.7885\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1097 - accuracy: 0.9689 - val_loss: 0.7781 - val_accuracy: 0.7828\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0707 - accuracy: 0.9856 - val_loss: 0.9282 - val_accuracy: 0.7715\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0593 - accuracy: 0.9926 - val_loss: 0.9111 - val_accuracy: 0.7952\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0487 - accuracy: 0.9958 - val_loss: 1.0655 - val_accuracy: 0.7986\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0661 - accuracy: 0.9881 - val_loss: 1.0270 - val_accuracy: 0.7704\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0786 - accuracy: 0.9825 - val_loss: 1.0326 - val_accuracy: 0.7828\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0840 - accuracy: 0.9785 - val_loss: 1.0186 - val_accuracy: 0.7873\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 0.9859 - val_loss: 0.9011 - val_accuracy: 0.7964\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0594 - accuracy: 0.9907 - val_loss: 1.0831 - val_accuracy: 0.7941\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0761 - accuracy: 0.9847 - val_loss: 1.0982 - val_accuracy: 0.7523\n","Epoch 41/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0755 - accuracy: 0.9808 - val_loss: 0.9264 - val_accuracy: 0.8122\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0657 - accuracy: 0.9847 - val_loss: 1.0252 - val_accuracy: 0.7952\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0516 - accuracy: 0.9946 - val_loss: 1.0887 - val_accuracy: 0.7794\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0477 - accuracy: 0.9946 - val_loss: 1.0912 - val_accuracy: 0.7828\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0473 - accuracy: 0.9935 - val_loss: 1.1248 - val_accuracy: 0.7624\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0724 - accuracy: 0.9830 - val_loss: 0.9634 - val_accuracy: 0.7704\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0764 - accuracy: 0.9825 - val_loss: 0.9901 - val_accuracy: 0.7805\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0556 - accuracy: 0.9907 - val_loss: 1.0347 - val_accuracy: 0.7783\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0492 - accuracy: 0.9932 - val_loss: 1.2181 - val_accuracy: 0.7839\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0444 - accuracy: 0.9955 - val_loss: 1.1395 - val_accuracy: 0.7919\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0387 - accuracy: 0.9977 - val_loss: 1.1162 - val_accuracy: 0.7975\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9972 - val_loss: 1.1523 - val_accuracy: 0.7907\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0370 - accuracy: 0.9969 - val_loss: 1.1597 - val_accuracy: 0.7952\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0349 - accuracy: 0.9986 - val_loss: 1.1901 - val_accuracy: 0.7930\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0374 - accuracy: 0.9980 - val_loss: 1.1882 - val_accuracy: 0.8020\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0375 - accuracy: 0.9975 - val_loss: 1.2929 - val_accuracy: 0.7726\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0505 - accuracy: 0.9909 - val_loss: 1.1916 - val_accuracy: 0.7738\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0699 - accuracy: 0.9850 - val_loss: 1.3252 - val_accuracy: 0.7681\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.9825 - val_loss: 1.0005 - val_accuracy: 0.7692\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1090 - accuracy: 0.9689 - val_loss: 0.9216 - val_accuracy: 0.7545\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0729 - accuracy: 0.9825 - val_loss: 1.0540 - val_accuracy: 0.7817\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0545 - accuracy: 0.9895 - val_loss: 1.0348 - val_accuracy: 0.7670\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0522 - accuracy: 0.9884 - val_loss: 0.9911 - val_accuracy: 0.7986\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0500 - accuracy: 0.9912 - val_loss: 1.1780 - val_accuracy: 0.7568\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0481 - accuracy: 0.9926 - val_loss: 1.0451 - val_accuracy: 0.7851\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0439 - accuracy: 0.9946 - val_loss: 1.4192 - val_accuracy: 0.7602\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0443 - accuracy: 0.9938 - val_loss: 1.0872 - val_accuracy: 0.7941\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0412 - accuracy: 0.9952 - val_loss: 1.1473 - val_accuracy: 0.7658\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0432 - accuracy: 0.9938 - val_loss: 1.2763 - val_accuracy: 0.7817\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1078 - accuracy: 0.9700 - val_loss: 0.9964 - val_accuracy: 0.7647\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9850 - val_loss: 0.9904 - val_accuracy: 0.7919\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0462 - accuracy: 0.9929 - val_loss: 1.1238 - val_accuracy: 0.7738\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0390 - accuracy: 0.9960 - val_loss: 1.1036 - val_accuracy: 0.7828\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0352 - accuracy: 0.9969 - val_loss: 1.2407 - val_accuracy: 0.7658\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0383 - accuracy: 0.9949 - val_loss: 1.1353 - val_accuracy: 0.7862\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0405 - accuracy: 0.9941 - val_loss: 1.2349 - val_accuracy: 0.7828\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0789 - accuracy: 0.9810 - val_loss: 0.9529 - val_accuracy: 0.7885\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0740 - accuracy: 0.9796 - val_loss: 0.9162 - val_accuracy: 0.7952\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0426 - accuracy: 0.9941 - val_loss: 0.9436 - val_accuracy: 0.8043\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0356 - accuracy: 0.9963 - val_loss: 1.0912 - val_accuracy: 0.7805\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0302 - accuracy: 0.9983 - val_loss: 1.1733 - val_accuracy: 0.7862\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0283 - accuracy: 0.9992 - val_loss: 1.1053 - val_accuracy: 0.7952\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0299 - accuracy: 0.9986 - val_loss: 1.1212 - val_accuracy: 0.8032\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0286 - accuracy: 0.9989 - val_loss: 1.0368 - val_accuracy: 0.7941\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9986 - val_loss: 1.0726 - val_accuracy: 0.8020\n","Epoch 86/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0567 - accuracy: 0.9870 - val_loss: 1.4492 - val_accuracy: 0.7387\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1246 - accuracy: 0.9610 - val_loss: 0.7538 - val_accuracy: 0.7919\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0540 - accuracy: 0.9895 - val_loss: 0.9402 - val_accuracy: 0.7851\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9983 - val_loss: 1.0419 - val_accuracy: 0.7896\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0295 - accuracy: 0.9986 - val_loss: 1.0371 - val_accuracy: 0.7941\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9992 - val_loss: 1.0572 - val_accuracy: 0.7930\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0278 - accuracy: 0.9986 - val_loss: 1.0875 - val_accuracy: 0.7817\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9992 - val_loss: 1.1173 - val_accuracy: 0.7930\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0264 - accuracy: 0.9989 - val_loss: 1.1652 - val_accuracy: 0.7930\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.7907\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.1710 - val_accuracy: 0.7930\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.1470 - val_accuracy: 0.7941\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.7930\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.1208 - val_accuracy: 0.7885\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.7885\n","{'loss': [0.44243884086608887, 0.36360591650009155, 0.3256683349609375, 0.29452770948410034, 0.26056569814682007, 0.22898827493190765, 0.20384284853935242, 0.20083676278591156, 0.18503186106681824, 0.17750759422779083, 0.16255010664463043, 0.19708219170570374, 0.14947664737701416, 0.13043123483657837, 0.1191997155547142, 0.10457717627286911, 0.1351637989282608, 0.10829635709524155, 0.11728985607624054, 0.1424269676208496, 0.10171931236982346, 0.09415976703166962, 0.09552941471338272, 0.117026187479496, 0.08821778744459152, 0.08272538334131241, 0.07057788968086243, 0.07845134288072586, 0.13983754813671112, 0.15204967558383942, 0.10974344611167908, 0.07067873328924179, 0.05928240343928337, 0.04871667921543121, 0.0660734623670578, 0.07855779677629471, 0.08396308869123459, 0.07391377538442612, 0.05943603441119194, 0.0761401504278183, 0.07549376785755157, 0.06572471559047699, 0.051624707877635956, 0.04765971004962921, 0.047302570194005966, 0.07237821072340012, 0.07637054473161697, 0.0555742122232914, 0.04918134957551956, 0.044432930648326874, 0.038713980466127396, 0.03702392801642418, 0.03701876476407051, 0.03487180173397064, 0.037368740886449814, 0.03749586641788483, 0.050452154129743576, 0.06992289423942566, 0.07594289630651474, 0.10900980234146118, 0.0728810653090477, 0.05445626750588417, 0.05221275985240936, 0.05003140866756439, 0.04806862771511078, 0.04392985254526138, 0.04431754723191261, 0.04121950641274452, 0.04315207898616791, 0.10781411826610565, 0.06801865249872208, 0.04616209492087364, 0.03900625929236412, 0.0351736955344677, 0.0383363701403141, 0.04045805335044861, 0.07888022810220718, 0.07399951666593552, 0.04262608289718628, 0.035565007477998734, 0.030210908502340317, 0.028331425040960312, 0.02986636757850647, 0.028637612238526344, 0.02799122966825962, 0.056748829782009125, 0.12462581694126129, 0.053972091525793076, 0.03166045621037483, 0.02952124923467636, 0.027111848816275597, 0.027775969356298447, 0.025658750906586647, 0.02640542760491371, 0.023342756554484367, 0.02287614531815052, 0.022502001374959946, 0.022185320034623146, 0.02192181721329689, 0.02161576598882675], 'accuracy': [0.8121109008789062, 0.8528579473495483, 0.8672891855239868, 0.8893604874610901, 0.9020939469337463, 0.9176570177078247, 0.92840975522995, 0.9255800843238831, 0.9371816515922546, 0.9417091012001038, 0.9479343295097351, 0.9295415878295898, 0.9533106684684753, 0.9643463492393494, 0.9666100740432739, 0.974816083908081, 0.9598188996315002, 0.9717034697532654, 0.9657611846923828, 0.9558573961257935, 0.9725523591041565, 0.9787775874137878, 0.9779286980628967, 0.9708545804023743, 0.9816072583198547, 0.9799094796180725, 0.9875495433807373, 0.9838709831237793, 0.9606677889823914, 0.9499151110649109, 0.9688737988471985, 0.9855687618255615, 0.992642879486084, 0.9957554936408997, 0.9881154298782349, 0.9824561476707458, 0.9784946441650391, 0.9858517050743103, 0.990662157535553, 0.9847198724746704, 0.9807583689689636, 0.9847198724746704, 0.9946236610412598, 0.9946236610412598, 0.9934917688369751, 0.9830220937728882, 0.9824561476707458, 0.990662157535553, 0.9932088255882263, 0.9954725503921509, 0.9977362751960754, 0.9971703290939331, 0.9968873858451843, 0.9985851645469666, 0.9980192184448242, 0.9974533319473267, 0.9909451007843018, 0.9850028157234192, 0.9824561476707458, 0.9688737988471985, 0.9824561476707458, 0.9895302653312683, 0.9883984327316284, 0.9912280440330505, 0.992642879486084, 0.9946236610412598, 0.9937747716903687, 0.9951896071434021, 0.9937747716903687, 0.9700056314468384, 0.9850028157234192, 0.9929258823394775, 0.9960384964942932, 0.9968873858451843, 0.9949066042900085, 0.9940577149391174, 0.9810413122177124, 0.979626476764679, 0.9940577149391174, 0.996321439743042, 0.9983022212982178, 0.9991511106491089, 0.9985851645469666, 0.9988681674003601, 0.9985851645469666, 0.986983597278595, 0.9609507918357849, 0.9895302653312683, 0.9983022212982178, 0.9985851645469666, 0.9991511106491089, 0.9985851645469666, 0.9991511106491089, 0.9988681674003601, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.72380530834198, 0.7231857776641846, 0.7167247533798218, 0.7115887403488159, 0.7045027017593384, 0.6928594708442688, 0.6775926947593689, 0.664489209651947, 0.6468060612678528, 0.6242266297340393, 0.5928201675415039, 0.6002310514450073, 0.5515146851539612, 0.5366899967193604, 0.5406985878944397, 0.5271788239479065, 0.5270569324493408, 0.5282098650932312, 0.7245926856994629, 0.5053240656852722, 0.5909666419029236, 0.5943824052810669, 0.6439766883850098, 0.7184953093528748, 0.6359823942184448, 0.7617116570472717, 0.9418463110923767, 0.894748330116272, 0.7638745307922363, 0.7495141625404358, 0.7781107425689697, 0.9282447099685669, 0.9110564589500427, 1.0654851198196411, 1.027004599571228, 1.0325756072998047, 1.0186219215393066, 0.9010993838310242, 1.0831316709518433, 1.098153829574585, 0.9264227151870728, 1.02521812915802, 1.088733196258545, 1.0912171602249146, 1.1248455047607422, 0.9634080529212952, 0.9900813698768616, 1.0347256660461426, 1.2181309461593628, 1.1394883394241333, 1.1162257194519043, 1.1523314714431763, 1.1596524715423584, 1.190085530281067, 1.1881791353225708, 1.2929219007492065, 1.1915853023529053, 1.3252209424972534, 1.0005145072937012, 0.9216495752334595, 1.0539592504501343, 1.0348151922225952, 0.9911460876464844, 1.1780306100845337, 1.045098066329956, 1.4191991090774536, 1.0871543884277344, 1.1473298072814941, 1.2762842178344727, 0.9963812232017517, 0.9904053211212158, 1.1237637996673584, 1.1035925149917603, 1.2406913042068481, 1.1352664232254028, 1.2349315881729126, 0.9528952240943909, 0.9162108898162842, 0.9436008334159851, 1.09117591381073, 1.1732871532440186, 1.1053282022476196, 1.1212081909179688, 1.0367740392684937, 1.0726120471954346, 1.449241280555725, 0.7537919282913208, 0.9402281045913696, 1.0418999195098877, 1.0371445417404175, 1.0572047233581543, 1.0874829292297363, 1.1173334121704102, 1.1652154922485352, 1.1372424364089966, 1.1709843873977661, 1.1469838619232178, 1.1270253658294678, 1.1207897663116455, 1.1130927801132202], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.5124434232711792, 0.5147058963775635, 0.5248869061470032, 0.5486425161361694, 0.5848416090011597, 0.6142534017562866, 0.651583731174469, 0.6640271544456482, 0.7013574838638306, 0.7024886608123779, 0.7466063499450684, 0.7443438768386841, 0.7217194437980652, 0.75, 0.7319004535675049, 0.779411792755127, 0.7251130938529968, 0.7805429697036743, 0.779411792755127, 0.7839366793632507, 0.7839366793632507, 0.7556561231613159, 0.8065611124038696, 0.7963801026344299, 0.7816742062568665, 0.8054298758506775, 0.7884615659713745, 0.7884615659713745, 0.7828054428100586, 0.7714931964874268, 0.7952488660812378, 0.7986425161361694, 0.7703620195388794, 0.7828054428100586, 0.7873303294181824, 0.7963801026344299, 0.7941176295280457, 0.7522624731063843, 0.8122171759605408, 0.7952488660812378, 0.779411792755127, 0.7828054428100586, 0.7624434232711792, 0.7703620195388794, 0.7805429697036743, 0.7782805562019348, 0.7839366793632507, 0.7918552160263062, 0.7975113391876221, 0.790723979473114, 0.7952488660812378, 0.7929864525794983, 0.8020362257957458, 0.7726244330406189, 0.773755669593811, 0.7680995464324951, 0.7692307829856873, 0.7545248866081238, 0.7816742062568665, 0.766968309879303, 0.7986425161361694, 0.7567873597145081, 0.7850678563117981, 0.7601810097694397, 0.7941176295280457, 0.7658371329307556, 0.7816742062568665, 0.7647058963775635, 0.7918552160263062, 0.773755669593811, 0.7828054428100586, 0.7658371329307556, 0.7861990928649902, 0.7828054428100586, 0.7884615659713745, 0.7952488660812378, 0.8042986392974854, 0.7805429697036743, 0.7861990928649902, 0.7952488660812378, 0.8031674027442932, 0.7941176295280457, 0.8020362257957458, 0.7386877536773682, 0.7918552160263062, 0.7850678563117981, 0.7895927429199219, 0.7941176295280457, 0.7929864525794983, 0.7816742062568665, 0.7929864525794983, 0.7929864525794983, 0.790723979473114, 0.7929864525794983, 0.7941176295280457, 0.7929864525794983, 0.7884615659713745, 0.7884615659713745]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.4386 - accuracy: 0.8117"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 51ms/step - loss: 0.4369 - accuracy: 0.8124 - val_loss: 0.7242 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3654 - accuracy: 0.8481 - val_loss: 0.7226 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3210 - accuracy: 0.8687 - val_loss: 0.7199 - val_accuracy: 0.4938\n","Epoch 4/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.2856 - accuracy: 0.8925 - val_loss: 0.7113 - val_accuracy: 0.5165\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2893 - accuracy: 0.8853 - val_loss: 0.7018 - val_accuracy: 0.5486\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2514 - accuracy: 0.9078 - val_loss: 0.6968 - val_accuracy: 0.5217\n","Epoch 7/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2503 - accuracy: 0.9080 - val_loss: 0.6670 - val_accuracy: 0.7273\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2544 - accuracy: 0.9044 - val_loss: 0.6505 - val_accuracy: 0.7107\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1979 - accuracy: 0.9323 - val_loss: 0.6487 - val_accuracy: 0.6229\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1830 - accuracy: 0.9382 - val_loss: 0.6062 - val_accuracy: 0.7159\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1752 - accuracy: 0.9398 - val_loss: 0.5803 - val_accuracy: 0.7355\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1964 - accuracy: 0.9320 - val_loss: 0.5721 - val_accuracy: 0.7283\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1680 - accuracy: 0.9452 - val_loss: 0.5397 - val_accuracy: 0.7407\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.5631 - val_accuracy: 0.6994\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1804 - accuracy: 0.9403 - val_loss: 0.5606 - val_accuracy: 0.7118\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1507 - accuracy: 0.9561 - val_loss: 0.5438 - val_accuracy: 0.7521\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1580 - accuracy: 0.9481 - val_loss: 0.5501 - val_accuracy: 0.7180\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1386 - accuracy: 0.9563 - val_loss: 0.5855 - val_accuracy: 0.7407\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1643 - accuracy: 0.9439 - val_loss: 0.5852 - val_accuracy: 0.7624\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1163 - accuracy: 0.9659 - val_loss: 0.6555 - val_accuracy: 0.7603\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1023 - accuracy: 0.9744 - val_loss: 0.7270 - val_accuracy: 0.7748\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1272 - accuracy: 0.9623 - val_loss: 0.7454 - val_accuracy: 0.7345\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1589 - accuracy: 0.9463 - val_loss: 0.7535 - val_accuracy: 0.7448\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1117 - accuracy: 0.9690 - val_loss: 0.7765 - val_accuracy: 0.7717\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0984 - accuracy: 0.9767 - val_loss: 0.8792 - val_accuracy: 0.7500\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0893 - accuracy: 0.9744 - val_loss: 1.0341 - val_accuracy: 0.7407\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0970 - accuracy: 0.9760 - val_loss: 1.0170 - val_accuracy: 0.7510\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0872 - accuracy: 0.9796 - val_loss: 1.0478 - val_accuracy: 0.7634\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0955 - accuracy: 0.9736 - val_loss: 1.0669 - val_accuracy: 0.7614\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1313 - accuracy: 0.9620 - val_loss: 0.8855 - val_accuracy: 0.7593\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1176 - accuracy: 0.9649 - val_loss: 0.9554 - val_accuracy: 0.7572\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0793 - accuracy: 0.9835 - val_loss: 1.1482 - val_accuracy: 0.7531\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0917 - accuracy: 0.9762 - val_loss: 1.3162 - val_accuracy: 0.7459\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1178 - accuracy: 0.9643 - val_loss: 1.0266 - val_accuracy: 0.7624\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0773 - accuracy: 0.9837 - val_loss: 1.0990 - val_accuracy: 0.7583\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0728 - accuracy: 0.9837 - val_loss: 1.1914 - val_accuracy: 0.7459\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0926 - accuracy: 0.9765 - val_loss: 1.2883 - val_accuracy: 0.7428\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1074 - accuracy: 0.9703 - val_loss: 0.9515 - val_accuracy: 0.7707\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0785 - accuracy: 0.9837 - val_loss: 1.1583 - val_accuracy: 0.7614\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0659 - accuracy: 0.9879 - val_loss: 1.1457 - val_accuracy: 0.7655\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0618 - accuracy: 0.9902 - val_loss: 1.1704 - val_accuracy: 0.7593\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.9855 - val_loss: 1.1749 - val_accuracy: 0.7634\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0808 - accuracy: 0.9798 - val_loss: 1.2770 - val_accuracy: 0.7314\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 0.9674 - val_loss: 1.1959 - val_accuracy: 0.7324\n","Epoch 45/100\n","31/31 [==============================] - 2s 58ms/step - loss: 0.1365 - accuracy: 0.9574 - val_loss: 0.9776 - val_accuracy: 0.7779\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0678 - accuracy: 0.9866 - val_loss: 1.3587 - val_accuracy: 0.7459\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0756 - accuracy: 0.9817 - val_loss: 1.0827 - val_accuracy: 0.7676\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0564 - accuracy: 0.9917 - val_loss: 1.2543 - val_accuracy: 0.7510\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0569 - accuracy: 0.9899 - val_loss: 1.2161 - val_accuracy: 0.7386\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0578 - accuracy: 0.9889 - val_loss: 1.1628 - val_accuracy: 0.7603\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0556 - accuracy: 0.9897 - val_loss: 1.2897 - val_accuracy: 0.7727\n","Epoch 52/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0580 - accuracy: 0.9884 - val_loss: 1.1534 - val_accuracy: 0.7872\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0530 - accuracy: 0.9891 - val_loss: 1.2333 - val_accuracy: 0.7593\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0529 - accuracy: 0.9912 - val_loss: 1.1990 - val_accuracy: 0.7727\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0631 - accuracy: 0.9850 - val_loss: 1.2673 - val_accuracy: 0.7614\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0883 - accuracy: 0.9775 - val_loss: 1.0749 - val_accuracy: 0.7634\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0817 - accuracy: 0.9760 - val_loss: 1.0900 - val_accuracy: 0.7562\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0571 - accuracy: 0.9891 - val_loss: 1.2047 - val_accuracy: 0.7479\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0565 - accuracy: 0.9904 - val_loss: 1.1663 - val_accuracy: 0.7676\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0496 - accuracy: 0.9917 - val_loss: 1.3649 - val_accuracy: 0.7645\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0569 - accuracy: 0.9884 - val_loss: 1.3774 - val_accuracy: 0.7397\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0841 - accuracy: 0.9770 - val_loss: 1.1205 - val_accuracy: 0.7407\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0602 - accuracy: 0.9881 - val_loss: 1.2203 - val_accuracy: 0.7614\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0499 - accuracy: 0.9915 - val_loss: 1.4042 - val_accuracy: 0.7490\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0508 - accuracy: 0.9902 - val_loss: 1.4955 - val_accuracy: 0.7521\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0544 - accuracy: 0.9879 - val_loss: 1.2015 - val_accuracy: 0.7572\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0496 - accuracy: 0.9922 - val_loss: 1.4231 - val_accuracy: 0.7107\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0562 - accuracy: 0.9866 - val_loss: 1.3361 - val_accuracy: 0.7417\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1152 - accuracy: 0.9638 - val_loss: 0.9892 - val_accuracy: 0.7614\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0588 - accuracy: 0.9868 - val_loss: 1.1688 - val_accuracy: 0.7593\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0421 - accuracy: 0.9938 - val_loss: 1.2675 - val_accuracy: 0.7428\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0352 - accuracy: 0.9974 - val_loss: 1.2785 - val_accuracy: 0.7655\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0435 - accuracy: 0.9917 - val_loss: 1.2980 - val_accuracy: 0.7583\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0371 - accuracy: 0.9969 - val_loss: 1.3082 - val_accuracy: 0.7459\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0392 - accuracy: 0.9948 - val_loss: 1.3615 - val_accuracy: 0.7521\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0332 - accuracy: 0.9972 - val_loss: 1.3154 - val_accuracy: 0.7572\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9977 - val_loss: 1.3672 - val_accuracy: 0.7603\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0294 - accuracy: 0.9992 - val_loss: 1.8726 - val_accuracy: 0.7293\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0372 - accuracy: 0.9943 - val_loss: 1.3764 - val_accuracy: 0.7479\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0363 - accuracy: 0.9964 - val_loss: 1.3198 - val_accuracy: 0.7655\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0769 - accuracy: 0.9796 - val_loss: 1.2218 - val_accuracy: 0.7562\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1446 - accuracy: 0.9519 - val_loss: 0.8467 - val_accuracy: 0.7614\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0688 - accuracy: 0.9814 - val_loss: 1.1727 - val_accuracy: 0.7407\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0750 - accuracy: 0.9793 - val_loss: 1.4595 - val_accuracy: 0.7252\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0659 - accuracy: 0.9842 - val_loss: 1.1346 - val_accuracy: 0.7459\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0636 - accuracy: 0.9850 - val_loss: 1.0176 - val_accuracy: 0.7469\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0368 - accuracy: 0.9959 - val_loss: 1.2281 - val_accuracy: 0.7521\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0302 - accuracy: 0.9979 - val_loss: 1.3230 - val_accuracy: 0.7696\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0342 - accuracy: 0.9953 - val_loss: 1.4321 - val_accuracy: 0.7469\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0285 - accuracy: 0.9979 - val_loss: 1.3600 - val_accuracy: 0.7583\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0264 - accuracy: 0.9987 - val_loss: 1.3288 - val_accuracy: 0.7583\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9992 - val_loss: 1.4224 - val_accuracy: 0.7572\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0247 - accuracy: 0.9990 - val_loss: 1.4086 - val_accuracy: 0.7521\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0233 - accuracy: 0.9995 - val_loss: 1.3523 - val_accuracy: 0.7727\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9992 - val_loss: 1.3539 - val_accuracy: 0.7572\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.3537 - val_accuracy: 0.7562\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.3556 - val_accuracy: 0.7603\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.7583\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.7593\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.3337 - val_accuracy: 0.7531\n","{'loss': [0.43694156408309937, 0.3653568625450134, 0.32095611095428467, 0.285620778799057, 0.28926852345466614, 0.2514115869998932, 0.2502884864807129, 0.2543553411960602, 0.1978546530008316, 0.18298667669296265, 0.17515255510807037, 0.19638985395431519, 0.1680445522069931, 0.1447535753250122, 0.1803540289402008, 0.15074987709522247, 0.15800030529499054, 0.1386411190032959, 0.16432057321071625, 0.11632541567087173, 0.1023034155368805, 0.12715831398963928, 0.15890662372112274, 0.1116778552532196, 0.0983685702085495, 0.08929473906755447, 0.09699197858572006, 0.08718612045049667, 0.09552779793739319, 0.13127756118774414, 0.11760924011468887, 0.07927471399307251, 0.09171949326992035, 0.11778537184000015, 0.07725224643945694, 0.07283349335193634, 0.09264221042394638, 0.10744699835777283, 0.07854650169610977, 0.06592055410146713, 0.06179434433579445, 0.07155613601207733, 0.08079392462968826, 0.11196687817573547, 0.13645879924297333, 0.06778240203857422, 0.07562093436717987, 0.05642908439040184, 0.05692166090011597, 0.05775793269276619, 0.055632490664720535, 0.058008696883916855, 0.05296012759208679, 0.05288233608007431, 0.06307248026132584, 0.0882573127746582, 0.08165357261896133, 0.0571243092417717, 0.05654139444231987, 0.049636732786893845, 0.056935444474220276, 0.08411594480276108, 0.060191810131073, 0.04987214878201485, 0.05076075345277786, 0.05444461107254028, 0.04961362108588219, 0.05620904266834259, 0.115224190056324, 0.05878458172082901, 0.042065806686878204, 0.035228852182626724, 0.043529998511075974, 0.037120718508958817, 0.03917330503463745, 0.03315431997179985, 0.031718526035547256, 0.029422597959637642, 0.03715287148952484, 0.036298967897892, 0.07690032571554184, 0.14463506639003754, 0.06884657591581345, 0.07495436817407608, 0.0658624991774559, 0.06364593654870987, 0.036829449236392975, 0.030236052349209785, 0.03419553115963936, 0.028507815673947334, 0.026407549157738686, 0.024641331285238266, 0.024733232334256172, 0.023283200338482857, 0.023540159687399864, 0.02220974490046501, 0.02176058664917946, 0.0212432648986578, 0.020876392722129822, 0.02075021341443062], 'accuracy': [0.8124030828475952, 0.8480620384216309, 0.868733823299408, 0.89250648021698, 0.8852713108062744, 0.9077519178390503, 0.9080103635787964, 0.9043927788734436, 0.9322997331619263, 0.9382429122924805, 0.9397932887077332, 0.932041347026825, 0.9452196359634399, 0.9552971720695496, 0.9403100609779358, 0.9560723304748535, 0.948062002658844, 0.9563307762145996, 0.9439276456832886, 0.9658914804458618, 0.974418580532074, 0.962273895740509, 0.94625324010849, 0.9689922332763672, 0.9767441749572754, 0.974418580532074, 0.9759690165519714, 0.9795865416526794, 0.97364342212677, 0.9620155096054077, 0.9648578763008118, 0.9834625124931335, 0.9762274026870728, 0.9643411040306091, 0.9837209582328796, 0.9837209582328796, 0.9764857888221741, 0.9702842235565186, 0.9837209582328796, 0.9878553152084351, 0.9901808500289917, 0.9855297207832336, 0.9798449873924255, 0.9674418568611145, 0.9573643207550049, 0.9865633249282837, 0.9816537499427795, 0.9917312860488892, 0.9899224638938904, 0.9888888597488403, 0.9896640777587891, 0.9883720874786377, 0.9891473054885864, 0.9912144541740417, 0.985012948513031, 0.9775193929672241, 0.9759690165519714, 0.9891473054885864, 0.9904392957687378, 0.9917312860488892, 0.9883720874786377, 0.9770025610923767, 0.9881137013435364, 0.9914728403091431, 0.9901808500289917, 0.9878553152084351, 0.9922480583190918, 0.9865633249282837, 0.9638242721557617, 0.986821711063385, 0.9937984347343445, 0.9974160194396973, 0.9917312860488892, 0.9968992471694946, 0.9948320388793945, 0.997157633304596, 0.9976744055747986, 0.9992247819900513, 0.9943152666091919, 0.9963824152946472, 0.9795865416526794, 0.9519379734992981, 0.9813953638076782, 0.9793281555175781, 0.9842377305030823, 0.985012948513031, 0.9958656430244446, 0.9979327917098999, 0.9953488111495972, 0.9979327917098999, 0.9987080097198486, 0.9992247819900513, 0.99896639585495, 0.9994832277297974, 0.9992247819900513, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.724247395992279, 0.7225902676582336, 0.7199257016181946, 0.711283802986145, 0.701827883720398, 0.6968079805374146, 0.666994571685791, 0.6504912972450256, 0.6486672759056091, 0.606223464012146, 0.5803343653678894, 0.5720999240875244, 0.5396561622619629, 0.563120424747467, 0.5605885982513428, 0.5438068509101868, 0.5501290559768677, 0.5854644179344177, 0.585191547870636, 0.6554995179176331, 0.7270106077194214, 0.7453553676605225, 0.753483235836029, 0.7765321135520935, 0.8791595697402954, 1.0341267585754395, 1.016989827156067, 1.0478332042694092, 1.0668514966964722, 0.8855252265930176, 0.9554402828216553, 1.1481667757034302, 1.31615149974823, 1.026556372642517, 1.0990252494812012, 1.1913819313049316, 1.2883262634277344, 0.9515385627746582, 1.1582856178283691, 1.1457313299179077, 1.1704413890838623, 1.1749356985092163, 1.2770438194274902, 1.1958906650543213, 0.9775983095169067, 1.3587087392807007, 1.082713007926941, 1.2542603015899658, 1.2161426544189453, 1.162803053855896, 1.289689302444458, 1.15337336063385, 1.2332671880722046, 1.1989750862121582, 1.2672666311264038, 1.0748800039291382, 1.0899608135223389, 1.204667329788208, 1.1662702560424805, 1.3649423122406006, 1.377350091934204, 1.1205451488494873, 1.220302700996399, 1.404154658317566, 1.4954880475997925, 1.2015490531921387, 1.423081874847412, 1.3361330032348633, 0.989230215549469, 1.1687967777252197, 1.2675246000289917, 1.278507113456726, 1.2979737520217896, 1.3082048892974854, 1.3614610433578491, 1.3153533935546875, 1.3671523332595825, 1.8725720643997192, 1.3763571977615356, 1.3197885751724243, 1.2218036651611328, 0.8466587066650391, 1.1726568937301636, 1.4595186710357666, 1.1346112489700317, 1.0176451206207275, 1.2280665636062622, 1.3230098485946655, 1.4321372509002686, 1.3599722385406494, 1.3287698030471802, 1.4223902225494385, 1.408586025238037, 1.3523123264312744, 1.353939175605774, 1.3536938428878784, 1.355605959892273, 1.3571176528930664, 1.3468667268753052, 1.333683967590332], 'val_accuracy': [0.48553720116615295, 0.4876033067703247, 0.49380165338516235, 0.5165289044380188, 0.5485537052154541, 0.5216942429542542, 0.7272727489471436, 0.71074378490448, 0.6229338645935059, 0.7159090638160706, 0.7355371713638306, 0.7283057570457458, 0.7407024502754211, 0.6993801593780518, 0.711776852607727, 0.7520661354064941, 0.7179751992225647, 0.7407024502754211, 0.7623966932296753, 0.7603305578231812, 0.7747933864593506, 0.7345041036605835, 0.7448347210884094, 0.7716942429542542, 0.75, 0.7407024502754211, 0.7510330677032471, 0.7634297609329224, 0.7613636255264282, 0.7592975497245789, 0.7572314143180847, 0.7530992031097412, 0.7458677887916565, 0.7623966932296753, 0.7582644820213318, 0.7458677887916565, 0.7427685856819153, 0.7706611752510071, 0.7613636255264282, 0.7654958963394165, 0.7592975497245789, 0.7634297609329224, 0.7314049601554871, 0.7324380278587341, 0.7778925895690918, 0.7458677887916565, 0.7675619721412659, 0.7510330677032471, 0.7386363744735718, 0.7603305578231812, 0.7727272510528564, 0.7871900796890259, 0.7592975497245789, 0.7727272510528564, 0.7613636255264282, 0.7634297609329224, 0.7561983466148376, 0.7479338645935059, 0.7675619721412659, 0.7644628286361694, 0.7396694421768188, 0.7407024502754211, 0.7613636255264282, 0.7489669322967529, 0.7520661354064941, 0.7572314143180847, 0.71074378490448, 0.7417355179786682, 0.7613636255264282, 0.7592975497245789, 0.7427685856819153, 0.7654958963394165, 0.7582644820213318, 0.7458677887916565, 0.7520661354064941, 0.7572314143180847, 0.7603305578231812, 0.7293388247489929, 0.7479338645935059, 0.7654958963394165, 0.7561983466148376, 0.7613636255264282, 0.7407024502754211, 0.7252066135406494, 0.7458677887916565, 0.7469007968902588, 0.7520661354064941, 0.76962810754776, 0.7469007968902588, 0.7582644820213318, 0.7582644820213318, 0.7572314143180847, 0.7520661354064941, 0.7727272510528564, 0.7572314143180847, 0.7561983466148376, 0.7603305578231812, 0.7582644820213318, 0.7592975497245789, 0.7530992031097412]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9394"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 52ms/step - loss: 0.1850 - accuracy: 0.9394 - val_loss: 0.7108 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0822 - accuracy: 0.9793 - val_loss: 0.6965 - val_accuracy: 0.5043\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0558 - accuracy: 0.9871 - val_loss: 0.6836 - val_accuracy: 0.5539\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0495 - accuracy: 0.9914 - val_loss: 0.6610 - val_accuracy: 0.6412\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0411 - accuracy: 0.9935 - val_loss: 0.6470 - val_accuracy: 0.6121\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0911 - accuracy: 0.9720 - val_loss: 0.6396 - val_accuracy: 0.5808\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1021 - accuracy: 0.9658 - val_loss: 0.6317 - val_accuracy: 0.6875\n","Epoch 8/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0522 - accuracy: 0.9898 - val_loss: 0.5828 - val_accuracy: 0.7360\n","Epoch 9/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0393 - accuracy: 0.9938 - val_loss: 0.5402 - val_accuracy: 0.7619\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9946 - val_loss: 0.5134 - val_accuracy: 0.7532\n","Epoch 11/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0426 - accuracy: 0.9914 - val_loss: 0.4891 - val_accuracy: 0.7737\n","Epoch 12/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0430 - accuracy: 0.9911 - val_loss: 0.4666 - val_accuracy: 0.7780\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9895 - val_loss: 0.4698 - val_accuracy: 0.7748\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0484 - accuracy: 0.9876 - val_loss: 0.4696 - val_accuracy: 0.7737\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0529 - accuracy: 0.9884 - val_loss: 0.4913 - val_accuracy: 0.7586\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0583 - accuracy: 0.9841 - val_loss: 0.4619 - val_accuracy: 0.8017\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0808 - accuracy: 0.9771 - val_loss: 0.4780 - val_accuracy: 0.7726\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0874 - accuracy: 0.9739 - val_loss: 0.4677 - val_accuracy: 0.8017\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0382 - accuracy: 0.9954 - val_loss: 0.5268 - val_accuracy: 0.8179\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0270 - accuracy: 0.9987 - val_loss: 0.5879 - val_accuracy: 0.8211\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0327 - accuracy: 0.9952 - val_loss: 0.5698 - val_accuracy: 0.8287\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0532 - accuracy: 0.9868 - val_loss: 0.6404 - val_accuracy: 0.8028\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0653 - accuracy: 0.9836 - val_loss: 0.5395 - val_accuracy: 0.8233\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0440 - accuracy: 0.9908 - val_loss: 0.6320 - val_accuracy: 0.8157\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0431 - accuracy: 0.9916 - val_loss: 0.5660 - val_accuracy: 0.8384\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0313 - accuracy: 0.9954 - val_loss: 0.6821 - val_accuracy: 0.8448\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0288 - accuracy: 0.9970 - val_loss: 0.7162 - val_accuracy: 0.8373\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9976 - val_loss: 0.7624 - val_accuracy: 0.8416\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0456 - accuracy: 0.9890 - val_loss: 0.7106 - val_accuracy: 0.8179\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 1.1141 - val_accuracy: 0.7188\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0685 - accuracy: 0.9790 - val_loss: 0.7281 - val_accuracy: 0.7942\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0473 - accuracy: 0.9884 - val_loss: 0.6507 - val_accuracy: 0.8373\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0343 - accuracy: 0.9954 - val_loss: 0.7021 - val_accuracy: 0.8405\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9970 - val_loss: 0.6808 - val_accuracy: 0.8287\n","Epoch 35/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0336 - accuracy: 0.9938 - val_loss: 0.6696 - val_accuracy: 0.8470\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0539 - accuracy: 0.9846 - val_loss: 0.7768 - val_accuracy: 0.8405\n","Epoch 37/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0449 - accuracy: 0.9900 - val_loss: 0.6489 - val_accuracy: 0.8556\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 0.9946 - val_loss: 0.6915 - val_accuracy: 0.8438\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0336 - accuracy: 0.9925 - val_loss: 0.7316 - val_accuracy: 0.8448\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0390 - accuracy: 0.9916 - val_loss: 0.7367 - val_accuracy: 0.8362\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0427 - accuracy: 0.9911 - val_loss: 0.8077 - val_accuracy: 0.8319\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0425 - accuracy: 0.9898 - val_loss: 0.7690 - val_accuracy: 0.8384\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0466 - accuracy: 0.9887 - val_loss: 0.7557 - val_accuracy: 0.8351\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0407 - accuracy: 0.9908 - val_loss: 0.9624 - val_accuracy: 0.8168\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0436 - accuracy: 0.9903 - val_loss: 0.7500 - val_accuracy: 0.8276\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9949 - val_loss: 0.7388 - val_accuracy: 0.8405\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.9943 - val_loss: 0.7540 - val_accuracy: 0.8287\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9949 - val_loss: 0.7338 - val_accuracy: 0.8351\n","Epoch 49/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0231 - accuracy: 0.9987 - val_loss: 0.6925 - val_accuracy: 0.8599\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9995 - val_loss: 0.7762 - val_accuracy: 0.8276\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9995 - val_loss: 0.7332 - val_accuracy: 0.8513\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9989 - val_loss: 0.8059 - val_accuracy: 0.8459\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9973 - val_loss: 0.7707 - val_accuracy: 0.8448\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0261 - accuracy: 0.9968 - val_loss: 0.7636 - val_accuracy: 0.8330\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9987 - val_loss: 0.7406 - val_accuracy: 0.8362\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9976 - val_loss: 0.8971 - val_accuracy: 0.8394\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0825 - accuracy: 0.9774 - val_loss: 0.7083 - val_accuracy: 0.8276\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0475 - accuracy: 0.9887 - val_loss: 0.7030 - val_accuracy: 0.8233\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9957 - val_loss: 0.8436 - val_accuracy: 0.7920\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9976 - val_loss: 0.7203 - val_accuracy: 0.8394\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9997 - val_loss: 0.8065 - val_accuracy: 0.8211\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9995 - val_loss: 0.8784 - val_accuracy: 0.8244\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8405\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8394\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.8459\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8502\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8513\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8491\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8524\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8534\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8427\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.8448\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.8502\n","Epoch 74/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.6676 - val_accuracy: 0.8513\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.8524\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 0.8556\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 0.8513\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.6575 - val_accuracy: 0.8524\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8556\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.8556\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.8556\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.8556\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.8534\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 0.8491\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.8545\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.8534\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.8567\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8534\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.8491\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.8513\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.8524\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.8481\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.6356 - val_accuracy: 0.8470\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8502\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.8481\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 0.8470\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6293 - val_accuracy: 0.8481\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.8491\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8470\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.8513\n","{'loss': [0.18500885367393494, 0.08218955993652344, 0.055753082036972046, 0.04951591044664383, 0.04114854708313942, 0.09112304449081421, 0.10207455605268478, 0.05215480178594589, 0.03932168334722519, 0.036666907370090485, 0.04256526380777359, 0.043015338480472565, 0.04602683708071709, 0.04843151941895485, 0.052911512553691864, 0.05834058299660683, 0.080781489610672, 0.08742332458496094, 0.03817449510097504, 0.026998097077012062, 0.03269101306796074, 0.05318216606974602, 0.06533508747816086, 0.043973930180072784, 0.04311566799879074, 0.031268443912267685, 0.02876102365553379, 0.028058893978595734, 0.045617129653692245, 0.06961385160684586, 0.06853519380092621, 0.04727577045559883, 0.03431810066103935, 0.027373727411031723, 0.03362365439534187, 0.05388406664133072, 0.04494505375623703, 0.03216654434800148, 0.03357997164130211, 0.03897310793399811, 0.042697735130786896, 0.04254841431975365, 0.046634115278720856, 0.04074612632393837, 0.0435880646109581, 0.029650075361132622, 0.032155659049749374, 0.029702717438340187, 0.023111648857593536, 0.022085625678300858, 0.02187793143093586, 0.020649179816246033, 0.022913597524166107, 0.026093220338225365, 0.022247452288866043, 0.023628460243344307, 0.08252144604921341, 0.04751487448811531, 0.030270123854279518, 0.025276385247707367, 0.0186921339482069, 0.017724666744470596, 0.016885146498680115, 0.016221510246396065, 0.01584581285715103, 0.015698371455073357, 0.015515635721385479, 0.015329469926655293, 0.015233615413308144, 0.015048086643218994, 0.01497091818600893, 0.014920171350240707, 0.014776075258851051, 0.014616524800658226, 0.014521263539791107, 0.014446163550019264, 0.014276414178311825, 0.014175117015838623, 0.014126303605735302, 0.013990531675517559, 0.013896215707063675, 0.013785062357783318, 0.0136941559612751, 0.013612818904221058, 0.013515869155526161, 0.013407750986516476, 0.013316936790943146, 0.013240599073469639, 0.01322258822619915, 0.013074543327093124, 0.0130161726847291, 0.01291478518396616, 0.012815369293093681, 0.012715206481516361, 0.012615303508937359, 0.012524845078587532, 0.012471568770706654, 0.012374276295304298, 0.012298067100346088, 0.01224103756248951], 'accuracy': [0.9393857717514038, 0.9792564511299133, 0.9870689511299133, 0.9913793206214905, 0.993534505367279, 0.9719827771186829, 0.9657866358757019, 0.9897629022598267, 0.993803858757019, 0.9946120977401733, 0.9913793206214905, 0.9911099076271057, 0.9894935488700867, 0.9876077771186829, 0.9884159564971924, 0.9841055870056152, 0.9771012663841248, 0.9738685488700867, 0.9954202771186829, 0.998652994632721, 0.9951508641242981, 0.9867995977401733, 0.9835668206214905, 0.990840494632721, 0.9916487336158752, 0.9954202771186829, 0.9970366358757019, 0.9975754022598267, 0.9889547228813171, 0.9822198152542114, 0.9789870977401733, 0.9884159564971924, 0.9954202771186829, 0.9970366358757019, 0.993803858757019, 0.9846444129943848, 0.9900323152542114, 0.9946120977401733, 0.9924569129943848, 0.9916487336158752, 0.9911099076271057, 0.9897629022598267, 0.9886853694915771, 0.990840494632721, 0.9903017282485962, 0.9948814511299133, 0.9943426847457886, 0.9948814511299133, 0.998652994632721, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9973060488700867, 0.9967672228813171, 0.998652994632721, 0.9975754022598267, 0.9773706793785095, 0.9886853694915771, 0.9956896305084229, 0.9975754022598267, 0.9997305870056152, 0.9994612336158752, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.710814356803894, 0.6964713335037231, 0.6836059093475342, 0.6610258221626282, 0.6470165848731995, 0.6395694613456726, 0.6317476630210876, 0.5828348398208618, 0.5401838421821594, 0.5134234428405762, 0.48905667662620544, 0.4665874242782593, 0.46982815861701965, 0.4695683717727661, 0.4912608861923218, 0.4618946611881256, 0.4780043363571167, 0.4676764905452728, 0.5268121361732483, 0.5879294276237488, 0.5697914361953735, 0.6403521299362183, 0.5395039916038513, 0.6320316195487976, 0.5660496354103088, 0.6820763349533081, 0.7161841988563538, 0.7623608112335205, 0.7106207013130188, 1.1141047477722168, 0.7280523777008057, 0.6506757140159607, 0.7020658850669861, 0.6808444261550903, 0.6695603132247925, 0.7767817378044128, 0.6489225029945374, 0.6914660930633545, 0.7315730452537537, 0.7367042899131775, 0.8076658844947815, 0.7689904570579529, 0.7556504011154175, 0.9624120593070984, 0.7500154376029968, 0.7388181090354919, 0.7540119290351868, 0.7337994575500488, 0.6925390362739563, 0.776218056678772, 0.7332340478897095, 0.8058711290359497, 0.7707467079162598, 0.7635613679885864, 0.7405743598937988, 0.8971431255340576, 0.7083097100257874, 0.7030198574066162, 0.8435601592063904, 0.7203051447868347, 0.8065140843391418, 0.8783878684043884, 0.7709904909133911, 0.751095175743103, 0.732302188873291, 0.7152959108352661, 0.7064258456230164, 0.7036285400390625, 0.6943888664245605, 0.6917837262153625, 0.6878966689109802, 0.6819168329238892, 0.6714872121810913, 0.6676440834999084, 0.6664505004882812, 0.6596267223358154, 0.6587898135185242, 0.6575349569320679, 0.6554755568504333, 0.654248833656311, 0.6547377109527588, 0.6512319445610046, 0.6496471166610718, 0.646702229976654, 0.6427792906761169, 0.6421414017677307, 0.6405755877494812, 0.6385676860809326, 0.6440036296844482, 0.6375083327293396, 0.6518237590789795, 0.6424081325531006, 0.635583221912384, 0.6347355246543884, 0.6315141916275024, 0.629155695438385, 0.629289448261261, 0.6288925409317017, 0.6295973658561707, 0.631624698638916], 'val_accuracy': [0.48491379618644714, 0.5043103694915771, 0.5538793206214905, 0.6411637663841248, 0.6120689511299133, 0.5808189511299133, 0.6875, 0.735991358757019, 0.7618534564971924, 0.7532327771186829, 0.7737069129943848, 0.7780172228813171, 0.774784505367279, 0.7737069129943848, 0.7586206793785095, 0.8017241358757019, 0.7726293206214905, 0.8017241358757019, 0.8178879022598267, 0.8211206793785095, 0.8286637663841248, 0.8028017282485962, 0.8232758641242981, 0.8157327771186829, 0.8383620977401733, 0.8448275923728943, 0.837284505367279, 0.8415948152542114, 0.8178879022598267, 0.71875, 0.7941810488700867, 0.837284505367279, 0.8405172228813171, 0.8286637663841248, 0.8469827771186829, 0.8405172228813171, 0.8556034564971924, 0.84375, 0.8448275923728943, 0.8362069129943848, 0.8318965435028076, 0.8383620977401733, 0.8351293206214905, 0.8168103694915771, 0.8275862336158752, 0.8405172228813171, 0.8286637663841248, 0.8351293206214905, 0.8599137663841248, 0.8275862336158752, 0.8512930870056152, 0.8459051847457886, 0.8448275923728943, 0.8329741358757019, 0.8362069129943848, 0.8394396305084229, 0.8275862336158752, 0.8232758641242981, 0.7920258641242981, 0.8394396305084229, 0.8211206793785095, 0.8243534564971924, 0.8405172228813171, 0.8394396305084229, 0.8459051847457886, 0.850215494632721, 0.8512930870056152, 0.8491379022598267, 0.8523706793785095, 0.8534482717514038, 0.8426724076271057, 0.8448275923728943, 0.850215494632721, 0.8512930870056152, 0.8523706793785095, 0.8556034564971924, 0.8512930870056152, 0.8523706793785095, 0.8556034564971924, 0.8556034564971924, 0.8556034564971924, 0.8556034564971924, 0.8534482717514038, 0.8491379022598267, 0.8545258641242981, 0.8534482717514038, 0.8566810488700867, 0.8534482717514038, 0.8491379022598267, 0.8512930870056152, 0.8523706793785095, 0.8480603694915771, 0.8469827771186829, 0.850215494632721, 0.8480603694915771, 0.8469827771186829, 0.8480603694915771, 0.8491379022598267, 0.8469827771186829, 0.8512930870056152]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.1983 - accuracy: 0.9430"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 56ms/step - loss: 0.1969 - accuracy: 0.9437 - val_loss: 0.7047 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0679 - accuracy: 0.9844 - val_loss: 0.6907 - val_accuracy: 0.5226\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0502 - accuracy: 0.9895 - val_loss: 0.6785 - val_accuracy: 0.5407\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.6630 - val_accuracy: 0.5826\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0394 - accuracy: 0.9949 - val_loss: 0.6297 - val_accuracy: 0.7545\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0572 - accuracy: 0.9884 - val_loss: 0.6208 - val_accuracy: 0.6923\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0633 - accuracy: 0.9819 - val_loss: 0.6210 - val_accuracy: 0.6120\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0789 - accuracy: 0.9776 - val_loss: 0.5937 - val_accuracy: 0.6776\n","Epoch 9/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0860 - accuracy: 0.9740 - val_loss: 0.5652 - val_accuracy: 0.7658\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0743 - accuracy: 0.9808 - val_loss: 0.5516 - val_accuracy: 0.7534\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0412 - accuracy: 0.9935 - val_loss: 0.5064 - val_accuracy: 0.7817\n","Epoch 12/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0289 - accuracy: 0.9983 - val_loss: 0.4751 - val_accuracy: 0.7885\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0253 - accuracy: 0.9989 - val_loss: 0.4615 - val_accuracy: 0.7885\n","Epoch 14/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0259 - accuracy: 0.9986 - val_loss: 0.4640 - val_accuracy: 0.7907\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0235 - accuracy: 0.9992 - val_loss: 0.4595 - val_accuracy: 0.7964\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0226 - accuracy: 0.9994 - val_loss: 0.5262 - val_accuracy: 0.7986\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8258\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8326\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 0.9994 - val_loss: 0.4942 - val_accuracy: 0.8258\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0281 - accuracy: 0.9960 - val_loss: 0.5531 - val_accuracy: 0.8326\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0391 - accuracy: 0.9935 - val_loss: 1.0254 - val_accuracy: 0.7579\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1411 - accuracy: 0.9567 - val_loss: 0.5945 - val_accuracy: 0.7692\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1390 - accuracy: 0.9496 - val_loss: 0.4521 - val_accuracy: 0.8224\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0501 - accuracy: 0.9912 - val_loss: 0.4291 - val_accuracy: 0.8507\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0340 - accuracy: 0.9958 - val_loss: 0.5957 - val_accuracy: 0.8247\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0408 - accuracy: 0.9938 - val_loss: 0.5663 - val_accuracy: 0.8371\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0431 - accuracy: 0.9907 - val_loss: 0.5196 - val_accuracy: 0.8394\n","Epoch 28/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0549 - accuracy: 0.9881 - val_loss: 0.4642 - val_accuracy: 0.8710\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0355 - accuracy: 0.9938 - val_loss: 0.5979 - val_accuracy: 0.8609\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0286 - accuracy: 0.9972 - val_loss: 0.6010 - val_accuracy: 0.8563\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0250 - accuracy: 0.9975 - val_loss: 0.6160 - val_accuracy: 0.8620\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9969 - val_loss: 0.7002 - val_accuracy: 0.8643\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0315 - accuracy: 0.9963 - val_loss: 0.8150 - val_accuracy: 0.8439\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0533 - accuracy: 0.9887 - val_loss: 0.6327 - val_accuracy: 0.8541\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0501 - accuracy: 0.9881 - val_loss: 0.6495 - val_accuracy: 0.8507\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0460 - accuracy: 0.9892 - val_loss: 0.5667 - val_accuracy: 0.8541\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0348 - accuracy: 0.9924 - val_loss: 0.7377 - val_accuracy: 0.8360\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0612 - accuracy: 0.9827 - val_loss: 0.6905 - val_accuracy: 0.8269\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0798 - accuracy: 0.9765 - val_loss: 0.5209 - val_accuracy: 0.8450\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0362 - accuracy: 0.9952 - val_loss: 0.5456 - val_accuracy: 0.8609\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0235 - accuracy: 0.9983 - val_loss: 0.5858 - val_accuracy: 0.8575\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 0.9997 - val_loss: 0.6004 - val_accuracy: 0.8563\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.5941 - val_accuracy: 0.8699\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8665\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.5906 - val_accuracy: 0.8665\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.5971 - val_accuracy: 0.8643\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 0.8676\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.8688\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 0.8654\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.8676\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8699\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.8699\n","Epoch 53/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8722\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8699\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.8676\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.8722\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.8665\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.5802 - val_accuracy: 0.8688\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.8688\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.8688\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.8688\n","Epoch 62/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.8767\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.8699\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.8710\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.8676\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.8688\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.8710\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.5677 - val_accuracy: 0.8688\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5670 - val_accuracy: 0.8733\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.8744\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 0.8676\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.8710\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.5591 - val_accuracy: 0.8744\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.8733\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.8756\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5599 - val_accuracy: 0.8710\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.8699\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8722\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.8710\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.8744\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.8733\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.8744\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.5634 - val_accuracy: 0.8676\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.8699\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.8688\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.5593 - val_accuracy: 0.8710\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.8733\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.8699\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.8733\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.8722\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.8733\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.5573 - val_accuracy: 0.8710\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.8699\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.8722\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.8688\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.8710\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.8710\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.8699\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.8710\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8699\n","{'loss': [0.19694986939430237, 0.0679304227232933, 0.050195932388305664, 0.045238595455884933, 0.03944138437509537, 0.057164132595062256, 0.06333687901496887, 0.07889416813850403, 0.08596471697092056, 0.07427259534597397, 0.04124382138252258, 0.028900472447276115, 0.025282740592956543, 0.02592415362596512, 0.023543834686279297, 0.022564595565199852, 0.02118944376707077, 0.021124595776200294, 0.02248556539416313, 0.02814946509897709, 0.039104629307985306, 0.1410512775182724, 0.1389988362789154, 0.05013228952884674, 0.034039754420518875, 0.04078668728470802, 0.04309181496500969, 0.05486243963241577, 0.03549258038401604, 0.028559241443872452, 0.024982983246445656, 0.027072792872786522, 0.03148333355784416, 0.0533117838203907, 0.050072260200977325, 0.04599376767873764, 0.0347968153655529, 0.061181310564279556, 0.07978837937116623, 0.03617130592465401, 0.023513400927186012, 0.01954919472336769, 0.01852181926369667, 0.018025275319814682, 0.01778334006667137, 0.017567215487360954, 0.017428042367100716, 0.01725875213742256, 0.01719471998512745, 0.017028773203492165, 0.01688132993876934, 0.016727762296795845, 0.016632217913866043, 0.016504136845469475, 0.016405917704105377, 0.01634771004319191, 0.01622367836534977, 0.01609845645725727, 0.015964753925800323, 0.015880683436989784, 0.015751253813505173, 0.015640750527381897, 0.015541348606348038, 0.015433307737112045, 0.01537199504673481, 0.015250706113874912, 0.015164988115429878, 0.015065678395330906, 0.01499277725815773, 0.01484037097543478, 0.01476365141570568, 0.014656410552561283, 0.014517749659717083, 0.014498918317258358, 0.014336553402245045, 0.014281248673796654, 0.014158257283270359, 0.014037087559700012, 0.01398271881043911, 0.013910969719290733, 0.013776447623968124, 0.01366039551794529, 0.013612718321383, 0.01347760297358036, 0.013432065024971962, 0.013337487354874611, 0.013245763257145882, 0.013142487034201622, 0.013072755187749863, 0.012965441681444645, 0.012865542434155941, 0.012775965966284275, 0.01269759051501751, 0.012633784674108028, 0.012549263425171375, 0.012490644119679928, 0.012375939637422562, 0.012266894802451134, 0.012172806076705456, 0.012131103314459324], 'accuracy': [0.9436898827552795, 0.9844368696212769, 0.9895302653312683, 0.9903791546821594, 0.9949066042900085, 0.9883984327316284, 0.9818902015686035, 0.977645754814148, 0.9739671945571899, 0.9807583689689636, 0.9934917688369751, 0.9983022212982178, 0.9988681674003601, 0.9985851645469666, 0.9991511106491089, 0.9994340538978577, 1.0, 1.0, 0.9994340538978577, 0.9960384964942932, 0.9934917688369751, 0.9567062854766846, 0.9496321678161621, 0.9912280440330505, 0.9957554936408997, 0.9937747716903687, 0.990662157535553, 0.9881154298782349, 0.9937747716903687, 0.9971703290939331, 0.9974533319473267, 0.9968873858451843, 0.996321439743042, 0.9886813759803772, 0.9881154298782349, 0.9892473220825195, 0.9923599362373352, 0.9827390909194946, 0.9765138626098633, 0.9951896071434021, 0.9983022212982178, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7047039866447449, 0.6907439231872559, 0.6785151362419128, 0.6630239486694336, 0.6297333836555481, 0.6208316683769226, 0.6210262775421143, 0.5937360525131226, 0.5651766657829285, 0.551628828048706, 0.5063550472259521, 0.47509703040122986, 0.4614795744419098, 0.4639764130115509, 0.45953279733657837, 0.5261661410331726, 0.4934976100921631, 0.48512762784957886, 0.4942063093185425, 0.5530598759651184, 1.0254443883895874, 0.5945110321044922, 0.452100932598114, 0.42906075716018677, 0.5957364439964294, 0.5663394331932068, 0.5196062326431274, 0.4642065763473511, 0.5979195833206177, 0.601047158241272, 0.6159848570823669, 0.7001640796661377, 0.8150485157966614, 0.63273024559021, 0.6495087742805481, 0.5666531324386597, 0.737693190574646, 0.690492570400238, 0.5208649635314941, 0.5455635786056519, 0.5858349204063416, 0.6004472374916077, 0.5941177010536194, 0.5815460085868835, 0.5906005501747131, 0.5970856547355652, 0.5967013835906982, 0.598006010055542, 0.5957630276679993, 0.5898575186729431, 0.5912284851074219, 0.5914551615715027, 0.587580680847168, 0.5873063206672668, 0.5850158333778381, 0.580083966255188, 0.5869625806808472, 0.5801798701286316, 0.5797677636146545, 0.576257050037384, 0.5741590857505798, 0.5751680135726929, 0.5733973979949951, 0.5748569369316101, 0.5748076438903809, 0.5729722380638123, 0.5701543688774109, 0.567741334438324, 0.5670288801193237, 0.5625578761100769, 0.5630430579185486, 0.5607945919036865, 0.5590652227401733, 0.562082052230835, 0.557033121585846, 0.5598970055580139, 0.5603088736534119, 0.5605141520500183, 0.5609380602836609, 0.558549165725708, 0.561531662940979, 0.5596188902854919, 0.5633684992790222, 0.5588628649711609, 0.5607274770736694, 0.5592690110206604, 0.5585968494415283, 0.5551807880401611, 0.5526994466781616, 0.5561923980712891, 0.5572142601013184, 0.5573464035987854, 0.5569288730621338, 0.5569533705711365, 0.5619891881942749, 0.5648587346076965, 0.5621563196182251, 0.5598338842391968, 0.5569373965263367, 0.5568153858184814], 'val_accuracy': [0.4954751133918762, 0.5226244330406189, 0.540723979473114, 0.5825791954994202, 0.7545248866081238, 0.692307710647583, 0.6119909286499023, 0.6776018142700195, 0.7658371329307556, 0.7533936500549316, 0.7816742062568665, 0.7884615659713745, 0.7884615659713745, 0.790723979473114, 0.7963801026344299, 0.7986425161361694, 0.8257918357849121, 0.8325791954994202, 0.8257918357849121, 0.8325791954994202, 0.7579185366630554, 0.7692307829856873, 0.8223981857299805, 0.8506787419319153, 0.8246606588363647, 0.837104082107544, 0.8393664956092834, 0.8710407018661499, 0.860859751701355, 0.8563348650932312, 0.8619909286499023, 0.8642534017562866, 0.8438913822174072, 0.8540723919868469, 0.8506787419319153, 0.8540723919868469, 0.8359728455543518, 0.8269230723381042, 0.8450226187705994, 0.860859751701355, 0.8574660420417786, 0.8563348650932312, 0.8699095249176025, 0.8665158152580261, 0.8665158152580261, 0.8642534017562866, 0.8676470518112183, 0.8687782883644104, 0.8653846383094788, 0.8676470518112183, 0.8699095249176025, 0.8699095249176025, 0.872171938419342, 0.8699095249176025, 0.8676470518112183, 0.872171938419342, 0.8665158152580261, 0.8687782883644104, 0.8687782883644104, 0.8687782883644104, 0.8687782883644104, 0.8766968250274658, 0.8699095249176025, 0.8710407018661499, 0.8676470518112183, 0.8687782883644104, 0.8710407018661499, 0.8687782883644104, 0.8733031749725342, 0.8744344115257263, 0.8676470518112183, 0.8710407018661499, 0.8744344115257263, 0.8733031749725342, 0.8755655884742737, 0.8710407018661499, 0.8699095249176025, 0.872171938419342, 0.8710407018661499, 0.8744344115257263, 0.8733031749725342, 0.8744344115257263, 0.8676470518112183, 0.8699095249176025, 0.8687782883644104, 0.8710407018661499, 0.8733031749725342, 0.8699095249176025, 0.8733031749725342, 0.872171938419342, 0.8733031749725342, 0.8710407018661499, 0.8699095249176025, 0.872171938419342, 0.8687782883644104, 0.8710407018661499, 0.8710407018661499, 0.8699095249176025, 0.8710407018661499, 0.8699095249176025]}\n","45/45 [==============================] - 2s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 52ms/step - loss: 0.1626 - accuracy: 0.9488 - val_loss: 0.7044 - val_accuracy: 0.4876\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0831 - accuracy: 0.9786 - val_loss: 0.6916 - val_accuracy: 0.5269\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0759 - accuracy: 0.9786 - val_loss: 0.6798 - val_accuracy: 0.5475\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0594 - accuracy: 0.9871 - val_loss: 0.6670 - val_accuracy: 0.5847\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0539 - accuracy: 0.9873 - val_loss: 0.6341 - val_accuracy: 0.7149\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1055 - accuracy: 0.9641 - val_loss: 0.6353 - val_accuracy: 0.6911\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0800 - accuracy: 0.9765 - val_loss: 0.6143 - val_accuracy: 0.7107\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0596 - accuracy: 0.9858 - val_loss: 0.5864 - val_accuracy: 0.7169\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0481 - accuracy: 0.9897 - val_loss: 0.5701 - val_accuracy: 0.6818\n","Epoch 10/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0432 - accuracy: 0.9933 - val_loss: 0.5356 - val_accuracy: 0.7335\n","Epoch 11/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.5071 - val_accuracy: 0.7376\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0700 - accuracy: 0.9791 - val_loss: 0.5144 - val_accuracy: 0.7273\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.1475 - accuracy: 0.9483 - val_loss: 0.5095 - val_accuracy: 0.7614\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1238 - accuracy: 0.9584 - val_loss: 0.5422 - val_accuracy: 0.7066\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0540 - accuracy: 0.9884 - val_loss: 0.4833 - val_accuracy: 0.7593\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0337 - accuracy: 0.9966 - val_loss: 0.4578 - val_accuracy: 0.7903\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0283 - accuracy: 0.9972 - val_loss: 0.5016 - val_accuracy: 0.8048\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0326 - accuracy: 0.9953 - val_loss: 0.5251 - val_accuracy: 0.7903\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1058 - accuracy: 0.9680 - val_loss: 0.4715 - val_accuracy: 0.8068\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0819 - accuracy: 0.9778 - val_loss: 0.4642 - val_accuracy: 0.8213\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0694 - accuracy: 0.9814 - val_loss: 0.5289 - val_accuracy: 0.8140\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0482 - accuracy: 0.9884 - val_loss: 0.5199 - val_accuracy: 0.8388\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0300 - accuracy: 0.9977 - val_loss: 0.5786 - val_accuracy: 0.8306\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0239 - accuracy: 0.9990 - val_loss: 0.6615 - val_accuracy: 0.8450\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0339 - accuracy: 0.9946 - val_loss: 0.7447 - val_accuracy: 0.8182\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1154 - accuracy: 0.9667 - val_loss: 0.5434 - val_accuracy: 0.7996\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0559 - accuracy: 0.9871 - val_loss: 0.6686 - val_accuracy: 0.8254\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0348 - accuracy: 0.9953 - val_loss: 0.8114 - val_accuracy: 0.8161\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0275 - accuracy: 0.9972 - val_loss: 0.6822 - val_accuracy: 0.8368\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0232 - accuracy: 0.9987 - val_loss: 0.7807 - val_accuracy: 0.8378\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0233 - accuracy: 0.9995 - val_loss: 0.8950 - val_accuracy: 0.8275\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.8471\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.8378\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9995 - val_loss: 0.7720 - val_accuracy: 0.8430\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0303 - accuracy: 0.9943 - val_loss: 0.8558 - val_accuracy: 0.8223\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1108 - accuracy: 0.9695 - val_loss: 0.5370 - val_accuracy: 0.8399\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0771 - accuracy: 0.9783 - val_loss: 0.6440 - val_accuracy: 0.8378\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0483 - accuracy: 0.9907 - val_loss: 0.7385 - val_accuracy: 0.8244\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0362 - accuracy: 0.9933 - val_loss: 0.7643 - val_accuracy: 0.8337\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0315 - accuracy: 0.9946 - val_loss: 0.6875 - val_accuracy: 0.8388\n","Epoch 41/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0740 - accuracy: 0.9793 - val_loss: 0.7781 - val_accuracy: 0.8079\n","Epoch 42/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0578 - accuracy: 0.9848 - val_loss: 0.6823 - val_accuracy: 0.8151\n","Epoch 43/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.0515 - accuracy: 0.9894 - val_loss: 0.7637 - val_accuracy: 0.8037\n","Epoch 44/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.0405 - accuracy: 0.9917 - val_loss: 0.7853 - val_accuracy: 0.8006\n","Epoch 45/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0350 - accuracy: 0.9948 - val_loss: 0.7391 - val_accuracy: 0.8223\n","Epoch 46/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0264 - accuracy: 0.9977 - val_loss: 0.8046 - val_accuracy: 0.8275\n","Epoch 47/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0240 - accuracy: 0.9974 - val_loss: 0.8798 - val_accuracy: 0.8223\n","Epoch 48/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0226 - accuracy: 0.9984 - val_loss: 0.8254 - val_accuracy: 0.8316\n","Epoch 49/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0207 - accuracy: 0.9987 - val_loss: 0.9308 - val_accuracy: 0.8192\n","Epoch 50/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0281 - accuracy: 0.9959 - val_loss: 0.9257 - val_accuracy: 0.8110\n","Epoch 51/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0319 - accuracy: 0.9951 - val_loss: 0.8054 - val_accuracy: 0.8285\n","Epoch 52/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0239 - accuracy: 0.9977 - val_loss: 0.8197 - val_accuracy: 0.8316\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0381 - accuracy: 0.9933 - val_loss: 0.8315 - val_accuracy: 0.8213\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0445 - accuracy: 0.9902 - val_loss: 0.8664 - val_accuracy: 0.8027\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9966 - val_loss: 0.8129 - val_accuracy: 0.8182\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0333 - accuracy: 0.9946 - val_loss: 0.8752 - val_accuracy: 0.8089\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0337 - accuracy: 0.9938 - val_loss: 0.8983 - val_accuracy: 0.8233\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0329 - accuracy: 0.9933 - val_loss: 0.8807 - val_accuracy: 0.8213\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0443 - accuracy: 0.9884 - val_loss: 0.8062 - val_accuracy: 0.8233\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0480 - accuracy: 0.9884 - val_loss: 0.9681 - val_accuracy: 0.7934\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0287 - accuracy: 0.9966 - val_loss: 0.8470 - val_accuracy: 0.8316\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0193 - accuracy: 0.9995 - val_loss: 0.8658 - val_accuracy: 0.8285\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0178 - accuracy: 0.9997 - val_loss: 0.8673 - val_accuracy: 0.8233\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.8791 - val_accuracy: 0.8295\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.8275\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9997 - val_loss: 0.9079 - val_accuracy: 0.8337\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8306\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.8548 - val_accuracy: 0.8347\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.8399\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.8388\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.8357\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.8399\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.8419\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.8419\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.8419\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.7827 - val_accuracy: 0.8419\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.8430\n","Epoch 78/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.7724 - val_accuracy: 0.8378\n","Epoch 79/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8368\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.7698 - val_accuracy: 0.8419\n","Epoch 81/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.8409\n","Epoch 82/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.8388\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8419\n","Epoch 84/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.7802 - val_accuracy: 0.8450\n","Epoch 85/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.8378\n","Epoch 86/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.8337\n","Epoch 87/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.0174 - accuracy: 0.9990 - val_loss: 0.8058 - val_accuracy: 0.8254\n","Epoch 88/100\n","31/31 [==============================] - 1s 43ms/step - loss: 0.0151 - accuracy: 0.9997 - val_loss: 0.8740 - val_accuracy: 0.8213\n","Epoch 89/100\n","31/31 [==============================] - 1s 48ms/step - loss: 0.0150 - accuracy: 0.9997 - val_loss: 0.8399 - val_accuracy: 0.8244\n","Epoch 90/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0324 - accuracy: 0.9922 - val_loss: 1.1299 - val_accuracy: 0.7820\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1877 - accuracy: 0.9287 - val_loss: 0.5293 - val_accuracy: 0.7820\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0805 - accuracy: 0.9742 - val_loss: 0.7168 - val_accuracy: 0.8120\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.7941 - val_accuracy: 0.8192\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9946 - val_loss: 1.1083 - val_accuracy: 0.7738\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1612 - accuracy: 0.9411 - val_loss: 0.5692 - val_accuracy: 0.7872\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0824 - accuracy: 0.9757 - val_loss: 0.6489 - val_accuracy: 0.8068\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9948 - val_loss: 0.8579 - val_accuracy: 0.7789\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9951 - val_loss: 0.8810 - val_accuracy: 0.7986\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9979 - val_loss: 0.8505 - val_accuracy: 0.8151\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9995 - val_loss: 1.1051 - val_accuracy: 0.7986\n","{'loss': [0.16263599693775177, 0.08314887434244156, 0.0758737176656723, 0.05935297906398773, 0.053942229598760605, 0.10547851771116257, 0.08004630357027054, 0.059565700590610504, 0.048112791031599045, 0.043166182935237885, 0.04517636448144913, 0.07000759989023209, 0.14746786653995514, 0.12377145141363144, 0.0540241040289402, 0.033690545707941055, 0.028297265991568565, 0.032646846026182175, 0.10576152801513672, 0.08193228393793106, 0.06944651901721954, 0.04817674309015274, 0.03002198226749897, 0.023948373273015022, 0.03390982747077942, 0.11541330814361572, 0.05594058334827423, 0.03475181385874748, 0.027492737397551537, 0.02321336232125759, 0.02328643761575222, 0.020844832062721252, 0.01976533606648445, 0.021259348839521408, 0.030348360538482666, 0.11079362779855728, 0.07713071256875992, 0.04829506576061249, 0.03615666925907135, 0.031481243669986725, 0.07403654605150223, 0.057796984910964966, 0.0514557808637619, 0.04052072390913963, 0.035009078681468964, 0.026404952630400658, 0.02395925112068653, 0.022649241611361504, 0.020733678713440895, 0.028140369802713394, 0.031868383288383484, 0.023852353915572166, 0.03813602030277252, 0.04451071843504906, 0.029027482494711876, 0.03327054902911186, 0.03369773551821709, 0.03294149041175842, 0.04427548125386238, 0.048033393919467926, 0.02871311455965042, 0.019347503781318665, 0.017845625057816505, 0.017184840515255928, 0.01643943414092064, 0.016752758994698524, 0.01627633348107338, 0.016164008527994156, 0.015805011615157127, 0.01567036285996437, 0.015478759072721004, 0.015349975787103176, 0.015245185233652592, 0.015106314793229103, 0.01499348133802414, 0.01486945804208517, 0.014752289280295372, 0.014646007679402828, 0.014502763748168945, 0.014420071616768837, 0.014305544085800648, 0.014232225716114044, 0.014091594144701958, 0.013951079919934273, 0.01384007092565298, 0.013773309998214245, 0.017355961725115776, 0.015074153430759907, 0.015019270591437817, 0.03244401142001152, 0.18765689432621002, 0.0805320143699646, 0.02326146326959133, 0.03019111230969429, 0.16115163266658783, 0.08237382024526596, 0.03080226294696331, 0.028978604823350906, 0.022414615377783775, 0.016093939542770386], 'accuracy': [0.9488372206687927, 0.9785529971122742, 0.9785529971122742, 0.9870800971984863, 0.9873384833335876, 0.964082658290863, 0.9764857888221741, 0.985788106918335, 0.9896640777587891, 0.9932816624641418, 0.9904392957687378, 0.9790697693824768, 0.9483203887939453, 0.9583979249000549, 0.9883720874786377, 0.9966408014297485, 0.997157633304596, 0.9953488111495972, 0.9679586291313171, 0.9777777791023254, 0.9813953638076782, 0.9883720874786377, 0.9976744055747986, 0.99896639585495, 0.9945736527442932, 0.9666666388511658, 0.9870800971984863, 0.9953488111495972, 0.997157633304596, 0.9987080097198486, 0.9994832277297974, 1.0, 1.0, 0.9994832277297974, 0.9943152666091919, 0.9695090651512146, 0.9782945513725281, 0.9906976819038391, 0.9932816624641418, 0.9945736527442932, 0.9793281555175781, 0.9847545027732849, 0.9894056916236877, 0.9917312860488892, 0.9948320388793945, 0.9976744055747986, 0.9974160194396973, 0.9984496235847473, 0.9987080097198486, 0.9958656430244446, 0.9950904250144958, 0.9976744055747986, 0.9932816624641418, 0.9901808500289917, 0.9966408014297485, 0.9945736527442932, 0.9937984347343445, 0.9932816624641418, 0.9883720874786377, 0.9883720874786377, 0.9966408014297485, 0.9994832277297974, 0.9997416138648987, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99896639585495, 0.9997416138648987, 0.9997416138648987, 0.9922480583190918, 0.9286821484565735, 0.9741601943969727, 0.9968992471694946, 0.9945736527442932, 0.9410852789878845, 0.9757105708122253, 0.9948320388793945, 0.9950904250144958, 0.9979327917098999, 0.9994832277297974], 'val_loss': [0.704416036605835, 0.6916419863700867, 0.6798458695411682, 0.6669782996177673, 0.6341075301170349, 0.6353204846382141, 0.6143128871917725, 0.5863515138626099, 0.5701352953910828, 0.5355888605117798, 0.5071221590042114, 0.5143911242485046, 0.5095312595367432, 0.5421883463859558, 0.4833202660083771, 0.4577951729297638, 0.5015723705291748, 0.5250844359397888, 0.47150489687919617, 0.46420302987098694, 0.5288659930229187, 0.5198830366134644, 0.5786098837852478, 0.661536455154419, 0.7447002530097961, 0.5434038043022156, 0.6685608625411987, 0.8113940358161926, 0.6822085380554199, 0.7806819081306458, 0.8949722647666931, 0.7565885186195374, 0.7636043429374695, 0.7719963192939758, 0.8558021187782288, 0.537009060382843, 0.6440442204475403, 0.7385339140892029, 0.7643225789070129, 0.6875383853912354, 0.7781428098678589, 0.6822510957717896, 0.7636619210243225, 0.7853378057479858, 0.7390629649162292, 0.8046444058418274, 0.8797642588615417, 0.825447678565979, 0.9307894706726074, 0.9257004261016846, 0.805415153503418, 0.8196624517440796, 0.8314526677131653, 0.8663718700408936, 0.8129048347473145, 0.8752245306968689, 0.8982589840888977, 0.8806597590446472, 0.8061655163764954, 0.9680722951889038, 0.8470189571380615, 0.8657823204994202, 0.8673237562179565, 0.8790611028671265, 0.8750349879264832, 0.9079103469848633, 0.8837633728981018, 0.8548009395599365, 0.8171303272247314, 0.8133245706558228, 0.8072289824485779, 0.8047960996627808, 0.796197235584259, 0.7903479933738708, 0.7924028635025024, 0.7827009558677673, 0.7821979522705078, 0.7724459767341614, 0.7709961533546448, 0.769823431968689, 0.771098256111145, 0.7770098447799683, 0.7761180996894836, 0.780164897441864, 0.7832791805267334, 0.7899994850158691, 0.8058406710624695, 0.8739818334579468, 0.8398911952972412, 1.1298588514328003, 0.5293217301368713, 0.716804563999176, 0.7941307425498962, 1.1083489656448364, 0.5692023634910583, 0.6489174365997314, 0.8579411506652832, 0.8809663653373718, 0.8505244851112366, 1.105054259300232], 'val_accuracy': [0.4876033067703247, 0.5268595218658447, 0.547520637512207, 0.5847107172012329, 0.7148760557174683, 0.69111567735672, 0.71074378490448, 0.7169421315193176, 0.6818181872367859, 0.7334710955619812, 0.7376033067703247, 0.7272727489471436, 0.7613636255264282, 0.7066115736961365, 0.7592975497245789, 0.7902892827987671, 0.8047520518302917, 0.7902892827987671, 0.8068181872367859, 0.8212810158729553, 0.8140496015548706, 0.8388429880142212, 0.8305785059928894, 0.8450413346290588, 0.8181818127632141, 0.7995867729187012, 0.8254132270812988, 0.81611567735672, 0.836776852607727, 0.8378099203109741, 0.827479362487793, 0.8471074104309082, 0.8378099203109741, 0.8429751992225647, 0.8223140239715576, 0.8398760557174683, 0.8378099203109741, 0.8243801593780518, 0.8336777091026306, 0.8388429880142212, 0.807851254940033, 0.8150826692581177, 0.8037189841270447, 0.8006198406219482, 0.8223140239715576, 0.827479362487793, 0.8223140239715576, 0.8316115736961365, 0.8192148804664612, 0.8109503984451294, 0.8285123705863953, 0.8316115736961365, 0.8212810158729553, 0.8026859760284424, 0.8181818127632141, 0.80888432264328, 0.8233470916748047, 0.8212810158729553, 0.8233470916748047, 0.7933884263038635, 0.8316115736961365, 0.8285123705863953, 0.8233470916748047, 0.8295454382896423, 0.827479362487793, 0.8336777091026306, 0.8305785059928894, 0.8347107172012329, 0.8398760557174683, 0.8388429880142212, 0.83574378490448, 0.8398760557174683, 0.8419421315193176, 0.8419421315193176, 0.8419421315193176, 0.8419421315193176, 0.8429751992225647, 0.8378099203109741, 0.836776852607727, 0.8419421315193176, 0.8409090638160706, 0.8388429880142212, 0.8419421315193176, 0.8450413346290588, 0.8378099203109741, 0.8336777091026306, 0.8254132270812988, 0.8212810158729553, 0.8243801593780518, 0.7820248007774353, 0.7820248007774353, 0.8119834661483765, 0.8192148804664612, 0.7737603187561035, 0.7871900796890259, 0.8068181872367859, 0.7789255976676941, 0.7985537052154541, 0.8150826692581177, 0.7985537052154541]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.1036 - accuracy: 0.9708"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 52ms/step - loss: 0.1001 - accuracy: 0.9717 - val_loss: 0.6941 - val_accuracy: 0.4925\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0375 - accuracy: 0.9916 - val_loss: 0.6879 - val_accuracy: 0.5086\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0217 - accuracy: 0.9973 - val_loss: 0.6718 - val_accuracy: 0.5862\n","Epoch 4/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0276 - accuracy: 0.9943 - val_loss: 0.6572 - val_accuracy: 0.6175\n","Epoch 5/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0324 - accuracy: 0.9927 - val_loss: 0.6314 - val_accuracy: 0.7241\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.9962 - val_loss: 0.6087 - val_accuracy: 0.7026\n","Epoch 7/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0188 - accuracy: 0.9976 - val_loss: 0.5710 - val_accuracy: 0.7575\n","Epoch 8/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0268 - accuracy: 0.9946 - val_loss: 0.5410 - val_accuracy: 0.7791\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0617 - accuracy: 0.9803 - val_loss: 0.5518 - val_accuracy: 0.7511\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0583 - accuracy: 0.9793 - val_loss: 0.5452 - val_accuracy: 0.7468\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0328 - accuracy: 0.9930 - val_loss: 0.4827 - val_accuracy: 0.7877\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0224 - accuracy: 0.9970 - val_loss: 0.4700 - val_accuracy: 0.7769\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0375 - accuracy: 0.9914 - val_loss: 0.5043 - val_accuracy: 0.7532\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0510 - accuracy: 0.9844 - val_loss: 0.4195 - val_accuracy: 0.8050\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0338 - accuracy: 0.9922 - val_loss: 0.4028 - val_accuracy: 0.8190\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0378 - accuracy: 0.9898 - val_loss: 0.3991 - val_accuracy: 0.8362\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9941 - val_loss: 0.4353 - val_accuracy: 0.8114\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0250 - accuracy: 0.9957 - val_loss: 0.3869 - val_accuracy: 0.8373\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9954 - val_loss: 0.4891 - val_accuracy: 0.8287\n","Epoch 20/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.0341 - accuracy: 0.9927 - val_loss: 0.4715 - val_accuracy: 0.8394\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0404 - accuracy: 0.9903 - val_loss: 0.4469 - val_accuracy: 0.8491\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0339 - accuracy: 0.9933 - val_loss: 0.4109 - val_accuracy: 0.8567\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0369 - accuracy: 0.9914 - val_loss: 0.5898 - val_accuracy: 0.8308\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0781 - accuracy: 0.9749 - val_loss: 0.6140 - val_accuracy: 0.8168\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0255 - accuracy: 0.9965 - val_loss: 0.4902 - val_accuracy: 0.8459\n","Epoch 26/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0179 - accuracy: 0.9981 - val_loss: 0.4275 - val_accuracy: 0.8707\n","Epoch 27/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0142 - accuracy: 0.9997 - val_loss: 0.4464 - val_accuracy: 0.8750\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.8772\n","Epoch 29/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8901\n","Epoch 30/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.8847\n","Epoch 31/100\n","29/29 [==============================] - 1s 47ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.8987\n","Epoch 32/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.8966\n","Epoch 33/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.8987\n","Epoch 34/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8944\n","Epoch 35/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8933\n","Epoch 36/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8944\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8922\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8933\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8933\n","Epoch 40/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.8933\n","Epoch 41/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.8922\n","Epoch 42/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.8944\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.8933\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8933\n","Epoch 45/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8933\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.8912\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8901\n","Epoch 48/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8901\n","Epoch 49/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8890\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.8901\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8944\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.8901\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.8933\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8955\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.8976\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.8955\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8944\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8955\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.8955\n","Epoch 60/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8944\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.8976\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.8955\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.8955\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.8966\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.8976\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.8966\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8901\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.8944\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.8944\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.8976\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8944\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.8955\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.8955\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.8944\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8944\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.8922\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.8966\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.8912\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.8922\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.8933\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.8976\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8944\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.8955\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8922\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.8976\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.8901\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8966\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.8912\n","Epoch 89/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.8966\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.8944\n","Epoch 91/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.8966\n","Epoch 92/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.8933\n","Epoch 93/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.8933\n","Epoch 94/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.8966\n","Epoch 95/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8976\n","Epoch 96/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.8976\n","Epoch 97/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.8966\n","Epoch 98/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.8987\n","Epoch 99/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.8955\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.8955\n","{'loss': [0.10010545700788498, 0.0375230573117733, 0.02166496217250824, 0.027555102482438087, 0.03242037072777748, 0.024146245792508125, 0.018825875595211983, 0.02678876370191574, 0.06169828772544861, 0.058259282261133194, 0.03284202516078949, 0.02243710681796074, 0.03751451149582863, 0.05101923272013664, 0.03380841761827469, 0.037771377712488174, 0.028402693569660187, 0.02502639964222908, 0.022119058296084404, 0.03412045165896416, 0.04035395011305809, 0.03388990834355354, 0.03691757842898369, 0.07809706032276154, 0.02552090585231781, 0.017864109948277473, 0.014171908609569073, 0.012521402910351753, 0.012306123971939087, 0.012178868986666203, 0.012047276832163334, 0.012021837756037712, 0.011887422762811184, 0.011813600547611713, 0.01176332589238882, 0.01168623473495245, 0.011628203094005585, 0.011559773236513138, 0.011501021683216095, 0.011436867527663708, 0.011376318521797657, 0.011331728659570217, 0.011271674185991287, 0.011222532950341702, 0.011146125383675098, 0.011087669059634209, 0.011066120117902756, 0.01098668947815895, 0.010923623107373714, 0.010882442817091942, 0.01108997780829668, 0.010800788179039955, 0.010744750499725342, 0.010680659674108028, 0.01060414407402277, 0.01055027823895216, 0.010506605729460716, 0.0104439165443182, 0.01042358297854662, 0.010369861498475075, 0.010315493680536747, 0.010253490880131721, 0.010232735425233841, 0.01016276329755783, 0.010120781138539314, 0.01006554625928402, 0.010024848394095898, 0.009972268715500832, 0.009917816147208214, 0.009870508685708046, 0.009842856787145138, 0.009807637892663479, 0.009740778245031834, 0.009714795276522636, 0.009660421870648861, 0.009626009501516819, 0.009560791775584221, 0.00952108297497034, 0.009480015374720097, 0.009448762983083725, 0.00939586665481329, 0.009350256063044071, 0.009315837174654007, 0.009270674549043179, 0.00923755019903183, 0.009191405028104782, 0.00914323516190052, 0.009093768894672394, 0.00907212682068348, 0.00901734922081232, 0.008982288651168346, 0.00893339328467846, 0.00890670157968998, 0.00886575598269701, 0.00881635956466198, 0.008789784274995327, 0.00873685535043478, 0.008704728446900845, 0.00871093850582838, 0.008632742799818516], 'accuracy': [0.9717133641242981, 0.9916487336158752, 0.9973060488700867, 0.9943426847457886, 0.9927262663841248, 0.9962284564971924, 0.9975754022598267, 0.9946120977401733, 0.9803340435028076, 0.9792564511299133, 0.9929956793785095, 0.9970366358757019, 0.9913793206214905, 0.984375, 0.9921875, 0.9897629022598267, 0.9940732717514038, 0.9956896305084229, 0.9954202771186829, 0.9927262663841248, 0.9903017282485962, 0.9932650923728943, 0.9913793206214905, 0.974946141242981, 0.9964978694915771, 0.9981142282485962, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6941052675247192, 0.6878933906555176, 0.6717686653137207, 0.6572456359863281, 0.6314491033554077, 0.6087365746498108, 0.5710387825965881, 0.5409828424453735, 0.551791787147522, 0.5451550483703613, 0.48272672295570374, 0.46995753049850464, 0.5043310523033142, 0.41950589418411255, 0.40282905101776123, 0.3991321325302124, 0.4352673888206482, 0.3868671655654907, 0.48907193541526794, 0.47150731086730957, 0.44692376255989075, 0.4108736217021942, 0.5897967219352722, 0.6140190362930298, 0.4901641309261322, 0.4275151193141937, 0.44642606377601624, 0.4568418264389038, 0.4439367353916168, 0.4410315752029419, 0.4443145990371704, 0.4450686275959015, 0.4393707811832428, 0.4370793104171753, 0.4346236288547516, 0.4304819107055664, 0.42998120188713074, 0.42972099781036377, 0.4255053400993347, 0.4249221086502075, 0.4239062964916229, 0.42236289381980896, 0.4215027689933777, 0.4215948283672333, 0.41996830701828003, 0.41725844144821167, 0.4237639605998993, 0.42315930128097534, 0.4224560856819153, 0.41928786039352417, 0.44144120812416077, 0.42654386162757874, 0.42026039958000183, 0.4167265295982361, 0.41466599702835083, 0.41362258791923523, 0.41322046518325806, 0.4092215895652771, 0.4076187014579773, 0.41090095043182373, 0.4122534692287445, 0.40597307682037354, 0.41061970591545105, 0.4072202444076538, 0.40656644105911255, 0.4065280854701996, 0.41033852100372314, 0.40417546033859253, 0.40285050868988037, 0.40114957094192505, 0.40307483077049255, 0.402566522359848, 0.4052005112171173, 0.40562865138053894, 0.4030444920063019, 0.40610793232917786, 0.4027291536331177, 0.404003381729126, 0.40263691544532776, 0.4027308225631714, 0.40404704213142395, 0.4038695991039276, 0.4046236276626587, 0.40714019536972046, 0.40546438097953796, 0.40432462096214294, 0.4030584394931793, 0.403370201587677, 0.4027020335197449, 0.40282317996025085, 0.4035165011882782, 0.40653231739997864, 0.4065329432487488, 0.4037756025791168, 0.4030912518501282, 0.4052601754665375, 0.4074583649635315, 0.4057137370109558, 0.4223940074443817, 0.4145033359527588], 'val_accuracy': [0.4924568831920624, 0.5086206793785095, 0.5862069129943848, 0.6174569129943848, 0.7241379022598267, 0.7025862336158752, 0.7575430870056152, 0.7790948152542114, 0.7510775923728943, 0.7467672228813171, 0.787715494632721, 0.7769396305084229, 0.7532327771186829, 0.8049569129943848, 0.818965494632721, 0.8362069129943848, 0.8114224076271057, 0.837284505367279, 0.8286637663841248, 0.8394396305084229, 0.8491379022598267, 0.8566810488700867, 0.8308189511299133, 0.8168103694915771, 0.8459051847457886, 0.8706896305084229, 0.875, 0.8771551847457886, 0.8900862336158752, 0.8846982717514038, 0.8987069129943848, 0.8965517282485962, 0.8987069129943848, 0.8943965435028076, 0.8933189511299133, 0.8943965435028076, 0.892241358757019, 0.8933189511299133, 0.8933189511299133, 0.8933189511299133, 0.892241358757019, 0.8943965435028076, 0.8933189511299133, 0.8933189511299133, 0.8933189511299133, 0.8911637663841248, 0.8900862336158752, 0.8900862336158752, 0.889008641242981, 0.8900862336158752, 0.8943965435028076, 0.8900862336158752, 0.8933189511299133, 0.8954741358757019, 0.8976293206214905, 0.8954741358757019, 0.8943965435028076, 0.8954741358757019, 0.8954741358757019, 0.8943965435028076, 0.8976293206214905, 0.8954741358757019, 0.8954741358757019, 0.8965517282485962, 0.8976293206214905, 0.8965517282485962, 0.8900862336158752, 0.8943965435028076, 0.8943965435028076, 0.8976293206214905, 0.8943965435028076, 0.8954741358757019, 0.8954741358757019, 0.8943965435028076, 0.8943965435028076, 0.892241358757019, 0.8965517282485962, 0.8911637663841248, 0.892241358757019, 0.8933189511299133, 0.8976293206214905, 0.8943965435028076, 0.8954741358757019, 0.892241358757019, 0.8976293206214905, 0.8900862336158752, 0.8965517282485962, 0.8911637663841248, 0.8965517282485962, 0.8943965435028076, 0.8965517282485962, 0.8933189511299133, 0.8933189511299133, 0.8965517282485962, 0.8976293206214905, 0.8976293206214905, 0.8965517282485962, 0.8987069129943848, 0.8954741358757019, 0.8954741358757019]}\n","38/38 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9813"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 13s 59ms/step - loss: 0.0750 - accuracy: 0.9813 - val_loss: 0.6914 - val_accuracy: 0.5079\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 0.6818 - val_accuracy: 0.5735\n","Epoch 3/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0258 - accuracy: 0.9949 - val_loss: 0.6689 - val_accuracy: 0.6640\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0279 - accuracy: 0.9946 - val_loss: 0.6476 - val_accuracy: 0.7172\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 0.9946 - val_loss: 0.6285 - val_accuracy: 0.7014\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0604 - accuracy: 0.9819 - val_loss: 0.6217 - val_accuracy: 0.7251\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0598 - accuracy: 0.9850 - val_loss: 0.6052 - val_accuracy: 0.7704\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.5682 - val_accuracy: 0.7658\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.5225 - val_accuracy: 0.7828\n","Epoch 10/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0184 - accuracy: 0.9972 - val_loss: 0.5064 - val_accuracy: 0.7568\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 0.9989 - val_loss: 0.4762 - val_accuracy: 0.7817\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.4803 - val_accuracy: 0.7704\n","Epoch 13/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0563 - accuracy: 0.9827 - val_loss: 0.4569 - val_accuracy: 0.7986\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0335 - accuracy: 0.9935 - val_loss: 0.4391 - val_accuracy: 0.7952\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.4393 - val_accuracy: 0.8100\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0219 - accuracy: 0.9955 - val_loss: 0.5055 - val_accuracy: 0.7738\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.4634 - val_accuracy: 0.8054\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9949 - val_loss: 0.5341 - val_accuracy: 0.8009\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0268 - accuracy: 0.9941 - val_loss: 0.4742 - val_accuracy: 0.8179\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.4593 - val_accuracy: 0.8303\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0290 - accuracy: 0.9941 - val_loss: 0.4359 - val_accuracy: 0.8518\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.4145 - val_accuracy: 0.8586\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0167 - accuracy: 0.9989 - val_loss: 0.4318 - val_accuracy: 0.8857\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0204 - accuracy: 0.9972 - val_loss: 0.5732 - val_accuracy: 0.8552\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.4557 - val_accuracy: 0.8733\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0936 - accuracy: 0.9703 - val_loss: 0.7465 - val_accuracy: 0.7851\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0487 - accuracy: 0.9870 - val_loss: 0.4700 - val_accuracy: 0.8552\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0224 - accuracy: 0.9972 - val_loss: 0.3470 - val_accuracy: 0.9038\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 0.9986 - val_loss: 0.4090 - val_accuracy: 0.8993\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.4600 - val_accuracy: 0.8812\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 0.9980 - val_loss: 0.4546 - val_accuracy: 0.8982\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 0.4543 - val_accuracy: 0.8959\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9969 - val_loss: 0.6075 - val_accuracy: 0.8575\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.5083 - val_accuracy: 0.8869\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 0.9977 - val_loss: 0.5275 - val_accuracy: 0.8812\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0176 - accuracy: 0.9986 - val_loss: 0.4789 - val_accuracy: 0.8880\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.9005\n","Epoch 38/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.9061\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0142 - accuracy: 0.9994 - val_loss: 0.5187 - val_accuracy: 0.8948\n","Epoch 40/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.7745 - val_accuracy: 0.8179\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0794 - accuracy: 0.9734 - val_loss: 0.4630 - val_accuracy: 0.8597\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0299 - accuracy: 0.9938 - val_loss: 0.4042 - val_accuracy: 0.8880\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0299 - accuracy: 0.9924 - val_loss: 0.6032 - val_accuracy: 0.8484\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0215 - accuracy: 0.9975 - val_loss: 0.4694 - val_accuracy: 0.8767\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.6274 - val_accuracy: 0.8462\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 0.7107 - val_accuracy: 0.8484\n","Epoch 47/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0355 - accuracy: 0.9918 - val_loss: 0.6831 - val_accuracy: 0.8552\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0277 - accuracy: 0.9946 - val_loss: 0.4011 - val_accuracy: 0.8857\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9983 - val_loss: 0.5374 - val_accuracy: 0.8688\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.4328 - val_accuracy: 0.8971\n","Epoch 51/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0141 - accuracy: 0.9992 - val_loss: 0.4756 - val_accuracy: 0.8857\n","Epoch 52/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0177 - accuracy: 0.9977 - val_loss: 0.5442 - val_accuracy: 0.8812\n","Epoch 53/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0181 - accuracy: 0.9975 - val_loss: 0.5298 - val_accuracy: 0.8710\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0170 - accuracy: 0.9980 - val_loss: 0.5415 - val_accuracy: 0.8846\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0128 - accuracy: 0.9997 - val_loss: 0.4776 - val_accuracy: 0.8982\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.8925\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.8914\n","Epoch 58/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8982\n","Epoch 59/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8993\n","Epoch 60/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9005\n","Epoch 61/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9038\n","Epoch 62/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9016\n","Epoch 63/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9016\n","Epoch 64/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9027\n","Epoch 65/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9038\n","Epoch 66/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9061\n","Epoch 67/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9061\n","Epoch 68/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9061\n","Epoch 69/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9050\n","Epoch 70/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9050\n","Epoch 71/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9061\n","Epoch 72/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9061\n","Epoch 73/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9050\n","Epoch 74/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9050\n","Epoch 75/100\n","28/28 [==============================] - 2s 71ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9072\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9061\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9061\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.9050\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.9038\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9061\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9072\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9072\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9072\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.9072\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9050\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9072\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9072\n","Epoch 88/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9084\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9061\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9072\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9072\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9072\n","Epoch 93/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9072\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.9084\n","Epoch 95/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9095\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9095\n","Epoch 97/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9072\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9072\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9072\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9072\n","{'loss': [0.07497130334377289, 0.03972760960459709, 0.02578275464475155, 0.027931153774261475, 0.025368407368659973, 0.06039026379585266, 0.05978379771113396, 0.036488328129053116, 0.022567827254533768, 0.018417341634631157, 0.016597894951701164, 0.04948287457227707, 0.05629502609372139, 0.033477265387773514, 0.02175120823085308, 0.021937210112810135, 0.03096707910299301, 0.026477530598640442, 0.026752054691314697, 0.024315549060702324, 0.02900116518139839, 0.02101326361298561, 0.016720615327358246, 0.02038748189806938, 0.02852724865078926, 0.09364362061023712, 0.048736684024333954, 0.02235371060669422, 0.017331309616565704, 0.018220849335193634, 0.01809781789779663, 0.01946897618472576, 0.022589189931750298, 0.019627969712018967, 0.019933147355914116, 0.017601599916815758, 0.013706459663808346, 0.013055596500635147, 0.014204288832843304, 0.06129969656467438, 0.0793859213590622, 0.029875611886382103, 0.02991545759141445, 0.021512284874916077, 0.02263367548584938, 0.03771180287003517, 0.035490717738866806, 0.027677077800035477, 0.017790814861655235, 0.01821068301796913, 0.014073251746594906, 0.017714353278279305, 0.018138298764824867, 0.017000794410705566, 0.012754173949360847, 0.011636209674179554, 0.011398409493267536, 0.011075275018811226, 0.010975680314004421, 0.010900542140007019, 0.010835239663720131, 0.010782033205032349, 0.010720038786530495, 0.010664192028343678, 0.010594796389341354, 0.010557121597230434, 0.010499710217118263, 0.010450342670083046, 0.01041514053940773, 0.010361763648688793, 0.010324900969862938, 0.010271603241562843, 0.010232247412204742, 0.010187631472945213, 0.010146643966436386, 0.01010710746049881, 0.010068332776427269, 0.010022979229688644, 0.009991543367505074, 0.009943097829818726, 0.009909220971167088, 0.00986799318343401, 0.009820650331676006, 0.009785364381968975, 0.00975240208208561, 0.00971030443906784, 0.009670352563261986, 0.009642360731959343, 0.009598982520401478, 0.009563003666698933, 0.009536324068903923, 0.009487089700996876, 0.009450389072299004, 0.009410184808075428, 0.009387197904288769, 0.009341295808553696, 0.00930503848940134, 0.009273584000766277, 0.009231834672391415, 0.009192977100610733], 'accuracy': [0.9813242554664612, 0.9912280440330505, 0.9949066042900085, 0.9946236610412598, 0.9946236610412598, 0.9818902015686035, 0.9850028157234192, 0.9909451007843018, 0.996321439743042, 0.9971703290939331, 0.9988681674003601, 0.9847198724746704, 0.9827390909194946, 0.9934917688369751, 0.9980192184448242, 0.9954725503921509, 0.9920769929885864, 0.9949066042900085, 0.9940577149391174, 0.9951896071434021, 0.9940577149391174, 0.9968873858451843, 0.9988681674003601, 0.9971703290939331, 0.9934917688369751, 0.9702886343002319, 0.986983597278595, 0.9971703290939331, 0.9985851645469666, 0.9974533319473267, 0.9980192184448242, 0.9974533319473267, 0.9968873858451843, 0.9968873858451843, 0.9977362751960754, 0.9985851645469666, 1.0, 1.0, 0.9994340538978577, 0.9810413122177124, 0.9734012484550476, 0.9937747716903687, 0.9923599362373352, 0.9974533319473267, 0.996321439743042, 0.9903791546821594, 0.9917939901351929, 0.9946236610412598, 0.9983022212982178, 0.9974533319473267, 0.9991511106491089, 0.9977362751960754, 0.9974533319473267, 0.9980192184448242, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6914114356040955, 0.6817989945411682, 0.6688908338546753, 0.6476297378540039, 0.6285083889961243, 0.6216506361961365, 0.6051788926124573, 0.5681667327880859, 0.5224577188491821, 0.506438672542572, 0.47616496682167053, 0.4803396165370941, 0.4569433629512787, 0.43914854526519775, 0.43930909037590027, 0.505459189414978, 0.4633655846118927, 0.5340696573257446, 0.4741697609424591, 0.4593229591846466, 0.4359073340892792, 0.4145002067089081, 0.4318423867225647, 0.57315593957901, 0.4556838274002075, 0.7465060949325562, 0.47004932165145874, 0.3469615578651428, 0.40898409485816956, 0.4600221812725067, 0.4546325206756592, 0.45426347851753235, 0.6075469851493835, 0.5083262324333191, 0.5274873971939087, 0.4788581132888794, 0.4554324746131897, 0.4520896077156067, 0.5186916589736938, 0.7745133638381958, 0.4630017876625061, 0.40417373180389404, 0.6031924486160278, 0.46942922472953796, 0.6273509860038757, 0.7106875777244568, 0.6830673813819885, 0.4010995924472809, 0.5373645424842834, 0.4327586889266968, 0.4756484925746918, 0.5441680550575256, 0.5297632217407227, 0.541534423828125, 0.4775697886943817, 0.5310187935829163, 0.47039511799812317, 0.45884624123573303, 0.4476063847541809, 0.4412004351615906, 0.44091156125068665, 0.4369378089904785, 0.43581223487854004, 0.4305780231952667, 0.4284902811050415, 0.42607203125953674, 0.42413273453712463, 0.4213069677352905, 0.42287448048591614, 0.4208860695362091, 0.4182451069355011, 0.41560670733451843, 0.4158480167388916, 0.4149378538131714, 0.4133152961730957, 0.411704421043396, 0.41516295075416565, 0.4124889075756073, 0.40990540385246277, 0.41016557812690735, 0.40932849049568176, 0.40810054540634155, 0.4063935875892639, 0.4076818525791168, 0.40649303793907166, 0.41036084294319153, 0.40584567189216614, 0.40402013063430786, 0.40284836292266846, 0.4042530059814453, 0.40053796768188477, 0.400174081325531, 0.39934825897216797, 0.3994135558605194, 0.3997299373149872, 0.39694347977638245, 0.3980056941509247, 0.39792320132255554, 0.39653825759887695, 0.396761029958725], 'val_accuracy': [0.5079185366630554, 0.5735294222831726, 0.6640271544456482, 0.7171945571899414, 0.7013574838638306, 0.7251130938529968, 0.7703620195388794, 0.7658371329307556, 0.7828054428100586, 0.7567873597145081, 0.7816742062568665, 0.7703620195388794, 0.7986425161361694, 0.7952488660812378, 0.8099547624588013, 0.773755669593811, 0.8054298758506775, 0.8009049892425537, 0.8178732991218567, 0.8303167223930359, 0.8518099784851074, 0.8585972785949707, 0.8857465982437134, 0.8552036285400391, 0.8733031749725342, 0.7850678563117981, 0.8552036285400391, 0.9038461446762085, 0.8993212580680847, 0.8812217116355896, 0.8981900215148926, 0.8959276080131531, 0.8574660420417786, 0.8868778347969055, 0.8812217116355896, 0.8880090713500977, 0.9004524946212769, 0.9061086177825928, 0.8947963714599609, 0.8178732991218567, 0.8597285151481628, 0.8880090713500977, 0.848416268825531, 0.8766968250274658, 0.8461538553237915, 0.848416268825531, 0.8552036285400391, 0.8857465982437134, 0.8687782883644104, 0.8970588445663452, 0.8857465982437134, 0.8812217116355896, 0.8710407018661499, 0.8846153616905212, 0.8981900215148926, 0.8925339579582214, 0.8914027214050293, 0.8981900215148926, 0.8993212580680847, 0.9004524946212769, 0.9038461446762085, 0.901583731174469, 0.901583731174469, 0.9027149081230164, 0.9038461446762085, 0.9061086177825928, 0.9061086177825928, 0.9061086177825928, 0.9049773812294006, 0.9049773812294006, 0.9061086177825928, 0.9061086177825928, 0.9049773812294006, 0.9049773812294006, 0.9072397947311401, 0.9061086177825928, 0.9061086177825928, 0.9049773812294006, 0.9038461446762085, 0.9061086177825928, 0.9072397947311401, 0.9072397947311401, 0.9072397947311401, 0.9072397947311401, 0.9049773812294006, 0.9072397947311401, 0.9072397947311401, 0.9083710312843323, 0.9061086177825928, 0.9072397947311401, 0.9072397947311401, 0.9072397947311401, 0.9072397947311401, 0.9083710312843323, 0.9095022678375244, 0.9095022678375244, 0.9072397947311401, 0.9072397947311401, 0.9072397947311401, 0.9072397947311401]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9695"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 11s 123ms/step - loss: 0.0909 - accuracy: 0.9698 - val_loss: 0.6941 - val_accuracy: 0.5072\n","Epoch 2/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0370 - accuracy: 0.9930 - val_loss: 0.6858 - val_accuracy: 0.5713\n","Epoch 3/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.0329 - accuracy: 0.9938 - val_loss: 0.6688 - val_accuracy: 0.5909\n","Epoch 4/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0418 - accuracy: 0.9891 - val_loss: 0.6524 - val_accuracy: 0.7200\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9853 - val_loss: 0.6320 - val_accuracy: 0.7510\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0327 - accuracy: 0.9930 - val_loss: 0.5969 - val_accuracy: 0.7397\n","Epoch 7/100\n","31/31 [==============================] - 1s 40ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.5639 - val_accuracy: 0.7614\n","Epoch 8/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0649 - accuracy: 0.9801 - val_loss: 0.5691 - val_accuracy: 0.7355\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0729 - accuracy: 0.9760 - val_loss: 0.5561 - val_accuracy: 0.7448\n","Epoch 10/100\n","31/31 [==============================] - 1s 43ms/step - loss: 0.0251 - accuracy: 0.9964 - val_loss: 0.5018 - val_accuracy: 0.7841\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0168 - accuracy: 0.9987 - val_loss: 0.4707 - val_accuracy: 0.7707\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 0.4498 - val_accuracy: 0.7789\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0360 - accuracy: 0.9920 - val_loss: 0.4720 - val_accuracy: 0.7686\n","Epoch 14/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0528 - accuracy: 0.9853 - val_loss: 0.4695 - val_accuracy: 0.7748\n","Epoch 15/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.0430 - accuracy: 0.9871 - val_loss: 0.4492 - val_accuracy: 0.7862\n","Epoch 16/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0631 - accuracy: 0.9817 - val_loss: 0.4202 - val_accuracy: 0.8171\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0822 - accuracy: 0.9755 - val_loss: 0.4485 - val_accuracy: 0.8017\n","Epoch 18/100\n","31/31 [==============================] - 1s 46ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 0.4238 - val_accuracy: 0.8233\n","Epoch 19/100\n","31/31 [==============================] - 1s 41ms/step - loss: 0.0248 - accuracy: 0.9951 - val_loss: 0.4584 - val_accuracy: 0.8419\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.5554 - val_accuracy: 0.8151\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0307 - accuracy: 0.9922 - val_loss: 0.5498 - val_accuracy: 0.8388\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0230 - accuracy: 0.9972 - val_loss: 0.5278 - val_accuracy: 0.8471\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0177 - accuracy: 0.9982 - val_loss: 0.6132 - val_accuracy: 0.8502\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0164 - accuracy: 0.9987 - val_loss: 0.5664 - val_accuracy: 0.8543\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9987 - val_loss: 0.6617 - val_accuracy: 0.8533\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 0.8284 - val_accuracy: 0.8316\n","Epoch 27/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0203 - accuracy: 0.9977 - val_loss: 0.5365 - val_accuracy: 0.8781\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.8678\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.8791\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8781\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 0.8750\n","Epoch 32/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.8812\n","Epoch 33/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.8750\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.8771\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8791\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.8781\n","Epoch 37/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5898 - val_accuracy: 0.8802\n","Epoch 38/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.8781\n","Epoch 39/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8771\n","Epoch 40/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.8760\n","Epoch 41/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5903 - val_accuracy: 0.8781\n","Epoch 42/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5992 - val_accuracy: 0.8760\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.8740\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.8802\n","Epoch 45/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.8822\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8760\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8802\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.8802\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8791\n","Epoch 50/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.8791\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.8781\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.8771\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.8791\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.8781\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.8771\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.8750\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.8750\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.8760\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5859 - val_accuracy: 0.8791\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.8791\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.8760\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 0.8719\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.8760\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.8781\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.8781\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.8781\n","Epoch 67/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5802 - val_accuracy: 0.8771\n","Epoch 68/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.8750\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.8771\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8771\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8760\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5794 - val_accuracy: 0.8760\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.8760\n","Epoch 74/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5900 - val_accuracy: 0.8760\n","Epoch 75/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.8740\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.8729\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.8750\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.8740\n","Epoch 79/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8750\n","Epoch 80/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5904 - val_accuracy: 0.8750\n","Epoch 81/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.8719\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.8750\n","Epoch 83/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5906 - val_accuracy: 0.8740\n","Epoch 84/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.8740\n","Epoch 85/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5944 - val_accuracy: 0.8760\n","Epoch 86/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 0.8740\n","Epoch 87/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.8729\n","Epoch 88/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.8760\n","Epoch 89/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8760\n","Epoch 90/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5953 - val_accuracy: 0.8740\n","Epoch 91/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5965 - val_accuracy: 0.8729\n","Epoch 92/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.8729\n","Epoch 93/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.8698\n","Epoch 94/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8729\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5932 - val_accuracy: 0.8750\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.8740\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6042 - val_accuracy: 0.8688\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6042 - val_accuracy: 0.8698\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.8719\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8729\n","{'loss': [0.09085919708013535, 0.03695333003997803, 0.03294600918889046, 0.04183484986424446, 0.050785791128873825, 0.03272175416350365, 0.03694029524922371, 0.06485559046268463, 0.07286140322685242, 0.025082262232899666, 0.016830775886774063, 0.019759396091103554, 0.0359644740819931, 0.05275348201394081, 0.042977139353752136, 0.06311299651861191, 0.08219259977340698, 0.037149492651224136, 0.024815576151013374, 0.030698763206601143, 0.03068923018872738, 0.02300843596458435, 0.017650380730628967, 0.016365686431527138, 0.01615106873214245, 0.01975242979824543, 0.02026435174047947, 0.013156050816178322, 0.012488339096307755, 0.012165593914687634, 0.012068483978509903, 0.01197551004588604, 0.011876239441335201, 0.011792991310358047, 0.011734714731574059, 0.011647723615169525, 0.011567983776330948, 0.011502958834171295, 0.011435658670961857, 0.011388677172362804, 0.011304623447358608, 0.01125637348741293, 0.011195648461580276, 0.0111211147159338, 0.011105171404778957, 0.011018245480954647, 0.010974637232720852, 0.010900553315877914, 0.0108460308983922, 0.010787147097289562, 0.010751419700682163, 0.0106977429240942, 0.010629089549183846, 0.010574917308986187, 0.01052562054246664, 0.010470742359757423, 0.010445702821016312, 0.010384448803961277, 0.010339867323637009, 0.010283108800649643, 0.010233892127871513, 0.010213951580226421, 0.010185686871409416, 0.010107893496751785, 0.01004452258348465, 0.00999806821346283, 0.00995058286935091, 0.009894407354295254, 0.009861755184829235, 0.009797202423214912, 0.009749806486070156, 0.009721246547996998, 0.009679452516138554, 0.009620212018489838, 0.009570058435201645, 0.009524133987724781, 0.009465523064136505, 0.009434794075787067, 0.009388015605509281, 0.009347195737063885, 0.009295347146689892, 0.009261608123779297, 0.009210408665239811, 0.009160255081951618, 0.009131561033427715, 0.00907924771308899, 0.009032497182488441, 0.008995268493890762, 0.008956117555499077, 0.008897433988749981, 0.008856040425598621, 0.008818666450679302, 0.008768943138420582, 0.008720556274056435, 0.008692039176821709, 0.00865898560732603, 0.008611263707280159, 0.00856321956962347, 0.008522403426468372, 0.008485047146677971], 'accuracy': [0.9697674512863159, 0.9930232763290405, 0.9937984347343445, 0.9891473054885864, 0.9852713346481323, 0.9930232763290405, 0.9912144541740417, 0.9801033735275269, 0.9759690165519714, 0.9963824152946472, 0.9987080097198486, 0.9979327917098999, 0.9919896721839905, 0.9852713346481323, 0.9870800971984863, 0.9816537499427795, 0.975452184677124, 0.9912144541740417, 0.9950904250144958, 0.9927648305892944, 0.9922480583190918, 0.997157633304596, 0.998191237449646, 0.9987080097198486, 0.9987080097198486, 0.9979327917098999, 0.9976744055747986, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6941066980361938, 0.6858167052268982, 0.6688130497932434, 0.652358889579773, 0.6320107579231262, 0.5969168543815613, 0.5638913512229919, 0.5691196918487549, 0.5560821294784546, 0.5017891526222229, 0.4707474410533905, 0.4497607350349426, 0.47197213768959045, 0.46950024366378784, 0.44921422004699707, 0.4202435314655304, 0.4484897553920746, 0.42381614446640015, 0.4583512842655182, 0.5554490089416504, 0.5497720837593079, 0.5277999043464661, 0.6131688952445984, 0.5663861632347107, 0.6617003679275513, 0.8284236192703247, 0.5365347266197205, 0.606692910194397, 0.59009850025177, 0.599372148513794, 0.5986502170562744, 0.5972301363945007, 0.6028743982315063, 0.6018055081367493, 0.5904825925827026, 0.5999118685722351, 0.5898119807243347, 0.5914825201034546, 0.5885164737701416, 0.5882698893547058, 0.5903003811836243, 0.5992143750190735, 0.600734293460846, 0.5921902656555176, 0.5823519825935364, 0.5876128077507019, 0.5791165828704834, 0.5804997086524963, 0.5770948529243469, 0.5828123688697815, 0.5850217938423157, 0.5831268429756165, 0.5819326639175415, 0.5813416838645935, 0.58167564868927, 0.5772597789764404, 0.583370566368103, 0.5781329274177551, 0.5859169363975525, 0.5839935541152954, 0.5918208360671997, 0.5865346193313599, 0.5918625593185425, 0.5846981406211853, 0.5839176774024963, 0.5817275047302246, 0.5801748633384705, 0.5816555619239807, 0.5872002243995667, 0.58670574426651, 0.5866563320159912, 0.5794438123703003, 0.5933949947357178, 0.5899837017059326, 0.5938461422920227, 0.5916938185691833, 0.5884259939193726, 0.586265504360199, 0.5869020819664001, 0.5903654098510742, 0.5939288139343262, 0.5924974083900452, 0.5906128287315369, 0.5897179245948792, 0.594407856464386, 0.5931252241134644, 0.5915295481681824, 0.598844587802887, 0.5935078263282776, 0.5953388810157776, 0.5965045690536499, 0.5929442048072815, 0.5982735753059387, 0.5972591638565063, 0.5931808948516846, 0.6089207530021667, 0.6042487025260925, 0.6041924357414246, 0.6087946891784668, 0.6056113243103027], 'val_accuracy': [0.5072314143180847, 0.5712810158729553, 0.5909090638160706, 0.7200413346290588, 0.7510330677032471, 0.7396694421768188, 0.7613636255264282, 0.7355371713638306, 0.7448347210884094, 0.7840909361839294, 0.7706611752510071, 0.7789255976676941, 0.7685950398445129, 0.7747933864593506, 0.7861570119857788, 0.817148745059967, 0.8016529083251953, 0.8233470916748047, 0.8419421315193176, 0.8150826692581177, 0.8388429880142212, 0.8471074104309082, 0.8502066135406494, 0.8543388247489929, 0.8533057570457458, 0.8316115736961365, 0.8780992031097412, 0.8677685856819153, 0.8791322112083435, 0.8780992031097412, 0.875, 0.8811983466148376, 0.875, 0.8770661354064941, 0.8791322112083435, 0.8780992031097412, 0.8801652789115906, 0.8780992031097412, 0.8770661354064941, 0.8760330677032471, 0.8780992031097412, 0.8760330677032471, 0.8739669322967529, 0.8801652789115906, 0.8822314143180847, 0.8760330677032471, 0.8801652789115906, 0.8801652789115906, 0.8791322112083435, 0.8791322112083435, 0.8780992031097412, 0.8770661354064941, 0.8791322112083435, 0.8780992031097412, 0.8770661354064941, 0.875, 0.875, 0.8760330677032471, 0.8791322112083435, 0.8791322112083435, 0.8760330677032471, 0.8719007968902588, 0.8760330677032471, 0.8780992031097412, 0.8780992031097412, 0.8780992031097412, 0.8770661354064941, 0.875, 0.8770661354064941, 0.8770661354064941, 0.8760330677032471, 0.8760330677032471, 0.8760330677032471, 0.8760330677032471, 0.8739669322967529, 0.8729338645935059, 0.875, 0.8739669322967529, 0.875, 0.875, 0.8719007968902588, 0.875, 0.8739669322967529, 0.8739669322967529, 0.8760330677032471, 0.8739669322967529, 0.8729338645935059, 0.8760330677032471, 0.8760330677032471, 0.8739669322967529, 0.8729338645935059, 0.8729338645935059, 0.8698347210884094, 0.8729338645935059, 0.875, 0.8739669322967529, 0.8688016533851624, 0.8698347210884094, 0.8719007968902588, 0.8729338645935059]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.0698 - accuracy: 0.9805"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 51ms/step - loss: 0.0689 - accuracy: 0.9806 - val_loss: 0.6869 - val_accuracy: 0.6412\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.6774 - val_accuracy: 0.6541\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0183 - accuracy: 0.9973 - val_loss: 0.6619 - val_accuracy: 0.6972\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0159 - accuracy: 0.9978 - val_loss: 0.6417 - val_accuracy: 0.7241\n","Epoch 5/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0112 - accuracy: 0.9997 - val_loss: 0.6149 - val_accuracy: 0.7640\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.7565\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.7888\n","Epoch 8/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7974\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.8006\n","Epoch 10/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.8039\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.8125\n","Epoch 12/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8190\n","Epoch 13/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.8308\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.8524\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.8588\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.8707\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.8879\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9062\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9138\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9192\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9289\n","Epoch 22/100\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9418\n","Epoch 23/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9461\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9418\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9450\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9461\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9450\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9440\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9440\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9461\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9440\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9461\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9461\n","Epoch 34/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9461\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9461\n","Epoch 36/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9472\n","Epoch 37/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9472\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9461\n","Epoch 39/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9494\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9483\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9483\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9440\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9440\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9461\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9461\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9483\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9472\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9450\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9450\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9461\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9461\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9483\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9483\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9494\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9483\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9494\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9483\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9494\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9483\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9472\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9494\n","Epoch 62/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9504\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9483\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9472\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9504\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9483\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9494\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9472\n","Epoch 69/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9494\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9483\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9483\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9450\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9472\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9494\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9504\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9494\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9504\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9483\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9472\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9494\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9461\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9472\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9483\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9483\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9494\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9504\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9494\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9472\n","Epoch 89/100\n","29/29 [==============================] - 2s 67ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9515\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9494\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9483\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9504\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9494\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9504\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9483\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9483\n","Epoch 97/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9526\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9461\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9494\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9483\n","{'loss': [0.06894170492887497, 0.03483516722917557, 0.018326157703995705, 0.01591171883046627, 0.011150888167321682, 0.01008293405175209, 0.00940640363842249, 0.009124607779085636, 0.008980482816696167, 0.008928677998483181, 0.0089098596945405, 0.008864929899573326, 0.008827746845781803, 0.008801708929240704, 0.008755949325859547, 0.008722053840756416, 0.00870493333786726, 0.00867958553135395, 0.008625050075352192, 0.0086051682010293, 0.008572826161980629, 0.008554198779165745, 0.008527612313628197, 0.008489557541906834, 0.00847103912383318, 0.008436577394604683, 0.008409904316067696, 0.008374195545911789, 0.008349920623004436, 0.008327731862664223, 0.008302845060825348, 0.008268612436950207, 0.008237145841121674, 0.008221949450671673, 0.008184506557881832, 0.008154494687914848, 0.008129507303237915, 0.008099249564111233, 0.008081158623099327, 0.008036798797547817, 0.00801340863108635, 0.007998427376151085, 0.007965278811752796, 0.007938340306282043, 0.007910951040685177, 0.007883773185312748, 0.007863391190767288, 0.007846961729228497, 0.007813451811671257, 0.007781181484460831, 0.007751675322651863, 0.007729670498520136, 0.007701199036091566, 0.0076765562407672405, 0.007645617239177227, 0.007628237828612328, 0.0075994450598955154, 0.007570471614599228, 0.007545862812548876, 0.007524522021412849, 0.007496264763176441, 0.007471464108675718, 0.007446864619851112, 0.007422934286296368, 0.007395777851343155, 0.007371796760708094, 0.0073476796969771385, 0.00732201524078846, 0.007300007157027721, 0.0072761718183755875, 0.007249411195516586, 0.0072319647297263145, 0.007207046262919903, 0.007183292880654335, 0.007158955093473196, 0.00713586900383234, 0.007111378479748964, 0.007091462146490812, 0.007070639170706272, 0.007049656938761473, 0.0070244381204247475, 0.007002620957791805, 0.00698379660025239, 0.006959331221878529, 0.006938019301742315, 0.006918848026543856, 0.006898128893226385, 0.00688075041398406, 0.0068564326502382755, 0.006839177571237087, 0.006818708963692188, 0.006799299735575914, 0.006782095413655043, 0.006759883835911751, 0.00674346461892128, 0.006722981110215187, 0.0067140948958694935, 0.006701435428112745, 0.006677309516817331, 0.006652250420302153], 'accuracy': [0.9806034564971924, 0.9900323152542114, 0.9973060488700867, 0.9978448152542114, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6869494318962097, 0.6773836612701416, 0.6619049310684204, 0.6416782736778259, 0.6149078607559204, 0.5870518088340759, 0.5447990298271179, 0.5084594488143921, 0.4738729000091553, 0.4442732632160187, 0.4167580008506775, 0.39603284001350403, 0.3710991144180298, 0.34945350885391235, 0.34295088052749634, 0.3260264992713928, 0.3190250098705292, 0.29669034481048584, 0.28392261266708374, 0.26470521092414856, 0.24583759903907776, 0.2392105907201767, 0.23526395857334137, 0.23172642290592194, 0.2316972315311432, 0.2348906695842743, 0.23377278447151184, 0.23521788418293, 0.23844704031944275, 0.24024298787117004, 0.239080548286438, 0.2407504916191101, 0.24052560329437256, 0.24263331294059753, 0.2425030618906021, 0.24375763535499573, 0.2438071370124817, 0.24320295453071594, 0.24359363317489624, 0.24454301595687866, 0.24406112730503082, 0.24742916226387024, 0.2458639144897461, 0.24550095200538635, 0.24246521294116974, 0.24251139163970947, 0.24380668997764587, 0.24528852105140686, 0.2457519769668579, 0.24645015597343445, 0.24544505774974823, 0.24429363012313843, 0.24424390494823456, 0.2446417510509491, 0.2440374791622162, 0.24393361806869507, 0.24381083250045776, 0.24523279070854187, 0.24559175968170166, 0.24728572368621826, 0.24627265334129333, 0.24613997340202332, 0.24799767136573792, 0.24893656373023987, 0.247931569814682, 0.24833188951015472, 0.24877408146858215, 0.24872568249702454, 0.24975711107254028, 0.24999114871025085, 0.25057604908943176, 0.25249284505844116, 0.25125062465667725, 0.25098687410354614, 0.24930378794670105, 0.2511509656906128, 0.2490060031414032, 0.24946053326129913, 0.2515123188495636, 0.25001299381256104, 0.24868378043174744, 0.24952886998653412, 0.24945014715194702, 0.2487557977437973, 0.24875667691230774, 0.2500661611557007, 0.2530108690261841, 0.2541348338127136, 0.251979261636734, 0.25349029898643494, 0.25418227910995483, 0.24986505508422852, 0.2525128424167633, 0.2505953907966614, 0.254085898399353, 0.25661900639533997, 0.2549934983253479, 0.2591322958469391, 0.25851529836654663, 0.2573905885219574], 'val_accuracy': [0.6411637663841248, 0.6540948152542114, 0.6971982717514038, 0.7241379022598267, 0.764008641242981, 0.756465494632721, 0.7887930870056152, 0.7974137663841248, 0.8006465435028076, 0.8038793206214905, 0.8125, 0.818965494632721, 0.8308189511299133, 0.8523706793785095, 0.8588362336158752, 0.8706896305084229, 0.8879310488700867, 0.90625, 0.9137930870056152, 0.9191810488700867, 0.9288793206214905, 0.9418103694915771, 0.9461206793785095, 0.9418103694915771, 0.9450430870056152, 0.9461206793785095, 0.9450430870056152, 0.943965494632721, 0.943965494632721, 0.9461206793785095, 0.943965494632721, 0.9461206793785095, 0.9461206793785095, 0.9461206793785095, 0.9461206793785095, 0.9471982717514038, 0.9471982717514038, 0.9461206793785095, 0.9493534564971924, 0.9482758641242981, 0.9482758641242981, 0.943965494632721, 0.943965494632721, 0.9461206793785095, 0.9461206793785095, 0.9482758641242981, 0.9471982717514038, 0.9450430870056152, 0.9450430870056152, 0.9461206793785095, 0.9461206793785095, 0.9482758641242981, 0.9482758641242981, 0.9493534564971924, 0.9482758641242981, 0.9493534564971924, 0.9482758641242981, 0.9493534564971924, 0.9482758641242981, 0.9471982717514038, 0.9493534564971924, 0.9504310488700867, 0.9482758641242981, 0.9471982717514038, 0.9504310488700867, 0.9482758641242981, 0.9493534564971924, 0.9471982717514038, 0.9493534564971924, 0.9482758641242981, 0.9482758641242981, 0.9450430870056152, 0.9471982717514038, 0.9493534564971924, 0.9504310488700867, 0.9493534564971924, 0.9504310488700867, 0.9482758641242981, 0.9471982717514038, 0.9493534564971924, 0.9461206793785095, 0.9471982717514038, 0.9482758641242981, 0.9482758641242981, 0.9493534564971924, 0.9504310488700867, 0.9493534564971924, 0.9471982717514038, 0.951508641242981, 0.9493534564971924, 0.9482758641242981, 0.9504310488700867, 0.9493534564971924, 0.9504310488700867, 0.9482758641242981, 0.9482758641242981, 0.9525862336158752, 0.9461206793785095, 0.9493534564971924, 0.9482758641242981]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.0552 - accuracy: 0.9838"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 56ms/step - loss: 0.0544 - accuracy: 0.9842 - val_loss: 0.6837 - val_accuracy: 0.6143\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 0.6729 - val_accuracy: 0.7002\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0243 - accuracy: 0.9943 - val_loss: 0.6616 - val_accuracy: 0.7534\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.6406 - val_accuracy: 0.6799\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9963 - val_loss: 0.6202 - val_accuracy: 0.7093\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.5987 - val_accuracy: 0.7398\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.6025 - val_accuracy: 0.7081\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0273 - accuracy: 0.9943 - val_loss: 0.5621 - val_accuracy: 0.7149\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 0.5040 - val_accuracy: 0.7817\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.8179\n","Epoch 11/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8281\n","Epoch 12/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.8360\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.8371\n","Epoch 14/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.8439\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.8439\n","Epoch 16/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.8597\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.8699\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.8767\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.8993\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9016\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9140\n","Epoch 22/100\n","28/28 [==============================] - 3s 92ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9197\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9253\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9367\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9412\n","Epoch 26/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9423\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9412\n","Epoch 28/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9446\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9446\n","Epoch 30/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9468\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9446\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9446\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9468\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9446\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9468\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9457\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9446\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9412\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9423\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9434\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9434\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9434\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9423\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9423\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9423\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9446\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9434\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9434\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9446\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9423\n","Epoch 51/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9457\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9457\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9468\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9457\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9446\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9457\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9457\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9446\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9468\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9457\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9446\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9457\n","Epoch 63/100\n","28/28 [==============================] - 1s 45ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9457\n","Epoch 64/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9446\n","Epoch 65/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9446\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9446\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9457\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9457\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9446\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9468\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9457\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9457\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9468\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9457\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9468\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9468\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9468\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9468\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9457\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9457\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9457\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9434\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9446\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9446\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9457\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9457\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9457\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9468\n","Epoch 89/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9457\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9468\n","Epoch 91/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9468\n","Epoch 92/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9468\n","Epoch 93/100\n","28/28 [==============================] - 2s 73ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9480\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9468\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9468\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9468\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9434\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9468\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9457\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9446\n","{'loss': [0.0543903149664402, 0.026965929195284843, 0.02425592578947544, 0.01529405266046524, 0.020060665905475616, 0.030636388808488846, 0.03951715677976608, 0.02728160098195076, 0.012351058423519135, 0.009648626670241356, 0.009152374230325222, 0.00900724995881319, 0.00896396767348051, 0.008888725191354752, 0.008879405446350574, 0.008829166181385517, 0.008814193308353424, 0.008745066821575165, 0.00871436856687069, 0.00873221829533577, 0.008656415157020092, 0.008610107935965061, 0.008611371740698814, 0.008558831177651882, 0.008531494066119194, 0.008498771116137505, 0.008467255160212517, 0.008446457795798779, 0.0084140719845891, 0.008388321846723557, 0.0083897914737463, 0.008336211554706097, 0.008305730298161507, 0.008288975805044174, 0.008265268988907337, 0.008229650557041168, 0.00819606427103281, 0.008167942985892296, 0.008145580068230629, 0.008112474344670773, 0.008092982694506645, 0.008063058368861675, 0.00803818553686142, 0.008020123466849327, 0.007990427315235138, 0.007959806360304356, 0.007934549823403358, 0.00791244674474001, 0.007880302146077156, 0.007855604402720928, 0.007836262695491314, 0.00781428162008524, 0.007782313972711563, 0.007759982254356146, 0.007738164626061916, 0.007717883214354515, 0.007688511628657579, 0.007664785720407963, 0.0076453122310340405, 0.007615568116307259, 0.007589411456137896, 0.007571995258331299, 0.007542417850345373, 0.007520091254264116, 0.007494723424315453, 0.007471379358321428, 0.007445885334163904, 0.007424389012157917, 0.007397896144539118, 0.007378360256552696, 0.007355551701039076, 0.007330345921218395, 0.007305270526558161, 0.007285811007022858, 0.007264057174324989, 0.0072435038164258, 0.007223437074571848, 0.007195281330496073, 0.007173565682023764, 0.007149008102715015, 0.007127856835722923, 0.007108705583959818, 0.0070884944871068, 0.007067055907100439, 0.0070404852740466595, 0.007019514683634043, 0.0070009478367865086, 0.0069813961163163185, 0.006957142613828182, 0.006940154824405909, 0.006919654086232185, 0.006899471394717693, 0.006883560214191675, 0.006865008268505335, 0.006839989218860865, 0.006823128554970026, 0.006802805699408054, 0.00678457273170352, 0.006764423102140427, 0.006748495157808065], 'accuracy': [0.9841539263725281, 0.9937747716903687, 0.994340717792511, 0.9974533319473267, 0.996321439743042, 0.9915110468864441, 0.9883984327316284, 0.994340717792511, 0.9991511106491089, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.683740496635437, 0.672921895980835, 0.6616455316543579, 0.6405764818191528, 0.6202070713043213, 0.5987080931663513, 0.6024922728538513, 0.5621129274368286, 0.5039905905723572, 0.4489421844482422, 0.4132239520549774, 0.39095982909202576, 0.37617284059524536, 0.3662126064300537, 0.3642064034938812, 0.35321253538131714, 0.34838345646858215, 0.3422790765762329, 0.31647565960884094, 0.3198521137237549, 0.29716047644615173, 0.2805272042751312, 0.2667631208896637, 0.2513335943222046, 0.2433941662311554, 0.24122075736522675, 0.23936697840690613, 0.23961664736270905, 0.23938128352165222, 0.2414652556180954, 0.2532429099082947, 0.25026991963386536, 0.25089091062545776, 0.2513923943042755, 0.25050097703933716, 0.24816489219665527, 0.25303786993026733, 0.25223684310913086, 0.254319965839386, 0.25258731842041016, 0.2523469626903534, 0.25147390365600586, 0.25522851943969727, 0.2552588880062103, 0.2533310353755951, 0.2539578974246979, 0.25097256898880005, 0.2528681457042694, 0.2524096369743347, 0.252469003200531, 0.25623607635498047, 0.25190916657447815, 0.2533878684043884, 0.2522239089012146, 0.25369516015052795, 0.2543087303638458, 0.25758281350135803, 0.25615251064300537, 0.2585460841655731, 0.25890907645225525, 0.26226094365119934, 0.26152852177619934, 0.25947415828704834, 0.2579702138900757, 0.25868353247642517, 0.2616082727909088, 0.2621230185031891, 0.2626391053199768, 0.26074644923210144, 0.2613639235496521, 0.2607104480266571, 0.26064160466194153, 0.2599177956581116, 0.26439210772514343, 0.26234331727027893, 0.26177576184272766, 0.2632003426551819, 0.2623389959335327, 0.26277750730514526, 0.2628543972969055, 0.2620939016342163, 0.2633829712867737, 0.2659565806388855, 0.2668309509754181, 0.26641038060188293, 0.2649592161178589, 0.26417142152786255, 0.26746994256973267, 0.26788780093193054, 0.26637449860572815, 0.266463041305542, 0.2671686112880707, 0.2627631425857544, 0.26723191142082214, 0.26811936497688293, 0.27072155475616455, 0.2722843289375305, 0.2712576985359192, 0.27003350853919983, 0.27269530296325684], 'val_accuracy': [0.6142534017562866, 0.7002262473106384, 0.7533936500549316, 0.679864227771759, 0.709276020526886, 0.7398189902305603, 0.7081447839736938, 0.7149321436882019, 0.7816742062568665, 0.8178732991218567, 0.8280543088912964, 0.8359728455543518, 0.837104082107544, 0.8438913822174072, 0.8438913822174072, 0.8597285151481628, 0.8699095249176025, 0.8766968250274658, 0.8993212580680847, 0.901583731174469, 0.9140271544456482, 0.9196832776069641, 0.9253393411636353, 0.9366515874862671, 0.9411764740943909, 0.942307710647583, 0.9411764740943909, 0.9445701241493225, 0.9445701241493225, 0.9468325972557068, 0.9445701241493225, 0.9445701241493225, 0.9468325972557068, 0.9445701241493225, 0.9468325972557068, 0.9457013607025146, 0.9445701241493225, 0.9411764740943909, 0.942307710647583, 0.9434388875961304, 0.9434388875961304, 0.9434388875961304, 0.942307710647583, 0.942307710647583, 0.942307710647583, 0.9445701241493225, 0.9434388875961304, 0.9434388875961304, 0.9445701241493225, 0.942307710647583, 0.9457013607025146, 0.9457013607025146, 0.9468325972557068, 0.9457013607025146, 0.9445701241493225, 0.9457013607025146, 0.9457013607025146, 0.9445701241493225, 0.9468325972557068, 0.9457013607025146, 0.9445701241493225, 0.9457013607025146, 0.9457013607025146, 0.9445701241493225, 0.9445701241493225, 0.9445701241493225, 0.9457013607025146, 0.9457013607025146, 0.9445701241493225, 0.9468325972557068, 0.9457013607025146, 0.9457013607025146, 0.9468325972557068, 0.9457013607025146, 0.9468325972557068, 0.9468325972557068, 0.9468325972557068, 0.9468325972557068, 0.9457013607025146, 0.9457013607025146, 0.9457013607025146, 0.9434388875961304, 0.9445701241493225, 0.9445701241493225, 0.9457013607025146, 0.9457013607025146, 0.9457013607025146, 0.9468325972557068, 0.9457013607025146, 0.9468325972557068, 0.9468325972557068, 0.9468325972557068, 0.9479637742042542, 0.9468325972557068, 0.9468325972557068, 0.9468325972557068, 0.9434388875961304, 0.9468325972557068, 0.9457013607025146, 0.9445701241493225]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9811"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 10s 53ms/step - loss: 0.0678 - accuracy: 0.9811 - val_loss: 0.6861 - val_accuracy: 0.5568\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0312 - accuracy: 0.9910 - val_loss: 0.6753 - val_accuracy: 0.6157\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0258 - accuracy: 0.9941 - val_loss: 0.6572 - val_accuracy: 0.6157\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0356 - accuracy: 0.9920 - val_loss: 0.6362 - val_accuracy: 0.7614\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0415 - accuracy: 0.9889 - val_loss: 0.6183 - val_accuracy: 0.7459\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0316 - accuracy: 0.9915 - val_loss: 0.5982 - val_accuracy: 0.7614\n","Epoch 7/100\n","31/31 [==============================] - 1s 45ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.5570 - val_accuracy: 0.7645\n","Epoch 8/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.5172 - val_accuracy: 0.7831\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0137 - accuracy: 0.9992 - val_loss: 0.4923 - val_accuracy: 0.7789\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.4648 - val_accuracy: 0.7924\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0504 - accuracy: 0.9835 - val_loss: 0.4733 - val_accuracy: 0.7758\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.4449 - val_accuracy: 0.7924\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 0.5371 - val_accuracy: 0.7211\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.6800 - val_accuracy: 0.6860\n","Epoch 15/100\n","31/31 [==============================] - 1s 40ms/step - loss: 0.0337 - accuracy: 0.9922 - val_loss: 0.4654 - val_accuracy: 0.7944\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: 0.4095 - val_accuracy: 0.8223\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0104 - accuracy: 0.9997 - val_loss: 0.3821 - val_accuracy: 0.8554\n","Epoch 18/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.8636\n","Epoch 19/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.8771\n","Epoch 20/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.8812\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8843\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.8884\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.8895\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.8884\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.8926\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.8936\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.8977\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.8957\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.8967\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.8977\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.8977\n","Epoch 32/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.8998\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.8988\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.8988\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.8998\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.8988\n","Epoch 37/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.8977\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8957\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8967\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8977\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8988\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.8998\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.8988\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.8988\n","Epoch 45/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9008\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.8998\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8998\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.8998\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.8998\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9019\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9019\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9008\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.8977\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.8977\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.9008\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.8967\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.8957\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.8977\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8967\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9019\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9019\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8967\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.8977\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.8998\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.8998\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.8998\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8998\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8977\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8988\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.8977\n","Epoch 71/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.8988\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.8977\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.8957\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8988\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.9008\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9008\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.8988\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.8998\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8988\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.8988\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.8988\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8977\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.8988\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.8988\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.8988\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.8988\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.8998\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.8988\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.8998\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.8998\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.8988\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8988\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.8998\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8988\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8967\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.8957\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.8977\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.8977\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.8998\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.8977\n","{'loss': [0.06775382161140442, 0.031244410201907158, 0.025777054950594902, 0.0356086865067482, 0.041473012417554855, 0.031585827469825745, 0.02290475368499756, 0.017473528161644936, 0.013684886507689953, 0.022891631349921227, 0.05035668984055519, 0.0437886081635952, 0.04470323026180267, 0.03598737344145775, 0.033695291727781296, 0.012895550578832626, 0.010382060892879963, 0.009202823042869568, 0.009247095324099064, 0.009053938090801239, 0.00902004074305296, 0.008942474611103535, 0.008882701396942139, 0.00884705688804388, 0.00881195068359375, 0.008771825581789017, 0.008758030831813812, 0.008709302172064781, 0.00869399681687355, 0.008645613677799702, 0.008618746884167194, 0.008581489324569702, 0.008567125536501408, 0.008530447259545326, 0.008519234135746956, 0.008569108322262764, 0.008462058380246162, 0.008449701592326164, 0.008412392809987068, 0.00838150829076767, 0.00835105124861002, 0.008330405689775944, 0.008293607272207737, 0.008286166936159134, 0.008263854309916496, 0.008238192647695541, 0.008208059705793858, 0.008177339099347591, 0.008168049156665802, 0.008134075440466404, 0.008108513429760933, 0.00809010211378336, 0.008072571828961372, 0.008041405119001865, 0.008028206415474415, 0.00800334382802248, 0.007975728251039982, 0.007951428182423115, 0.00793524645268917, 0.007906082086265087, 0.00787853728979826, 0.007863467559218407, 0.007830419577658176, 0.007819971069693565, 0.007787980604916811, 0.007768367882817984, 0.007746891118586063, 0.0077268448658287525, 0.007711962331086397, 0.0076798866502940655, 0.0076613714918494225, 0.007643508724868298, 0.007617657072842121, 0.007596035022288561, 0.007571894209831953, 0.007552271708846092, 0.007532136980444193, 0.007509191986173391, 0.007489742711186409, 0.007468098308891058, 0.007444013375788927, 0.007422286085784435, 0.0074035306461155415, 0.00738114770501852, 0.007360899820923805, 0.007347782142460346, 0.007323176134377718, 0.007303968537598848, 0.007280811667442322, 0.007263649255037308, 0.007242558524012566, 0.0072220442816615105, 0.007210236974060535, 0.007184502203017473, 0.007162176538258791, 0.007139630150049925, 0.007120804395526648, 0.007106940262019634, 0.007085984572768211, 0.007065169047564268], 'accuracy': [0.9811369776725769, 0.9909560680389404, 0.9940568208694458, 0.9919896721839905, 0.9888888597488403, 0.9914728403091431, 0.9953488111495972, 0.9968992471694946, 0.9992247819900513, 0.9953488111495972, 0.9834625124931335, 0.9860464930534363, 0.9855297207832336, 0.9909560680389404, 0.9922480583190918, 0.9987080097198486, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6860566735267639, 0.675335705280304, 0.6571822166442871, 0.6361850500106812, 0.6183303594589233, 0.598217248916626, 0.5570285320281982, 0.5172253251075745, 0.49234551191329956, 0.4648389518260956, 0.4733005464076996, 0.4448758363723755, 0.537077784538269, 0.6799663305282593, 0.4653572142124176, 0.4095058739185333, 0.3821491599082947, 0.4059649407863617, 0.4050907790660858, 0.4195353388786316, 0.4273216426372528, 0.42610135674476624, 0.4265165328979492, 0.42773696780204773, 0.4303123950958252, 0.431840717792511, 0.4352046847343445, 0.437831848859787, 0.44264116883277893, 0.4460375905036926, 0.4499265253543854, 0.45119887590408325, 0.4535931944847107, 0.4511468708515167, 0.4512258768081665, 0.46417900919914246, 0.45986226201057434, 0.47154420614242554, 0.46532708406448364, 0.4618622958660126, 0.4596630334854126, 0.46031078696250916, 0.45901480317115784, 0.4609713554382324, 0.45571497082710266, 0.45794448256492615, 0.45795735716819763, 0.458600789308548, 0.4606840908527374, 0.4616808593273163, 0.46109750866889954, 0.4628964364528656, 0.4622689485549927, 0.4634528160095215, 0.4618246257305145, 0.46195927262306213, 0.4667453467845917, 0.4643288850784302, 0.4663800001144409, 0.4615724980831146, 0.4635492265224457, 0.4658794701099396, 0.46278491616249084, 0.4638076424598694, 0.4641881585121155, 0.4647637605667114, 0.46597960591316223, 0.4693523943424225, 0.4660423994064331, 0.4695533514022827, 0.4690668284893036, 0.4719882607460022, 0.4721759557723999, 0.4682198464870453, 0.4712993800640106, 0.47036319971084595, 0.47290363907814026, 0.4753985106945038, 0.4743689298629761, 0.4733984172344208, 0.4766627848148346, 0.4757789969444275, 0.47619131207466125, 0.4754607379436493, 0.4741673767566681, 0.47515031695365906, 0.47620001435279846, 0.4765550196170807, 0.4783691465854645, 0.47898566722869873, 0.4772365391254425, 0.479596346616745, 0.48425671458244324, 0.4852219521999359, 0.48516353964805603, 0.48503822088241577, 0.4845844507217407, 0.4830643832683563, 0.48189258575439453, 0.4845166802406311], 'val_accuracy': [0.5568181872367859, 0.6157024502754211, 0.6157024502754211, 0.7613636255264282, 0.7458677887916565, 0.7613636255264282, 0.7644628286361694, 0.7830578684806824, 0.7789255976676941, 0.7923553586006165, 0.7758264541625977, 0.7923553586006165, 0.7210744023323059, 0.6859503984451294, 0.7944214940071106, 0.8223140239715576, 0.85537189245224, 0.8636363744735718, 0.8770661354064941, 0.8811983466148376, 0.8842975497245789, 0.8884297609329224, 0.8894628286361694, 0.8884297609329224, 0.8925619721412659, 0.8935950398445129, 0.8977272510528564, 0.8956611752510071, 0.8966942429542542, 0.8977272510528564, 0.8977272510528564, 0.8997933864593506, 0.8987603187561035, 0.8987603187561035, 0.8997933864593506, 0.8987603187561035, 0.8977272510528564, 0.8956611752510071, 0.8966942429542542, 0.8977272510528564, 0.8987603187561035, 0.8997933864593506, 0.8987603187561035, 0.8987603187561035, 0.9008264541625977, 0.8997933864593506, 0.8997933864593506, 0.8997933864593506, 0.8997933864593506, 0.9018595218658447, 0.9018595218658447, 0.9008264541625977, 0.8977272510528564, 0.8977272510528564, 0.9008264541625977, 0.8966942429542542, 0.8956611752510071, 0.8977272510528564, 0.8966942429542542, 0.9018595218658447, 0.9018595218658447, 0.8966942429542542, 0.8977272510528564, 0.8997933864593506, 0.8997933864593506, 0.8997933864593506, 0.8997933864593506, 0.8977272510528564, 0.8987603187561035, 0.8977272510528564, 0.8987603187561035, 0.8977272510528564, 0.8956611752510071, 0.8987603187561035, 0.9008264541625977, 0.9008264541625977, 0.8987603187561035, 0.8997933864593506, 0.8987603187561035, 0.8987603187561035, 0.8987603187561035, 0.8977272510528564, 0.8987603187561035, 0.8987603187561035, 0.8987603187561035, 0.8987603187561035, 0.8997933864593506, 0.8987603187561035, 0.8997933864593506, 0.8997933864593506, 0.8987603187561035, 0.8987603187561035, 0.8997933864593506, 0.8987603187561035, 0.8966942429542542, 0.8956611752510071, 0.8977272510528564, 0.8977272510528564, 0.8997933864593506, 0.8977272510528564]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717498993621,"user_tz":-360,"elapsed":25,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"2279ff1a-247a-4ecd-c454-4f0f08532dc5"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.655      0.660   0.640  0.650        0.640        0.670   \n","1        1     0.700      0.744   0.609  0.670        0.609        0.791   \n","2        2     0.606      0.601   0.633  0.616        0.633        0.580   \n","3        0     0.679      0.673   0.697  0.685        0.697        0.662   \n","4        1     0.753      0.766   0.729  0.747        0.729        0.777   \n","5        2     0.668      0.658   0.699  0.678        0.699        0.637   \n","6        0     0.779      0.738   0.866  0.797        0.866        0.692   \n","7        1     0.819      0.803   0.845  0.823        0.845        0.792   \n","8        2     0.784      0.754   0.843  0.796        0.843        0.725   \n","9        0     0.830      0.804   0.873  0.837        0.873        0.787   \n","10       1     0.862      0.847   0.883  0.864        0.883        0.840   \n","11       2     0.837      0.798   0.904  0.847        0.904        0.771   \n","12       0     0.889      0.858   0.931  0.893        0.931        0.846   \n","13       1     0.899      0.881   0.922  0.901        0.922        0.876   \n","14       2     0.879      0.838   0.938  0.885        0.938        0.819   \n","\n","    Kappa  \n","0   0.310  \n","1   0.400  \n","2   0.213  \n","3   0.358  \n","4   0.506  \n","5   0.335  \n","6   0.558  \n","7   0.637  \n","8   0.568  \n","9   0.660  \n","10  0.723  \n","11  0.675  \n","12  0.777  \n","13  0.798  \n","14  0.757  "],"text/html":["\n","  <div id=\"df-e560bc1f-d5e9-4ba3-ac0f-276f7b93ef4d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.655</td>\n","      <td>0.660</td>\n","      <td>0.640</td>\n","      <td>0.650</td>\n","      <td>0.640</td>\n","      <td>0.670</td>\n","      <td>0.310</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.700</td>\n","      <td>0.744</td>\n","      <td>0.609</td>\n","      <td>0.670</td>\n","      <td>0.609</td>\n","      <td>0.791</td>\n","      <td>0.400</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.606</td>\n","      <td>0.601</td>\n","      <td>0.633</td>\n","      <td>0.616</td>\n","      <td>0.633</td>\n","      <td>0.580</td>\n","      <td>0.213</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.679</td>\n","      <td>0.673</td>\n","      <td>0.697</td>\n","      <td>0.685</td>\n","      <td>0.697</td>\n","      <td>0.662</td>\n","      <td>0.358</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.753</td>\n","      <td>0.766</td>\n","      <td>0.729</td>\n","      <td>0.747</td>\n","      <td>0.729</td>\n","      <td>0.777</td>\n","      <td>0.506</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.668</td>\n","      <td>0.658</td>\n","      <td>0.699</td>\n","      <td>0.678</td>\n","      <td>0.699</td>\n","      <td>0.637</td>\n","      <td>0.335</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.779</td>\n","      <td>0.738</td>\n","      <td>0.866</td>\n","      <td>0.797</td>\n","      <td>0.866</td>\n","      <td>0.692</td>\n","      <td>0.558</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.819</td>\n","      <td>0.803</td>\n","      <td>0.845</td>\n","      <td>0.823</td>\n","      <td>0.845</td>\n","      <td>0.792</td>\n","      <td>0.637</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.784</td>\n","      <td>0.754</td>\n","      <td>0.843</td>\n","      <td>0.796</td>\n","      <td>0.843</td>\n","      <td>0.725</td>\n","      <td>0.568</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.830</td>\n","      <td>0.804</td>\n","      <td>0.873</td>\n","      <td>0.837</td>\n","      <td>0.873</td>\n","      <td>0.787</td>\n","      <td>0.660</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.862</td>\n","      <td>0.847</td>\n","      <td>0.883</td>\n","      <td>0.864</td>\n","      <td>0.883</td>\n","      <td>0.840</td>\n","      <td>0.723</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.837</td>\n","      <td>0.798</td>\n","      <td>0.904</td>\n","      <td>0.847</td>\n","      <td>0.904</td>\n","      <td>0.771</td>\n","      <td>0.675</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.889</td>\n","      <td>0.858</td>\n","      <td>0.931</td>\n","      <td>0.893</td>\n","      <td>0.931</td>\n","      <td>0.846</td>\n","      <td>0.777</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.899</td>\n","      <td>0.881</td>\n","      <td>0.922</td>\n","      <td>0.901</td>\n","      <td>0.922</td>\n","      <td>0.876</td>\n","      <td>0.798</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.879</td>\n","      <td>0.838</td>\n","      <td>0.938</td>\n","      <td>0.885</td>\n","      <td>0.938</td>\n","      <td>0.819</td>\n","      <td>0.757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e560bc1f-d5e9-4ba3-ac0f-276f7b93ef4d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e560bc1f-d5e9-4ba3-ac0f-276f7b93ef4d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e560bc1f-d5e9-4ba3-ac0f-276f7b93ef4d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0628796c-ca46-4033-81cc-d330c9a6bd21\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0628796c-ca46-4033-81cc-d330c9a6bd21')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0628796c-ca46-4033-81cc-d330c9a6bd21 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0946349879927131,\n        \"min\": 0.606,\n        \"max\": 0.899,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.83,\n          0.837,\n          0.655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0833056906533887,\n        \"min\": 0.601,\n        \"max\": 0.881,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.804,\n          0.798,\n          0.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11897310620472175,\n        \"min\": 0.609,\n        \"max\": 0.938,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.873,\n          0.904,\n          0.64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09711147252121191,\n        \"min\": 0.616,\n        \"max\": 0.901,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.837,\n          0.847,\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11897310620472175,\n        \"min\": 0.609,\n        \"max\": 0.938,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.873,\n          0.904,\n          0.64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0860747183722209,\n        \"min\": 0.58,\n        \"max\": 0.876,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.787,\n          0.771,\n          0.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18900969992745523,\n        \"min\": 0.213,\n        \"max\": 0.798,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.66,\n          0.675,\n          0.31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/CNN_LSTM/Beta_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717498994369,"user_tz":-360,"elapsed":765,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# CNN-LSTM Graph"],"metadata":{"id":"ZUR_QwblhNjJ"}},{"cell_type":"code","source":["import wandb\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import seaborn as sns\n","\n","# Initialize the API\n","api = wandb.Api()\n","\n","# Specify the entity and project\n","entity = \"raihanrabby\"\n","project = \"Beta_time_domain_CNN_Lstm\"\n","\n","# Fetch all runs from the project\n","runs = api.runs(f\"{entity}/{project}\")\n","\n","# List to store the dataframes\n","dataframes = []\n","\n","# Iterate over each run and fetch the history\n","for run in runs:\n","    # Fetch the history for each run\n","    history = run.history()\n","\n","    # Add columns to identify the run, model name, epoch, and client\n","    history['run_id'] = run.id\n","    history['model_name'] = run.name\n","\n","    # Extract epoch and client from model name\n","    match = re.match(r'epoch_(\\d+)_client_(\\d+)', run.name)\n","    if match:\n","        history['epoch_number'] = int(match.group(1))\n","        history['client_number'] = int(match.group(2))\n","    else:\n","        history['epoch_number'] = None\n","        history['client_number'] = None\n","\n","    # Append to the list of dataframes\n","    dataframes.append(history)\n","\n","# Concatenate all dataframes into a single dataframe\n","all_metrics_df = pd.concat(dataframes)\n","\n","# Filter out rows with None epoch_number\n","all_metrics_df = all_metrics_df.dropna(subset=['epoch_number'])\n","\n","# Get the unique epochs\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Set the Seaborn style\n","sns.set(style=\"whitegrid\")\n","\n","# Create subplots for each epoch\n","fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","# Set the color palette\n","palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","# Store the lines and labels for the legend\n","lines = []\n","labels = []\n","\n","# Iterate through each epoch and plot the training and validation accuracy\n","for i, epoch in enumerate(unique_epochs):\n","    epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","    for j, client in enumerate(epoch_df['client_number'].unique()):\n","        client_df = epoch_df[epoch_df['client_number'] == client]\n","        line, = axes[0, i].plot(client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","        axes[1, i].plot(client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","        if i == 0:\n","            lines.append(line)\n","            labels.append(f'Client {client}')\n","\n","    axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","    axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    # axes[0, i].set_ylim(0.5)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_ylim(0.5, 1.0)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","    axes[0, i].grid(True)\n","    axes[1, i].grid(True)\n","    axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","    axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","# Add a single legend for the entire figure\n","fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","# Add row labels\n","fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"zdihdEQAk8x9","executionInfo":{"status":"ok","timestamp":1716740043376,"user_tz":-360,"elapsed":15427,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"6f210444-99b7-4a2d-e54d-c63ffe64373a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"F0IzJ6S5k8vk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_metrics_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"dF-KSdKdhsqv","executionInfo":{"status":"ok","timestamp":1716636800286,"user_tz":-360,"elapsed":373,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"468ed3c0-e85c-4f92-da49-0afecd4c142c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      _runtime  accuracy  val_loss    _timestamp  val_accuracy      loss  \\\n","0    13.310213  0.894723  0.860759  1.716588e+09      0.504283  0.247455   \n","1    22.364346  0.917493  0.848398  1.716588e+09      0.504283  0.195490   \n","2    33.860330  0.914814  0.825522  1.716588e+09      0.504283  0.204736   \n","3    43.363837  0.909992  0.825889  1.716588e+09      0.504283  0.208303   \n","4    44.307076  0.922047  0.801610  1.716588e+09      0.504283  0.188477   \n","..         ...       ...       ...           ...           ...       ...   \n","95  416.614793  0.788910  0.553507  1.716585e+09      0.730193  0.455315   \n","96  417.041695  0.782213  0.548009  1.716585e+09      0.732334  0.458011   \n","97  417.444440  0.778998  0.550679  1.716585e+09      0.729122  0.459626   \n","98  417.884801  0.792660  0.559028  1.716585e+09      0.722698  0.451855   \n","99  418.304440  0.782748  0.551085  1.716585e+09      0.729122  0.454946   \n","\n","    _step  epoch    run_id  \n","0       0      0  2nsbmzjb  \n","1       1      1  2nsbmzjb  \n","2       2      2  2nsbmzjb  \n","3       3      3  2nsbmzjb  \n","4       4      4  2nsbmzjb  \n","..    ...    ...       ...  \n","95     95     95  u6ki5wej  \n","96     96     96  u6ki5wej  \n","97     97     97  u6ki5wej  \n","98     98     98  u6ki5wej  \n","99     99     99  u6ki5wej  \n","\n","[1500 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-c54c6cd2-19dd-4a84-90fb-57f868070b89\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>_runtime</th>\n","      <th>accuracy</th>\n","      <th>val_loss</th>\n","      <th>_timestamp</th>\n","      <th>val_accuracy</th>\n","      <th>loss</th>\n","      <th>_step</th>\n","      <th>epoch</th>\n","      <th>run_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13.310213</td>\n","      <td>0.894723</td>\n","      <td>0.860759</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.247455</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.364346</td>\n","      <td>0.917493</td>\n","      <td>0.848398</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.195490</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33.860330</td>\n","      <td>0.914814</td>\n","      <td>0.825522</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.204736</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43.363837</td>\n","      <td>0.909992</td>\n","      <td>0.825889</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.208303</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>44.307076</td>\n","      <td>0.922047</td>\n","      <td>0.801610</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.188477</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>416.614793</td>\n","      <td>0.788910</td>\n","      <td>0.553507</td>\n","      <td>1.716585e+09</td>\n","      <td>0.730193</td>\n","      <td>0.455315</td>\n","      <td>95</td>\n","      <td>95</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>417.041695</td>\n","      <td>0.782213</td>\n","      <td>0.548009</td>\n","      <td>1.716585e+09</td>\n","      <td>0.732334</td>\n","      <td>0.458011</td>\n","      <td>96</td>\n","      <td>96</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>417.444440</td>\n","      <td>0.778998</td>\n","      <td>0.550679</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.459626</td>\n","      <td>97</td>\n","      <td>97</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>417.884801</td>\n","      <td>0.792660</td>\n","      <td>0.559028</td>\n","      <td>1.716585e+09</td>\n","      <td>0.722698</td>\n","      <td>0.451855</td>\n","      <td>98</td>\n","      <td>98</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>418.304440</td>\n","      <td>0.782748</td>\n","      <td>0.551085</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.454946</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1500 rows  9 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c54c6cd2-19dd-4a84-90fb-57f868070b89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_af67ca15-c1be-45e1-84f8-5c85a974368d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_metrics_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_af67ca15-c1be-45e1-84f8-5c85a974368d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('all_metrics_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"all_metrics_df","summary":"{\n  \"name\": \"all_metrics_df\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 88.45497529136644,\n        \"min\": 10.388507843017578,\n        \"max\": 525.9502971172333,\n        \"num_unique_values\": 1499,\n        \"samples\": [\n          171.23451471328735,\n          514.5650720596313,\n          154.19228529930115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08458249714165784,\n        \"min\": 0.5001339316368103,\n        \"max\": 0.9694615602493286,\n        \"num_unique_values\": 773,\n        \"samples\": [\n          0.8494508266448975,\n          0.7013126015663147,\n          0.7811411619186401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07423729060194581,\n        \"min\": 0.42367106676101685,\n        \"max\": 0.898168683052063,\n        \"num_unique_values\": 1498,\n        \"samples\": [\n          0.49998635053634644,\n          0.6923187971115112,\n          0.5667726397514343\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1152.2215388098273,\n        \"min\": 1716584329.3731794,\n        \"max\": 1716588576.7424233,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          1716585811.4945405,\n          1716585200.7616174,\n          1716587598.5155294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08631999854487923,\n        \"min\": 0.4860813617706299,\n        \"max\": 0.835117757320404,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          0.7644539475440979,\n          0.5920770764350891,\n          0.5224839448928833\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1503027321511436,\n        \"min\": 0.08336261659860611,\n        \"max\": 0.6930587291717529,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          0.46639472246170044,\n          0.4926566481590271,\n          0.23360194265842438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"0ebggn8j\",\n          \"tsl17cy8\",\n          \"2nsbmzjb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Beta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Beta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717498994370,"user_tz":-360,"elapsed":5,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"ce068105-c4be-42de-8007-7dc5702ae3e3","executionInfo":{"status":"ok","timestamp":1717499794565,"user_tz":-360,"elapsed":800199,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 35ms/step - loss: 1.7605 - accuracy: 0.5870 - val_loss: 1.7667 - val_accuracy: 0.4849\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 21ms/step - loss: 1.7316 - accuracy: 0.6519 - val_loss: 1.7572 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.7060 - accuracy: 0.6711 - val_loss: 1.7475 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.6839 - accuracy: 0.6713 - val_loss: 1.7371 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.6609 - accuracy: 0.6797 - val_loss: 1.7265 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6387 - accuracy: 0.6891 - val_loss: 1.7152 - val_accuracy: 0.4957\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.6206 - accuracy: 0.6923 - val_loss: 1.7045 - val_accuracy: 0.4957\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6048 - accuracy: 0.7020 - val_loss: 1.6929 - val_accuracy: 0.5011\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5905 - accuracy: 0.7031 - val_loss: 1.6770 - val_accuracy: 0.6703\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5760 - accuracy: 0.7085 - val_loss: 1.6654 - val_accuracy: 0.6121\n","Epoch 11/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.5607 - accuracy: 0.7150 - val_loss: 1.6478 - val_accuracy: 0.7091\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5469 - accuracy: 0.7244 - val_loss: 1.6314 - val_accuracy: 0.7069\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.5350 - accuracy: 0.7212 - val_loss: 1.6152 - val_accuracy: 0.6875\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5290 - accuracy: 0.7166 - val_loss: 1.5985 - val_accuracy: 0.6940\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.5115 - accuracy: 0.7252 - val_loss: 1.5827 - val_accuracy: 0.6832\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5008 - accuracy: 0.7295 - val_loss: 1.5620 - val_accuracy: 0.7123\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4896 - accuracy: 0.7249 - val_loss: 1.5452 - val_accuracy: 0.7101\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4839 - accuracy: 0.7241 - val_loss: 1.5351 - val_accuracy: 0.6886\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4694 - accuracy: 0.7355 - val_loss: 1.5143 - val_accuracy: 0.7123\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4597 - accuracy: 0.7403 - val_loss: 1.5035 - val_accuracy: 0.7112\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4464 - accuracy: 0.7376 - val_loss: 1.4858 - val_accuracy: 0.7155\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4378 - accuracy: 0.7411 - val_loss: 1.4958 - val_accuracy: 0.6897\n","Epoch 23/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.4292 - accuracy: 0.7408 - val_loss: 1.4543 - val_accuracy: 0.7349\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4189 - accuracy: 0.7425 - val_loss: 1.4495 - val_accuracy: 0.7306\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4087 - accuracy: 0.7487 - val_loss: 1.4319 - val_accuracy: 0.7274\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4013 - accuracy: 0.7500 - val_loss: 1.4210 - val_accuracy: 0.7338\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3925 - accuracy: 0.7468 - val_loss: 1.4133 - val_accuracy: 0.7317\n","Epoch 28/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3848 - accuracy: 0.7470 - val_loss: 1.4032 - val_accuracy: 0.7328\n","Epoch 29/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3746 - accuracy: 0.7540 - val_loss: 1.3939 - val_accuracy: 0.7338\n","Epoch 30/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3682 - accuracy: 0.7489 - val_loss: 1.3886 - val_accuracy: 0.7177\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3618 - accuracy: 0.7505 - val_loss: 1.3780 - val_accuracy: 0.7338\n","Epoch 32/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.3512 - accuracy: 0.7540 - val_loss: 1.3709 - val_accuracy: 0.7381\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3426 - accuracy: 0.7584 - val_loss: 1.3632 - val_accuracy: 0.7274\n","Epoch 34/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3334 - accuracy: 0.7570 - val_loss: 1.3579 - val_accuracy: 0.7188\n","Epoch 35/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3270 - accuracy: 0.7573 - val_loss: 1.3470 - val_accuracy: 0.7349\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3222 - accuracy: 0.7586 - val_loss: 1.3443 - val_accuracy: 0.7177\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3152 - accuracy: 0.7586 - val_loss: 1.3334 - val_accuracy: 0.7360\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3068 - accuracy: 0.7575 - val_loss: 1.3428 - val_accuracy: 0.7209\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3132 - accuracy: 0.7492 - val_loss: 1.3190 - val_accuracy: 0.7360\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2923 - accuracy: 0.7662 - val_loss: 1.3115 - val_accuracy: 0.7360\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2832 - accuracy: 0.7651 - val_loss: 1.3116 - val_accuracy: 0.7241\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2787 - accuracy: 0.7635 - val_loss: 1.2991 - val_accuracy: 0.7338\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2684 - accuracy: 0.7729 - val_loss: 1.2923 - val_accuracy: 0.7381\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2645 - accuracy: 0.7629 - val_loss: 1.3065 - val_accuracy: 0.7144\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2585 - accuracy: 0.7640 - val_loss: 1.2818 - val_accuracy: 0.7274\n","Epoch 46/100\n","29/29 [==============================] - 1s 33ms/step - loss: 1.2501 - accuracy: 0.7713 - val_loss: 1.2734 - val_accuracy: 0.7392\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2407 - accuracy: 0.7718 - val_loss: 1.2696 - val_accuracy: 0.7338\n","Epoch 48/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2360 - accuracy: 0.7670 - val_loss: 1.2768 - val_accuracy: 0.7457\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2282 - accuracy: 0.7716 - val_loss: 1.2581 - val_accuracy: 0.7381\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2276 - accuracy: 0.7667 - val_loss: 1.2519 - val_accuracy: 0.7381\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2163 - accuracy: 0.7680 - val_loss: 1.2522 - val_accuracy: 0.7306\n","Epoch 52/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2113 - accuracy: 0.7740 - val_loss: 1.2372 - val_accuracy: 0.7360\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2042 - accuracy: 0.7721 - val_loss: 1.2419 - val_accuracy: 0.7317\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1970 - accuracy: 0.7740 - val_loss: 1.2355 - val_accuracy: 0.7446\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1948 - accuracy: 0.7740 - val_loss: 1.2263 - val_accuracy: 0.7317\n","Epoch 56/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1841 - accuracy: 0.7807 - val_loss: 1.2145 - val_accuracy: 0.7381\n","Epoch 57/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.1763 - accuracy: 0.7839 - val_loss: 1.2102 - val_accuracy: 0.7371\n","Epoch 58/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.1713 - accuracy: 0.7799 - val_loss: 1.2035 - val_accuracy: 0.7371\n","Epoch 59/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.1671 - accuracy: 0.7775 - val_loss: 1.1976 - val_accuracy: 0.7381\n","Epoch 60/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.1596 - accuracy: 0.7796 - val_loss: 1.2140 - val_accuracy: 0.7177\n","Epoch 61/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.1596 - accuracy: 0.7740 - val_loss: 1.1960 - val_accuracy: 0.7478\n","Epoch 62/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.1544 - accuracy: 0.7772 - val_loss: 1.1833 - val_accuracy: 0.7317\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1409 - accuracy: 0.7821 - val_loss: 1.1784 - val_accuracy: 0.7328\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1352 - accuracy: 0.7880 - val_loss: 1.1718 - val_accuracy: 0.7360\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1337 - accuracy: 0.7826 - val_loss: 1.1659 - val_accuracy: 0.7338\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1293 - accuracy: 0.7837 - val_loss: 1.1626 - val_accuracy: 0.7349\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1206 - accuracy: 0.7877 - val_loss: 1.1564 - val_accuracy: 0.7381\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1163 - accuracy: 0.7866 - val_loss: 1.1540 - val_accuracy: 0.7435\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1116 - accuracy: 0.7842 - val_loss: 1.1894 - val_accuracy: 0.7112\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1101 - accuracy: 0.7796 - val_loss: 1.1439 - val_accuracy: 0.7446\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1003 - accuracy: 0.7877 - val_loss: 1.1440 - val_accuracy: 0.7295\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0899 - accuracy: 0.7918 - val_loss: 1.1380 - val_accuracy: 0.7274\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0851 - accuracy: 0.7939 - val_loss: 1.1364 - val_accuracy: 0.7338\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0800 - accuracy: 0.7963 - val_loss: 1.1264 - val_accuracy: 0.7338\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0852 - accuracy: 0.7767 - val_loss: 1.1572 - val_accuracy: 0.7532\n","Epoch 76/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0763 - accuracy: 0.7931 - val_loss: 1.1169 - val_accuracy: 0.7371\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0671 - accuracy: 0.7901 - val_loss: 1.1199 - val_accuracy: 0.7317\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0636 - accuracy: 0.7920 - val_loss: 1.1069 - val_accuracy: 0.7338\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0552 - accuracy: 0.7926 - val_loss: 1.1029 - val_accuracy: 0.7392\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0473 - accuracy: 0.7945 - val_loss: 1.0989 - val_accuracy: 0.7371\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0510 - accuracy: 0.7920 - val_loss: 1.1419 - val_accuracy: 0.7414\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0543 - accuracy: 0.7842 - val_loss: 1.1008 - val_accuracy: 0.7328\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0348 - accuracy: 0.7966 - val_loss: 1.0849 - val_accuracy: 0.7403\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0269 - accuracy: 0.7988 - val_loss: 1.0912 - val_accuracy: 0.7306\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0284 - accuracy: 0.7977 - val_loss: 1.0776 - val_accuracy: 0.7435\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0185 - accuracy: 0.8023 - val_loss: 1.0728 - val_accuracy: 0.7435\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0179 - accuracy: 0.7950 - val_loss: 1.0837 - val_accuracy: 0.7328\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0134 - accuracy: 0.7982 - val_loss: 1.0678 - val_accuracy: 0.7371\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0027 - accuracy: 0.8082 - val_loss: 1.0612 - val_accuracy: 0.7478\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9991 - accuracy: 0.8068 - val_loss: 1.0581 - val_accuracy: 0.7500\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9913 - accuracy: 0.8066 - val_loss: 1.0534 - val_accuracy: 0.7446\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9863 - accuracy: 0.8079 - val_loss: 1.0585 - val_accuracy: 0.7414\n","Epoch 93/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9832 - accuracy: 0.8098 - val_loss: 1.0476 - val_accuracy: 0.7575\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9791 - accuracy: 0.8093 - val_loss: 1.0431 - val_accuracy: 0.7522\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9807 - accuracy: 0.7990 - val_loss: 1.0395 - val_accuracy: 0.7543\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9686 - accuracy: 0.8114 - val_loss: 1.0361 - val_accuracy: 0.7522\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9657 - accuracy: 0.8103 - val_loss: 1.0320 - val_accuracy: 0.7511\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9603 - accuracy: 0.8077 - val_loss: 1.0291 - val_accuracy: 0.7392\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9545 - accuracy: 0.8122 - val_loss: 1.0482 - val_accuracy: 0.7306\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9537 - accuracy: 0.8090 - val_loss: 1.0214 - val_accuracy: 0.7468\n","{'loss': [1.7604708671569824, 1.7316129207611084, 1.706040859222412, 1.6839431524276733, 1.6608521938323975, 1.6387207508087158, 1.62059485912323, 1.6047507524490356, 1.5905420780181885, 1.5759661197662354, 1.5606589317321777, 1.5468989610671997, 1.5350345373153687, 1.5289504528045654, 1.5114977359771729, 1.5007517337799072, 1.4895914793014526, 1.48389732837677, 1.4694087505340576, 1.4596800804138184, 1.4464335441589355, 1.4377751350402832, 1.4292258024215698, 1.4188860654830933, 1.4086593389511108, 1.4013304710388184, 1.392487645149231, 1.3847957849502563, 1.3745535612106323, 1.368249535560608, 1.3618314266204834, 1.3512181043624878, 1.3425534963607788, 1.3333704471588135, 1.3269898891448975, 1.3221745491027832, 1.3152302503585815, 1.30681574344635, 1.313155174255371, 1.2922897338867188, 1.2831538915634155, 1.278685212135315, 1.268406629562378, 1.2644522190093994, 1.258484125137329, 1.2500897645950317, 1.2406662702560425, 1.23597252368927, 1.2281615734100342, 1.2276077270507812, 1.2162716388702393, 1.2112541198730469, 1.204224705696106, 1.19696044921875, 1.1947673559188843, 1.1840510368347168, 1.17631995677948, 1.1713451147079468, 1.1670976877212524, 1.1595629453659058, 1.1596436500549316, 1.1544075012207031, 1.140905737876892, 1.135185956954956, 1.1337175369262695, 1.1293396949768066, 1.1205841302871704, 1.1162985563278198, 1.1115654706954956, 1.110119104385376, 1.1003282070159912, 1.0899137258529663, 1.0851359367370605, 1.079986572265625, 1.0851991176605225, 1.076287865638733, 1.0671439170837402, 1.0635541677474976, 1.0551623106002808, 1.0473169088363647, 1.0509926080703735, 1.0542807579040527, 1.034767746925354, 1.0269393920898438, 1.0283595323562622, 1.0184838771820068, 1.0178757905960083, 1.0133715867996216, 1.002724528312683, 0.999074399471283, 0.9913138151168823, 0.9863425493240356, 0.983192503452301, 0.9791020750999451, 0.9806730151176453, 0.9686346650123596, 0.965703547000885, 0.9602699279785156, 0.9544889330863953, 0.953717052936554], 'accuracy': [0.5870150923728943, 0.6519396305084229, 0.6710668206214905, 0.6713362336158752, 0.6796875, 0.689116358757019, 0.6923491358757019, 0.7020474076271057, 0.703125, 0.7085129022598267, 0.7149784564971924, 0.7244073152542114, 0.7211745977401733, 0.7165948152542114, 0.725215494632721, 0.7295258641242981, 0.724946141242981, 0.7241379022598267, 0.7354525923728943, 0.7403017282485962, 0.7376077771186829, 0.7411099076271057, 0.740840494632721, 0.7424569129943848, 0.748652994632721, 0.75, 0.7467672228813171, 0.7470366358757019, 0.7540409564971924, 0.7489224076271057, 0.7505387663841248, 0.7540409564971924, 0.7583512663841248, 0.7570043206214905, 0.7572737336158752, 0.7586206793785095, 0.7586206793785095, 0.7575430870056152, 0.7491918206214905, 0.7661637663841248, 0.7650862336158752, 0.7634698152542114, 0.7728987336158752, 0.7629310488700867, 0.764008641242981, 0.7712823152542114, 0.771821141242981, 0.766972005367279, 0.7715517282485962, 0.7667025923728943, 0.7680495977401733, 0.7739762663841248, 0.772090494632721, 0.7739762663841248, 0.7739762663841248, 0.7807112336158752, 0.7839439511299133, 0.779902994632721, 0.7774784564971924, 0.779633641242981, 0.7739762663841248, 0.7772090435028076, 0.7820581793785095, 0.7879849076271057, 0.782597005367279, 0.7836745977401733, 0.787715494632721, 0.7866379022598267, 0.7842133641242981, 0.779633641242981, 0.787715494632721, 0.7917564511299133, 0.7939116358757019, 0.7963362336158752, 0.7766702771186829, 0.7931034564971924, 0.7901400923728943, 0.7920258641242981, 0.7925646305084229, 0.7944504022598267, 0.7920258641242981, 0.7842133641242981, 0.7966055870056152, 0.7987607717514038, 0.7976831793785095, 0.8022629022598267, 0.7949892282485962, 0.798222005367279, 0.8081896305084229, 0.8068426847457886, 0.8065732717514038, 0.8079202771186829, 0.8098060488700867, 0.8092672228813171, 0.7990301847457886, 0.8114224076271057, 0.8103448152542114, 0.8076508641242981, 0.8122305870056152, 0.8089978694915771], 'val_loss': [1.7667086124420166, 1.7572433948516846, 1.7474510669708252, 1.737128734588623, 1.7264554500579834, 1.7151687145233154, 1.7045338153839111, 1.6929131746292114, 1.6769704818725586, 1.6653560400009155, 1.6478434801101685, 1.6313849687576294, 1.6152280569076538, 1.5984615087509155, 1.582705020904541, 1.562049388885498, 1.5451515913009644, 1.535056710243225, 1.5142954587936401, 1.5035245418548584, 1.4858249425888062, 1.4957835674285889, 1.4542614221572876, 1.4495400190353394, 1.4319493770599365, 1.4210083484649658, 1.4133188724517822, 1.4032244682312012, 1.393882393836975, 1.3886288404464722, 1.377977728843689, 1.3709094524383545, 1.363226294517517, 1.357912540435791, 1.34703528881073, 1.3442878723144531, 1.3333796262741089, 1.342807650566101, 1.319029450416565, 1.3115066289901733, 1.3116259574890137, 1.299107551574707, 1.292343020439148, 1.3064757585525513, 1.2818269729614258, 1.2734057903289795, 1.2696332931518555, 1.2767767906188965, 1.2580569982528687, 1.2518783807754517, 1.2521735429763794, 1.237209439277649, 1.241942286491394, 1.2354662418365479, 1.226306676864624, 1.2144509553909302, 1.2101744413375854, 1.2035415172576904, 1.1976077556610107, 1.2139540910720825, 1.1959697008132935, 1.1832743883132935, 1.1783926486968994, 1.1717534065246582, 1.1659265756607056, 1.1625592708587646, 1.1563620567321777, 1.1539850234985352, 1.189354419708252, 1.1439104080200195, 1.1440272331237793, 1.1380338668823242, 1.136383295059204, 1.1263757944107056, 1.1571718454360962, 1.1168696880340576, 1.1199288368225098, 1.106881856918335, 1.1029099225997925, 1.09889554977417, 1.1418644189834595, 1.1007922887802124, 1.0848991870880127, 1.0912050008773804, 1.0776094198226929, 1.0728404521942139, 1.0836577415466309, 1.0677570104599, 1.061188817024231, 1.0580971240997314, 1.0533801317214966, 1.0584912300109863, 1.0476484298706055, 1.0431060791015625, 1.0394798517227173, 1.0361037254333496, 1.0319650173187256, 1.029128909111023, 1.048214077949524, 1.0214447975158691], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.49568966031074524, 0.49568966031074524, 0.5010775923728943, 0.670258641242981, 0.6120689511299133, 0.7090517282485962, 0.7068965435028076, 0.6875, 0.693965494632721, 0.6831896305084229, 0.712284505367279, 0.7101293206214905, 0.6885775923728943, 0.712284505367279, 0.7112069129943848, 0.7155172228813171, 0.6896551847457886, 0.7349137663841248, 0.7306034564971924, 0.7273706793785095, 0.7338362336158752, 0.7316810488700867, 0.732758641242981, 0.7338362336158752, 0.7176724076271057, 0.7338362336158752, 0.7381465435028076, 0.7273706793785095, 0.71875, 0.7349137663841248, 0.7176724076271057, 0.735991358757019, 0.7209051847457886, 0.735991358757019, 0.735991358757019, 0.7241379022598267, 0.7338362336158752, 0.7381465435028076, 0.7144396305084229, 0.7273706793785095, 0.7392241358757019, 0.7338362336158752, 0.7456896305084229, 0.7381465435028076, 0.7381465435028076, 0.7306034564971924, 0.735991358757019, 0.7316810488700867, 0.7446120977401733, 0.7316810488700867, 0.7381465435028076, 0.7370689511299133, 0.7370689511299133, 0.7381465435028076, 0.7176724076271057, 0.7478448152542114, 0.7316810488700867, 0.732758641242981, 0.735991358757019, 0.7338362336158752, 0.7349137663841248, 0.7381465435028076, 0.743534505367279, 0.7112069129943848, 0.7446120977401733, 0.7295258641242981, 0.7273706793785095, 0.7338362336158752, 0.7338362336158752, 0.7532327771186829, 0.7370689511299133, 0.7316810488700867, 0.7338362336158752, 0.7392241358757019, 0.7370689511299133, 0.7413793206214905, 0.732758641242981, 0.7403017282485962, 0.7306034564971924, 0.743534505367279, 0.743534505367279, 0.732758641242981, 0.7370689511299133, 0.7478448152542114, 0.75, 0.7446120977401733, 0.7413793206214905, 0.7575430870056152, 0.7521551847457886, 0.7543103694915771, 0.7521551847457886, 0.7510775923728943, 0.7392241358757019, 0.7306034564971924, 0.7467672228813171]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 5s 29ms/step - loss: 1.7631 - accuracy: 0.5917 - val_loss: 1.7668 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.7477 - accuracy: 0.7109"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 11ms/step - loss: 1.7372 - accuracy: 0.6517 - val_loss: 1.7573 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7155 - accuracy: 0.6613 - val_loss: 1.7477 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6936 - accuracy: 0.6718 - val_loss: 1.7375 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6757 - accuracy: 0.6729 - val_loss: 1.7288 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6571 - accuracy: 0.6783 - val_loss: 1.7161 - val_accuracy: 0.5973\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6421 - accuracy: 0.6817 - val_loss: 1.7064 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6225 - accuracy: 0.6890 - val_loss: 1.6934 - val_accuracy: 0.6493\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6073 - accuracy: 0.6952 - val_loss: 1.6828 - val_accuracy: 0.5679\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5892 - accuracy: 0.7037 - val_loss: 1.6677 - val_accuracy: 0.6618\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5785 - accuracy: 0.7020 - val_loss: 1.6539 - val_accuracy: 0.6719\n","Epoch 12/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5662 - accuracy: 0.7077 - val_loss: 1.6416 - val_accuracy: 0.6403\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5535 - accuracy: 0.7083 - val_loss: 1.6252 - val_accuracy: 0.6833\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5371 - accuracy: 0.7139 - val_loss: 1.6077 - val_accuracy: 0.7036\n","Epoch 15/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5249 - accuracy: 0.7264 - val_loss: 1.5922 - val_accuracy: 0.7059\n","Epoch 16/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5159 - accuracy: 0.7196 - val_loss: 1.5739 - val_accuracy: 0.7025\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5051 - accuracy: 0.7193 - val_loss: 1.5583 - val_accuracy: 0.7002\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4935 - accuracy: 0.7213 - val_loss: 1.5398 - val_accuracy: 0.7104\n","Epoch 19/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4789 - accuracy: 0.7317 - val_loss: 1.5349 - val_accuracy: 0.6934\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4687 - accuracy: 0.7371 - val_loss: 1.5282 - val_accuracy: 0.6821\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4595 - accuracy: 0.7337 - val_loss: 1.5298 - val_accuracy: 0.6640\n","Epoch 22/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4508 - accuracy: 0.7351 - val_loss: 1.4765 - val_accuracy: 0.7081\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4414 - accuracy: 0.7343 - val_loss: 1.4686 - val_accuracy: 0.7229\n","Epoch 24/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4296 - accuracy: 0.7383 - val_loss: 1.4546 - val_accuracy: 0.7161\n","Epoch 25/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4218 - accuracy: 0.7329 - val_loss: 1.4423 - val_accuracy: 0.7183\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4105 - accuracy: 0.7462 - val_loss: 1.4360 - val_accuracy: 0.7172\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4034 - accuracy: 0.7408 - val_loss: 1.4266 - val_accuracy: 0.7115\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3941 - accuracy: 0.7484 - val_loss: 1.4223 - val_accuracy: 0.7262\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3839 - accuracy: 0.7476 - val_loss: 1.4069 - val_accuracy: 0.7183\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3756 - accuracy: 0.7518 - val_loss: 1.3993 - val_accuracy: 0.7183\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3667 - accuracy: 0.7504 - val_loss: 1.3965 - val_accuracy: 0.7104\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3616 - accuracy: 0.7445 - val_loss: 1.3878 - val_accuracy: 0.7183\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3497 - accuracy: 0.7552 - val_loss: 1.4054 - val_accuracy: 0.7262\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3450 - accuracy: 0.7538 - val_loss: 1.3721 - val_accuracy: 0.7217\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3337 - accuracy: 0.7530 - val_loss: 1.3833 - val_accuracy: 0.7330\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3303 - accuracy: 0.7501 - val_loss: 1.3558 - val_accuracy: 0.7229\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3181 - accuracy: 0.7592 - val_loss: 1.3492 - val_accuracy: 0.7206\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3114 - accuracy: 0.7603 - val_loss: 1.3472 - val_accuracy: 0.7274\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3030 - accuracy: 0.7651 - val_loss: 1.3370 - val_accuracy: 0.7229\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2974 - accuracy: 0.7629 - val_loss: 1.3314 - val_accuracy: 0.7206\n","Epoch 41/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2916 - accuracy: 0.7606 - val_loss: 1.3244 - val_accuracy: 0.7206\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2817 - accuracy: 0.7660 - val_loss: 1.3177 - val_accuracy: 0.7240\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2737 - accuracy: 0.7651 - val_loss: 1.3207 - val_accuracy: 0.7172\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2717 - accuracy: 0.7615 - val_loss: 1.3043 - val_accuracy: 0.7274\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2653 - accuracy: 0.7583 - val_loss: 1.2976 - val_accuracy: 0.7285\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2526 - accuracy: 0.7683 - val_loss: 1.2982 - val_accuracy: 0.7240\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2508 - accuracy: 0.7666 - val_loss: 1.2861 - val_accuracy: 0.7285\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2395 - accuracy: 0.7683 - val_loss: 1.2816 - val_accuracy: 0.7240\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2325 - accuracy: 0.7719 - val_loss: 1.2807 - val_accuracy: 0.7206\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2332 - accuracy: 0.7685 - val_loss: 1.2752 - val_accuracy: 0.7308\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2218 - accuracy: 0.7719 - val_loss: 1.2668 - val_accuracy: 0.7251\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2141 - accuracy: 0.7722 - val_loss: 1.2742 - val_accuracy: 0.7432\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2089 - accuracy: 0.7748 - val_loss: 1.2515 - val_accuracy: 0.7274\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2008 - accuracy: 0.7733 - val_loss: 1.2491 - val_accuracy: 0.7308\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1971 - accuracy: 0.7750 - val_loss: 1.2425 - val_accuracy: 0.7319\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1928 - accuracy: 0.7742 - val_loss: 1.2349 - val_accuracy: 0.7353\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1834 - accuracy: 0.7748 - val_loss: 1.2323 - val_accuracy: 0.7376\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1750 - accuracy: 0.7810 - val_loss: 1.2258 - val_accuracy: 0.7308\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1680 - accuracy: 0.7810 - val_loss: 1.2196 - val_accuracy: 0.7308\n","Epoch 60/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1628 - accuracy: 0.7852 - val_loss: 1.2254 - val_accuracy: 0.7466\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1593 - accuracy: 0.7830 - val_loss: 1.2109 - val_accuracy: 0.7376\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1513 - accuracy: 0.7796 - val_loss: 1.2047 - val_accuracy: 0.7376\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1457 - accuracy: 0.7810 - val_loss: 1.2032 - val_accuracy: 0.7387\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1391 - accuracy: 0.7869 - val_loss: 1.1932 - val_accuracy: 0.7364\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1311 - accuracy: 0.7929 - val_loss: 1.2084 - val_accuracy: 0.7398\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1292 - accuracy: 0.7895 - val_loss: 1.1845 - val_accuracy: 0.7387\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1208 - accuracy: 0.7903 - val_loss: 1.1826 - val_accuracy: 0.7410\n","Epoch 68/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1117 - accuracy: 0.7912 - val_loss: 1.1772 - val_accuracy: 0.7364\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1183 - accuracy: 0.7810 - val_loss: 1.1725 - val_accuracy: 0.7387\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1119 - accuracy: 0.7847 - val_loss: 1.1703 - val_accuracy: 0.7330\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0959 - accuracy: 0.7934 - val_loss: 1.1623 - val_accuracy: 0.7353\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0895 - accuracy: 0.7946 - val_loss: 1.1661 - val_accuracy: 0.7455\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0840 - accuracy: 0.7957 - val_loss: 1.1611 - val_accuracy: 0.7443\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0771 - accuracy: 0.7982 - val_loss: 1.1479 - val_accuracy: 0.7398\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0724 - accuracy: 0.7971 - val_loss: 1.1466 - val_accuracy: 0.7398\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0712 - accuracy: 0.7960 - val_loss: 1.1611 - val_accuracy: 0.7410\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0643 - accuracy: 0.7957 - val_loss: 1.1350 - val_accuracy: 0.7398\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0590 - accuracy: 0.7982 - val_loss: 1.1346 - val_accuracy: 0.7353\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0533 - accuracy: 0.7960 - val_loss: 1.1352 - val_accuracy: 0.7477\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0486 - accuracy: 0.7971 - val_loss: 1.1295 - val_accuracy: 0.7387\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0456 - accuracy: 0.7991 - val_loss: 1.1375 - val_accuracy: 0.7262\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0416 - accuracy: 0.7954 - val_loss: 1.1148 - val_accuracy: 0.7387\n","Epoch 83/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0375 - accuracy: 0.7954 - val_loss: 1.1113 - val_accuracy: 0.7410\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0235 - accuracy: 0.8084 - val_loss: 1.1079 - val_accuracy: 0.7330\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0172 - accuracy: 0.8107 - val_loss: 1.1020 - val_accuracy: 0.7330\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0170 - accuracy: 0.8022 - val_loss: 1.1064 - val_accuracy: 0.7443\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0107 - accuracy: 0.8042 - val_loss: 1.1139 - val_accuracy: 0.7455\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0118 - accuracy: 0.8016 - val_loss: 1.0970 - val_accuracy: 0.7443\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9953 - accuracy: 0.8138 - val_loss: 1.0908 - val_accuracy: 0.7319\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9931 - accuracy: 0.8101 - val_loss: 1.0963 - val_accuracy: 0.7466\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9876 - accuracy: 0.8115 - val_loss: 1.0973 - val_accuracy: 0.7500\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9829 - accuracy: 0.8101 - val_loss: 1.0751 - val_accuracy: 0.7455\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9775 - accuracy: 0.8158 - val_loss: 1.0907 - val_accuracy: 0.7342\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9756 - accuracy: 0.8118 - val_loss: 1.0813 - val_accuracy: 0.7489\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9661 - accuracy: 0.8132 - val_loss: 1.0701 - val_accuracy: 0.7296\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9605 - accuracy: 0.8189 - val_loss: 1.0611 - val_accuracy: 0.7500\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9614 - accuracy: 0.8147 - val_loss: 1.0626 - val_accuracy: 0.7319\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9515 - accuracy: 0.8209 - val_loss: 1.0589 - val_accuracy: 0.7296\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9623 - accuracy: 0.8079 - val_loss: 1.0813 - val_accuracy: 0.7534\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9522 - accuracy: 0.8186 - val_loss: 1.0473 - val_accuracy: 0.7477\n","{'loss': [1.763129711151123, 1.7372474670410156, 1.7155050039291382, 1.693590760231018, 1.6757142543792725, 1.6570731401443481, 1.6421030759811401, 1.6224803924560547, 1.6072791814804077, 1.5892103910446167, 1.5784974098205566, 1.566182255744934, 1.5535192489624023, 1.5371135473251343, 1.5248745679855347, 1.5159101486206055, 1.5051389932632446, 1.4935153722763062, 1.4789388179779053, 1.4687089920043945, 1.4595006704330444, 1.450774073600769, 1.4413963556289673, 1.4296324253082275, 1.4218006134033203, 1.4104962348937988, 1.4034045934677124, 1.39412260055542, 1.3838509321212769, 1.3756470680236816, 1.366736888885498, 1.361566424369812, 1.3497463464736938, 1.344962239265442, 1.3337478637695312, 1.330251932144165, 1.3181062936782837, 1.3113547563552856, 1.3029979467391968, 1.2974315881729126, 1.2915605306625366, 1.2816519737243652, 1.2737222909927368, 1.2716726064682007, 1.2653130292892456, 1.252578854560852, 1.2508187294006348, 1.239530324935913, 1.2324934005737305, 1.2331970930099487, 1.221827507019043, 1.21406888961792, 1.2089476585388184, 1.2008028030395508, 1.1970982551574707, 1.1928133964538574, 1.1834436655044556, 1.174961805343628, 1.168013095855713, 1.1627881526947021, 1.1592937707901, 1.1512724161148071, 1.1456809043884277, 1.1391195058822632, 1.1311205625534058, 1.1292167901992798, 1.1207829713821411, 1.1117326021194458, 1.1183085441589355, 1.1118605136871338, 1.0959362983703613, 1.0895001888275146, 1.0839864015579224, 1.0770645141601562, 1.0724085569381714, 1.0711541175842285, 1.064284324645996, 1.0590087175369263, 1.0533028841018677, 1.0486328601837158, 1.0455763339996338, 1.0416070222854614, 1.0374618768692017, 1.0235366821289062, 1.0171548128128052, 1.0169780254364014, 1.0107022523880005, 1.0117851495742798, 0.995252788066864, 0.9930868744850159, 0.9876148700714111, 0.982924222946167, 0.9774686098098755, 0.9755943417549133, 0.9660691618919373, 0.9604671597480774, 0.9613786935806274, 0.9514815211296082, 0.9622666239738464, 0.952195405960083], 'accuracy': [0.5916808247566223, 0.6516695022583008, 0.6612903475761414, 0.6717600226402283, 0.6728919148445129, 0.6782682538032532, 0.6816638112068176, 0.6890209317207336, 0.695246160030365, 0.7037351727485657, 0.7020373344421387, 0.7076966762542725, 0.70826256275177, 0.7139219045639038, 0.7263723611831665, 0.7195811867713928, 0.719298243522644, 0.7212790250778198, 0.7317487001419067, 0.7371250987052917, 0.7337294816970825, 0.735144317150116, 0.7342954277992249, 0.7382569313049316, 0.7328805923461914, 0.7461799383163452, 0.740803599357605, 0.7484436631202698, 0.7475947737693787, 0.751839280128479, 0.7504244446754456, 0.744482159614563, 0.7552348375320435, 0.7538200616836548, 0.7529711127281189, 0.7501415014266968, 0.759196400642395, 0.7603282332420349, 0.7651386260986328, 0.7628749012947083, 0.7606111764907837, 0.7659875750541687, 0.7651386260986328, 0.7614601254463196, 0.7583475112915039, 0.7682512998580933, 0.7665534615516663, 0.7682512998580933, 0.7719298005104065, 0.768534243106842, 0.7719298005104065, 0.7722128033638, 0.7747594714164734, 0.7733446359634399, 0.7750424742698669, 0.774193525314331, 0.7747594714164734, 0.7809846997261047, 0.7809846997261047, 0.7852292060852051, 0.7829654812812805, 0.7795698642730713, 0.7809846997261047, 0.7869269847869873, 0.7928692698478699, 0.7894737124443054, 0.7903226017951965, 0.7911714911460876, 0.7809846997261047, 0.7846632599830627, 0.7934352159500122, 0.7945670485496521, 0.7956989407539368, 0.7982456088066101, 0.7971137762069702, 0.7959818840026855, 0.7956989407539368, 0.7982456088066101, 0.7959818840026855, 0.7971137762069702, 0.7990944981575012, 0.7954159379005432, 0.7954159379005432, 0.808432400226593, 0.8106960654258728, 0.8022071123123169, 0.8041878938674927, 0.8016412258148193, 0.8138087391853333, 0.8101301789283752, 0.8115450143814087, 0.8101301789283752, 0.8157894611358643, 0.8118279576301575, 0.8132427930831909, 0.8189020752906799, 0.8146576285362244, 0.8208828568458557, 0.8078664541244507, 0.8186191320419312], 'val_loss': [1.7667622566223145, 1.757303237915039, 1.7477331161499023, 1.7375174760818481, 1.7288494110107422, 1.7161275148391724, 1.7063658237457275, 1.6934137344360352, 1.6827584505081177, 1.6676746606826782, 1.6539254188537598, 1.64155113697052, 1.625226378440857, 1.607680320739746, 1.592236876487732, 1.5739195346832275, 1.5582531690597534, 1.5398081541061401, 1.534900188446045, 1.5281693935394287, 1.5298330783843994, 1.476465106010437, 1.4686102867126465, 1.4545544385910034, 1.4423359632492065, 1.4360034465789795, 1.426628589630127, 1.4222508668899536, 1.4069219827651978, 1.3992630243301392, 1.3964992761611938, 1.3877840042114258, 1.4054218530654907, 1.372124433517456, 1.3832758665084839, 1.35579252243042, 1.3492088317871094, 1.347180724143982, 1.3370314836502075, 1.3314133882522583, 1.3243657350540161, 1.3176555633544922, 1.3206881284713745, 1.3042758703231812, 1.297574520111084, 1.298177719116211, 1.2861144542694092, 1.2816147804260254, 1.2806588411331177, 1.275160789489746, 1.2667808532714844, 1.2742416858673096, 1.2514848709106445, 1.2490965127944946, 1.2424943447113037, 1.2349154949188232, 1.2322583198547363, 1.2257517576217651, 1.2195746898651123, 1.22542142868042, 1.2109044790267944, 1.2047443389892578, 1.2032164335250854, 1.1932077407836914, 1.2084317207336426, 1.184522032737732, 1.1825660467147827, 1.1772245168685913, 1.172513484954834, 1.1703407764434814, 1.1622987985610962, 1.16611909866333, 1.1611264944076538, 1.1479215621948242, 1.1466200351715088, 1.1610981225967407, 1.1349691152572632, 1.1346279382705688, 1.1351521015167236, 1.1294902563095093, 1.1374717950820923, 1.1147822141647339, 1.111279010772705, 1.1079254150390625, 1.1020108461380005, 1.1063892841339111, 1.1138578653335571, 1.0969667434692383, 1.090807557106018, 1.0962846279144287, 1.0973091125488281, 1.0751128196716309, 1.090734839439392, 1.081262469291687, 1.0700585842132568, 1.0611122846603394, 1.0625791549682617, 1.0589284896850586, 1.0813379287719727, 1.047335147857666], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5972850918769836, 0.4954751133918762, 0.6493212580680847, 0.5678732991218567, 0.6617646813392639, 0.6719456911087036, 0.6402714848518372, 0.6832579374313354, 0.7036198973655701, 0.7058823704719543, 0.7024886608123779, 0.7002262473106384, 0.7104072570800781, 0.6934388875961304, 0.6821267008781433, 0.6640271544456482, 0.7081447839736938, 0.7228506803512573, 0.7160633206367493, 0.7183257937431335, 0.7171945571899414, 0.7115384340286255, 0.726244330406189, 0.7183257937431335, 0.7183257937431335, 0.7104072570800781, 0.7183257937431335, 0.726244330406189, 0.7217194437980652, 0.733031690120697, 0.7228506803512573, 0.720588207244873, 0.7273755669593811, 0.7228506803512573, 0.720588207244873, 0.720588207244873, 0.7239819169044495, 0.7171945571899414, 0.7273755669593811, 0.7285068035125732, 0.7239819169044495, 0.7285068035125732, 0.7239819169044495, 0.720588207244873, 0.7307692170143127, 0.7251130938529968, 0.7432126402854919, 0.7273755669593811, 0.7307692170143127, 0.7319004535675049, 0.7352941036224365, 0.7375565767288208, 0.7307692170143127, 0.7307692170143127, 0.7466063499450684, 0.7375565767288208, 0.7375565767288208, 0.7386877536773682, 0.7364253401756287, 0.7398189902305603, 0.7386877536773682, 0.7409502267837524, 0.7364253401756287, 0.7386877536773682, 0.733031690120697, 0.7352941036224365, 0.7454751133918762, 0.7443438768386841, 0.7398189902305603, 0.7398189902305603, 0.7409502267837524, 0.7398189902305603, 0.7352941036224365, 0.7477375268936157, 0.7386877536773682, 0.726244330406189, 0.7386877536773682, 0.7409502267837524, 0.733031690120697, 0.733031690120697, 0.7443438768386841, 0.7454751133918762, 0.7443438768386841, 0.7319004535675049, 0.7466063499450684, 0.75, 0.7454751133918762, 0.7341628670692444, 0.7488687634468079, 0.7296379804611206, 0.75, 0.7319004535675049, 0.7296379804611206, 0.7533936500549316, 0.7477375268936157]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 6s 28ms/step - loss: 1.7578 - accuracy: 0.6080 - val_loss: 1.7662 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.7432 - accuracy: 0.6484"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 12ms/step - loss: 1.7278 - accuracy: 0.6532 - val_loss: 1.7563 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6997 - accuracy: 0.6711 - val_loss: 1.7456 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6731 - accuracy: 0.6796 - val_loss: 1.7343 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6480 - accuracy: 0.6891 - val_loss: 1.7225 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6259 - accuracy: 0.6933 - val_loss: 1.7105 - val_accuracy: 0.4876\n","Epoch 7/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6075 - accuracy: 0.6974 - val_loss: 1.6985 - val_accuracy: 0.4876\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5902 - accuracy: 0.7031 - val_loss: 1.6825 - val_accuracy: 0.5444\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5692 - accuracy: 0.7098 - val_loss: 1.6663 - val_accuracy: 0.6395\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5520 - accuracy: 0.7163 - val_loss: 1.6492 - val_accuracy: 0.6860\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5404 - accuracy: 0.7160 - val_loss: 1.6315 - val_accuracy: 0.6942\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5328 - accuracy: 0.7220 - val_loss: 1.6127 - val_accuracy: 0.7107\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5133 - accuracy: 0.7271 - val_loss: 1.5944 - val_accuracy: 0.7087\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5003 - accuracy: 0.7266 - val_loss: 1.5752 - val_accuracy: 0.7149\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4896 - accuracy: 0.7305 - val_loss: 1.5561 - val_accuracy: 0.7200\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4805 - accuracy: 0.7292 - val_loss: 1.5377 - val_accuracy: 0.7118\n","Epoch 17/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4677 - accuracy: 0.7359 - val_loss: 1.5254 - val_accuracy: 0.7014\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4556 - accuracy: 0.7398 - val_loss: 1.5047 - val_accuracy: 0.7180\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4484 - accuracy: 0.7333 - val_loss: 1.4950 - val_accuracy: 0.7190\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4329 - accuracy: 0.7421 - val_loss: 1.4755 - val_accuracy: 0.7293\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4301 - accuracy: 0.7375 - val_loss: 1.4639 - val_accuracy: 0.7304\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4157 - accuracy: 0.7434 - val_loss: 1.4854 - val_accuracy: 0.6870\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4131 - accuracy: 0.7411 - val_loss: 1.4430 - val_accuracy: 0.7355\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3971 - accuracy: 0.7478 - val_loss: 1.4359 - val_accuracy: 0.7231\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3954 - accuracy: 0.7421 - val_loss: 1.4251 - val_accuracy: 0.7262\n","Epoch 26/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3782 - accuracy: 0.7501 - val_loss: 1.4276 - val_accuracy: 0.7283\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3705 - accuracy: 0.7522 - val_loss: 1.4093 - val_accuracy: 0.7407\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3604 - accuracy: 0.7543 - val_loss: 1.4043 - val_accuracy: 0.7180\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3507 - accuracy: 0.7558 - val_loss: 1.3927 - val_accuracy: 0.7417\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3446 - accuracy: 0.7574 - val_loss: 1.3863 - val_accuracy: 0.7252\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3427 - accuracy: 0.7491 - val_loss: 1.3776 - val_accuracy: 0.7428\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3262 - accuracy: 0.7607 - val_loss: 1.3792 - val_accuracy: 0.7448\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3235 - accuracy: 0.7550 - val_loss: 1.3659 - val_accuracy: 0.7448\n","Epoch 34/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3122 - accuracy: 0.7594 - val_loss: 1.3646 - val_accuracy: 0.7200\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3052 - accuracy: 0.7558 - val_loss: 1.3499 - val_accuracy: 0.7407\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2975 - accuracy: 0.7641 - val_loss: 1.3520 - val_accuracy: 0.7159\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2865 - accuracy: 0.7659 - val_loss: 1.3375 - val_accuracy: 0.7407\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2783 - accuracy: 0.7661 - val_loss: 1.3366 - val_accuracy: 0.7459\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2744 - accuracy: 0.7636 - val_loss: 1.3241 - val_accuracy: 0.7386\n","Epoch 40/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2725 - accuracy: 0.7574 - val_loss: 1.3382 - val_accuracy: 0.7087\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2673 - accuracy: 0.7599 - val_loss: 1.3135 - val_accuracy: 0.7479\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2513 - accuracy: 0.7669 - val_loss: 1.3065 - val_accuracy: 0.7438\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2442 - accuracy: 0.7685 - val_loss: 1.3012 - val_accuracy: 0.7417\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2392 - accuracy: 0.7664 - val_loss: 1.2945 - val_accuracy: 0.7314\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2268 - accuracy: 0.7716 - val_loss: 1.2993 - val_accuracy: 0.7479\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2287 - accuracy: 0.7643 - val_loss: 1.3011 - val_accuracy: 0.7138\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2194 - accuracy: 0.7664 - val_loss: 1.2766 - val_accuracy: 0.7438\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2089 - accuracy: 0.7711 - val_loss: 1.2744 - val_accuracy: 0.7479\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2027 - accuracy: 0.7687 - val_loss: 1.2657 - val_accuracy: 0.7438\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1995 - accuracy: 0.7726 - val_loss: 1.2786 - val_accuracy: 0.7035\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1885 - accuracy: 0.7755 - val_loss: 1.2562 - val_accuracy: 0.7293\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1864 - accuracy: 0.7700 - val_loss: 1.2511 - val_accuracy: 0.7490\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1778 - accuracy: 0.7770 - val_loss: 1.2435 - val_accuracy: 0.7397\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1718 - accuracy: 0.7711 - val_loss: 1.2491 - val_accuracy: 0.7459\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1643 - accuracy: 0.7760 - val_loss: 1.2408 - val_accuracy: 0.7242\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1660 - accuracy: 0.7747 - val_loss: 1.2283 - val_accuracy: 0.7469\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1509 - accuracy: 0.7796 - val_loss: 1.2211 - val_accuracy: 0.7428\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1468 - accuracy: 0.7832 - val_loss: 1.2251 - val_accuracy: 0.7510\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1442 - accuracy: 0.7780 - val_loss: 1.2105 - val_accuracy: 0.7428\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1330 - accuracy: 0.7837 - val_loss: 1.2080 - val_accuracy: 0.7531\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1255 - accuracy: 0.7842 - val_loss: 1.2026 - val_accuracy: 0.7521\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1223 - accuracy: 0.7809 - val_loss: 1.1979 - val_accuracy: 0.7417\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1181 - accuracy: 0.7809 - val_loss: 1.1952 - val_accuracy: 0.7273\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1118 - accuracy: 0.7783 - val_loss: 1.1902 - val_accuracy: 0.7314\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1061 - accuracy: 0.7866 - val_loss: 1.1835 - val_accuracy: 0.7355\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0978 - accuracy: 0.7829 - val_loss: 1.1876 - val_accuracy: 0.7221\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0946 - accuracy: 0.7817 - val_loss: 1.1721 - val_accuracy: 0.7428\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0855 - accuracy: 0.7860 - val_loss: 1.1718 - val_accuracy: 0.7531\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0829 - accuracy: 0.7868 - val_loss: 1.1651 - val_accuracy: 0.7510\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0752 - accuracy: 0.7832 - val_loss: 1.1606 - val_accuracy: 0.7479\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0742 - accuracy: 0.7809 - val_loss: 1.1582 - val_accuracy: 0.7355\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0634 - accuracy: 0.7886 - val_loss: 1.1491 - val_accuracy: 0.7428\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0562 - accuracy: 0.7925 - val_loss: 1.1471 - val_accuracy: 0.7448\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0513 - accuracy: 0.7891 - val_loss: 1.1410 - val_accuracy: 0.7510\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0489 - accuracy: 0.7894 - val_loss: 1.1373 - val_accuracy: 0.7428\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0424 - accuracy: 0.7894 - val_loss: 1.1350 - val_accuracy: 0.7510\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0373 - accuracy: 0.7891 - val_loss: 1.1291 - val_accuracy: 0.7428\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0311 - accuracy: 0.7897 - val_loss: 1.1238 - val_accuracy: 0.7521\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0283 - accuracy: 0.7907 - val_loss: 1.1253 - val_accuracy: 0.7262\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0214 - accuracy: 0.7930 - val_loss: 1.1159 - val_accuracy: 0.7407\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0143 - accuracy: 0.7933 - val_loss: 1.1105 - val_accuracy: 0.7417\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0131 - accuracy: 0.7912 - val_loss: 1.1105 - val_accuracy: 0.7293\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0072 - accuracy: 0.7910 - val_loss: 1.1055 - val_accuracy: 0.7479\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0159 - accuracy: 0.7907 - val_loss: 1.1169 - val_accuracy: 0.7490\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0075 - accuracy: 0.7915 - val_loss: 1.1889 - val_accuracy: 0.6663\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0087 - accuracy: 0.7879 - val_loss: 1.0936 - val_accuracy: 0.7624\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9888 - accuracy: 0.7951 - val_loss: 1.0928 - val_accuracy: 0.7252\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9856 - accuracy: 0.7990 - val_loss: 1.0841 - val_accuracy: 0.7583\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9780 - accuracy: 0.7987 - val_loss: 1.0879 - val_accuracy: 0.7603\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9729 - accuracy: 0.7992 - val_loss: 1.0780 - val_accuracy: 0.7397\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9677 - accuracy: 0.7984 - val_loss: 1.0724 - val_accuracy: 0.7510\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9710 - accuracy: 0.7922 - val_loss: 1.0697 - val_accuracy: 0.7510\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9563 - accuracy: 0.8008 - val_loss: 1.0662 - val_accuracy: 0.7407\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9532 - accuracy: 0.8065 - val_loss: 1.0628 - val_accuracy: 0.7397\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9500 - accuracy: 0.7995 - val_loss: 1.0734 - val_accuracy: 0.7180\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9559 - accuracy: 0.7907 - val_loss: 1.0622 - val_accuracy: 0.7572\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9384 - accuracy: 0.8062 - val_loss: 1.0639 - val_accuracy: 0.7221\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9463 - accuracy: 0.7984 - val_loss: 1.0684 - val_accuracy: 0.7541\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9328 - accuracy: 0.8034 - val_loss: 1.0455 - val_accuracy: 0.7479\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9285 - accuracy: 0.8049 - val_loss: 1.0666 - val_accuracy: 0.7149\n","{'loss': [1.7578171491622925, 1.7278343439102173, 1.6996749639511108, 1.6730613708496094, 1.6479824781417847, 1.6259175539016724, 1.6075103282928467, 1.5901633501052856, 1.5692108869552612, 1.5520349740982056, 1.5403825044631958, 1.5328119993209839, 1.5133275985717773, 1.5003458261489868, 1.489580512046814, 1.4804532527923584, 1.4677163362503052, 1.455557942390442, 1.4484132528305054, 1.4328817129135132, 1.4300957918167114, 1.4156996011734009, 1.4131227731704712, 1.3970571756362915, 1.3954428434371948, 1.3781917095184326, 1.3705267906188965, 1.360371708869934, 1.3507285118103027, 1.3445885181427002, 1.342674732208252, 1.3261886835098267, 1.3234903812408447, 1.3121931552886963, 1.305182695388794, 1.297537922859192, 1.2864649295806885, 1.278287649154663, 1.2743756771087646, 1.2725238800048828, 1.2672691345214844, 1.2512574195861816, 1.2442485094070435, 1.2391715049743652, 1.226813554763794, 1.22865891456604, 1.2194428443908691, 1.2089049816131592, 1.2027207612991333, 1.1994541883468628, 1.1884874105453491, 1.1863549947738647, 1.177820086479187, 1.1717556715011597, 1.1642768383026123, 1.1659841537475586, 1.150929570198059, 1.146751046180725, 1.1441625356674194, 1.1330033540725708, 1.1255043745040894, 1.1222736835479736, 1.1181321144104004, 1.1118208169937134, 1.1060547828674316, 1.0978037118911743, 1.0945624113082886, 1.085533618927002, 1.082905650138855, 1.0752452611923218, 1.0741690397262573, 1.0633658170700073, 1.0562185049057007, 1.0512633323669434, 1.0489490032196045, 1.0423628091812134, 1.0372883081436157, 1.0311330556869507, 1.0282888412475586, 1.0214499235153198, 1.0143468379974365, 1.013108730316162, 1.0072095394134521, 1.015886664390564, 1.0075151920318604, 1.0086863040924072, 0.9888201951980591, 0.9856201410293579, 0.9780173301696777, 0.9728729128837585, 0.9676623940467834, 0.9709673523902893, 0.9563141465187073, 0.9532406330108643, 0.949970543384552, 0.9559037089347839, 0.9383599758148193, 0.9462828040122986, 0.9328048229217529, 0.9285172820091248], 'accuracy': [0.6080103516578674, 0.6532299518585205, 0.6710594296455383, 0.6795865893363953, 0.6891472935676575, 0.6932816505432129, 0.6974160075187683, 0.7031008005142212, 0.7098191380500793, 0.7162790894508362, 0.7160206437110901, 0.7219638228416443, 0.7271317839622498, 0.7266150116920471, 0.7304909825325012, 0.7291989922523499, 0.735917329788208, 0.7397933006286621, 0.7333333492279053, 0.7421188354492188, 0.7374677062034607, 0.7434108257293701, 0.7410852909088135, 0.7478036284446716, 0.7421188354492188, 0.750129222869873, 0.7521963715553284, 0.7542635798454285, 0.7558139562606812, 0.7573643326759338, 0.749095618724823, 0.7607235312461853, 0.7550387382507324, 0.7594315409660339, 0.7558139562606812, 0.764082670211792, 0.7658914923667908, 0.7661498785018921, 0.7635658979415894, 0.7573643326759338, 0.7599483132362366, 0.766925036907196, 0.7684754729270935, 0.7664082646369934, 0.7715762257575989, 0.7643410563468933, 0.7664082646369934, 0.7710594534873962, 0.7687338590621948, 0.7726098299026489, 0.775452196598053, 0.7700258493423462, 0.7770025730133057, 0.7710594534873962, 0.7759689688682556, 0.7746769785881042, 0.7795865535736084, 0.7832041382789612, 0.7780361771583557, 0.7837209105491638, 0.7842377424240112, 0.7808785438537598, 0.7808785438537598, 0.778294563293457, 0.7865633368492126, 0.7829457521438599, 0.7816537618637085, 0.7860465049743652, 0.786821722984314, 0.7832041382789612, 0.7808785438537598, 0.788630485534668, 0.7925064563751221, 0.7891472578048706, 0.7894057035446167, 0.7894057035446167, 0.7891472578048706, 0.789664089679718, 0.7906976938247681, 0.7930232286453247, 0.7932816743850708, 0.7912144660949707, 0.7909560799598694, 0.7906976938247681, 0.791472852230072, 0.7878552675247192, 0.7950904369354248, 0.7989664077758789, 0.7987080216407776, 0.7992247939109802, 0.7984496355056763, 0.7922480702400208, 0.8007751703262329, 0.8064599633216858, 0.7994831800460815, 0.7906976938247681, 0.8062015771865845, 0.7984496355056763, 0.8033591508865356, 0.8049095869064331], 'val_loss': [1.7661677598953247, 1.7563254833221436, 1.745598316192627, 1.7343367338180542, 1.7225054502487183, 1.710458755493164, 1.6984782218933105, 1.682474136352539, 1.6663308143615723, 1.6492140293121338, 1.6315027475357056, 1.6127415895462036, 1.5944243669509888, 1.5752415657043457, 1.5561044216156006, 1.5377075672149658, 1.525367259979248, 1.5046826601028442, 1.495011806488037, 1.4755431413650513, 1.463948130607605, 1.4853907823562622, 1.4430311918258667, 1.435868501663208, 1.4250640869140625, 1.4276095628738403, 1.4092607498168945, 1.4042680263519287, 1.3927204608917236, 1.3862963914871216, 1.3775891065597534, 1.379247784614563, 1.3659305572509766, 1.364606499671936, 1.3498997688293457, 1.3519706726074219, 1.3375147581100464, 1.3366326093673706, 1.3240708112716675, 1.3382374048233032, 1.3135181665420532, 1.3065077066421509, 1.3011937141418457, 1.2945338487625122, 1.2993015050888062, 1.3010507822036743, 1.276583194732666, 1.2744357585906982, 1.2657188177108765, 1.2786238193511963, 1.2562289237976074, 1.2511229515075684, 1.2435318231582642, 1.2491412162780762, 1.2407526969909668, 1.2283008098602295, 1.2211264371871948, 1.225051760673523, 1.210512399673462, 1.2080055475234985, 1.2025845050811768, 1.1978601217269897, 1.1951981782913208, 1.1901848316192627, 1.1834934949874878, 1.1876187324523926, 1.1721240282058716, 1.1718051433563232, 1.165088176727295, 1.1605702638626099, 1.1582210063934326, 1.1490614414215088, 1.1471490859985352, 1.1409876346588135, 1.137259602546692, 1.1350438594818115, 1.1291178464889526, 1.123829960823059, 1.1252881288528442, 1.1159347295761108, 1.11048424243927, 1.1104954481124878, 1.105507493019104, 1.1169171333312988, 1.1889468431472778, 1.0936248302459717, 1.09275484085083, 1.0841450691223145, 1.0879355669021606, 1.0779863595962524, 1.0724427700042725, 1.0697174072265625, 1.0661649703979492, 1.0628347396850586, 1.0733832120895386, 1.0622094869613647, 1.0639134645462036, 1.0683934688568115, 1.0454802513122559, 1.0666272640228271], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.4876033067703247, 0.5444214940071106, 0.6394628286361694, 0.6859503984451294, 0.6942148804664612, 0.71074378490448, 0.7086777091026306, 0.7148760557174683, 0.7200413346290588, 0.711776852607727, 0.7014462947845459, 0.7179751992225647, 0.7190082669258118, 0.7293388247489929, 0.73037189245224, 0.6869834661483765, 0.7355371713638306, 0.7231404781341553, 0.7262396812438965, 0.7283057570457458, 0.7407024502754211, 0.7179751992225647, 0.7417355179786682, 0.7252066135406494, 0.7427685856819153, 0.7448347210884094, 0.7448347210884094, 0.7200413346290588, 0.7407024502754211, 0.7159090638160706, 0.7407024502754211, 0.7458677887916565, 0.7386363744735718, 0.7086777091026306, 0.7479338645935059, 0.7438016533851624, 0.7417355179786682, 0.7314049601554871, 0.7479338645935059, 0.7138429880142212, 0.7438016533851624, 0.7479338645935059, 0.7438016533851624, 0.7035123705863953, 0.7293388247489929, 0.7489669322967529, 0.7396694421768188, 0.7458677887916565, 0.7241735458374023, 0.7469007968902588, 0.7427685856819153, 0.7510330677032471, 0.7427685856819153, 0.7530992031097412, 0.7520661354064941, 0.7417355179786682, 0.7272727489471436, 0.7314049601554871, 0.7355371713638306, 0.7221074104309082, 0.7427685856819153, 0.7530992031097412, 0.7510330677032471, 0.7479338645935059, 0.7355371713638306, 0.7427685856819153, 0.7448347210884094, 0.7510330677032471, 0.7427685856819153, 0.7510330677032471, 0.7427685856819153, 0.7520661354064941, 0.7262396812438965, 0.7407024502754211, 0.7417355179786682, 0.7293388247489929, 0.7479338645935059, 0.7489669322967529, 0.6663222908973694, 0.7623966932296753, 0.7252066135406494, 0.7582644820213318, 0.7603305578231812, 0.7396694421768188, 0.7510330677032471, 0.7510330677032471, 0.7407024502754211, 0.7396694421768188, 0.7179751992225647, 0.7572314143180847, 0.7221074104309082, 0.7541322112083435, 0.7479338645935059, 0.7148760557174683]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 27ms/step - loss: 1.0082 - accuracy: 0.7702 - val_loss: 1.2512 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.0777 - accuracy: 0.6875"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 11ms/step - loss: 0.9917 - accuracy: 0.7802 - val_loss: 1.2375 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9842 - accuracy: 0.7796 - val_loss: 1.2270 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9757 - accuracy: 0.7858 - val_loss: 1.2107 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9722 - accuracy: 0.7874 - val_loss: 1.1891 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9617 - accuracy: 0.7896 - val_loss: 1.1698 - val_accuracy: 0.5183\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9612 - accuracy: 0.7891 - val_loss: 1.1647 - val_accuracy: 0.5097\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9558 - accuracy: 0.7901 - val_loss: 1.1431 - val_accuracy: 0.6455\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9484 - accuracy: 0.7909 - val_loss: 1.1335 - val_accuracy: 0.6412\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9390 - accuracy: 0.7942 - val_loss: 1.1156 - val_accuracy: 0.7306\n","Epoch 11/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9359 - accuracy: 0.7928 - val_loss: 1.1010 - val_accuracy: 0.7295\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9311 - accuracy: 0.7939 - val_loss: 1.0848 - val_accuracy: 0.7425\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9244 - accuracy: 0.7947 - val_loss: 1.0709 - val_accuracy: 0.7252\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9223 - accuracy: 0.7971 - val_loss: 1.0562 - val_accuracy: 0.7284\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9205 - accuracy: 0.7936 - val_loss: 1.0539 - val_accuracy: 0.6875\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9218 - accuracy: 0.7955 - val_loss: 1.0267 - val_accuracy: 0.7349\n","Epoch 17/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9035 - accuracy: 0.8023 - val_loss: 1.0401 - val_accuracy: 0.6886\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9061 - accuracy: 0.7998 - val_loss: 0.9922 - val_accuracy: 0.7532\n","Epoch 19/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9008 - accuracy: 0.8006 - val_loss: 1.0123 - val_accuracy: 0.7155\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8901 - accuracy: 0.8071 - val_loss: 0.9817 - val_accuracy: 0.7522\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8916 - accuracy: 0.8047 - val_loss: 0.9574 - val_accuracy: 0.7554\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8833 - accuracy: 0.8050 - val_loss: 0.9702 - val_accuracy: 0.7565\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8762 - accuracy: 0.8098 - val_loss: 0.9408 - val_accuracy: 0.7608\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8721 - accuracy: 0.8114 - val_loss: 0.9442 - val_accuracy: 0.7619\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8721 - accuracy: 0.8087 - val_loss: 0.9235 - val_accuracy: 0.7532\n","Epoch 26/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8643 - accuracy: 0.8152 - val_loss: 0.9178 - val_accuracy: 0.7597\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8623 - accuracy: 0.8109 - val_loss: 0.9167 - val_accuracy: 0.7662\n","Epoch 28/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8613 - accuracy: 0.8117 - val_loss: 0.9355 - val_accuracy: 0.7565\n","Epoch 29/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8523 - accuracy: 0.8165 - val_loss: 0.9033 - val_accuracy: 0.7662\n","Epoch 30/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8547 - accuracy: 0.8125 - val_loss: 0.9241 - val_accuracy: 0.7640\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8694 - accuracy: 0.8006 - val_loss: 0.9158 - val_accuracy: 0.7586\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8420 - accuracy: 0.8206 - val_loss: 0.8955 - val_accuracy: 0.7683\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8352 - accuracy: 0.8214 - val_loss: 0.9029 - val_accuracy: 0.7672\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8348 - accuracy: 0.8182 - val_loss: 0.8962 - val_accuracy: 0.7672\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8287 - accuracy: 0.8225 - val_loss: 0.8975 - val_accuracy: 0.7575\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8238 - accuracy: 0.8225 - val_loss: 0.9056 - val_accuracy: 0.7716\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8231 - accuracy: 0.8214 - val_loss: 0.8822 - val_accuracy: 0.7662\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8135 - accuracy: 0.8284 - val_loss: 0.8785 - val_accuracy: 0.7716\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8133 - accuracy: 0.8249 - val_loss: 0.8858 - val_accuracy: 0.7705\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8098 - accuracy: 0.8244 - val_loss: 0.8859 - val_accuracy: 0.7629\n","Epoch 41/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8085 - accuracy: 0.8249 - val_loss: 0.8795 - val_accuracy: 0.7640\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8004 - accuracy: 0.8260 - val_loss: 0.8738 - val_accuracy: 0.7737\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7950 - accuracy: 0.8330 - val_loss: 0.8669 - val_accuracy: 0.7705\n","Epoch 44/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7919 - accuracy: 0.8354 - val_loss: 0.8653 - val_accuracy: 0.7726\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7937 - accuracy: 0.8297 - val_loss: 0.8881 - val_accuracy: 0.7532\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8116 - accuracy: 0.8120 - val_loss: 0.8608 - val_accuracy: 0.7802\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7893 - accuracy: 0.8246 - val_loss: 0.8587 - val_accuracy: 0.7726\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7842 - accuracy: 0.8289 - val_loss: 0.8751 - val_accuracy: 0.7694\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7727 - accuracy: 0.8421 - val_loss: 0.8570 - val_accuracy: 0.7672\n","Epoch 50/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7698 - accuracy: 0.8389 - val_loss: 0.8667 - val_accuracy: 0.7608\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7690 - accuracy: 0.8370 - val_loss: 0.8575 - val_accuracy: 0.7716\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7663 - accuracy: 0.8394 - val_loss: 0.8750 - val_accuracy: 0.7511\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7668 - accuracy: 0.8351 - val_loss: 0.8653 - val_accuracy: 0.7619\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7560 - accuracy: 0.8389 - val_loss: 0.8464 - val_accuracy: 0.7791\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7646 - accuracy: 0.8303 - val_loss: 0.8525 - val_accuracy: 0.7608\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7499 - accuracy: 0.8421 - val_loss: 0.8456 - val_accuracy: 0.7748\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7469 - accuracy: 0.8475 - val_loss: 0.8427 - val_accuracy: 0.7716\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7407 - accuracy: 0.8481 - val_loss: 0.8414 - val_accuracy: 0.7694\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7436 - accuracy: 0.8475 - val_loss: 0.8403 - val_accuracy: 0.7705\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7434 - accuracy: 0.8483 - val_loss: 0.8546 - val_accuracy: 0.7640\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7379 - accuracy: 0.8416 - val_loss: 0.8491 - val_accuracy: 0.7683\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7284 - accuracy: 0.8521 - val_loss: 0.8474 - val_accuracy: 0.7651\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7239 - accuracy: 0.8513 - val_loss: 0.8341 - val_accuracy: 0.7737\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7345 - accuracy: 0.8397 - val_loss: 0.8332 - val_accuracy: 0.7759\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7289 - accuracy: 0.8448 - val_loss: 0.8312 - val_accuracy: 0.7705\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7193 - accuracy: 0.8510 - val_loss: 0.8455 - val_accuracy: 0.7640\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7149 - accuracy: 0.8570 - val_loss: 0.8280 - val_accuracy: 0.7791\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7119 - accuracy: 0.8513 - val_loss: 0.8470 - val_accuracy: 0.7586\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7051 - accuracy: 0.8610 - val_loss: 0.8518 - val_accuracy: 0.7575\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7029 - accuracy: 0.8570 - val_loss: 0.8278 - val_accuracy: 0.7726\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7004 - accuracy: 0.8596 - val_loss: 0.8329 - val_accuracy: 0.7619\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6979 - accuracy: 0.8602 - val_loss: 0.8223 - val_accuracy: 0.7705\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.8588 - val_loss: 0.8322 - val_accuracy: 0.7716\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.8602 - val_loss: 0.8371 - val_accuracy: 0.7640\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6861 - accuracy: 0.8677 - val_loss: 0.8224 - val_accuracy: 0.7737\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.8516 - val_loss: 0.8361 - val_accuracy: 0.7640\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6853 - accuracy: 0.8623 - val_loss: 0.8242 - val_accuracy: 0.7748\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6793 - accuracy: 0.8642 - val_loss: 0.8215 - val_accuracy: 0.7748\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6765 - accuracy: 0.8664 - val_loss: 0.8639 - val_accuracy: 0.7306\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.8626 - val_loss: 0.8154 - val_accuracy: 0.7791\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6652 - accuracy: 0.8707 - val_loss: 0.8177 - val_accuracy: 0.7759\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6626 - accuracy: 0.8726 - val_loss: 0.8254 - val_accuracy: 0.7716\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6628 - accuracy: 0.8704 - val_loss: 0.8166 - val_accuracy: 0.7726\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6543 - accuracy: 0.8772 - val_loss: 0.8143 - val_accuracy: 0.7716\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6532 - accuracy: 0.8737 - val_loss: 0.8164 - val_accuracy: 0.7662\n","Epoch 86/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6561 - accuracy: 0.8710 - val_loss: 0.8143 - val_accuracy: 0.7737\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6555 - accuracy: 0.8715 - val_loss: 0.8134 - val_accuracy: 0.7737\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6449 - accuracy: 0.8812 - val_loss: 0.8142 - val_accuracy: 0.7716\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6436 - accuracy: 0.8788 - val_loss: 0.8185 - val_accuracy: 0.7726\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6411 - accuracy: 0.8785 - val_loss: 0.8145 - val_accuracy: 0.7748\n","Epoch 91/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6463 - accuracy: 0.8712 - val_loss: 0.8430 - val_accuracy: 0.7619\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6434 - accuracy: 0.8723 - val_loss: 0.8283 - val_accuracy: 0.7640\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6286 - accuracy: 0.8831 - val_loss: 0.8092 - val_accuracy: 0.7716\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6242 - accuracy: 0.8871 - val_loss: 0.8137 - val_accuracy: 0.7619\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6211 - accuracy: 0.8877 - val_loss: 0.8105 - val_accuracy: 0.7737\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6278 - accuracy: 0.8785 - val_loss: 0.8508 - val_accuracy: 0.7489\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6206 - accuracy: 0.8879 - val_loss: 0.8242 - val_accuracy: 0.7640\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6294 - accuracy: 0.8788 - val_loss: 0.8100 - val_accuracy: 0.7737\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6127 - accuracy: 0.8893 - val_loss: 0.8260 - val_accuracy: 0.7629\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6156 - accuracy: 0.8860 - val_loss: 0.8149 - val_accuracy: 0.7737\n","{'loss': [1.0082145929336548, 0.9917210340499878, 0.9841659069061279, 0.9756547212600708, 0.9721717238426208, 0.9617226719856262, 0.9612157344818115, 0.9558120369911194, 0.9483894109725952, 0.9390126466751099, 0.9358922839164734, 0.9311164617538452, 0.9243805408477783, 0.9222894906997681, 0.9204999804496765, 0.9218395948410034, 0.9035104513168335, 0.9060856103897095, 0.9008392095565796, 0.8901407718658447, 0.8915879726409912, 0.8833051323890686, 0.8762104511260986, 0.8720844984054565, 0.8721230030059814, 0.864327073097229, 0.862251341342926, 0.8613092303276062, 0.8522984981536865, 0.8547397255897522, 0.8694171905517578, 0.8420013189315796, 0.8352277874946594, 0.8348149061203003, 0.8286869525909424, 0.8237869739532471, 0.8231368660926819, 0.8135043978691101, 0.8133195638656616, 0.8098081946372986, 0.8085207939147949, 0.8004254102706909, 0.7949809432029724, 0.7918919920921326, 0.7937483787536621, 0.8116377592086792, 0.7893050909042358, 0.7841561436653137, 0.7727289795875549, 0.7697697281837463, 0.7689768075942993, 0.7663485407829285, 0.7668496370315552, 0.7560480833053589, 0.7646408677101135, 0.7498857378959656, 0.7468562126159668, 0.7406864762306213, 0.7435795068740845, 0.7433947920799255, 0.7379350066184998, 0.7284389734268188, 0.7239199280738831, 0.7345290184020996, 0.728909432888031, 0.7193417549133301, 0.7148569226264954, 0.7118783593177795, 0.7050720453262329, 0.7029410004615784, 0.7004108428955078, 0.6978841423988342, 0.6930599212646484, 0.6936908960342407, 0.6861386895179749, 0.6932334899902344, 0.6852807402610779, 0.6793147921562195, 0.676469624042511, 0.6786370277404785, 0.6651734709739685, 0.662629246711731, 0.6628461480140686, 0.6543266773223877, 0.6532458662986755, 0.6561258435249329, 0.6555287837982178, 0.6449120044708252, 0.6436272263526917, 0.6410857439041138, 0.6463444232940674, 0.6434248685836792, 0.628558337688446, 0.6242136359214783, 0.6211246252059937, 0.6277726292610168, 0.6205946803092957, 0.6293699145317078, 0.612679123878479, 0.6155584454536438], 'accuracy': [0.7702047228813171, 0.7801724076271057, 0.779633641242981, 0.7858297228813171, 0.787446141242981, 0.7896012663841248, 0.7890625, 0.7901400923728943, 0.7909482717514038, 0.7941810488700867, 0.7928340435028076, 0.7939116358757019, 0.7947198152542114, 0.7971444129943848, 0.7936422228813171, 0.795527994632721, 0.8022629022598267, 0.7998383641242981, 0.8006465435028076, 0.8071120977401733, 0.8046875, 0.8049569129943848, 0.8098060488700867, 0.8114224076271057, 0.8087284564971924, 0.8151939511299133, 0.810883641242981, 0.8116918206214905, 0.8165409564971924, 0.8125, 0.8006465435028076, 0.8205819129943848, 0.8213900923728943, 0.8181573152542114, 0.8224676847457886, 0.8224676847457886, 0.8213900923728943, 0.8283944129943848, 0.8248922228813171, 0.8243534564971924, 0.8248922228813171, 0.8259698152542114, 0.8329741358757019, 0.8353987336158752, 0.829741358757019, 0.8119612336158752, 0.8246228694915771, 0.8289331793785095, 0.842133641242981, 0.8389008641242981, 0.8370150923728943, 0.8394396305084229, 0.8351293206214905, 0.8389008641242981, 0.8302801847457886, 0.842133641242981, 0.8475215435028076, 0.8480603694915771, 0.8475215435028076, 0.8483297228813171, 0.8415948152542114, 0.8521012663841248, 0.8512930870056152, 0.8397090435028076, 0.8448275923728943, 0.8510237336158752, 0.8569504022598267, 0.8512930870056152, 0.860991358757019, 0.8569504022598267, 0.8596444129943848, 0.8601831793785095, 0.8588362336158752, 0.8601831793785095, 0.8677262663841248, 0.8515625, 0.8623383641242981, 0.8642241358757019, 0.8663793206214905, 0.8626077771186829, 0.8706896305084229, 0.8725754022598267, 0.8704202771186829, 0.8771551847457886, 0.873652994632721, 0.8709590435028076, 0.8714978694915771, 0.881196141242981, 0.8787715435028076, 0.8785021305084229, 0.8712284564971924, 0.8723060488700867, 0.8830819129943848, 0.8871228694915771, 0.8876616358757019, 0.8785021305084229, 0.8879310488700867, 0.8787715435028076, 0.889277994632721, 0.8860452771186829], 'val_loss': [1.2512338161468506, 1.2374950647354126, 1.2269905805587769, 1.2107429504394531, 1.1890736818313599, 1.1698248386383057, 1.164735198020935, 1.143103003501892, 1.133498191833496, 1.115586757659912, 1.1010339260101318, 1.0848042964935303, 1.0708813667297363, 1.0561922788619995, 1.0538936853408813, 1.0267318487167358, 1.0400810241699219, 0.9921926856040955, 1.01226007938385, 0.9817146062850952, 0.957431435585022, 0.9701746106147766, 0.9407623410224915, 0.9442225098609924, 0.9234930872917175, 0.9178206920623779, 0.9167209267616272, 0.9354888796806335, 0.9032878875732422, 0.924074649810791, 0.9157611727714539, 0.8954665660858154, 0.9028798937797546, 0.8962496519088745, 0.8975337743759155, 0.9055886268615723, 0.8821859955787659, 0.8784982562065125, 0.8858186602592468, 0.8859041929244995, 0.8794668912887573, 0.8738325238227844, 0.8668838739395142, 0.8653187155723572, 0.888096034526825, 0.860765814781189, 0.8587188720703125, 0.8750663995742798, 0.8570111393928528, 0.866659939289093, 0.8574812412261963, 0.8750408291816711, 0.8653476238250732, 0.8464450836181641, 0.8525338172912598, 0.8456326723098755, 0.8426572680473328, 0.841376781463623, 0.8402519226074219, 0.8546345233917236, 0.849065899848938, 0.847410261631012, 0.8340818285942078, 0.8331853151321411, 0.8311746716499329, 0.8455244898796082, 0.8280307054519653, 0.8470091223716736, 0.8517871499061584, 0.8277757167816162, 0.8329129219055176, 0.8223016858100891, 0.8321512937545776, 0.8371251225471497, 0.8223551511764526, 0.8361214399337769, 0.8241748809814453, 0.8215276598930359, 0.8638858795166016, 0.8153649568557739, 0.8177180290222168, 0.825438380241394, 0.8166216015815735, 0.8143322467803955, 0.8164258003234863, 0.8142699599266052, 0.8133831024169922, 0.8141893744468689, 0.8185086846351624, 0.814460813999176, 0.843005359172821, 0.828328013420105, 0.8092194199562073, 0.8137065172195435, 0.8104608058929443, 0.8507768511772156, 0.8241659998893738, 0.8099938631057739, 0.8259834051132202, 0.8149225115776062], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.5183189511299133, 0.5096982717514038, 0.6454741358757019, 0.6411637663841248, 0.7306034564971924, 0.7295258641242981, 0.7424569129943848, 0.725215494632721, 0.7284482717514038, 0.6875, 0.7349137663841248, 0.6885775923728943, 0.7532327771186829, 0.7155172228813171, 0.7521551847457886, 0.7553879022598267, 0.756465494632721, 0.7607758641242981, 0.7618534564971924, 0.7532327771186829, 0.7596982717514038, 0.7661637663841248, 0.756465494632721, 0.7661637663841248, 0.764008641242981, 0.7586206793785095, 0.7683189511299133, 0.767241358757019, 0.767241358757019, 0.7575430870056152, 0.7715517282485962, 0.7661637663841248, 0.7715517282485962, 0.7704741358757019, 0.7629310488700867, 0.764008641242981, 0.7737069129943848, 0.7704741358757019, 0.7726293206214905, 0.7532327771186829, 0.7801724076271057, 0.7726293206214905, 0.7693965435028076, 0.767241358757019, 0.7607758641242981, 0.7715517282485962, 0.7510775923728943, 0.7618534564971924, 0.7790948152542114, 0.7607758641242981, 0.774784505367279, 0.7715517282485962, 0.7693965435028076, 0.7704741358757019, 0.764008641242981, 0.7683189511299133, 0.7650862336158752, 0.7737069129943848, 0.7758620977401733, 0.7704741358757019, 0.764008641242981, 0.7790948152542114, 0.7586206793785095, 0.7575430870056152, 0.7726293206214905, 0.7618534564971924, 0.7704741358757019, 0.7715517282485962, 0.764008641242981, 0.7737069129943848, 0.764008641242981, 0.774784505367279, 0.774784505367279, 0.7306034564971924, 0.7790948152542114, 0.7758620977401733, 0.7715517282485962, 0.7726293206214905, 0.7715517282485962, 0.7661637663841248, 0.7737069129943848, 0.7737069129943848, 0.7715517282485962, 0.7726293206214905, 0.774784505367279, 0.7618534564971924, 0.764008641242981, 0.7715517282485962, 0.7618534564971924, 0.7737069129943848, 0.7489224076271057, 0.764008641242981, 0.7737069129943848, 0.7629310488700867, 0.7737069129943848]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 29ms/step - loss: 1.0132 - accuracy: 0.7663 - val_loss: 1.2447 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.9980 - accuracy: 0.8281"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 11ms/step - loss: 0.9932 - accuracy: 0.7733 - val_loss: 1.2318 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9824 - accuracy: 0.7782 - val_loss: 1.2140 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9773 - accuracy: 0.7790 - val_loss: 1.2036 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9711 - accuracy: 0.7830 - val_loss: 1.1937 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9624 - accuracy: 0.7923 - val_loss: 1.1755 - val_accuracy: 0.5000\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9534 - accuracy: 0.7883 - val_loss: 1.1654 - val_accuracy: 0.5090\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9501 - accuracy: 0.7898 - val_loss: 1.1439 - val_accuracy: 0.6448\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9422 - accuracy: 0.7912 - val_loss: 1.1314 - val_accuracy: 0.7002\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9379 - accuracy: 0.7943 - val_loss: 1.1206 - val_accuracy: 0.6957\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9293 - accuracy: 0.8005 - val_loss: 1.1049 - val_accuracy: 0.7195\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9266 - accuracy: 0.7965 - val_loss: 1.0921 - val_accuracy: 0.7161\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9186 - accuracy: 0.8016 - val_loss: 1.0747 - val_accuracy: 0.7240\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9257 - accuracy: 0.7915 - val_loss: 1.0674 - val_accuracy: 0.7048\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9114 - accuracy: 0.8014 - val_loss: 1.0514 - val_accuracy: 0.7127\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9090 - accuracy: 0.7954 - val_loss: 1.0387 - val_accuracy: 0.7172\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9077 - accuracy: 0.8025 - val_loss: 1.0190 - val_accuracy: 0.7364\n","Epoch 18/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8974 - accuracy: 0.8084 - val_loss: 1.0398 - val_accuracy: 0.7036\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8919 - accuracy: 0.8096 - val_loss: 0.9950 - val_accuracy: 0.7342\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8873 - accuracy: 0.8084 - val_loss: 0.9859 - val_accuracy: 0.7410\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8842 - accuracy: 0.8076 - val_loss: 0.9885 - val_accuracy: 0.7353\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8768 - accuracy: 0.8161 - val_loss: 0.9683 - val_accuracy: 0.7455\n","Epoch 23/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8702 - accuracy: 0.8104 - val_loss: 1.0166 - val_accuracy: 0.7229\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8733 - accuracy: 0.8048 - val_loss: 0.9526 - val_accuracy: 0.7613\n","Epoch 25/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8647 - accuracy: 0.8130 - val_loss: 0.9585 - val_accuracy: 0.7613\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8583 - accuracy: 0.8164 - val_loss: 0.9706 - val_accuracy: 0.7511\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8547 - accuracy: 0.8189 - val_loss: 0.9868 - val_accuracy: 0.7387\n","Epoch 28/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8695 - accuracy: 0.8056 - val_loss: 0.9425 - val_accuracy: 0.7647\n","Epoch 29/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8492 - accuracy: 0.8161 - val_loss: 0.9450 - val_accuracy: 0.7432\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8498 - accuracy: 0.8155 - val_loss: 0.9488 - val_accuracy: 0.7590\n","Epoch 31/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8482 - accuracy: 0.8101 - val_loss: 0.9310 - val_accuracy: 0.7353\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8356 - accuracy: 0.8254 - val_loss: 0.9240 - val_accuracy: 0.7466\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8285 - accuracy: 0.8265 - val_loss: 0.9454 - val_accuracy: 0.7590\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8266 - accuracy: 0.8214 - val_loss: 0.9225 - val_accuracy: 0.7387\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8242 - accuracy: 0.8260 - val_loss: 0.9234 - val_accuracy: 0.7636\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8167 - accuracy: 0.8280 - val_loss: 0.9260 - val_accuracy: 0.7670\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8173 - accuracy: 0.8274 - val_loss: 0.9318 - val_accuracy: 0.7613\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8205 - accuracy: 0.8214 - val_loss: 0.9228 - val_accuracy: 0.7658\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8066 - accuracy: 0.8325 - val_loss: 0.9095 - val_accuracy: 0.7647\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8156 - accuracy: 0.8175 - val_loss: 0.9522 - val_accuracy: 0.7217\n","Epoch 41/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8183 - accuracy: 0.8203 - val_loss: 0.9352 - val_accuracy: 0.7613\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8061 - accuracy: 0.8280 - val_loss: 0.9029 - val_accuracy: 0.7613\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7885 - accuracy: 0.8381 - val_loss: 0.8993 - val_accuracy: 0.7590\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7855 - accuracy: 0.8379 - val_loss: 0.9018 - val_accuracy: 0.7489\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7900 - accuracy: 0.8359 - val_loss: 0.8970 - val_accuracy: 0.7568\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7872 - accuracy: 0.8282 - val_loss: 0.9111 - val_accuracy: 0.7613\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7815 - accuracy: 0.8373 - val_loss: 0.8905 - val_accuracy: 0.7590\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7714 - accuracy: 0.8401 - val_loss: 0.8944 - val_accuracy: 0.7647\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7674 - accuracy: 0.8424 - val_loss: 0.9091 - val_accuracy: 0.7296\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7749 - accuracy: 0.8319 - val_loss: 0.8925 - val_accuracy: 0.7364\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7642 - accuracy: 0.8353 - val_loss: 0.8861 - val_accuracy: 0.7579\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7576 - accuracy: 0.8506 - val_loss: 0.8900 - val_accuracy: 0.7704\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7666 - accuracy: 0.8328 - val_loss: 0.8971 - val_accuracy: 0.7692\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7575 - accuracy: 0.8379 - val_loss: 0.8816 - val_accuracy: 0.7681\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7463 - accuracy: 0.8509 - val_loss: 0.8824 - val_accuracy: 0.7681\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7432 - accuracy: 0.8461 - val_loss: 0.8775 - val_accuracy: 0.7579\n","Epoch 57/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7428 - accuracy: 0.8441 - val_loss: 0.8848 - val_accuracy: 0.7387\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7371 - accuracy: 0.8531 - val_loss: 0.8779 - val_accuracy: 0.7557\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7496 - accuracy: 0.8427 - val_loss: 0.8766 - val_accuracy: 0.7511\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7289 - accuracy: 0.8546 - val_loss: 0.8898 - val_accuracy: 0.7658\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7287 - accuracy: 0.8503 - val_loss: 0.8861 - val_accuracy: 0.7681\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7230 - accuracy: 0.8523 - val_loss: 0.8669 - val_accuracy: 0.7647\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7269 - accuracy: 0.8480 - val_loss: 0.8757 - val_accuracy: 0.7511\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7169 - accuracy: 0.8551 - val_loss: 0.8753 - val_accuracy: 0.7658\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7091 - accuracy: 0.8619 - val_loss: 0.8753 - val_accuracy: 0.7489\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7106 - accuracy: 0.8591 - val_loss: 0.8754 - val_accuracy: 0.7410\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7107 - accuracy: 0.8557 - val_loss: 0.8670 - val_accuracy: 0.7568\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7033 - accuracy: 0.8625 - val_loss: 0.8631 - val_accuracy: 0.7624\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6977 - accuracy: 0.8687 - val_loss: 0.8726 - val_accuracy: 0.7692\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7012 - accuracy: 0.8602 - val_loss: 0.8744 - val_accuracy: 0.7658\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6976 - accuracy: 0.8647 - val_loss: 0.8783 - val_accuracy: 0.7432\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7047 - accuracy: 0.8557 - val_loss: 0.8663 - val_accuracy: 0.7636\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6854 - accuracy: 0.8642 - val_loss: 0.8587 - val_accuracy: 0.7658\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7014 - accuracy: 0.8568 - val_loss: 0.8593 - val_accuracy: 0.7704\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.8619 - val_loss: 0.8640 - val_accuracy: 0.7647\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6762 - accuracy: 0.8704 - val_loss: 0.8586 - val_accuracy: 0.7681\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.8704 - val_loss: 0.8546 - val_accuracy: 0.7670\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6757 - accuracy: 0.8698 - val_loss: 0.8832 - val_accuracy: 0.7681\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6792 - accuracy: 0.8667 - val_loss: 0.8692 - val_accuracy: 0.7670\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6648 - accuracy: 0.8749 - val_loss: 0.8661 - val_accuracy: 0.7658\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6656 - accuracy: 0.8721 - val_loss: 0.8542 - val_accuracy: 0.7647\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6719 - accuracy: 0.8613 - val_loss: 0.8568 - val_accuracy: 0.7636\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6553 - accuracy: 0.8769 - val_loss: 0.8623 - val_accuracy: 0.7658\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6506 - accuracy: 0.8780 - val_loss: 0.8609 - val_accuracy: 0.7624\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6545 - accuracy: 0.8707 - val_loss: 0.8505 - val_accuracy: 0.7613\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6483 - accuracy: 0.8803 - val_loss: 0.8599 - val_accuracy: 0.7545\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6476 - accuracy: 0.8729 - val_loss: 0.8584 - val_accuracy: 0.7568\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6402 - accuracy: 0.8840 - val_loss: 0.8605 - val_accuracy: 0.7590\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6382 - accuracy: 0.8812 - val_loss: 0.8543 - val_accuracy: 0.7636\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6509 - accuracy: 0.8707 - val_loss: 0.8672 - val_accuracy: 0.7636\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6406 - accuracy: 0.8769 - val_loss: 0.8765 - val_accuracy: 0.7670\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6310 - accuracy: 0.8882 - val_loss: 0.8522 - val_accuracy: 0.7670\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6281 - accuracy: 0.8848 - val_loss: 0.8493 - val_accuracy: 0.7624\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6202 - accuracy: 0.8908 - val_loss: 0.8551 - val_accuracy: 0.7613\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6248 - accuracy: 0.8871 - val_loss: 0.8511 - val_accuracy: 0.7602\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6175 - accuracy: 0.8871 - val_loss: 0.8552 - val_accuracy: 0.7579\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6169 - accuracy: 0.8902 - val_loss: 0.8492 - val_accuracy: 0.7568\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6098 - accuracy: 0.8959 - val_loss: 0.8663 - val_accuracy: 0.7602\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6099 - accuracy: 0.8942 - val_loss: 0.8506 - val_accuracy: 0.7636\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6223 - accuracy: 0.8814 - val_loss: 0.8893 - val_accuracy: 0.7602\n","{'loss': [1.013220191001892, 0.9932319521903992, 0.9823729395866394, 0.977337121963501, 0.9711179137229919, 0.9624099135398865, 0.9534383416175842, 0.9500943422317505, 0.9422290325164795, 0.9379057288169861, 0.9293173551559448, 0.9266314506530762, 0.9186345934867859, 0.9257177710533142, 0.9114128351211548, 0.9090368747711182, 0.9077436923980713, 0.8974400758743286, 0.8919309377670288, 0.887289822101593, 0.8841934204101562, 0.8768154382705688, 0.8702067732810974, 0.873291552066803, 0.8646500706672668, 0.8583343029022217, 0.8547288775444031, 0.8695138096809387, 0.8491853475570679, 0.8498139977455139, 0.8482257127761841, 0.8356145620346069, 0.8284924626350403, 0.8265883326530457, 0.8241857290267944, 0.816710352897644, 0.8172738552093506, 0.8204734921455383, 0.8065922260284424, 0.815647304058075, 0.8183389902114868, 0.8061159253120422, 0.7884925007820129, 0.7854950428009033, 0.789989173412323, 0.7872111797332764, 0.7815293073654175, 0.7713871002197266, 0.7674201130867004, 0.7748968601226807, 0.7641739845275879, 0.7576237916946411, 0.7665847539901733, 0.7574979662895203, 0.7463206648826599, 0.7432361841201782, 0.7428393959999084, 0.7370727062225342, 0.7495921850204468, 0.7288539409637451, 0.7287228107452393, 0.7230055332183838, 0.726879894733429, 0.7168961763381958, 0.7090539336204529, 0.7106016874313354, 0.7107267379760742, 0.7033426761627197, 0.6977461576461792, 0.7011665105819702, 0.6976484656333923, 0.7047316431999207, 0.6853699684143066, 0.7013663053512573, 0.6876646876335144, 0.6761941909790039, 0.6762645840644836, 0.6756946444511414, 0.67920982837677, 0.6647922396659851, 0.6655786633491516, 0.6718616485595703, 0.6553300023078918, 0.6505710482597351, 0.6545426249504089, 0.648294985294342, 0.6475624442100525, 0.6402162909507751, 0.6382318735122681, 0.6509217619895935, 0.6405580639839172, 0.630954921245575, 0.6280876994132996, 0.6201764345169067, 0.6247997879981995, 0.6174554824829102, 0.6168514490127563, 0.6098214387893677, 0.6099405288696289, 0.6222500801086426], 'accuracy': [0.7662705183029175, 0.7733446359634399, 0.7781550884246826, 0.7790039777755737, 0.7829654812812805, 0.7923033237457275, 0.7883418202400208, 0.7897566556930542, 0.7911714911460876, 0.7942841053009033, 0.8005093336105347, 0.7965478301048279, 0.8016412258148193, 0.7914544343948364, 0.8013582229614258, 0.7954159379005432, 0.8024901151657104, 0.808432400226593, 0.8095642328262329, 0.808432400226593, 0.8075834512710571, 0.8160724639892578, 0.810413122177124, 0.804753839969635, 0.8129597902297974, 0.8163554072380066, 0.8189020752906799, 0.8056027293205261, 0.8160724639892578, 0.8155065178871155, 0.8101301789283752, 0.8254103064537048, 0.8265421390533447, 0.821448802947998, 0.8259762525558472, 0.8279569745063782, 0.8273910880088806, 0.821448802947998, 0.8324844241142273, 0.8174872398376465, 0.8203169107437134, 0.8279569745063782, 0.8381437659263611, 0.8378607630729675, 0.8358800411224365, 0.8282399773597717, 0.83729487657547, 0.8401244878768921, 0.8423882126808167, 0.831918478012085, 0.8353140950202942, 0.8505942225456238, 0.8327674269676208, 0.8378607630729675, 0.8508771657943726, 0.8460667729377747, 0.8440860509872437, 0.8531408905982971, 0.8426712155342102, 0.8545557260513306, 0.850311279296875, 0.852292001247406, 0.8480475544929504, 0.8551216721534729, 0.8619128465652466, 0.8590831756591797, 0.8556876182556152, 0.8624787926673889, 0.8687040209770203, 0.8602150678634644, 0.8647425174713135, 0.8556876182556152, 0.8641765713691711, 0.8568194508552551, 0.8619128465652466, 0.8704017996788025, 0.8704017996788025, 0.8698358535766602, 0.8667232394218445, 0.8749292492866516, 0.8720995783805847, 0.8613469004631042, 0.8769100308418274, 0.8780418634414673, 0.870684802532196, 0.8803055882453918, 0.8729485273361206, 0.8839841485023499, 0.881154477596283, 0.870684802532196, 0.8769100308418274, 0.8882286548614502, 0.884833037853241, 0.8907753229141235, 0.8870967626571655, 0.8870967626571655, 0.8902093768119812, 0.895868718624115, 0.8941709399223328, 0.8814374804496765], 'val_loss': [1.2446552515029907, 1.2317838668823242, 1.2139750719070435, 1.2036064863204956, 1.1936686038970947, 1.175469160079956, 1.1653937101364136, 1.1439120769500732, 1.1314328908920288, 1.1206378936767578, 1.1048932075500488, 1.0921330451965332, 1.0747134685516357, 1.0673718452453613, 1.051435112953186, 1.0387121438980103, 1.018995761871338, 1.0397937297821045, 0.9950404763221741, 0.9859398603439331, 0.9885122179985046, 0.96831876039505, 1.0166033506393433, 0.9526223540306091, 0.95853590965271, 0.9705564975738525, 0.9867796301841736, 0.9424790740013123, 0.944989800453186, 0.9488433003425598, 0.9309561848640442, 0.9240474104881287, 0.945421040058136, 0.9225005507469177, 0.9233660697937012, 0.9260275959968567, 0.9318124055862427, 0.9227808713912964, 0.9095436930656433, 0.9522262215614319, 0.9351600408554077, 0.9029340744018555, 0.8993492722511292, 0.9017913937568665, 0.8969913125038147, 0.9111498594284058, 0.8905209302902222, 0.894406259059906, 0.9091028571128845, 0.8924993872642517, 0.886134147644043, 0.8900012969970703, 0.8970516920089722, 0.8816373944282532, 0.8824306130409241, 0.8774656653404236, 0.884790301322937, 0.8779226541519165, 0.8766376376152039, 0.8898258805274963, 0.8860692977905273, 0.8669061660766602, 0.8757057785987854, 0.8753031492233276, 0.8752868175506592, 0.8753601312637329, 0.8670003414154053, 0.8631283044815063, 0.8726417422294617, 0.8743813633918762, 0.8783338069915771, 0.8663280606269836, 0.8587484359741211, 0.8592510223388672, 0.8639887571334839, 0.8586311936378479, 0.8546153903007507, 0.8831665515899658, 0.8692344427108765, 0.866138219833374, 0.8541597127914429, 0.8567957878112793, 0.8623124361038208, 0.8609231114387512, 0.8504917025566101, 0.8599352836608887, 0.8584332466125488, 0.8604681491851807, 0.8543221354484558, 0.8671993017196655, 0.8765148520469666, 0.8521522879600525, 0.8492762446403503, 0.85508131980896, 0.8511070609092712, 0.8552046418190002, 0.8491700887680054, 0.8663141131401062, 0.8505731225013733, 0.889331042766571], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5, 0.5090497732162476, 0.6447963714599609, 0.7002262473106384, 0.6957013607025146, 0.7194570302963257, 0.7160633206367493, 0.7239819169044495, 0.7047511339187622, 0.7126696705818176, 0.7171945571899414, 0.7364253401756287, 0.7036198973655701, 0.7341628670692444, 0.7409502267837524, 0.7352941036224365, 0.7454751133918762, 0.7228506803512573, 0.7613122463226318, 0.7613122463226318, 0.7511312365531921, 0.7386877536773682, 0.7647058963775635, 0.7432126402854919, 0.7590497732162476, 0.7352941036224365, 0.7466063499450684, 0.7590497732162476, 0.7386877536773682, 0.7635746598243713, 0.766968309879303, 0.7613122463226318, 0.7658371329307556, 0.7647058963775635, 0.7217194437980652, 0.7613122463226318, 0.7613122463226318, 0.7590497732162476, 0.7488687634468079, 0.7567873597145081, 0.7613122463226318, 0.7590497732162476, 0.7647058963775635, 0.7296379804611206, 0.7364253401756287, 0.7579185366630554, 0.7703620195388794, 0.7692307829856873, 0.7680995464324951, 0.7680995464324951, 0.7579185366630554, 0.7386877536773682, 0.7556561231613159, 0.7511312365531921, 0.7658371329307556, 0.7680995464324951, 0.7647058963775635, 0.7511312365531921, 0.7658371329307556, 0.7488687634468079, 0.7409502267837524, 0.7567873597145081, 0.7624434232711792, 0.7692307829856873, 0.7658371329307556, 0.7432126402854919, 0.7635746598243713, 0.7658371329307556, 0.7703620195388794, 0.7647058963775635, 0.7680995464324951, 0.766968309879303, 0.7680995464324951, 0.766968309879303, 0.7658371329307556, 0.7647058963775635, 0.7635746598243713, 0.7658371329307556, 0.7624434232711792, 0.7613122463226318, 0.7545248866081238, 0.7567873597145081, 0.7590497732162476, 0.7635746598243713, 0.7635746598243713, 0.766968309879303, 0.766968309879303, 0.7624434232711792, 0.7613122463226318, 0.7601810097694397, 0.7579185366630554, 0.7567873597145081, 0.7601810097694397, 0.7635746598243713, 0.7601810097694397]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/31 [=========================>....] - ETA: 0s - loss: 1.0077 - accuracy: 0.7665"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 5s 37ms/step - loss: 1.0079 - accuracy: 0.7641 - val_loss: 1.2531 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9840 - accuracy: 0.7804 - val_loss: 1.2392 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9760 - accuracy: 0.7786 - val_loss: 1.2302 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9704 - accuracy: 0.7760 - val_loss: 1.2052 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9643 - accuracy: 0.7796 - val_loss: 1.1916 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9533 - accuracy: 0.7848 - val_loss: 1.1829 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9498 - accuracy: 0.7840 - val_loss: 1.1726 - val_accuracy: 0.4876\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9508 - accuracy: 0.7804 - val_loss: 1.1489 - val_accuracy: 0.5238\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9394 - accuracy: 0.7884 - val_loss: 1.1203 - val_accuracy: 0.6870\n","Epoch 10/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9424 - accuracy: 0.7873 - val_loss: 1.1314 - val_accuracy: 0.5424\n","Epoch 11/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9316 - accuracy: 0.7855 - val_loss: 1.1080 - val_accuracy: 0.6126\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9224 - accuracy: 0.7881 - val_loss: 1.0722 - val_accuracy: 0.7397\n","Epoch 13/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9263 - accuracy: 0.7866 - val_loss: 1.0660 - val_accuracy: 0.7004\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9104 - accuracy: 0.7915 - val_loss: 1.0415 - val_accuracy: 0.7490\n","Epoch 15/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9095 - accuracy: 0.7956 - val_loss: 1.0265 - val_accuracy: 0.7448\n","Epoch 16/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9017 - accuracy: 0.7930 - val_loss: 1.0295 - val_accuracy: 0.7076\n","Epoch 17/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8993 - accuracy: 0.7933 - val_loss: 1.0016 - val_accuracy: 0.7521\n","Epoch 18/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8928 - accuracy: 0.7953 - val_loss: 0.9878 - val_accuracy: 0.7521\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8866 - accuracy: 0.8005 - val_loss: 0.9912 - val_accuracy: 0.7500\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8819 - accuracy: 0.8052 - val_loss: 0.9717 - val_accuracy: 0.7603\n","Epoch 21/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8772 - accuracy: 0.8034 - val_loss: 0.9859 - val_accuracy: 0.7531\n","Epoch 22/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8739 - accuracy: 0.8065 - val_loss: 0.9591 - val_accuracy: 0.7562\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8719 - accuracy: 0.8010 - val_loss: 0.9563 - val_accuracy: 0.7686\n","Epoch 24/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8634 - accuracy: 0.8072 - val_loss: 0.9524 - val_accuracy: 0.7521\n","Epoch 25/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8672 - accuracy: 0.8008 - val_loss: 0.9758 - val_accuracy: 0.7624\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8562 - accuracy: 0.8070 - val_loss: 0.9489 - val_accuracy: 0.7738\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8509 - accuracy: 0.8075 - val_loss: 0.9407 - val_accuracy: 0.7676\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8461 - accuracy: 0.8085 - val_loss: 0.9555 - val_accuracy: 0.7293\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8576 - accuracy: 0.7966 - val_loss: 0.9442 - val_accuracy: 0.7696\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8393 - accuracy: 0.8103 - val_loss: 0.9333 - val_accuracy: 0.7593\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8358 - accuracy: 0.8085 - val_loss: 0.9347 - val_accuracy: 0.7707\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8321 - accuracy: 0.8088 - val_loss: 0.9293 - val_accuracy: 0.7645\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8317 - accuracy: 0.8088 - val_loss: 0.9262 - val_accuracy: 0.7634\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8232 - accuracy: 0.8171 - val_loss: 0.9236 - val_accuracy: 0.7655\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8183 - accuracy: 0.8186 - val_loss: 0.9220 - val_accuracy: 0.7634\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8160 - accuracy: 0.8173 - val_loss: 0.9397 - val_accuracy: 0.7665\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8125 - accuracy: 0.8165 - val_loss: 0.9202 - val_accuracy: 0.7676\n","Epoch 38/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8145 - accuracy: 0.8096 - val_loss: 0.9528 - val_accuracy: 0.7200\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8206 - accuracy: 0.8067 - val_loss: 0.9158 - val_accuracy: 0.7541\n","Epoch 40/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8075 - accuracy: 0.8150 - val_loss: 0.9281 - val_accuracy: 0.7324\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8018 - accuracy: 0.8183 - val_loss: 0.9090 - val_accuracy: 0.7603\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7925 - accuracy: 0.8253 - val_loss: 0.9130 - val_accuracy: 0.7407\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7990 - accuracy: 0.8137 - val_loss: 0.9119 - val_accuracy: 0.7376\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7875 - accuracy: 0.8217 - val_loss: 0.9037 - val_accuracy: 0.7614\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7830 - accuracy: 0.8269 - val_loss: 0.9174 - val_accuracy: 0.7717\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7815 - accuracy: 0.8222 - val_loss: 0.9217 - val_accuracy: 0.7304\n","Epoch 47/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7816 - accuracy: 0.8248 - val_loss: 0.9215 - val_accuracy: 0.7366\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7697 - accuracy: 0.8388 - val_loss: 0.8969 - val_accuracy: 0.7603\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7662 - accuracy: 0.8292 - val_loss: 0.8950 - val_accuracy: 0.7583\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7698 - accuracy: 0.8248 - val_loss: 0.8969 - val_accuracy: 0.7500\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7607 - accuracy: 0.8313 - val_loss: 0.8952 - val_accuracy: 0.7624\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7636 - accuracy: 0.8256 - val_loss: 0.8907 - val_accuracy: 0.7459\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7537 - accuracy: 0.8364 - val_loss: 0.8986 - val_accuracy: 0.7386\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7497 - accuracy: 0.8349 - val_loss: 0.8901 - val_accuracy: 0.7614\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7439 - accuracy: 0.8390 - val_loss: 0.8954 - val_accuracy: 0.7417\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7470 - accuracy: 0.8331 - val_loss: 0.8819 - val_accuracy: 0.7510\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7473 - accuracy: 0.8320 - val_loss: 0.8946 - val_accuracy: 0.7448\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7394 - accuracy: 0.8382 - val_loss: 0.9026 - val_accuracy: 0.7407\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7522 - accuracy: 0.8204 - val_loss: 0.8758 - val_accuracy: 0.7655\n","Epoch 60/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7321 - accuracy: 0.8403 - val_loss: 0.8744 - val_accuracy: 0.7531\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7266 - accuracy: 0.8460 - val_loss: 0.8731 - val_accuracy: 0.7521\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7232 - accuracy: 0.8429 - val_loss: 0.8888 - val_accuracy: 0.7552\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7227 - accuracy: 0.8419 - val_loss: 0.8799 - val_accuracy: 0.7624\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7172 - accuracy: 0.8468 - val_loss: 0.9020 - val_accuracy: 0.7676\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7198 - accuracy: 0.8403 - val_loss: 0.8669 - val_accuracy: 0.7603\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7203 - accuracy: 0.8382 - val_loss: 0.8768 - val_accuracy: 0.7614\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7138 - accuracy: 0.8426 - val_loss: 0.8911 - val_accuracy: 0.7448\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7054 - accuracy: 0.8486 - val_loss: 0.8796 - val_accuracy: 0.7624\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7032 - accuracy: 0.8512 - val_loss: 0.8646 - val_accuracy: 0.7479\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6998 - accuracy: 0.8517 - val_loss: 0.8846 - val_accuracy: 0.7376\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7091 - accuracy: 0.8398 - val_loss: 0.8642 - val_accuracy: 0.7521\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6963 - accuracy: 0.8506 - val_loss: 0.8682 - val_accuracy: 0.7655\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6866 - accuracy: 0.8574 - val_loss: 0.8604 - val_accuracy: 0.7552\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.8499 - val_loss: 0.8757 - val_accuracy: 0.7397\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.8496 - val_loss: 0.8751 - val_accuracy: 0.7603\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6814 - accuracy: 0.8525 - val_loss: 0.8589 - val_accuracy: 0.7510\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6731 - accuracy: 0.8566 - val_loss: 0.8985 - val_accuracy: 0.7273\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6848 - accuracy: 0.8465 - val_loss: 0.8612 - val_accuracy: 0.7614\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6692 - accuracy: 0.8636 - val_loss: 0.8660 - val_accuracy: 0.7448\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6750 - accuracy: 0.8545 - val_loss: 0.8548 - val_accuracy: 0.7552\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6637 - accuracy: 0.8623 - val_loss: 0.8554 - val_accuracy: 0.7603\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6659 - accuracy: 0.8605 - val_loss: 0.8533 - val_accuracy: 0.7541\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6639 - accuracy: 0.8587 - val_loss: 0.8543 - val_accuracy: 0.7603\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6627 - accuracy: 0.8607 - val_loss: 0.8808 - val_accuracy: 0.7386\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6591 - accuracy: 0.8610 - val_loss: 0.8659 - val_accuracy: 0.7645\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6653 - accuracy: 0.8537 - val_loss: 0.8529 - val_accuracy: 0.7583\n","Epoch 87/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6459 - accuracy: 0.8724 - val_loss: 0.8619 - val_accuracy: 0.7676\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6453 - accuracy: 0.8700 - val_loss: 0.8619 - val_accuracy: 0.7624\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6470 - accuracy: 0.8677 - val_loss: 0.8530 - val_accuracy: 0.7614\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6416 - accuracy: 0.8690 - val_loss: 0.8525 - val_accuracy: 0.7479\n","Epoch 91/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6568 - accuracy: 0.8558 - val_loss: 0.8476 - val_accuracy: 0.7614\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6649 - accuracy: 0.8494 - val_loss: 0.8458 - val_accuracy: 0.7572\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6331 - accuracy: 0.8742 - val_loss: 0.8495 - val_accuracy: 0.7562\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6343 - accuracy: 0.8729 - val_loss: 0.8495 - val_accuracy: 0.7562\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6263 - accuracy: 0.8739 - val_loss: 0.8512 - val_accuracy: 0.7541\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6257 - accuracy: 0.8762 - val_loss: 0.8458 - val_accuracy: 0.7593\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6249 - accuracy: 0.8742 - val_loss: 0.8614 - val_accuracy: 0.7500\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6308 - accuracy: 0.8674 - val_loss: 0.8619 - val_accuracy: 0.7397\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6200 - accuracy: 0.8700 - val_loss: 0.8440 - val_accuracy: 0.7583\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6162 - accuracy: 0.8788 - val_loss: 0.8499 - val_accuracy: 0.7603\n","{'loss': [1.0078532695770264, 0.9840439558029175, 0.9760130047798157, 0.9704394936561584, 0.9642854928970337, 0.9533489346504211, 0.9497761130332947, 0.9508306384086609, 0.9394068717956543, 0.9423892498016357, 0.9315831661224365, 0.9223516583442688, 0.9262536764144897, 0.9103601574897766, 0.9095026850700378, 0.9016536474227905, 0.8992973566055298, 0.8927527070045471, 0.8865997791290283, 0.8819296360015869, 0.8772493600845337, 0.8739075064659119, 0.8719052672386169, 0.8634280562400818, 0.8672285079956055, 0.8562271595001221, 0.8508894443511963, 0.8461377620697021, 0.8575752377510071, 0.8393478393554688, 0.8357795476913452, 0.8320911526679993, 0.8317368030548096, 0.8232044577598572, 0.8182995319366455, 0.8160451650619507, 0.8124842643737793, 0.8144549131393433, 0.8205530047416687, 0.8075027465820312, 0.8018348813056946, 0.7924651503562927, 0.7990391850471497, 0.7875444293022156, 0.7829770445823669, 0.7814992666244507, 0.7816227674484253, 0.7697166204452515, 0.7661628723144531, 0.7697552442550659, 0.760737955570221, 0.7635908126831055, 0.7536776661872864, 0.7497410774230957, 0.7439069151878357, 0.7469592690467834, 0.7472944259643555, 0.7393760681152344, 0.7521634697914124, 0.7320645451545715, 0.726603627204895, 0.7232313752174377, 0.722749650478363, 0.7171692252159119, 0.7197824716567993, 0.7203097939491272, 0.713805615901947, 0.7053766846656799, 0.7032115459442139, 0.6997682452201843, 0.7091067433357239, 0.6963221430778503, 0.686595618724823, 0.6900919675827026, 0.6902140974998474, 0.6814149618148804, 0.6731255054473877, 0.6848397850990295, 0.6691519618034363, 0.6749594211578369, 0.6637088656425476, 0.6659396886825562, 0.6638582348823547, 0.6626691222190857, 0.6591076254844666, 0.665349006652832, 0.6459404230117798, 0.6452875733375549, 0.6469639539718628, 0.6415603756904602, 0.6567721366882324, 0.6649199724197388, 0.6331366896629333, 0.6343191266059875, 0.6262653470039368, 0.6256723403930664, 0.6248975396156311, 0.6307876706123352, 0.6199880242347717, 0.6161705255508423], 'accuracy': [0.764082670211792, 0.7803617715835571, 0.7785529494285583, 0.7759689688682556, 0.7795865535736084, 0.7847545146942139, 0.7839793562889099, 0.7803617715835571, 0.7883720993995667, 0.7873384952545166, 0.7855297327041626, 0.7881137132644653, 0.7865633368492126, 0.791472852230072, 0.7956072092056274, 0.7930232286453247, 0.7932816743850708, 0.7953488230705261, 0.8005167841911316, 0.8051679730415344, 0.8033591508865356, 0.8064599633216858, 0.801033616065979, 0.8072351217269897, 0.8007751703262329, 0.8069767355918884, 0.8074935674667358, 0.8085271120071411, 0.7966408133506775, 0.8103359341621399, 0.8085271120071411, 0.8087855577468872, 0.8087855577468872, 0.817054271697998, 0.8186046481132507, 0.8173126578330994, 0.8165374398231506, 0.8095607161521912, 0.8067183494567871, 0.814987063407898, 0.8183462619781494, 0.8253229856491089, 0.8136950731277466, 0.8217054009437561, 0.8268733620643616, 0.8222222328186035, 0.8248062133789062, 0.8387596607208252, 0.829198956489563, 0.8248062133789062, 0.8312661647796631, 0.8255813717842102, 0.8364341259002686, 0.8348837494850159, 0.8390181064605713, 0.8330749273300171, 0.832041323184967, 0.8382428884506226, 0.8204134106636047, 0.8403100967407227, 0.8459948301315308, 0.8428940773010254, 0.8418604731559753, 0.8467700481414795, 0.8403100967407227, 0.8382428884506226, 0.8426356315612793, 0.8485788106918335, 0.8511627912521362, 0.8516795635223389, 0.8397932648658752, 0.8506460189819336, 0.8573643565177917, 0.8498708009719849, 0.8496124148368835, 0.8524547815322876, 0.856589138507843, 0.8465116024017334, 0.8635658621788025, 0.8545219898223877, 0.8622739315032959, 0.8604651093482971, 0.8586563467979431, 0.8607234954833984, 0.8609819412231445, 0.853746771812439, 0.8723514080047607, 0.8700258135795593, 0.8677002787590027, 0.868992269039154, 0.8558139801025391, 0.8493540287017822, 0.8741602301597595, 0.8728682398796082, 0.8739017844200134, 0.8762273788452148, 0.8741602301597595, 0.8674418330192566, 0.8700258135795593, 0.8788113594055176], 'val_loss': [1.2531318664550781, 1.239205002784729, 1.2302361726760864, 1.2052185535430908, 1.1915676593780518, 1.1828974485397339, 1.17258620262146, 1.1488525867462158, 1.1202902793884277, 1.1314347982406616, 1.1080446243286133, 1.0722275972366333, 1.0659936666488647, 1.041504144668579, 1.0264811515808105, 1.0295021533966064, 1.00164794921875, 0.987757682800293, 0.991218626499176, 0.9716701507568359, 0.9859002828598022, 0.9590761065483093, 0.9562689661979675, 0.9524191617965698, 0.9758008718490601, 0.948897123336792, 0.9407404065132141, 0.9554992318153381, 0.9442229270935059, 0.9332910180091858, 0.9347262978553772, 0.9293001294136047, 0.9262000322341919, 0.9236387610435486, 0.9220262169837952, 0.9396779537200928, 0.9201882481575012, 0.9527928829193115, 0.9158255457878113, 0.9281091690063477, 0.9090107083320618, 0.9129908084869385, 0.9119459390640259, 0.9037055373191833, 0.9174103736877441, 0.9216721653938293, 0.9215220212936401, 0.8969101309776306, 0.8950181603431702, 0.8969430327415466, 0.8952193260192871, 0.8907147645950317, 0.898585855960846, 0.8900704979896545, 0.8954474329948425, 0.8819147348403931, 0.8945964574813843, 0.9026219248771667, 0.8758469223976135, 0.8743899464607239, 0.8730902075767517, 0.8888407945632935, 0.8799213767051697, 0.9020461440086365, 0.8668906688690186, 0.8768173456192017, 0.8911092877388, 0.8795667886734009, 0.864591121673584, 0.8845973610877991, 0.864220380783081, 0.8682239055633545, 0.8603751063346863, 0.875720202922821, 0.8751456141471863, 0.8589030504226685, 0.8984621167182922, 0.8612101078033447, 0.8660166263580322, 0.8547937273979187, 0.8554078936576843, 0.853325366973877, 0.8543059229850769, 0.8808380365371704, 0.865875244140625, 0.8529062867164612, 0.861883819103241, 0.8618519306182861, 0.8529784083366394, 0.8525137305259705, 0.8475500345230103, 0.845842719078064, 0.8495113849639893, 0.8495109677314758, 0.8512192368507385, 0.8458263874053955, 0.8613830804824829, 0.861930251121521, 0.8440253138542175, 0.8499003052711487], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.4876033067703247, 0.5237603187561035, 0.6869834661483765, 0.5423553586006165, 0.6126033067703247, 0.7396694421768188, 0.7004132270812988, 0.7489669322967529, 0.7448347210884094, 0.7076446413993835, 0.7520661354064941, 0.7520661354064941, 0.75, 0.7603305578231812, 0.7530992031097412, 0.7561983466148376, 0.7685950398445129, 0.7520661354064941, 0.7623966932296753, 0.7737603187561035, 0.7675619721412659, 0.7293388247489929, 0.76962810754776, 0.7592975497245789, 0.7706611752510071, 0.7644628286361694, 0.7634297609329224, 0.7654958963394165, 0.7634297609329224, 0.7665289044380188, 0.7675619721412659, 0.7200413346290588, 0.7541322112083435, 0.7324380278587341, 0.7603305578231812, 0.7407024502754211, 0.7376033067703247, 0.7613636255264282, 0.7716942429542542, 0.73037189245224, 0.7365702390670776, 0.7603305578231812, 0.7582644820213318, 0.75, 0.7623966932296753, 0.7458677887916565, 0.7386363744735718, 0.7613636255264282, 0.7417355179786682, 0.7510330677032471, 0.7448347210884094, 0.7407024502754211, 0.7654958963394165, 0.7530992031097412, 0.7520661354064941, 0.7551652789115906, 0.7623966932296753, 0.7675619721412659, 0.7603305578231812, 0.7613636255264282, 0.7448347210884094, 0.7623966932296753, 0.7479338645935059, 0.7376033067703247, 0.7520661354064941, 0.7654958963394165, 0.7551652789115906, 0.7396694421768188, 0.7603305578231812, 0.7510330677032471, 0.7272727489471436, 0.7613636255264282, 0.7448347210884094, 0.7551652789115906, 0.7603305578231812, 0.7541322112083435, 0.7603305578231812, 0.7386363744735718, 0.7644628286361694, 0.7582644820213318, 0.7675619721412659, 0.7623966932296753, 0.7613636255264282, 0.7479338645935059, 0.7613636255264282, 0.7572314143180847, 0.7561983466148376, 0.7561983466148376, 0.7541322112083435, 0.7592975497245789, 0.75, 0.7396694421768188, 0.7582644820213318, 0.7603305578231812]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 30ms/step - loss: 0.7065 - accuracy: 0.8343 - val_loss: 1.1314 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.6570 - accuracy: 0.8750"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 10ms/step - loss: 0.6761 - accuracy: 0.8489 - val_loss: 1.1236 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6711 - accuracy: 0.8489 - val_loss: 1.1135 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6701 - accuracy: 0.8459 - val_loss: 1.0975 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.8526 - val_loss: 1.0896 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6571 - accuracy: 0.8586 - val_loss: 1.0714 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6483 - accuracy: 0.8640 - val_loss: 1.0483 - val_accuracy: 0.4881\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6440 - accuracy: 0.8642 - val_loss: 1.0389 - val_accuracy: 0.4935\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6457 - accuracy: 0.8588 - val_loss: 1.0014 - val_accuracy: 0.5226\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6460 - accuracy: 0.8607 - val_loss: 1.0085 - val_accuracy: 0.5237\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6420 - accuracy: 0.8677 - val_loss: 0.9921 - val_accuracy: 0.5409\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6417 - accuracy: 0.8648 - val_loss: 0.9152 - val_accuracy: 0.6487\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6283 - accuracy: 0.8704 - val_loss: 0.9126 - val_accuracy: 0.6541\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6281 - accuracy: 0.8731 - val_loss: 0.8802 - val_accuracy: 0.6843\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6296 - accuracy: 0.8658 - val_loss: 0.8494 - val_accuracy: 0.7381\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6190 - accuracy: 0.8782 - val_loss: 0.8282 - val_accuracy: 0.7543\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6194 - accuracy: 0.8739 - val_loss: 0.8113 - val_accuracy: 0.7629\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6131 - accuracy: 0.8745 - val_loss: 0.8012 - val_accuracy: 0.7651\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6111 - accuracy: 0.8780 - val_loss: 0.7844 - val_accuracy: 0.7802\n","Epoch 20/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6211 - accuracy: 0.8696 - val_loss: 0.8196 - val_accuracy: 0.7543\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6209 - accuracy: 0.8704 - val_loss: 0.7762 - val_accuracy: 0.7812\n","Epoch 22/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6045 - accuracy: 0.8825 - val_loss: 0.7756 - val_accuracy: 0.7716\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6022 - accuracy: 0.8820 - val_loss: 0.7491 - val_accuracy: 0.7920\n","Epoch 24/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5964 - accuracy: 0.8855 - val_loss: 0.7557 - val_accuracy: 0.7845\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5969 - accuracy: 0.8820 - val_loss: 0.7369 - val_accuracy: 0.8017\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5886 - accuracy: 0.8920 - val_loss: 0.7723 - val_accuracy: 0.7845\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5935 - accuracy: 0.8823 - val_loss: 0.7338 - val_accuracy: 0.8060\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 0.8930 - val_loss: 0.7352 - val_accuracy: 0.8028\n","Epoch 29/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5856 - accuracy: 0.8858 - val_loss: 0.7241 - val_accuracy: 0.7996\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5862 - accuracy: 0.8850 - val_loss: 0.7666 - val_accuracy: 0.7845\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5825 - accuracy: 0.8890 - val_loss: 0.7286 - val_accuracy: 0.8039\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5809 - accuracy: 0.8871 - val_loss: 0.7228 - val_accuracy: 0.8093\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5796 - accuracy: 0.8909 - val_loss: 0.7237 - val_accuracy: 0.8082\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5685 - accuracy: 0.8957 - val_loss: 0.7233 - val_accuracy: 0.8093\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5716 - accuracy: 0.8949 - val_loss: 0.7316 - val_accuracy: 0.8028\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5663 - accuracy: 0.8971 - val_loss: 0.7209 - val_accuracy: 0.8125\n","Epoch 37/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5648 - accuracy: 0.8976 - val_loss: 0.7305 - val_accuracy: 0.8006\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5680 - accuracy: 0.8947 - val_loss: 0.7445 - val_accuracy: 0.7953\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5736 - accuracy: 0.8887 - val_loss: 0.7317 - val_accuracy: 0.8050\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5836 - accuracy: 0.8844 - val_loss: 0.7242 - val_accuracy: 0.8136\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5791 - accuracy: 0.8828 - val_loss: 0.7325 - val_accuracy: 0.8050\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.8936 - val_loss: 0.7343 - val_accuracy: 0.7866\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5472 - accuracy: 0.9062 - val_loss: 0.7228 - val_accuracy: 0.8028\n","Epoch 44/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5487 - accuracy: 0.9046 - val_loss: 0.7225 - val_accuracy: 0.8050\n","Epoch 45/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5561 - accuracy: 0.8939 - val_loss: 0.7465 - val_accuracy: 0.7909\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5470 - accuracy: 0.9084 - val_loss: 0.7240 - val_accuracy: 0.8039\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5433 - accuracy: 0.9030 - val_loss: 0.7624 - val_accuracy: 0.7802\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5448 - accuracy: 0.9049 - val_loss: 0.7283 - val_accuracy: 0.7963\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5470 - accuracy: 0.8987 - val_loss: 0.7285 - val_accuracy: 0.8125\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5433 - accuracy: 0.9011 - val_loss: 0.7231 - val_accuracy: 0.8028\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5397 - accuracy: 0.9095 - val_loss: 0.7283 - val_accuracy: 0.8017\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5439 - accuracy: 0.9006 - val_loss: 0.8529 - val_accuracy: 0.7349\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5332 - accuracy: 0.9095 - val_loss: 0.7581 - val_accuracy: 0.7812\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5239 - accuracy: 0.9162 - val_loss: 0.7241 - val_accuracy: 0.8028\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5216 - accuracy: 0.9189 - val_loss: 0.7265 - val_accuracy: 0.8093\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5228 - accuracy: 0.9130 - val_loss: 0.7260 - val_accuracy: 0.8103\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5160 - accuracy: 0.9246 - val_loss: 0.7268 - val_accuracy: 0.8039\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5198 - accuracy: 0.9114 - val_loss: 0.7301 - val_accuracy: 0.8017\n","Epoch 59/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5125 - accuracy: 0.9195 - val_loss: 0.7548 - val_accuracy: 0.7899\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5192 - accuracy: 0.9135 - val_loss: 0.7229 - val_accuracy: 0.8114\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5106 - accuracy: 0.9238 - val_loss: 0.7347 - val_accuracy: 0.7931\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5082 - accuracy: 0.9235 - val_loss: 0.7301 - val_accuracy: 0.8071\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5109 - accuracy: 0.9219 - val_loss: 0.7454 - val_accuracy: 0.7931\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5008 - accuracy: 0.9275 - val_loss: 0.7436 - val_accuracy: 0.7909\n","Epoch 65/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5071 - accuracy: 0.9205 - val_loss: 0.7278 - val_accuracy: 0.8093\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5047 - accuracy: 0.9235 - val_loss: 0.7285 - val_accuracy: 0.8082\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5019 - accuracy: 0.9221 - val_loss: 0.7269 - val_accuracy: 0.8060\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4968 - accuracy: 0.9238 - val_loss: 0.7342 - val_accuracy: 0.8006\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4958 - accuracy: 0.9251 - val_loss: 0.7358 - val_accuracy: 0.8050\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4881 - accuracy: 0.9308 - val_loss: 0.7411 - val_accuracy: 0.8006\n","Epoch 71/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4871 - accuracy: 0.9321 - val_loss: 0.7305 - val_accuracy: 0.8050\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4841 - accuracy: 0.9332 - val_loss: 0.7680 - val_accuracy: 0.7845\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5090 - accuracy: 0.9114 - val_loss: 0.7490 - val_accuracy: 0.7834\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4903 - accuracy: 0.9289 - val_loss: 0.7541 - val_accuracy: 0.7974\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4912 - accuracy: 0.9278 - val_loss: 0.7297 - val_accuracy: 0.8071\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4856 - accuracy: 0.9270 - val_loss: 0.7361 - val_accuracy: 0.8060\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4878 - accuracy: 0.9283 - val_loss: 0.7407 - val_accuracy: 0.8060\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4753 - accuracy: 0.9359 - val_loss: 0.7339 - val_accuracy: 0.8039\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4794 - accuracy: 0.9337 - val_loss: 0.7397 - val_accuracy: 0.8028\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4761 - accuracy: 0.9348 - val_loss: 0.7618 - val_accuracy: 0.7909\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4689 - accuracy: 0.9399 - val_loss: 0.7388 - val_accuracy: 0.8071\n","Epoch 82/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4683 - accuracy: 0.9362 - val_loss: 0.7370 - val_accuracy: 0.8028\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4714 - accuracy: 0.9399 - val_loss: 0.7365 - val_accuracy: 0.8071\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4606 - accuracy: 0.9434 - val_loss: 0.7636 - val_accuracy: 0.7823\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4649 - accuracy: 0.9410 - val_loss: 0.7522 - val_accuracy: 0.7974\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4677 - accuracy: 0.9378 - val_loss: 0.8000 - val_accuracy: 0.7716\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4624 - accuracy: 0.9434 - val_loss: 0.7536 - val_accuracy: 0.7985\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4593 - accuracy: 0.9442 - val_loss: 0.7782 - val_accuracy: 0.7812\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4547 - accuracy: 0.9445 - val_loss: 0.7641 - val_accuracy: 0.7845\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4676 - accuracy: 0.9372 - val_loss: 0.7930 - val_accuracy: 0.7737\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4690 - accuracy: 0.9324 - val_loss: 0.7871 - val_accuracy: 0.7823\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4493 - accuracy: 0.9483 - val_loss: 0.7435 - val_accuracy: 0.7996\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4484 - accuracy: 0.9483 - val_loss: 0.7502 - val_accuracy: 0.8017\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4420 - accuracy: 0.9537 - val_loss: 0.7517 - val_accuracy: 0.7974\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4490 - accuracy: 0.9496 - val_loss: 0.7595 - val_accuracy: 0.7953\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4447 - accuracy: 0.9464 - val_loss: 0.8340 - val_accuracy: 0.7565\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4534 - accuracy: 0.9445 - val_loss: 0.7521 - val_accuracy: 0.8082\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.9550 - val_loss: 0.7519 - val_accuracy: 0.7942\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4397 - accuracy: 0.9539 - val_loss: 0.7625 - val_accuracy: 0.8028\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 0.9515 - val_loss: 0.7745 - val_accuracy: 0.7759\n","{'loss': [0.7064815759658813, 0.6760730743408203, 0.6711037755012512, 0.6700643301010132, 0.6663495302200317, 0.6570919752120972, 0.6483003497123718, 0.6440395712852478, 0.6456958055496216, 0.6459617614746094, 0.6419807076454163, 0.6416676044464111, 0.6283329725265503, 0.6281026601791382, 0.629557728767395, 0.6189561486244202, 0.619409441947937, 0.6131012439727783, 0.611127495765686, 0.6211114525794983, 0.6209174990653992, 0.6044939756393433, 0.6021614074707031, 0.5963886380195618, 0.596924901008606, 0.588565468788147, 0.5934751033782959, 0.5866987705230713, 0.5855998396873474, 0.586227536201477, 0.582470178604126, 0.5808764100074768, 0.5796217322349548, 0.5685293078422546, 0.5716053247451782, 0.5663227438926697, 0.5647724270820618, 0.5679824352264404, 0.573647677898407, 0.5835512280464172, 0.5790514349937439, 0.5639932751655579, 0.5471519231796265, 0.5487264394760132, 0.5561202764511108, 0.5469749569892883, 0.5432516932487488, 0.5448177456855774, 0.5470415353775024, 0.5432771444320679, 0.5396507382392883, 0.5439242720603943, 0.5332367420196533, 0.5238934755325317, 0.5215878486633301, 0.5227884650230408, 0.5159721970558167, 0.5197604298591614, 0.5124533772468567, 0.519180178642273, 0.5106079578399658, 0.5082097053527832, 0.5108504295349121, 0.5008200407028198, 0.5070655345916748, 0.50465989112854, 0.5019150376319885, 0.4968112111091614, 0.4957782030105591, 0.4880889058113098, 0.48712337017059326, 0.48409348726272583, 0.5090489387512207, 0.4902563691139221, 0.49118149280548096, 0.48555880784988403, 0.48776933550834656, 0.4752664566040039, 0.4793735444545746, 0.47608044743537903, 0.4689406156539917, 0.4683167040348053, 0.471426784992218, 0.4605769217014313, 0.464897096157074, 0.4677455723285675, 0.46239832043647766, 0.4592639207839966, 0.4546704590320587, 0.4676220118999481, 0.46901729702949524, 0.4492858946323395, 0.4483650028705597, 0.44197484850883484, 0.449039101600647, 0.44469237327575684, 0.4533950090408325, 0.438454270362854, 0.4397468864917755, 0.4379598796367645], 'accuracy': [0.834321141242981, 0.8488685488700867, 0.8488685488700867, 0.8459051847457886, 0.8526400923728943, 0.8585668206214905, 0.8639547228813171, 0.8642241358757019, 0.8588362336158752, 0.860722005367279, 0.8677262663841248, 0.8647629022598267, 0.8704202771186829, 0.8731142282485962, 0.865840494632721, 0.8782327771186829, 0.8739224076271057, 0.8744612336158752, 0.8779633641242981, 0.8696120977401733, 0.8704202771186829, 0.8825430870056152, 0.8820043206214905, 0.8855064511299133, 0.8820043206214905, 0.891972005367279, 0.8822737336158752, 0.8930495977401733, 0.8857758641242981, 0.8849676847457886, 0.889008641242981, 0.8871228694915771, 0.8908944129943848, 0.8957435488700867, 0.8949353694915771, 0.897090494632721, 0.8976293206214905, 0.8946659564971924, 0.8887392282485962, 0.884428858757019, 0.8828125, 0.8935883641242981, 0.90625, 0.904633641242981, 0.8938577771186829, 0.9084051847457886, 0.9030172228813171, 0.904902994632721, 0.8987069129943848, 0.9011314511299133, 0.9094827771186829, 0.9005926847457886, 0.9094827771186829, 0.9162176847457886, 0.9189116358757019, 0.9129849076271057, 0.9245689511299133, 0.9113685488700867, 0.9194504022598267, 0.9135237336158752, 0.9237607717514038, 0.923491358757019, 0.921875, 0.9275323152542114, 0.920527994632721, 0.923491358757019, 0.9221444129943848, 0.9237607717514038, 0.9251077771186829, 0.9307650923728943, 0.9321120977401733, 0.9331896305084229, 0.9113685488700867, 0.9288793206214905, 0.9278017282485962, 0.9269935488700867, 0.928340494632721, 0.935883641242981, 0.9337284564971924, 0.9348060488700867, 0.9399245977401733, 0.936152994632721, 0.9399245977401733, 0.9434267282485962, 0.9410021305084229, 0.9377694129943848, 0.9434267282485962, 0.9442349076271057, 0.9445043206214905, 0.9372305870056152, 0.9323814511299133, 0.9482758641242981, 0.9482758641242981, 0.9536637663841248, 0.9496228694915771, 0.9463900923728943, 0.9445043206214905, 0.9550107717514038, 0.9539331793785095, 0.951508641242981], 'val_loss': [1.1314374208450317, 1.1236276626586914, 1.1135034561157227, 1.0975441932678223, 1.0895869731903076, 1.0714261531829834, 1.0482760667800903, 1.0388766527175903, 1.0013744831085205, 1.0085152387619019, 0.9921281933784485, 0.9152303338050842, 0.9126399755477905, 0.8801537752151489, 0.8493579626083374, 0.8281923532485962, 0.8113466501235962, 0.8011809587478638, 0.7844492793083191, 0.8196426630020142, 0.7762086391448975, 0.7755545973777771, 0.7491424679756165, 0.7557119727134705, 0.7369354367256165, 0.7722588181495667, 0.7338382601737976, 0.7351827025413513, 0.7241466641426086, 0.7666175961494446, 0.7285953760147095, 0.7227632999420166, 0.7236602902412415, 0.7233027219772339, 0.7316455245018005, 0.7209336757659912, 0.7305195927619934, 0.7445040345191956, 0.7317216992378235, 0.7242430448532104, 0.7324653267860413, 0.7342866063117981, 0.7227789163589478, 0.722480297088623, 0.7464709281921387, 0.7239975333213806, 0.7624085545539856, 0.728308379650116, 0.7284666895866394, 0.723086416721344, 0.7283200025558472, 0.852881669998169, 0.7581314444541931, 0.7240720391273499, 0.7265124917030334, 0.7259534001350403, 0.7267995476722717, 0.7301036715507507, 0.7548224329948425, 0.7229354381561279, 0.7346979975700378, 0.7300862073898315, 0.7453939318656921, 0.743598222732544, 0.7277792096138, 0.728533923625946, 0.7268505692481995, 0.7342495322227478, 0.7358454465866089, 0.7411431074142456, 0.7305260896682739, 0.7680390477180481, 0.7489690184593201, 0.75409334897995, 0.7297369837760925, 0.7361497282981873, 0.7407107353210449, 0.7339284420013428, 0.7396883964538574, 0.7618412971496582, 0.7388050556182861, 0.737000584602356, 0.7365263104438782, 0.763643205165863, 0.752183735370636, 0.8000345826148987, 0.7536072134971619, 0.778231143951416, 0.7640647888183594, 0.7929845452308655, 0.7871077060699463, 0.7434836030006409, 0.7502359747886658, 0.7517498135566711, 0.7594629526138306, 0.8339935541152954, 0.7520960569381714, 0.7519369721412659, 0.762489914894104, 0.7745054364204407], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4881465435028076, 0.49353447556495667, 0.5226293206214905, 0.5237069129943848, 0.5409482717514038, 0.6487069129943848, 0.6540948152542114, 0.6842672228813171, 0.7381465435028076, 0.7543103694915771, 0.7629310488700867, 0.7650862336158752, 0.7801724076271057, 0.7543103694915771, 0.78125, 0.7715517282485962, 0.7920258641242981, 0.7844827771186829, 0.8017241358757019, 0.7844827771186829, 0.806034505367279, 0.8028017282485962, 0.7995689511299133, 0.7844827771186829, 0.8038793206214905, 0.8092672228813171, 0.8081896305084229, 0.8092672228813171, 0.8028017282485962, 0.8125, 0.8006465435028076, 0.795258641242981, 0.8049569129943848, 0.8135775923728943, 0.8049569129943848, 0.7866379022598267, 0.8028017282485962, 0.8049569129943848, 0.7909482717514038, 0.8038793206214905, 0.7801724076271057, 0.7963362336158752, 0.8125, 0.8028017282485962, 0.8017241358757019, 0.7349137663841248, 0.78125, 0.8028017282485962, 0.8092672228813171, 0.8103448152542114, 0.8038793206214905, 0.8017241358757019, 0.7898706793785095, 0.8114224076271057, 0.7931034564971924, 0.8071120977401733, 0.7931034564971924, 0.7909482717514038, 0.8092672228813171, 0.8081896305084229, 0.806034505367279, 0.8006465435028076, 0.8049569129943848, 0.8006465435028076, 0.8049569129943848, 0.7844827771186829, 0.7834051847457886, 0.7974137663841248, 0.8071120977401733, 0.806034505367279, 0.806034505367279, 0.8038793206214905, 0.8028017282485962, 0.7909482717514038, 0.8071120977401733, 0.8028017282485962, 0.8071120977401733, 0.7823275923728943, 0.7974137663841248, 0.7715517282485962, 0.798491358757019, 0.78125, 0.7844827771186829, 0.7737069129943848, 0.7823275923728943, 0.7995689511299133, 0.8017241358757019, 0.7974137663841248, 0.795258641242981, 0.756465494632721, 0.8081896305084229, 0.7941810488700867, 0.8028017282485962, 0.7758620977401733]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 5s 34ms/step - loss: 0.6804 - accuracy: 0.8407 - val_loss: 1.1230 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.6144 - accuracy: 0.8906"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 0.6630 - accuracy: 0.8534 - val_loss: 1.1192 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6559 - accuracy: 0.8580 - val_loss: 1.1044 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6491 - accuracy: 0.8580 - val_loss: 1.0791 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6530 - accuracy: 0.8582 - val_loss: 1.0588 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6395 - accuracy: 0.8662 - val_loss: 1.0528 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6383 - accuracy: 0.8647 - val_loss: 1.0495 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6289 - accuracy: 0.8732 - val_loss: 1.0304 - val_accuracy: 0.5034\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6398 - accuracy: 0.8664 - val_loss: 0.9843 - val_accuracy: 0.5441\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6335 - accuracy: 0.8611 - val_loss: 0.9688 - val_accuracy: 0.5577\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6256 - accuracy: 0.8707 - val_loss: 0.9423 - val_accuracy: 0.5939\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6161 - accuracy: 0.8775 - val_loss: 0.9609 - val_accuracy: 0.5724\n","Epoch 13/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6309 - accuracy: 0.8693 - val_loss: 0.9420 - val_accuracy: 0.5939\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6240 - accuracy: 0.8681 - val_loss: 0.9428 - val_accuracy: 0.5950\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6136 - accuracy: 0.8763 - val_loss: 0.8694 - val_accuracy: 0.7014\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6077 - accuracy: 0.8831 - val_loss: 0.8442 - val_accuracy: 0.7342\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6066 - accuracy: 0.8778 - val_loss: 0.8291 - val_accuracy: 0.7421\n","Epoch 18/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6017 - accuracy: 0.8846 - val_loss: 0.8305 - val_accuracy: 0.7342\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5985 - accuracy: 0.8812 - val_loss: 0.8380 - val_accuracy: 0.7262\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6151 - accuracy: 0.8738 - val_loss: 0.8251 - val_accuracy: 0.7342\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5972 - accuracy: 0.8814 - val_loss: 0.7976 - val_accuracy: 0.7636\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5876 - accuracy: 0.8913 - val_loss: 0.7799 - val_accuracy: 0.7828\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5857 - accuracy: 0.8922 - val_loss: 0.7749 - val_accuracy: 0.7862\n","Epoch 24/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5826 - accuracy: 0.8911 - val_loss: 0.7779 - val_accuracy: 0.7738\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5797 - accuracy: 0.8939 - val_loss: 0.7602 - val_accuracy: 0.7794\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5827 - accuracy: 0.8894 - val_loss: 0.7643 - val_accuracy: 0.7817\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5899 - accuracy: 0.8922 - val_loss: 0.7610 - val_accuracy: 0.7930\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5741 - accuracy: 0.8964 - val_loss: 0.7592 - val_accuracy: 0.7828\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5833 - accuracy: 0.8911 - val_loss: 0.7820 - val_accuracy: 0.7851\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5688 - accuracy: 0.8970 - val_loss: 0.7746 - val_accuracy: 0.7862\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5902 - accuracy: 0.8823 - val_loss: 0.7579 - val_accuracy: 0.7975\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5607 - accuracy: 0.9027 - val_loss: 0.7600 - val_accuracy: 0.7873\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5626 - accuracy: 0.8987 - val_loss: 0.7613 - val_accuracy: 0.7885\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5603 - accuracy: 0.9012 - val_loss: 0.7613 - val_accuracy: 0.7941\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5554 - accuracy: 0.9024 - val_loss: 0.7636 - val_accuracy: 0.7851\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5499 - accuracy: 0.9095 - val_loss: 0.7710 - val_accuracy: 0.7941\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5547 - accuracy: 0.8950 - val_loss: 0.7745 - val_accuracy: 0.7907\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5520 - accuracy: 0.9041 - val_loss: 0.7742 - val_accuracy: 0.7817\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5529 - accuracy: 0.9075 - val_loss: 0.7761 - val_accuracy: 0.7839\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5454 - accuracy: 0.9109 - val_loss: 0.7666 - val_accuracy: 0.7885\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5451 - accuracy: 0.9083 - val_loss: 0.7697 - val_accuracy: 0.7896\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5415 - accuracy: 0.9066 - val_loss: 0.7663 - val_accuracy: 0.7919\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5419 - accuracy: 0.9103 - val_loss: 0.7684 - val_accuracy: 0.7885\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5465 - accuracy: 0.9035 - val_loss: 0.7667 - val_accuracy: 0.7930\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5399 - accuracy: 0.9111 - val_loss: 0.7834 - val_accuracy: 0.7738\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5315 - accuracy: 0.9168 - val_loss: 0.7719 - val_accuracy: 0.7839\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5282 - accuracy: 0.9128 - val_loss: 0.7784 - val_accuracy: 0.7805\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5252 - accuracy: 0.9213 - val_loss: 0.7721 - val_accuracy: 0.7828\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5294 - accuracy: 0.9114 - val_loss: 0.7704 - val_accuracy: 0.7851\n","Epoch 50/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5196 - accuracy: 0.9211 - val_loss: 0.7721 - val_accuracy: 0.7896\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5227 - accuracy: 0.9160 - val_loss: 0.7771 - val_accuracy: 0.7862\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5205 - accuracy: 0.9228 - val_loss: 0.7694 - val_accuracy: 0.7907\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5180 - accuracy: 0.9208 - val_loss: 0.7978 - val_accuracy: 0.7715\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5150 - accuracy: 0.9253 - val_loss: 0.7785 - val_accuracy: 0.7873\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5160 - accuracy: 0.9171 - val_loss: 0.7756 - val_accuracy: 0.7851\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5159 - accuracy: 0.9177 - val_loss: 0.7825 - val_accuracy: 0.7805\n","Epoch 57/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5039 - accuracy: 0.9233 - val_loss: 0.7739 - val_accuracy: 0.7896\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5025 - accuracy: 0.9256 - val_loss: 0.7862 - val_accuracy: 0.7817\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5208 - accuracy: 0.9128 - val_loss: 0.8093 - val_accuracy: 0.7783\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5123 - accuracy: 0.9151 - val_loss: 0.7791 - val_accuracy: 0.7794\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5009 - accuracy: 0.9290 - val_loss: 0.7795 - val_accuracy: 0.7862\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.9298 - val_loss: 0.7856 - val_accuracy: 0.7783\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4967 - accuracy: 0.9295 - val_loss: 0.7858 - val_accuracy: 0.7828\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5062 - accuracy: 0.9179 - val_loss: 0.7829 - val_accuracy: 0.7805\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4941 - accuracy: 0.9290 - val_loss: 0.8030 - val_accuracy: 0.7715\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4907 - accuracy: 0.9293 - val_loss: 0.7821 - val_accuracy: 0.7771\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4826 - accuracy: 0.9383 - val_loss: 0.8024 - val_accuracy: 0.7760\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4804 - accuracy: 0.9377 - val_loss: 0.7847 - val_accuracy: 0.7839\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4819 - accuracy: 0.9375 - val_loss: 0.7911 - val_accuracy: 0.7885\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4914 - accuracy: 0.9244 - val_loss: 0.7933 - val_accuracy: 0.7907\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4759 - accuracy: 0.9392 - val_loss: 0.7902 - val_accuracy: 0.7828\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4712 - accuracy: 0.9443 - val_loss: 0.7928 - val_accuracy: 0.7805\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4812 - accuracy: 0.9327 - val_loss: 0.8032 - val_accuracy: 0.7817\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4703 - accuracy: 0.9380 - val_loss: 0.8098 - val_accuracy: 0.7794\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4739 - accuracy: 0.9394 - val_loss: 0.7936 - val_accuracy: 0.7873\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4876 - accuracy: 0.9264 - val_loss: 0.7997 - val_accuracy: 0.7873\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4640 - accuracy: 0.9457 - val_loss: 0.8033 - val_accuracy: 0.7726\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4829 - accuracy: 0.9244 - val_loss: 0.7951 - val_accuracy: 0.7783\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4751 - accuracy: 0.9315 - val_loss: 0.7920 - val_accuracy: 0.7828\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4584 - accuracy: 0.9485 - val_loss: 0.8164 - val_accuracy: 0.7828\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4641 - accuracy: 0.9409 - val_loss: 0.8004 - val_accuracy: 0.7885\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4575 - accuracy: 0.9468 - val_loss: 0.8301 - val_accuracy: 0.7749\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4620 - accuracy: 0.9360 - val_loss: 0.8088 - val_accuracy: 0.7839\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4695 - accuracy: 0.9349 - val_loss: 0.8730 - val_accuracy: 0.7647\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4765 - accuracy: 0.9318 - val_loss: 0.8147 - val_accuracy: 0.7805\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4535 - accuracy: 0.9426 - val_loss: 0.7990 - val_accuracy: 0.7817\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4537 - accuracy: 0.9443 - val_loss: 0.8304 - val_accuracy: 0.7783\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4577 - accuracy: 0.9406 - val_loss: 0.8065 - val_accuracy: 0.7771\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4402 - accuracy: 0.9556 - val_loss: 0.8154 - val_accuracy: 0.7839\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4431 - accuracy: 0.9488 - val_loss: 0.8060 - val_accuracy: 0.7839\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4391 - accuracy: 0.9550 - val_loss: 0.8123 - val_accuracy: 0.7749\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4372 - accuracy: 0.9542 - val_loss: 0.8087 - val_accuracy: 0.7805\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4341 - accuracy: 0.9573 - val_loss: 0.8187 - val_accuracy: 0.7760\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4406 - accuracy: 0.9530 - val_loss: 0.8478 - val_accuracy: 0.7670\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4570 - accuracy: 0.9380 - val_loss: 0.8313 - val_accuracy: 0.7738\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4314 - accuracy: 0.9610 - val_loss: 0.8261 - val_accuracy: 0.7805\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.9542 - val_loss: 0.8253 - val_accuracy: 0.7828\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4394 - accuracy: 0.9479 - val_loss: 0.8251 - val_accuracy: 0.7885\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4281 - accuracy: 0.9584 - val_loss: 0.8227 - val_accuracy: 0.7715\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4323 - accuracy: 0.9508 - val_loss: 0.8184 - val_accuracy: 0.7771\n","{'loss': [0.6804335117340088, 0.6629613041877747, 0.6559358835220337, 0.6490646600723267, 0.6529769897460938, 0.6394953727722168, 0.6382935643196106, 0.628943681716919, 0.6398210525512695, 0.6335233449935913, 0.625630259513855, 0.6160556674003601, 0.6309272646903992, 0.6239581108093262, 0.613635241985321, 0.6077033877372742, 0.6065806746482849, 0.6017072796821594, 0.5984821915626526, 0.6151248216629028, 0.5972082614898682, 0.5875799655914307, 0.5857176780700684, 0.582556962966919, 0.579650342464447, 0.5826860666275024, 0.589943528175354, 0.5741305947303772, 0.583328902721405, 0.5688109993934631, 0.590207040309906, 0.5606641173362732, 0.5626135468482971, 0.5602605938911438, 0.5554397702217102, 0.5498840808868408, 0.5546571016311646, 0.5519701242446899, 0.5528528690338135, 0.5454052686691284, 0.5450958013534546, 0.5414562821388245, 0.5418955683708191, 0.5465174317359924, 0.5399273037910461, 0.5315000414848328, 0.5281845927238464, 0.5251546502113342, 0.5293555855751038, 0.5196266174316406, 0.5226985216140747, 0.52049320936203, 0.5180355310440063, 0.5149522423744202, 0.5159693956375122, 0.5159139633178711, 0.5039064288139343, 0.5024605393409729, 0.5208056569099426, 0.5122835040092468, 0.500923216342926, 0.49720630049705505, 0.49670863151550293, 0.5062422752380371, 0.4940626621246338, 0.49068552255630493, 0.482647567987442, 0.4804382026195526, 0.4818810224533081, 0.49141237139701843, 0.4759426414966583, 0.47116467356681824, 0.48118776082992554, 0.47026190161705017, 0.47388729453086853, 0.4875660240650177, 0.46402508020401, 0.48293060064315796, 0.4750979542732239, 0.4583851397037506, 0.4640718400478363, 0.4574719965457916, 0.46203938126564026, 0.4695381820201874, 0.47649314999580383, 0.4534873068332672, 0.45366033911705017, 0.4576967656612396, 0.44019657373428345, 0.44313308596611023, 0.4391177296638489, 0.4372241795063019, 0.4340868294239044, 0.44057515263557434, 0.45696625113487244, 0.43139129877090454, 0.43238207697868347, 0.43943095207214355, 0.4280640184879303, 0.4323248863220215], 'accuracy': [0.8406904339790344, 0.8534238934516907, 0.8579513430595398, 0.8579513430595398, 0.8582342863082886, 0.8661573529243469, 0.8647425174713135, 0.8732314705848694, 0.8664402961730957, 0.8610639572143555, 0.870684802532196, 0.8774759769439697, 0.8692699670791626, 0.8681380748748779, 0.8763440847396851, 0.8831352591514587, 0.8777589201927185, 0.8845500946044922, 0.881154477596283, 0.8737974166870117, 0.8814374804496765, 0.8913412690162659, 0.892190158367157, 0.8910582661628723, 0.8938879370689392, 0.8893604874610901, 0.892190158367157, 0.8964346647262573, 0.8910582661628723, 0.8970005512237549, 0.8822863698005676, 0.9026598930358887, 0.8986983299255371, 0.9012450575828552, 0.9023768901824951, 0.9094510674476624, 0.8950198292732239, 0.9040747284889221, 0.9074702858924866, 0.9108659029006958, 0.9083191752433777, 0.9066213965415955, 0.9102999567985535, 0.9035087823867798, 0.9111488461494446, 0.9168081283569336, 0.9128466248512268, 0.9213355779647827, 0.9114317893981934, 0.9210526347160339, 0.9159592390060425, 0.9227504134178162, 0.9207696914672852, 0.9252971410751343, 0.9170911312103271, 0.9176570177078247, 0.9233163595199585, 0.9255800843238831, 0.9128466248512268, 0.9151103496551514, 0.9289756417274475, 0.9298245906829834, 0.9295415878295898, 0.9179400205612183, 0.9289756417274475, 0.9292586445808411, 0.9383135437965393, 0.937747597694397, 0.9374646544456482, 0.9244481921195984, 0.9391624331474304, 0.9442558288574219, 0.9326542019844055, 0.9380305409431458, 0.9394453763961792, 0.9264289736747742, 0.9456706047058105, 0.9244481921195984, 0.9315223693847656, 0.9485002756118774, 0.9408602118492126, 0.9468024969100952, 0.9360498189926147, 0.9349179267883301, 0.9318053126335144, 0.9425579905509949, 0.9442558288574219, 0.9405772686004639, 0.9555743932723999, 0.9487832188606262, 0.9550085067749023, 0.9541596174240112, 0.9572722315788269, 0.9530277252197266, 0.9380305409431458, 0.9609507918357849, 0.9541596174240112, 0.9479343295097351, 0.9584040641784668, 0.950764000415802], 'val_loss': [1.1230428218841553, 1.119154691696167, 1.1044301986694336, 1.079070806503296, 1.0587735176086426, 1.0528197288513184, 1.0494813919067383, 1.030400037765503, 0.9843117594718933, 0.9688171148300171, 0.9423379302024841, 0.9608947038650513, 0.9420012831687927, 0.9427759051322937, 0.8694102168083191, 0.8442145586013794, 0.8291186094284058, 0.830478847026825, 0.8379554152488708, 0.8250514268875122, 0.7975532412528992, 0.7798961400985718, 0.7749170064926147, 0.7778909802436829, 0.7602124810218811, 0.764299750328064, 0.760955810546875, 0.759242832660675, 0.7820115685462952, 0.7745755314826965, 0.7579250335693359, 0.7600097060203552, 0.7612517476081848, 0.7613308429718018, 0.7636323571205139, 0.7710140347480774, 0.7745097875595093, 0.7741585373878479, 0.7761301398277283, 0.7666082382202148, 0.7696868181228638, 0.7662883996963501, 0.7683925032615662, 0.7667437791824341, 0.7833530902862549, 0.7719173431396484, 0.7783762216567993, 0.7720664143562317, 0.7704394459724426, 0.7721446752548218, 0.7771438956260681, 0.7694252133369446, 0.7978490591049194, 0.7785248160362244, 0.7756469249725342, 0.7825253009796143, 0.7738560438156128, 0.7862182855606079, 0.809326171875, 0.7791454195976257, 0.7795310616493225, 0.7856065034866333, 0.7857546806335449, 0.7828911542892456, 0.8030115365982056, 0.7820754647254944, 0.8024253249168396, 0.7846822142601013, 0.7910817861557007, 0.7932562232017517, 0.7902027368545532, 0.7927870750427246, 0.803210973739624, 0.809842050075531, 0.7936222553253174, 0.7996705174446106, 0.8033010959625244, 0.7950708270072937, 0.792025625705719, 0.8164471983909607, 0.8003560304641724, 0.8300511240959167, 0.8087915182113647, 0.8729697465896606, 0.8147216439247131, 0.799043595790863, 0.8304092884063721, 0.8065373301506042, 0.8154074549674988, 0.8059946894645691, 0.812255859375, 0.8086634278297424, 0.8186811804771423, 0.8478227853775024, 0.831298828125, 0.8260951042175293, 0.8252714276313782, 0.8250969052314758, 0.8226801753044128, 0.8184155821800232], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5033936500549316, 0.5441176295280457, 0.557692289352417, 0.5938913822174072, 0.5723981857299805, 0.5938913822174072, 0.5950226187705994, 0.7013574838638306, 0.7341628670692444, 0.7420814633369446, 0.7341628670692444, 0.726244330406189, 0.7341628670692444, 0.7635746598243713, 0.7828054428100586, 0.7861990928649902, 0.773755669593811, 0.779411792755127, 0.7816742062568665, 0.7929864525794983, 0.7828054428100586, 0.7850678563117981, 0.7861990928649902, 0.7975113391876221, 0.7873303294181824, 0.7884615659713745, 0.7941176295280457, 0.7850678563117981, 0.7941176295280457, 0.790723979473114, 0.7816742062568665, 0.7839366793632507, 0.7884615659713745, 0.7895927429199219, 0.7918552160263062, 0.7884615659713745, 0.7929864525794983, 0.773755669593811, 0.7839366793632507, 0.7805429697036743, 0.7828054428100586, 0.7850678563117981, 0.7895927429199219, 0.7861990928649902, 0.790723979473114, 0.7714931964874268, 0.7873303294181824, 0.7850678563117981, 0.7805429697036743, 0.7895927429199219, 0.7816742062568665, 0.7782805562019348, 0.779411792755127, 0.7861990928649902, 0.7782805562019348, 0.7828054428100586, 0.7805429697036743, 0.7714931964874268, 0.7771493196487427, 0.7760180830955505, 0.7839366793632507, 0.7884615659713745, 0.790723979473114, 0.7828054428100586, 0.7805429697036743, 0.7816742062568665, 0.779411792755127, 0.7873303294181824, 0.7873303294181824, 0.7726244330406189, 0.7782805562019348, 0.7828054428100586, 0.7828054428100586, 0.7884615659713745, 0.7748869061470032, 0.7839366793632507, 0.7647058963775635, 0.7805429697036743, 0.7816742062568665, 0.7782805562019348, 0.7771493196487427, 0.7839366793632507, 0.7839366793632507, 0.7748869061470032, 0.7805429697036743, 0.7760180830955505, 0.766968309879303, 0.773755669593811, 0.7805429697036743, 0.7828054428100586, 0.7884615659713745, 0.7714931964874268, 0.7771493196487427]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 28ms/step - loss: 0.6962 - accuracy: 0.8351 - val_loss: 1.1404 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.7354 - accuracy: 0.8125"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.8367 - val_loss: 1.1371 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6724 - accuracy: 0.8491 - val_loss: 1.1248 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6605 - accuracy: 0.8540 - val_loss: 1.1213 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6591 - accuracy: 0.8514 - val_loss: 1.1021 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6558 - accuracy: 0.8535 - val_loss: 1.1128 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6507 - accuracy: 0.8553 - val_loss: 1.0962 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6446 - accuracy: 0.8610 - val_loss: 1.0815 - val_accuracy: 0.4907\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6562 - accuracy: 0.8460 - val_loss: 1.0739 - val_accuracy: 0.4938\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6393 - accuracy: 0.8561 - val_loss: 1.0465 - val_accuracy: 0.5031\n","Epoch 11/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.8587 - val_loss: 1.1063 - val_accuracy: 0.4969\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6446 - accuracy: 0.8548 - val_loss: 0.9191 - val_accuracy: 0.6271\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6491 - accuracy: 0.8514 - val_loss: 0.9016 - val_accuracy: 0.6498\n","Epoch 14/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6324 - accuracy: 0.8597 - val_loss: 0.9115 - val_accuracy: 0.6426\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6213 - accuracy: 0.8687 - val_loss: 0.8891 - val_accuracy: 0.6653\n","Epoch 16/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6216 - accuracy: 0.8690 - val_loss: 0.8511 - val_accuracy: 0.7211\n","Epoch 17/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6183 - accuracy: 0.8695 - val_loss: 0.8641 - val_accuracy: 0.6932\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6273 - accuracy: 0.8618 - val_loss: 0.8027 - val_accuracy: 0.7645\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6084 - accuracy: 0.8760 - val_loss: 0.8015 - val_accuracy: 0.7603\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6159 - accuracy: 0.8677 - val_loss: 0.7966 - val_accuracy: 0.7696\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6149 - accuracy: 0.8693 - val_loss: 0.8296 - val_accuracy: 0.7438\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6089 - accuracy: 0.8749 - val_loss: 0.7818 - val_accuracy: 0.7769\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6073 - accuracy: 0.8693 - val_loss: 0.8198 - val_accuracy: 0.7355\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6011 - accuracy: 0.8788 - val_loss: 0.7958 - val_accuracy: 0.7717\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6047 - accuracy: 0.8747 - val_loss: 0.8007 - val_accuracy: 0.7696\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5959 - accuracy: 0.8804 - val_loss: 0.7768 - val_accuracy: 0.7779\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5937 - accuracy: 0.8783 - val_loss: 0.7722 - val_accuracy: 0.7810\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5866 - accuracy: 0.8868 - val_loss: 0.7806 - val_accuracy: 0.7727\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5913 - accuracy: 0.8778 - val_loss: 0.7768 - val_accuracy: 0.7769\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5860 - accuracy: 0.8845 - val_loss: 0.7865 - val_accuracy: 0.7686\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5841 - accuracy: 0.8860 - val_loss: 0.7758 - val_accuracy: 0.7851\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5864 - accuracy: 0.8806 - val_loss: 0.7785 - val_accuracy: 0.7800\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5760 - accuracy: 0.8891 - val_loss: 0.7772 - val_accuracy: 0.7696\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5726 - accuracy: 0.8894 - val_loss: 0.7770 - val_accuracy: 0.7769\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5732 - accuracy: 0.8915 - val_loss: 0.7790 - val_accuracy: 0.7820\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5788 - accuracy: 0.8848 - val_loss: 0.7932 - val_accuracy: 0.7758\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5652 - accuracy: 0.8982 - val_loss: 0.8032 - val_accuracy: 0.7800\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5738 - accuracy: 0.8917 - val_loss: 0.7923 - val_accuracy: 0.7810\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5660 - accuracy: 0.8948 - val_loss: 0.7754 - val_accuracy: 0.7779\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5607 - accuracy: 0.8979 - val_loss: 0.7818 - val_accuracy: 0.7748\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5618 - accuracy: 0.8917 - val_loss: 0.7904 - val_accuracy: 0.7758\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5642 - accuracy: 0.8915 - val_loss: 0.7755 - val_accuracy: 0.7851\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5507 - accuracy: 0.8984 - val_loss: 0.7919 - val_accuracy: 0.7665\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5673 - accuracy: 0.8868 - val_loss: 0.7806 - val_accuracy: 0.7831\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.8972 - val_loss: 0.7762 - val_accuracy: 0.7727\n","Epoch 46/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5487 - accuracy: 0.9065 - val_loss: 0.7859 - val_accuracy: 0.7717\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.8964 - val_loss: 0.7842 - val_accuracy: 0.7820\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.8984 - val_loss: 0.7788 - val_accuracy: 0.7779\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5443 - accuracy: 0.9039 - val_loss: 0.7979 - val_accuracy: 0.7665\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5622 - accuracy: 0.8835 - val_loss: 0.7968 - val_accuracy: 0.7686\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5370 - accuracy: 0.9052 - val_loss: 0.7950 - val_accuracy: 0.7758\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5499 - accuracy: 0.8951 - val_loss: 0.7921 - val_accuracy: 0.7727\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5389 - accuracy: 0.9072 - val_loss: 0.8514 - val_accuracy: 0.7448\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5445 - accuracy: 0.8959 - val_loss: 0.7850 - val_accuracy: 0.7748\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5358 - accuracy: 0.9065 - val_loss: 0.7829 - val_accuracy: 0.7758\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5323 - accuracy: 0.9080 - val_loss: 0.8004 - val_accuracy: 0.7572\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5336 - accuracy: 0.9039 - val_loss: 0.7834 - val_accuracy: 0.7727\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5215 - accuracy: 0.9124 - val_loss: 0.8111 - val_accuracy: 0.7738\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5164 - accuracy: 0.9207 - val_loss: 0.7875 - val_accuracy: 0.7738\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5176 - accuracy: 0.9150 - val_loss: 0.7863 - val_accuracy: 0.7769\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5128 - accuracy: 0.9222 - val_loss: 0.7899 - val_accuracy: 0.7769\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5210 - accuracy: 0.9119 - val_loss: 0.7975 - val_accuracy: 0.7779\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5128 - accuracy: 0.9140 - val_loss: 0.8557 - val_accuracy: 0.7717\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5166 - accuracy: 0.9178 - val_loss: 0.8166 - val_accuracy: 0.7696\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5073 - accuracy: 0.9189 - val_loss: 0.8554 - val_accuracy: 0.7448\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5193 - accuracy: 0.9119 - val_loss: 0.8479 - val_accuracy: 0.7696\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5238 - accuracy: 0.9021 - val_loss: 0.7948 - val_accuracy: 0.7727\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5074 - accuracy: 0.9207 - val_loss: 0.8032 - val_accuracy: 0.7676\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5004 - accuracy: 0.9248 - val_loss: 0.8047 - val_accuracy: 0.7748\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4977 - accuracy: 0.9222 - val_loss: 0.7972 - val_accuracy: 0.7686\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4966 - accuracy: 0.9261 - val_loss: 0.7978 - val_accuracy: 0.7738\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4907 - accuracy: 0.9300 - val_loss: 0.7989 - val_accuracy: 0.7727\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4934 - accuracy: 0.9264 - val_loss: 0.8025 - val_accuracy: 0.7748\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4890 - accuracy: 0.9284 - val_loss: 0.8358 - val_accuracy: 0.7707\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4997 - accuracy: 0.9183 - val_loss: 0.8099 - val_accuracy: 0.7738\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4877 - accuracy: 0.9302 - val_loss: 0.8051 - val_accuracy: 0.7810\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4873 - accuracy: 0.9261 - val_loss: 0.8028 - val_accuracy: 0.7769\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4836 - accuracy: 0.9292 - val_loss: 0.8060 - val_accuracy: 0.7758\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4799 - accuracy: 0.9300 - val_loss: 0.8068 - val_accuracy: 0.7748\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4795 - accuracy: 0.9297 - val_loss: 0.8127 - val_accuracy: 0.7707\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4826 - accuracy: 0.9266 - val_loss: 0.8093 - val_accuracy: 0.7727\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4780 - accuracy: 0.9346 - val_loss: 0.8172 - val_accuracy: 0.7748\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4987 - accuracy: 0.9134 - val_loss: 0.8228 - val_accuracy: 0.7696\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4917 - accuracy: 0.9191 - val_loss: 0.8122 - val_accuracy: 0.7686\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4671 - accuracy: 0.9408 - val_loss: 0.8155 - val_accuracy: 0.7696\n","Epoch 86/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4676 - accuracy: 0.9403 - val_loss: 0.8193 - val_accuracy: 0.7655\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4687 - accuracy: 0.9380 - val_loss: 0.8231 - val_accuracy: 0.7603\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4685 - accuracy: 0.9362 - val_loss: 0.8155 - val_accuracy: 0.7665\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4613 - accuracy: 0.9408 - val_loss: 0.8215 - val_accuracy: 0.7696\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4645 - accuracy: 0.9375 - val_loss: 0.9025 - val_accuracy: 0.7645\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4653 - accuracy: 0.9357 - val_loss: 0.8186 - val_accuracy: 0.7707\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4596 - accuracy: 0.9413 - val_loss: 0.8594 - val_accuracy: 0.7603\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4702 - accuracy: 0.9307 - val_loss: 0.8235 - val_accuracy: 0.7727\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4562 - accuracy: 0.9416 - val_loss: 0.8548 - val_accuracy: 0.7717\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4512 - accuracy: 0.9486 - val_loss: 0.8311 - val_accuracy: 0.7696\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4507 - accuracy: 0.9463 - val_loss: 0.8675 - val_accuracy: 0.7624\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4520 - accuracy: 0.9473 - val_loss: 0.8362 - val_accuracy: 0.7707\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4440 - accuracy: 0.9514 - val_loss: 0.8362 - val_accuracy: 0.7645\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4444 - accuracy: 0.9491 - val_loss: 0.8308 - val_accuracy: 0.7727\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4459 - accuracy: 0.9501 - val_loss: 0.8584 - val_accuracy: 0.7758\n","{'loss': [0.6961951851844788, 0.6819011569023132, 0.6723740696907043, 0.6604966521263123, 0.659051775932312, 0.6557818055152893, 0.6507403254508972, 0.6446456909179688, 0.6562071442604065, 0.6392793655395508, 0.6426963210105896, 0.6445513963699341, 0.6491045355796814, 0.6324239373207092, 0.6213368773460388, 0.6216135621070862, 0.6182981729507446, 0.6272783875465393, 0.6084434986114502, 0.6158747673034668, 0.6149234175682068, 0.6089094877243042, 0.607322633266449, 0.6010833382606506, 0.6047143936157227, 0.5958531498908997, 0.5936811566352844, 0.5866150259971619, 0.5913066864013672, 0.5860285758972168, 0.5841139554977417, 0.5864301323890686, 0.576007068157196, 0.5725515484809875, 0.5732377767562866, 0.5788406133651733, 0.5651693940162659, 0.5737521648406982, 0.5659962296485901, 0.5606544017791748, 0.561840295791626, 0.5641536116600037, 0.5506938695907593, 0.5672892332077026, 0.5500290393829346, 0.5486810803413391, 0.5500189065933228, 0.5492869019508362, 0.5442682504653931, 0.5621890425682068, 0.53700852394104, 0.5499216318130493, 0.5388925075531006, 0.544451117515564, 0.5357544422149658, 0.5322903394699097, 0.5335879921913147, 0.5215348601341248, 0.5163751244544983, 0.5176301598548889, 0.5128161907196045, 0.52096027135849, 0.5127843618392944, 0.5165602564811707, 0.5073493719100952, 0.5193347334861755, 0.5238416790962219, 0.5073745846748352, 0.5003883242607117, 0.4976527690887451, 0.4965558648109436, 0.49067017436027527, 0.493365079164505, 0.4890419542789459, 0.49965062737464905, 0.4877215325832367, 0.48733940720558167, 0.4835567772388458, 0.47985148429870605, 0.47950515151023865, 0.4826078414916992, 0.4780307114124298, 0.4987400770187378, 0.4917351007461548, 0.4671456217765808, 0.4676278531551361, 0.46871620416641235, 0.46849092841148376, 0.4612986445426941, 0.4644625186920166, 0.4653306305408478, 0.45957455039024353, 0.4701782464981079, 0.45622241497039795, 0.4512360990047455, 0.4507388770580292, 0.45199379324913025, 0.44397348165512085, 0.444372296333313, 0.44589805603027344], 'accuracy': [0.8351421356201172, 0.8366925120353699, 0.8490955829620361, 0.8540051579475403, 0.8514211773872375, 0.8534883856773376, 0.8552971482276917, 0.8609819412231445, 0.8459948301315308, 0.8560723662376404, 0.8586563467979431, 0.854780375957489, 0.8514211773872375, 0.8596899509429932, 0.868733823299408, 0.868992269039154, 0.8695090413093567, 0.8617570996284485, 0.8759689927101135, 0.8677002787590027, 0.8692506551742554, 0.8749353885650635, 0.8692506551742554, 0.8788113594055176, 0.8746770024299622, 0.8803617358207703, 0.8782945871353149, 0.8868216872215271, 0.8777777552604675, 0.8844961524009705, 0.8860465288162231, 0.8806201815605164, 0.8891472816467285, 0.8894056677818298, 0.8914728760719299, 0.8847545385360718, 0.8981912136077881, 0.8917312622070312, 0.8948320150375366, 0.8979328274726868, 0.8917312622070312, 0.8914728760719299, 0.8984495997428894, 0.8868216872215271, 0.897157609462738, 0.9064599275588989, 0.8963824510574341, 0.8984495997428894, 0.9038759469985962, 0.8834625482559204, 0.9051679372787476, 0.8950904607772827, 0.9072351455688477, 0.8958656191825867, 0.9064599275588989, 0.9080103635787964, 0.9038759469985962, 0.9124031066894531, 0.920671820640564, 0.9149870872497559, 0.9222221970558167, 0.9118863344192505, 0.9139534831047058, 0.9178294539451599, 0.91886305809021, 0.9118863344192505, 0.9020671844482422, 0.920671820640564, 0.9248061776161194, 0.9222221970558167, 0.9260981678962708, 0.9299741387367249, 0.9263566136360168, 0.9284237623214722, 0.9183462262153625, 0.930232584476471, 0.9260981678962708, 0.9291989803314209, 0.9299741387367249, 0.9297157526016235, 0.9266149997711182, 0.9346253275871277, 0.9134367108345032, 0.9191214442253113, 0.9408268928527832, 0.9403100609779358, 0.9379844665527344, 0.9361757040023804, 0.9408268928527832, 0.9374676942825317, 0.9356589317321777, 0.9413436651229858, 0.9307493567466736, 0.9416020512580872, 0.9485788345336914, 0.94625324010849, 0.94728684425354, 0.9514212012290955, 0.949095606803894, 0.9501292109489441], 'val_loss': [1.1404235363006592, 1.1371169090270996, 1.1248198747634888, 1.1213371753692627, 1.1021431684494019, 1.1127859354019165, 1.0962108373641968, 1.0815247297286987, 1.0739266872406006, 1.0464649200439453, 1.106329083442688, 0.9190595746040344, 0.901614785194397, 0.9114924073219299, 0.8891144394874573, 0.8510956168174744, 0.8641006350517273, 0.8027308583259583, 0.8014984130859375, 0.7965582013130188, 0.8296236395835876, 0.781792163848877, 0.8198142647743225, 0.7957671880722046, 0.800713300704956, 0.77681964635849, 0.7721652388572693, 0.7806493639945984, 0.7768296003341675, 0.7864639759063721, 0.7758426070213318, 0.7785438895225525, 0.7771999835968018, 0.7770093083381653, 0.7789989709854126, 0.7931795120239258, 0.8031889796257019, 0.7922676205635071, 0.7754355669021606, 0.781754195690155, 0.7903798818588257, 0.7754725813865662, 0.7918649315834045, 0.7806224226951599, 0.7761846780776978, 0.7858946323394775, 0.7841711044311523, 0.7788427472114563, 0.7978646755218506, 0.7967848181724548, 0.7950124740600586, 0.7921165823936462, 0.85140460729599, 0.7850279211997986, 0.7829232811927795, 0.80039381980896, 0.7833520770072937, 0.8110979795455933, 0.7874523997306824, 0.7862876653671265, 0.7899281978607178, 0.7975067496299744, 0.8556978106498718, 0.8165722489356995, 0.8554330468177795, 0.8478601574897766, 0.7948124408721924, 0.8031737208366394, 0.804725170135498, 0.7971897721290588, 0.7978395819664001, 0.7989408373832703, 0.8024983406066895, 0.8357668519020081, 0.8098902702331543, 0.8051122426986694, 0.8028375506401062, 0.8059779405593872, 0.8068363070487976, 0.8127120733261108, 0.8093451261520386, 0.8172494769096375, 0.8228352069854736, 0.8122336268424988, 0.8155259490013123, 0.8193071484565735, 0.8231280446052551, 0.815508246421814, 0.821546733379364, 0.902522087097168, 0.818559467792511, 0.8593985438346863, 0.823492169380188, 0.8548017144203186, 0.8311288952827454, 0.8674850463867188, 0.8362324833869934, 0.8361708521842957, 0.8308136463165283, 0.8583669066429138], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.49070248007774353, 0.49380165338516235, 0.5030992031097412, 0.4969008266925812, 0.6270661354064941, 0.6497933864593506, 0.6425619721412659, 0.6652892827987671, 0.7210744023323059, 0.6931818127632141, 0.7644628286361694, 0.7603305578231812, 0.76962810754776, 0.7438016533851624, 0.7768595218658447, 0.7355371713638306, 0.7716942429542542, 0.76962810754776, 0.7778925895690918, 0.7809917330741882, 0.7727272510528564, 0.7768595218658447, 0.7685950398445129, 0.7851239442825317, 0.7799586653709412, 0.76962810754776, 0.7768595218658447, 0.7820248007774353, 0.7758264541625977, 0.7799586653709412, 0.7809917330741882, 0.7778925895690918, 0.7747933864593506, 0.7758264541625977, 0.7851239442825317, 0.7665289044380188, 0.7830578684806824, 0.7727272510528564, 0.7716942429542542, 0.7820248007774353, 0.7778925895690918, 0.7665289044380188, 0.7685950398445129, 0.7758264541625977, 0.7727272510528564, 0.7448347210884094, 0.7747933864593506, 0.7758264541625977, 0.7572314143180847, 0.7727272510528564, 0.7737603187561035, 0.7737603187561035, 0.7768595218658447, 0.7768595218658447, 0.7778925895690918, 0.7716942429542542, 0.76962810754776, 0.7448347210884094, 0.76962810754776, 0.7727272510528564, 0.7675619721412659, 0.7747933864593506, 0.7685950398445129, 0.7737603187561035, 0.7727272510528564, 0.7747933864593506, 0.7706611752510071, 0.7737603187561035, 0.7809917330741882, 0.7768595218658447, 0.7758264541625977, 0.7747933864593506, 0.7706611752510071, 0.7727272510528564, 0.7747933864593506, 0.76962810754776, 0.7685950398445129, 0.76962810754776, 0.7654958963394165, 0.7603305578231812, 0.7665289044380188, 0.76962810754776, 0.7644628286361694, 0.7706611752510071, 0.7603305578231812, 0.7727272510528564, 0.7716942429542542, 0.76962810754776, 0.7623966932296753, 0.7706611752510071, 0.7644628286361694, 0.7727272510528564, 0.7758264541625977]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 28ms/step - loss: 0.5593 - accuracy: 0.8895 - val_loss: 1.2169 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.5183 - accuracy: 0.9062"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 10ms/step - loss: 0.5057 - accuracy: 0.9143 - val_loss: 1.2144 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5024 - accuracy: 0.9111 - val_loss: 1.2062 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4976 - accuracy: 0.9168 - val_loss: 1.1981 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4961 - accuracy: 0.9189 - val_loss: 1.2041 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4865 - accuracy: 0.9205 - val_loss: 1.2205 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4947 - accuracy: 0.9154 - val_loss: 1.1970 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4811 - accuracy: 0.9267 - val_loss: 1.1991 - val_accuracy: 0.4925\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4813 - accuracy: 0.9243 - val_loss: 1.1793 - val_accuracy: 0.4989\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4727 - accuracy: 0.9321 - val_loss: 1.1812 - val_accuracy: 0.5054\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4767 - accuracy: 0.9321 - val_loss: 1.2444 - val_accuracy: 0.5065\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4768 - accuracy: 0.9275 - val_loss: 1.0820 - val_accuracy: 0.5442\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4719 - accuracy: 0.9300 - val_loss: 1.1091 - val_accuracy: 0.5506\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4836 - accuracy: 0.9232 - val_loss: 1.0007 - val_accuracy: 0.5981\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4718 - accuracy: 0.9308 - val_loss: 1.0309 - val_accuracy: 0.5981\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4565 - accuracy: 0.9415 - val_loss: 0.8550 - val_accuracy: 0.6897\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4589 - accuracy: 0.9405 - val_loss: 0.7904 - val_accuracy: 0.7457\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4571 - accuracy: 0.9429 - val_loss: 0.7682 - val_accuracy: 0.7662\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4585 - accuracy: 0.9367 - val_loss: 0.7834 - val_accuracy: 0.7716\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4533 - accuracy: 0.9399 - val_loss: 0.7564 - val_accuracy: 0.7759\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4496 - accuracy: 0.9445 - val_loss: 0.7537 - val_accuracy: 0.7823\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4497 - accuracy: 0.9437 - val_loss: 0.7171 - val_accuracy: 0.8093\n","Epoch 23/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4488 - accuracy: 0.9448 - val_loss: 0.7236 - val_accuracy: 0.7942\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4434 - accuracy: 0.9461 - val_loss: 0.6994 - val_accuracy: 0.8157\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4413 - accuracy: 0.9518 - val_loss: 0.6755 - val_accuracy: 0.8222\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4392 - accuracy: 0.9504 - val_loss: 0.7174 - val_accuracy: 0.8125\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4372 - accuracy: 0.9475 - val_loss: 0.6666 - val_accuracy: 0.8276\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4399 - accuracy: 0.9448 - val_loss: 0.6698 - val_accuracy: 0.8265\n","Epoch 29/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4308 - accuracy: 0.9566 - val_loss: 0.6824 - val_accuracy: 0.8222\n","Epoch 30/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4396 - accuracy: 0.9488 - val_loss: 0.6861 - val_accuracy: 0.8222\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4435 - accuracy: 0.9440 - val_loss: 0.6635 - val_accuracy: 0.8244\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4345 - accuracy: 0.9510 - val_loss: 0.7020 - val_accuracy: 0.8233\n","Epoch 33/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4311 - accuracy: 0.9499 - val_loss: 0.6674 - val_accuracy: 0.8308\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4225 - accuracy: 0.9558 - val_loss: 0.6699 - val_accuracy: 0.8297\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4211 - accuracy: 0.9593 - val_loss: 0.6899 - val_accuracy: 0.8211\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4311 - accuracy: 0.9502 - val_loss: 0.6993 - val_accuracy: 0.8211\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4217 - accuracy: 0.9558 - val_loss: 0.6693 - val_accuracy: 0.8265\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4389 - accuracy: 0.9407 - val_loss: 0.7822 - val_accuracy: 0.7823\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4290 - accuracy: 0.9515 - val_loss: 0.6737 - val_accuracy: 0.8265\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4125 - accuracy: 0.9615 - val_loss: 0.6769 - val_accuracy: 0.8308\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4104 - accuracy: 0.9615 - val_loss: 0.6737 - val_accuracy: 0.8244\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4086 - accuracy: 0.9612 - val_loss: 0.6812 - val_accuracy: 0.8276\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.9577 - val_loss: 0.6778 - val_accuracy: 0.8254\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.9658 - val_loss: 0.6863 - val_accuracy: 0.8308\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4030 - accuracy: 0.9685 - val_loss: 0.6798 - val_accuracy: 0.8254\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4045 - accuracy: 0.9634 - val_loss: 0.6792 - val_accuracy: 0.8287\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3987 - accuracy: 0.9679 - val_loss: 0.6906 - val_accuracy: 0.8308\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3957 - accuracy: 0.9677 - val_loss: 0.6851 - val_accuracy: 0.8265\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4073 - accuracy: 0.9599 - val_loss: 0.6839 - val_accuracy: 0.8330\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4215 - accuracy: 0.9480 - val_loss: 0.6851 - val_accuracy: 0.8287\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4143 - accuracy: 0.9585 - val_loss: 0.6814 - val_accuracy: 0.8233\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3945 - accuracy: 0.9693 - val_loss: 0.6965 - val_accuracy: 0.8200\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.9704 - val_loss: 0.7579 - val_accuracy: 0.7899\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3979 - accuracy: 0.9634 - val_loss: 0.6895 - val_accuracy: 0.8287\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3967 - accuracy: 0.9661 - val_loss: 0.6890 - val_accuracy: 0.8287\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4018 - accuracy: 0.9588 - val_loss: 0.6872 - val_accuracy: 0.8233\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3989 - accuracy: 0.9663 - val_loss: 0.7311 - val_accuracy: 0.8168\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3935 - accuracy: 0.9663 - val_loss: 0.6916 - val_accuracy: 0.8244\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3819 - accuracy: 0.9744 - val_loss: 0.6984 - val_accuracy: 0.8254\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3825 - accuracy: 0.9731 - val_loss: 0.7430 - val_accuracy: 0.8039\n","Epoch 61/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3831 - accuracy: 0.9749 - val_loss: 0.7035 - val_accuracy: 0.8168\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3809 - accuracy: 0.9739 - val_loss: 0.6931 - val_accuracy: 0.8254\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3770 - accuracy: 0.9749 - val_loss: 0.7140 - val_accuracy: 0.8254\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3928 - accuracy: 0.9647 - val_loss: 0.6968 - val_accuracy: 0.8136\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3812 - accuracy: 0.9725 - val_loss: 0.6935 - val_accuracy: 0.8297\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3824 - accuracy: 0.9690 - val_loss: 0.7261 - val_accuracy: 0.8136\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3741 - accuracy: 0.9776 - val_loss: 0.6993 - val_accuracy: 0.8254\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3768 - accuracy: 0.9717 - val_loss: 0.6999 - val_accuracy: 0.8265\n","Epoch 69/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3682 - accuracy: 0.9798 - val_loss: 0.7169 - val_accuracy: 0.8147\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3987 - accuracy: 0.9612 - val_loss: 0.7159 - val_accuracy: 0.8157\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3753 - accuracy: 0.9736 - val_loss: 0.6998 - val_accuracy: 0.8190\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3680 - accuracy: 0.9790 - val_loss: 0.7530 - val_accuracy: 0.8114\n","Epoch 73/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3702 - accuracy: 0.9771 - val_loss: 0.7045 - val_accuracy: 0.8308\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3672 - accuracy: 0.9779 - val_loss: 0.7560 - val_accuracy: 0.8082\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3782 - accuracy: 0.9693 - val_loss: 0.7163 - val_accuracy: 0.8276\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3636 - accuracy: 0.9793 - val_loss: 0.7114 - val_accuracy: 0.8254\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3680 - accuracy: 0.9741 - val_loss: 0.7113 - val_accuracy: 0.8276\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3612 - accuracy: 0.9793 - val_loss: 0.7100 - val_accuracy: 0.8168\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3601 - accuracy: 0.9811 - val_loss: 0.7130 - val_accuracy: 0.8254\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3672 - accuracy: 0.9763 - val_loss: 0.7655 - val_accuracy: 0.8039\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3754 - accuracy: 0.9690 - val_loss: 0.7185 - val_accuracy: 0.8190\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3583 - accuracy: 0.9806 - val_loss: 0.7981 - val_accuracy: 0.7866\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3633 - accuracy: 0.9779 - val_loss: 0.7451 - val_accuracy: 0.8179\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.9803 - val_loss: 0.7158 - val_accuracy: 0.8276\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3568 - accuracy: 0.9779 - val_loss: 0.7221 - val_accuracy: 0.8233\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3530 - accuracy: 0.9825 - val_loss: 0.7230 - val_accuracy: 0.8244\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3566 - accuracy: 0.9811 - val_loss: 0.7223 - val_accuracy: 0.8190\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3567 - accuracy: 0.9806 - val_loss: 0.7223 - val_accuracy: 0.8244\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3498 - accuracy: 0.9822 - val_loss: 0.7253 - val_accuracy: 0.8222\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3558 - accuracy: 0.9817 - val_loss: 0.7874 - val_accuracy: 0.7953\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3643 - accuracy: 0.9731 - val_loss: 0.7507 - val_accuracy: 0.8265\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3475 - accuracy: 0.9838 - val_loss: 0.7401 - val_accuracy: 0.8168\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3450 - accuracy: 0.9852 - val_loss: 0.7263 - val_accuracy: 0.8287\n","Epoch 94/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3476 - accuracy: 0.9830 - val_loss: 0.7311 - val_accuracy: 0.8222\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3492 - accuracy: 0.9809 - val_loss: 0.7379 - val_accuracy: 0.8244\n","Epoch 96/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3472 - accuracy: 0.9846 - val_loss: 0.7797 - val_accuracy: 0.8179\n","Epoch 97/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3613 - accuracy: 0.9739 - val_loss: 0.8108 - val_accuracy: 0.7996\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3457 - accuracy: 0.9841 - val_loss: 0.7393 - val_accuracy: 0.8179\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3386 - accuracy: 0.9873 - val_loss: 0.7369 - val_accuracy: 0.8222\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3358 - accuracy: 0.9884 - val_loss: 0.7493 - val_accuracy: 0.8211\n","{'loss': [0.5593070387840271, 0.5056992173194885, 0.5024440884590149, 0.4975726306438446, 0.4960564970970154, 0.48647305369377136, 0.4947452247142792, 0.4811130166053772, 0.4813404679298401, 0.4727495312690735, 0.47670432925224304, 0.47682881355285645, 0.4719046354293823, 0.4836121201515198, 0.4717605412006378, 0.4564736783504486, 0.45886868238449097, 0.457091748714447, 0.4584866762161255, 0.4533235430717468, 0.4495527148246765, 0.4497184157371521, 0.44880276918411255, 0.44344326853752136, 0.4413228929042816, 0.43924373388290405, 0.43718692660331726, 0.43987876176834106, 0.43079501390457153, 0.4396258294582367, 0.44348689913749695, 0.43450579047203064, 0.43110191822052, 0.42252567410469055, 0.4210960268974304, 0.4311297535896301, 0.4217432141304016, 0.4388694167137146, 0.4290083944797516, 0.4124815762042999, 0.41044455766677856, 0.4085833728313446, 0.4180780053138733, 0.40659099817276, 0.4029827117919922, 0.4044763445854187, 0.3986596465110779, 0.39573395252227783, 0.40733233094215393, 0.4215095341205597, 0.41432568430900574, 0.3944510817527771, 0.3938489556312561, 0.3978939354419708, 0.396685928106308, 0.40176793932914734, 0.39888471364974976, 0.39352068305015564, 0.38192570209503174, 0.38248342275619507, 0.38313427567481995, 0.3809325397014618, 0.3770461678504944, 0.39277738332748413, 0.3812163770198822, 0.38237306475639343, 0.3740561008453369, 0.37684449553489685, 0.36818063259124756, 0.3987118899822235, 0.3752874732017517, 0.3679613769054413, 0.37018707394599915, 0.367194801568985, 0.3781585693359375, 0.3636109232902527, 0.3680104613304138, 0.36122024059295654, 0.36009520292282104, 0.367173433303833, 0.3754119873046875, 0.35826554894447327, 0.3633047342300415, 0.35801053047180176, 0.35679957270622253, 0.3530130386352539, 0.356619656085968, 0.3567184507846832, 0.34982556104660034, 0.35576769709587097, 0.36425599455833435, 0.3475245535373688, 0.34496408700942993, 0.34763437509536743, 0.34921425580978394, 0.34719908237457275, 0.3612940311431885, 0.3456743061542511, 0.33862051367759705, 0.335798442363739], 'accuracy': [0.8895474076271057, 0.9143319129943848, 0.9110991358757019, 0.9167564511299133, 0.9189116358757019, 0.920527994632721, 0.915409505367279, 0.9267241358757019, 0.9242995977401733, 0.9321120977401733, 0.9321120977401733, 0.9275323152542114, 0.9299569129943848, 0.923222005367279, 0.9307650923728943, 0.9415409564971924, 0.9404633641242981, 0.9428879022598267, 0.9366918206214905, 0.9399245977401733, 0.9445043206214905, 0.943696141242981, 0.9447737336158752, 0.9461206793785095, 0.951777994632721, 0.9504310488700867, 0.9474676847457886, 0.9447737336158752, 0.9566271305084229, 0.9488146305084229, 0.943965494632721, 0.9509698152542114, 0.9498922228813171, 0.9558189511299133, 0.959321141242981, 0.9501616358757019, 0.9558189511299133, 0.9407327771186829, 0.951508641242981, 0.9614762663841248, 0.9614762663841248, 0.9612069129943848, 0.9577047228813171, 0.9657866358757019, 0.9684805870056152, 0.9633620977401733, 0.9679418206214905, 0.9676724076271057, 0.9598599076271057, 0.9480064511299133, 0.9585129022598267, 0.9692887663841248, 0.970366358757019, 0.9633620977401733, 0.9660560488700867, 0.9587823152542114, 0.9663254022598267, 0.9663254022598267, 0.9744073152542114, 0.9730603694915771, 0.974946141242981, 0.9738685488700867, 0.974946141242981, 0.9647090435028076, 0.9725215435028076, 0.9690194129943848, 0.9776400923728943, 0.9717133641242981, 0.9797952771186829, 0.9612069129943848, 0.9735991358757019, 0.9789870977401733, 0.9771012663841248, 0.977909505367279, 0.9692887663841248, 0.9792564511299133, 0.9741379022598267, 0.9792564511299133, 0.9811422228813171, 0.9762930870056152, 0.9690194129943848, 0.9806034564971924, 0.977909505367279, 0.9803340435028076, 0.977909505367279, 0.9824892282485962, 0.9811422228813171, 0.9806034564971924, 0.9822198152542114, 0.9816810488700867, 0.9730603694915771, 0.9838362336158752, 0.9851831793785095, 0.983027994632721, 0.9808728694915771, 0.9846444129943848, 0.9738685488700867, 0.9841055870056152, 0.9873383641242981, 0.9884159564971924], 'val_loss': [1.216943383216858, 1.2143950462341309, 1.2061729431152344, 1.198065996170044, 1.2040923833847046, 1.220521330833435, 1.1970351934432983, 1.1990931034088135, 1.1793482303619385, 1.1811941862106323, 1.244389533996582, 1.0820224285125732, 1.1090853214263916, 1.000707983970642, 1.0308650732040405, 0.8550219535827637, 0.7904124855995178, 0.7681682109832764, 0.7834087014198303, 0.7564466595649719, 0.7536532878875732, 0.7170932292938232, 0.7236152291297913, 0.6993827223777771, 0.6754807233810425, 0.7174007296562195, 0.6665769219398499, 0.6698180437088013, 0.6824480891227722, 0.6860712766647339, 0.6634759306907654, 0.7019636631011963, 0.6674001812934875, 0.6698527336120605, 0.6898786425590515, 0.6992676854133606, 0.6692695617675781, 0.7822320461273193, 0.6736920475959778, 0.676936686038971, 0.6737352609634399, 0.6811986565589905, 0.6777704358100891, 0.6862626075744629, 0.6798338294029236, 0.6791603565216064, 0.6905738711357117, 0.6850966215133667, 0.6838615536689758, 0.6850649118423462, 0.6813566088676453, 0.6965477466583252, 0.7579460740089417, 0.689471960067749, 0.6889895796775818, 0.6871721148490906, 0.7311028242111206, 0.6916162967681885, 0.6984431147575378, 0.742956817150116, 0.7035079002380371, 0.6930792331695557, 0.7139932513237, 0.6967508792877197, 0.693525493144989, 0.7260699272155762, 0.6993108987808228, 0.6998756527900696, 0.7169327735900879, 0.7158966064453125, 0.699821412563324, 0.7529610395431519, 0.7045047879219055, 0.7559620141983032, 0.7162864804267883, 0.7114134430885315, 0.7113304734230042, 0.7100349068641663, 0.7130473852157593, 0.7654902935028076, 0.7184633016586304, 0.7980584502220154, 0.7450646758079529, 0.7157645225524902, 0.7220885157585144, 0.7230478525161743, 0.7222622036933899, 0.7223402261734009, 0.725295901298523, 0.7873895168304443, 0.7507296800613403, 0.7401118278503418, 0.7263145446777344, 0.7311262488365173, 0.7378756403923035, 0.7797194123268127, 0.8107664585113525, 0.7393006086349487, 0.7368819713592529, 0.749305784702301], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4924568831920624, 0.4989224076271057, 0.5053879022598267, 0.506465494632721, 0.5441810488700867, 0.5506465435028076, 0.5980603694915771, 0.5980603694915771, 0.6896551847457886, 0.7456896305084229, 0.7661637663841248, 0.7715517282485962, 0.7758620977401733, 0.7823275923728943, 0.8092672228813171, 0.7941810488700867, 0.8157327771186829, 0.8221982717514038, 0.8125, 0.8275862336158752, 0.826508641242981, 0.8221982717514038, 0.8221982717514038, 0.8243534564971924, 0.8232758641242981, 0.8308189511299133, 0.829741358757019, 0.8211206793785095, 0.8211206793785095, 0.826508641242981, 0.7823275923728943, 0.826508641242981, 0.8308189511299133, 0.8243534564971924, 0.8275862336158752, 0.8254310488700867, 0.8308189511299133, 0.8254310488700867, 0.8286637663841248, 0.8308189511299133, 0.826508641242981, 0.8329741358757019, 0.8286637663841248, 0.8232758641242981, 0.8200430870056152, 0.7898706793785095, 0.8286637663841248, 0.8286637663841248, 0.8232758641242981, 0.8168103694915771, 0.8243534564971924, 0.8254310488700867, 0.8038793206214905, 0.8168103694915771, 0.8254310488700867, 0.8254310488700867, 0.8135775923728943, 0.829741358757019, 0.8135775923728943, 0.8254310488700867, 0.826508641242981, 0.8146551847457886, 0.8157327771186829, 0.818965494632721, 0.8114224076271057, 0.8308189511299133, 0.8081896305084229, 0.8275862336158752, 0.8254310488700867, 0.8275862336158752, 0.8168103694915771, 0.8254310488700867, 0.8038793206214905, 0.818965494632721, 0.7866379022598267, 0.8178879022598267, 0.8275862336158752, 0.8232758641242981, 0.8243534564971924, 0.818965494632721, 0.8243534564971924, 0.8221982717514038, 0.795258641242981, 0.826508641242981, 0.8168103694915771, 0.8286637663841248, 0.8221982717514038, 0.8243534564971924, 0.8178879022598267, 0.7995689511299133, 0.8178879022598267, 0.8221982717514038, 0.8211206793785095]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 31ms/step - loss: 0.5661 - accuracy: 0.8727 - val_loss: 1.2052 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.4937 - accuracy: 0.9297"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 0.5016 - accuracy: 0.9106 - val_loss: 1.1894 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4896 - accuracy: 0.9165 - val_loss: 1.1936 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4844 - accuracy: 0.9230 - val_loss: 1.1913 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4747 - accuracy: 0.9304 - val_loss: 1.1921 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4790 - accuracy: 0.9298 - val_loss: 1.1639 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4687 - accuracy: 0.9338 - val_loss: 1.2054 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4673 - accuracy: 0.9338 - val_loss: 1.2121 - val_accuracy: 0.4977\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4635 - accuracy: 0.9358 - val_loss: 1.2412 - val_accuracy: 0.4989\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4851 - accuracy: 0.9171 - val_loss: 1.1334 - val_accuracy: 0.5204\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4596 - accuracy: 0.9394 - val_loss: 1.1525 - val_accuracy: 0.5271\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4699 - accuracy: 0.9278 - val_loss: 1.1880 - val_accuracy: 0.5351\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4557 - accuracy: 0.9383 - val_loss: 1.0239 - val_accuracy: 0.5656\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4556 - accuracy: 0.9392 - val_loss: 1.0275 - val_accuracy: 0.5769\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4514 - accuracy: 0.9414 - val_loss: 0.9954 - val_accuracy: 0.6018\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4479 - accuracy: 0.9460 - val_loss: 0.9117 - val_accuracy: 0.6459\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4501 - accuracy: 0.9423 - val_loss: 0.8448 - val_accuracy: 0.7059\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4435 - accuracy: 0.9471 - val_loss: 0.8011 - val_accuracy: 0.7398\n","Epoch 19/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4500 - accuracy: 0.9389 - val_loss: 0.7699 - val_accuracy: 0.7590\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4422 - accuracy: 0.9434 - val_loss: 0.7649 - val_accuracy: 0.7670\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4386 - accuracy: 0.9462 - val_loss: 0.7537 - val_accuracy: 0.7828\n","Epoch 22/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4406 - accuracy: 0.9457 - val_loss: 0.7497 - val_accuracy: 0.7783\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4318 - accuracy: 0.9513 - val_loss: 0.7374 - val_accuracy: 0.7998\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4436 - accuracy: 0.9409 - val_loss: 0.7223 - val_accuracy: 0.8066\n","Epoch 25/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4291 - accuracy: 0.9525 - val_loss: 0.7231 - val_accuracy: 0.8066\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.9496 - val_loss: 0.7046 - val_accuracy: 0.8032\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4278 - accuracy: 0.9544 - val_loss: 0.7109 - val_accuracy: 0.8111\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4273 - accuracy: 0.9522 - val_loss: 0.7151 - val_accuracy: 0.8111\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4229 - accuracy: 0.9547 - val_loss: 0.6995 - val_accuracy: 0.8179\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4217 - accuracy: 0.9587 - val_loss: 0.7093 - val_accuracy: 0.8145\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4158 - accuracy: 0.9604 - val_loss: 0.7148 - val_accuracy: 0.8020\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4187 - accuracy: 0.9612 - val_loss: 0.7122 - val_accuracy: 0.8179\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4112 - accuracy: 0.9621 - val_loss: 0.7219 - val_accuracy: 0.8145\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4133 - accuracy: 0.9587 - val_loss: 0.7150 - val_accuracy: 0.8190\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4133 - accuracy: 0.9607 - val_loss: 0.7235 - val_accuracy: 0.8179\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.9561 - val_loss: 0.7547 - val_accuracy: 0.7998\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4186 - accuracy: 0.9556 - val_loss: 0.7243 - val_accuracy: 0.8122\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4126 - accuracy: 0.9601 - val_loss: 0.7237 - val_accuracy: 0.8167\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4022 - accuracy: 0.9666 - val_loss: 0.7244 - val_accuracy: 0.8145\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4017 - accuracy: 0.9666 - val_loss: 0.7258 - val_accuracy: 0.8190\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4102 - accuracy: 0.9595 - val_loss: 0.7808 - val_accuracy: 0.7975\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4005 - accuracy: 0.9669 - val_loss: 0.7355 - val_accuracy: 0.8156\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4031 - accuracy: 0.9660 - val_loss: 0.7312 - val_accuracy: 0.8100\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3985 - accuracy: 0.9669 - val_loss: 0.7542 - val_accuracy: 0.8020\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3965 - accuracy: 0.9675 - val_loss: 0.7338 - val_accuracy: 0.8111\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3956 - accuracy: 0.9669 - val_loss: 0.7429 - val_accuracy: 0.8122\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3908 - accuracy: 0.9703 - val_loss: 0.7349 - val_accuracy: 0.8100\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.9649 - val_loss: 0.7735 - val_accuracy: 0.8032\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4053 - accuracy: 0.9581 - val_loss: 0.7696 - val_accuracy: 0.8043\n","Epoch 50/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3873 - accuracy: 0.9703 - val_loss: 0.7572 - val_accuracy: 0.8009\n","Epoch 51/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3928 - accuracy: 0.9680 - val_loss: 0.7737 - val_accuracy: 0.8077\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4058 - accuracy: 0.9547 - val_loss: 0.7546 - val_accuracy: 0.8088\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3832 - accuracy: 0.9731 - val_loss: 0.7567 - val_accuracy: 0.8009\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3791 - accuracy: 0.9771 - val_loss: 0.7453 - val_accuracy: 0.8077\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3809 - accuracy: 0.9737 - val_loss: 0.7654 - val_accuracy: 0.8043\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3792 - accuracy: 0.9771 - val_loss: 0.7686 - val_accuracy: 0.8111\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3836 - accuracy: 0.9709 - val_loss: 0.7469 - val_accuracy: 0.8167\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3738 - accuracy: 0.9805 - val_loss: 0.7472 - val_accuracy: 0.8179\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3769 - accuracy: 0.9740 - val_loss: 0.7552 - val_accuracy: 0.8054\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3707 - accuracy: 0.9819 - val_loss: 0.7533 - val_accuracy: 0.8043\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3733 - accuracy: 0.9779 - val_loss: 0.7615 - val_accuracy: 0.8122\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3687 - accuracy: 0.9788 - val_loss: 0.7825 - val_accuracy: 0.8020\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3741 - accuracy: 0.9743 - val_loss: 0.7648 - val_accuracy: 0.8133\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3745 - accuracy: 0.9740 - val_loss: 0.7887 - val_accuracy: 0.8088\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3671 - accuracy: 0.9796 - val_loss: 0.7582 - val_accuracy: 0.8122\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3623 - accuracy: 0.9830 - val_loss: 0.7643 - val_accuracy: 0.8100\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3619 - accuracy: 0.9830 - val_loss: 0.8226 - val_accuracy: 0.8009\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3746 - accuracy: 0.9740 - val_loss: 0.7711 - val_accuracy: 0.8066\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3638 - accuracy: 0.9793 - val_loss: 0.7734 - val_accuracy: 0.8100\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3670 - accuracy: 0.9788 - val_loss: 0.7701 - val_accuracy: 0.7998\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3802 - accuracy: 0.9672 - val_loss: 0.7813 - val_accuracy: 0.8054\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3559 - accuracy: 0.9853 - val_loss: 0.7697 - val_accuracy: 0.8122\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3611 - accuracy: 0.9788 - val_loss: 0.7756 - val_accuracy: 0.8111\n","Epoch 74/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3570 - accuracy: 0.9853 - val_loss: 0.7847 - val_accuracy: 0.8077\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3550 - accuracy: 0.9822 - val_loss: 0.7747 - val_accuracy: 0.8032\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3506 - accuracy: 0.9847 - val_loss: 0.7858 - val_accuracy: 0.8054\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3531 - accuracy: 0.9853 - val_loss: 0.8134 - val_accuracy: 0.8009\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3520 - accuracy: 0.9856 - val_loss: 0.7760 - val_accuracy: 0.8077\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3574 - accuracy: 0.9836 - val_loss: 0.8101 - val_accuracy: 0.7952\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3462 - accuracy: 0.9881 - val_loss: 0.7858 - val_accuracy: 0.8156\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3459 - accuracy: 0.9895 - val_loss: 0.8065 - val_accuracy: 0.8054\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3471 - accuracy: 0.9864 - val_loss: 0.7935 - val_accuracy: 0.8100\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3489 - accuracy: 0.9825 - val_loss: 0.7794 - val_accuracy: 0.8100\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3584 - accuracy: 0.9768 - val_loss: 0.8040 - val_accuracy: 0.8100\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3444 - accuracy: 0.9895 - val_loss: 0.8070 - val_accuracy: 0.7998\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3407 - accuracy: 0.9884 - val_loss: 0.8005 - val_accuracy: 0.7975\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3473 - accuracy: 0.9836 - val_loss: 0.8015 - val_accuracy: 0.8088\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3535 - accuracy: 0.9793 - val_loss: 0.8121 - val_accuracy: 0.8054\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3416 - accuracy: 0.9890 - val_loss: 0.8088 - val_accuracy: 0.8100\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3426 - accuracy: 0.9856 - val_loss: 0.8122 - val_accuracy: 0.8066\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3462 - accuracy: 0.9830 - val_loss: 0.8310 - val_accuracy: 0.8020\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3370 - accuracy: 0.9909 - val_loss: 0.8077 - val_accuracy: 0.8088\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3352 - accuracy: 0.9901 - val_loss: 0.8291 - val_accuracy: 0.8009\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3431 - accuracy: 0.9833 - val_loss: 0.8320 - val_accuracy: 0.8032\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3438 - accuracy: 0.9844 - val_loss: 0.8462 - val_accuracy: 0.7998\n","Epoch 96/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3502 - accuracy: 0.9788 - val_loss: 0.8039 - val_accuracy: 0.8111\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3599 - accuracy: 0.9751 - val_loss: 0.8398 - val_accuracy: 0.7986\n","Epoch 98/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3345 - accuracy: 0.9881 - val_loss: 0.8348 - val_accuracy: 0.8054\n","Epoch 99/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3461 - accuracy: 0.9810 - val_loss: 0.8459 - val_accuracy: 0.8020\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3340 - accuracy: 0.9870 - val_loss: 0.8322 - val_accuracy: 0.7998\n","{'loss': [0.5661179423332214, 0.5016356706619263, 0.48961418867111206, 0.48441049456596375, 0.4746590554714203, 0.478961706161499, 0.46872660517692566, 0.46725544333457947, 0.46354660391807556, 0.4851486384868622, 0.4596239924430847, 0.46987301111221313, 0.4557059407234192, 0.45563724637031555, 0.4514349699020386, 0.44791266322135925, 0.45013585686683655, 0.4435252547264099, 0.44996434450149536, 0.4422072470188141, 0.4385969638824463, 0.4405892789363861, 0.4317844808101654, 0.4436345398426056, 0.4290752708911896, 0.43242794275283813, 0.4278147518634796, 0.4272940456867218, 0.4228530824184418, 0.42170804738998413, 0.41580867767333984, 0.418687641620636, 0.41115903854370117, 0.41326478123664856, 0.4133087396621704, 0.4188859462738037, 0.41856202483177185, 0.4125821590423584, 0.40223580598831177, 0.40169456601142883, 0.41016334295272827, 0.4005391299724579, 0.403074711561203, 0.3985137641429901, 0.39645376801490784, 0.39555561542510986, 0.39081084728240967, 0.4007226526737213, 0.4052887260913849, 0.3873046040534973, 0.39283567667007446, 0.40582406520843506, 0.3831841051578522, 0.37914976477622986, 0.38093966245651245, 0.3791630268096924, 0.38364866375923157, 0.37384259700775146, 0.3769022822380066, 0.3706777095794678, 0.37329283356666565, 0.36865487694740295, 0.3740781843662262, 0.3745245933532715, 0.367143452167511, 0.36234092712402344, 0.3618773818016052, 0.37462761998176575, 0.3637799024581909, 0.3669900894165039, 0.38020527362823486, 0.3559468388557434, 0.36110344529151917, 0.3569949269294739, 0.35500797629356384, 0.35061272978782654, 0.3530723452568054, 0.3520023822784424, 0.35738059878349304, 0.3461707830429077, 0.345889687538147, 0.3471241295337677, 0.34888848662376404, 0.35840579867362976, 0.34441936016082764, 0.34070587158203125, 0.3473161458969116, 0.3534785211086273, 0.3415631353855133, 0.34261250495910645, 0.3462115526199341, 0.33700546622276306, 0.33515897393226624, 0.3431103229522705, 0.343777596950531, 0.35019299387931824, 0.3598780035972595, 0.33449965715408325, 0.3461017906665802, 0.3339552581310272], 'accuracy': [0.872665524482727, 0.9105829000473022, 0.9165251851081848, 0.9230334162712097, 0.930390477180481, 0.9298245906829834, 0.9337860941886902, 0.9337860941886902, 0.9357668161392212, 0.9170911312103271, 0.9394453763961792, 0.9278438091278076, 0.9383135437965393, 0.9391624331474304, 0.941426157951355, 0.9459536075592041, 0.9422750473022461, 0.947085440158844, 0.9388794302940369, 0.943406879901886, 0.9462365508079529, 0.9456706047058105, 0.9513299465179443, 0.9408602118492126, 0.9524617791175842, 0.9496321678161621, 0.95444256067276, 0.9521788358688354, 0.9547255039215088, 0.9586870670318604, 0.9603848457336426, 0.9612337350845337, 0.9620826244354248, 0.9586870670318604, 0.9606677889823914, 0.9561403393745422, 0.9555743932723999, 0.960101842880249, 0.9666100740432739, 0.9666100740432739, 0.9595359563827515, 0.9668930172920227, 0.9660441279411316, 0.9668930172920227, 0.967458963394165, 0.9668930172920227, 0.9702886343002319, 0.9649122953414917, 0.958121120929718, 0.9702886343002319, 0.9680249094963074, 0.9547255039215088, 0.9731183052062988, 0.9770798087120056, 0.9736841917037964, 0.9770798087120056, 0.9708545804023743, 0.9804753661155701, 0.9739671945571899, 0.9818902015686035, 0.9779286980628967, 0.9787775874137878, 0.9742501378059387, 0.9739671945571899, 0.979626476764679, 0.9830220937728882, 0.9830220937728882, 0.9739671945571899, 0.9793435335159302, 0.9787775874137878, 0.9671760201454163, 0.9852858185768127, 0.9787775874137878, 0.9852858185768127, 0.9821732044219971, 0.9847198724746704, 0.9852858185768127, 0.9855687618255615, 0.9835879802703857, 0.9881154298782349, 0.9895302653312683, 0.9864176511764526, 0.9824561476707458, 0.9767968058586121, 0.9895302653312683, 0.9883984327316284, 0.9835879802703857, 0.9793435335159302, 0.988964319229126, 0.9855687618255615, 0.9830220937728882, 0.9909451007843018, 0.9900962114334106, 0.983305037021637, 0.9844368696212769, 0.9787775874137878, 0.9750990271568298, 0.9881154298782349, 0.9810413122177124, 0.986983597278595], 'val_loss': [1.2051619291305542, 1.1894201040267944, 1.1935884952545166, 1.1912503242492676, 1.1920591592788696, 1.1639313697814941, 1.2054030895233154, 1.212149739265442, 1.241244912147522, 1.133396863937378, 1.15245521068573, 1.1879698038101196, 1.0238884687423706, 1.0275379419326782, 0.9954044222831726, 0.9117280840873718, 0.8448486924171448, 0.8011416792869568, 0.7698817849159241, 0.7648698687553406, 0.7536525726318359, 0.7497097253799438, 0.7374455332756042, 0.7223135828971863, 0.723065972328186, 0.7045628428459167, 0.7109300494194031, 0.715063750743866, 0.6994802951812744, 0.7092901468276978, 0.714777410030365, 0.7122260332107544, 0.7218616604804993, 0.7149524688720703, 0.7235100269317627, 0.7547017335891724, 0.7243481278419495, 0.7236782312393188, 0.724432110786438, 0.7258414030075073, 0.7807560563087463, 0.7354655265808105, 0.7312303185462952, 0.7542309165000916, 0.7337534427642822, 0.7429329752922058, 0.7349271178245544, 0.7734790444374084, 0.7695873379707336, 0.7572352290153503, 0.7737266421318054, 0.7545907497406006, 0.7566784620285034, 0.7452893853187561, 0.7653892040252686, 0.7685967087745667, 0.7469099760055542, 0.7471749782562256, 0.7551652193069458, 0.7533267140388489, 0.7615025639533997, 0.7825217247009277, 0.7647889256477356, 0.7886660695075989, 0.7582151889801025, 0.7642587423324585, 0.8226120471954346, 0.7711381316184998, 0.773409903049469, 0.7701366543769836, 0.7813432812690735, 0.7697395086288452, 0.7755642533302307, 0.7846585512161255, 0.7746517658233643, 0.7858272194862366, 0.8134034872055054, 0.7760132551193237, 0.810143232345581, 0.7858067154884338, 0.8065125942230225, 0.7934870719909668, 0.7793914675712585, 0.804030179977417, 0.8069907426834106, 0.8005332350730896, 0.8015028834342957, 0.8120570182800293, 0.8087518215179443, 0.812248706817627, 0.8309776782989502, 0.8077443838119507, 0.8291101455688477, 0.8319604396820068, 0.8461605310440063, 0.803902804851532, 0.8397880792617798, 0.8347885608673096, 0.845893919467926, 0.8322497010231018], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.49886876344680786, 0.5203620195388794, 0.5271493196487427, 0.5350678563117981, 0.5656108856201172, 0.5769230723381042, 0.6018099784851074, 0.6459276080131531, 0.7058823704719543, 0.7398189902305603, 0.7590497732162476, 0.766968309879303, 0.7828054428100586, 0.7782805562019348, 0.7997737526893616, 0.8065611124038696, 0.8065611124038696, 0.8031674027442932, 0.8110859990119934, 0.8110859990119934, 0.8178732991218567, 0.814479649066925, 0.8020362257957458, 0.8178732991218567, 0.814479649066925, 0.8190045356750488, 0.8178732991218567, 0.7997737526893616, 0.8122171759605408, 0.8167420625686646, 0.814479649066925, 0.8190045356750488, 0.7975113391876221, 0.8156108856201172, 0.8099547624588013, 0.8020362257957458, 0.8110859990119934, 0.8122171759605408, 0.8099547624588013, 0.8031674027442932, 0.8042986392974854, 0.8009049892425537, 0.807692289352417, 0.8088235259056091, 0.8009049892425537, 0.807692289352417, 0.8042986392974854, 0.8110859990119934, 0.8167420625686646, 0.8178732991218567, 0.8054298758506775, 0.8042986392974854, 0.8122171759605408, 0.8020362257957458, 0.8133484125137329, 0.8088235259056091, 0.8122171759605408, 0.8099547624588013, 0.8009049892425537, 0.8065611124038696, 0.8099547624588013, 0.7997737526893616, 0.8054298758506775, 0.8122171759605408, 0.8110859990119934, 0.807692289352417, 0.8031674027442932, 0.8054298758506775, 0.8009049892425537, 0.807692289352417, 0.7952488660812378, 0.8156108856201172, 0.8054298758506775, 0.8099547624588013, 0.8099547624588013, 0.8099547624588013, 0.7997737526893616, 0.7975113391876221, 0.8088235259056091, 0.8054298758506775, 0.8099547624588013, 0.8065611124038696, 0.8020362257957458, 0.8088235259056091, 0.8009049892425537, 0.8031674027442932, 0.7997737526893616, 0.8110859990119934, 0.7986425161361694, 0.8054298758506775, 0.8020362257957458, 0.7997737526893616]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 28ms/step - loss: 0.5556 - accuracy: 0.8796 - val_loss: 1.2185 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.5624 - accuracy: 0.8828"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 12ms/step - loss: 0.5121 - accuracy: 0.9080 - val_loss: 1.2102 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5054 - accuracy: 0.9147 - val_loss: 1.2119 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5011 - accuracy: 0.9127 - val_loss: 1.2140 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5007 - accuracy: 0.9150 - val_loss: 1.2083 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4924 - accuracy: 0.9220 - val_loss: 1.2463 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4890 - accuracy: 0.9282 - val_loss: 1.3199 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5040 - accuracy: 0.9124 - val_loss: 1.2851 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4903 - accuracy: 0.9191 - val_loss: 1.3093 - val_accuracy: 0.4928\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4909 - accuracy: 0.9235 - val_loss: 1.1914 - val_accuracy: 0.5072\n","Epoch 11/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4831 - accuracy: 0.9220 - val_loss: 1.2860 - val_accuracy: 0.5031\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4726 - accuracy: 0.9313 - val_loss: 1.1892 - val_accuracy: 0.5258\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4698 - accuracy: 0.9333 - val_loss: 1.1021 - val_accuracy: 0.5475\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4702 - accuracy: 0.9300 - val_loss: 1.0970 - val_accuracy: 0.5640\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4790 - accuracy: 0.9253 - val_loss: 0.9426 - val_accuracy: 0.6353\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4713 - accuracy: 0.9269 - val_loss: 0.8115 - val_accuracy: 0.7211\n","Epoch 17/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4784 - accuracy: 0.9276 - val_loss: 0.8115 - val_accuracy: 0.7211\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4659 - accuracy: 0.9339 - val_loss: 0.8116 - val_accuracy: 0.7345\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4689 - accuracy: 0.9289 - val_loss: 0.7847 - val_accuracy: 0.7572\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4616 - accuracy: 0.9333 - val_loss: 0.7642 - val_accuracy: 0.7779\n","Epoch 21/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4591 - accuracy: 0.9362 - val_loss: 0.8331 - val_accuracy: 0.7366\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4661 - accuracy: 0.9292 - val_loss: 0.7470 - val_accuracy: 0.7903\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.9442 - val_loss: 0.7788 - val_accuracy: 0.7655\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4633 - accuracy: 0.9349 - val_loss: 0.7418 - val_accuracy: 0.7913\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4462 - accuracy: 0.9481 - val_loss: 0.7577 - val_accuracy: 0.7820\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4451 - accuracy: 0.9452 - val_loss: 0.7546 - val_accuracy: 0.7944\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4458 - accuracy: 0.9486 - val_loss: 0.7323 - val_accuracy: 0.7996\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4408 - accuracy: 0.9468 - val_loss: 0.8106 - val_accuracy: 0.7789\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4722 - accuracy: 0.9207 - val_loss: 0.9360 - val_accuracy: 0.7614\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4832 - accuracy: 0.9140 - val_loss: 0.8055 - val_accuracy: 0.7831\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4509 - accuracy: 0.9370 - val_loss: 0.7543 - val_accuracy: 0.7851\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4361 - accuracy: 0.9527 - val_loss: 0.7593 - val_accuracy: 0.8006\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4343 - accuracy: 0.9481 - val_loss: 0.7524 - val_accuracy: 0.7893\n","Epoch 34/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4346 - accuracy: 0.9522 - val_loss: 0.7541 - val_accuracy: 0.7934\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4318 - accuracy: 0.9545 - val_loss: 0.7681 - val_accuracy: 0.7986\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4337 - accuracy: 0.9499 - val_loss: 0.7730 - val_accuracy: 0.7944\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4376 - accuracy: 0.9432 - val_loss: 0.7652 - val_accuracy: 0.7934\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4328 - accuracy: 0.9540 - val_loss: 0.7611 - val_accuracy: 0.7986\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4253 - accuracy: 0.9535 - val_loss: 0.7662 - val_accuracy: 0.7965\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4248 - accuracy: 0.9550 - val_loss: 0.7758 - val_accuracy: 0.7965\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4231 - accuracy: 0.9550 - val_loss: 0.7706 - val_accuracy: 0.7996\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4279 - accuracy: 0.9496 - val_loss: 0.7907 - val_accuracy: 0.7955\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.9398 - val_loss: 0.7713 - val_accuracy: 0.7986\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4146 - accuracy: 0.9625 - val_loss: 0.7747 - val_accuracy: 0.7944\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4137 - accuracy: 0.9607 - val_loss: 0.7727 - val_accuracy: 0.7944\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4239 - accuracy: 0.9537 - val_loss: 0.7777 - val_accuracy: 0.7924\n","Epoch 47/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4629 - accuracy: 0.9194 - val_loss: 0.7658 - val_accuracy: 0.8006\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4303 - accuracy: 0.9447 - val_loss: 0.7898 - val_accuracy: 0.8006\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4143 - accuracy: 0.9615 - val_loss: 0.7804 - val_accuracy: 0.7924\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4117 - accuracy: 0.9587 - val_loss: 0.7765 - val_accuracy: 0.7955\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4154 - accuracy: 0.9579 - val_loss: 0.7776 - val_accuracy: 0.7924\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4113 - accuracy: 0.9592 - val_loss: 0.7745 - val_accuracy: 0.7924\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4027 - accuracy: 0.9674 - val_loss: 0.7790 - val_accuracy: 0.7955\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4091 - accuracy: 0.9602 - val_loss: 0.7959 - val_accuracy: 0.8037\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4266 - accuracy: 0.9411 - val_loss: 0.7788 - val_accuracy: 0.7934\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4217 - accuracy: 0.9501 - val_loss: 0.7834 - val_accuracy: 0.8006\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4012 - accuracy: 0.9646 - val_loss: 0.7862 - val_accuracy: 0.7955\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3964 - accuracy: 0.9677 - val_loss: 0.7858 - val_accuracy: 0.7965\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3946 - accuracy: 0.9685 - val_loss: 0.7929 - val_accuracy: 0.7924\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3958 - accuracy: 0.9669 - val_loss: 0.7816 - val_accuracy: 0.8027\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3964 - accuracy: 0.9654 - val_loss: 0.7980 - val_accuracy: 0.7965\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3939 - accuracy: 0.9695 - val_loss: 0.7966 - val_accuracy: 0.7934\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3873 - accuracy: 0.9731 - val_loss: 0.7972 - val_accuracy: 0.7924\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3894 - accuracy: 0.9695 - val_loss: 0.8220 - val_accuracy: 0.7841\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3917 - accuracy: 0.9677 - val_loss: 0.8098 - val_accuracy: 0.7944\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3916 - accuracy: 0.9695 - val_loss: 0.7991 - val_accuracy: 0.8037\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3870 - accuracy: 0.9718 - val_loss: 0.8455 - val_accuracy: 0.7841\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3942 - accuracy: 0.9643 - val_loss: 0.7984 - val_accuracy: 0.7975\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3872 - accuracy: 0.9687 - val_loss: 0.8045 - val_accuracy: 0.7872\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3876 - accuracy: 0.9677 - val_loss: 0.8246 - val_accuracy: 0.7986\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3878 - accuracy: 0.9693 - val_loss: 0.8199 - val_accuracy: 0.7913\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4206 - accuracy: 0.9444 - val_loss: 0.8069 - val_accuracy: 0.7934\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3779 - accuracy: 0.9739 - val_loss: 0.8082 - val_accuracy: 0.7882\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3790 - accuracy: 0.9731 - val_loss: 0.8473 - val_accuracy: 0.7924\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3765 - accuracy: 0.9744 - val_loss: 0.8202 - val_accuracy: 0.7882\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3742 - accuracy: 0.9770 - val_loss: 0.8506 - val_accuracy: 0.7831\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.9628 - val_loss: 0.8343 - val_accuracy: 0.7851\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3795 - accuracy: 0.9690 - val_loss: 0.8454 - val_accuracy: 0.7841\n","Epoch 79/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3819 - accuracy: 0.9669 - val_loss: 0.8172 - val_accuracy: 0.7965\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3741 - accuracy: 0.9742 - val_loss: 0.8261 - val_accuracy: 0.7893\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3692 - accuracy: 0.9801 - val_loss: 0.8538 - val_accuracy: 0.7893\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3820 - accuracy: 0.9695 - val_loss: 0.8203 - val_accuracy: 0.7851\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3845 - accuracy: 0.9656 - val_loss: 0.9447 - val_accuracy: 0.7655\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3860 - accuracy: 0.9630 - val_loss: 0.8384 - val_accuracy: 0.7975\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3674 - accuracy: 0.9765 - val_loss: 0.8304 - val_accuracy: 0.7913\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3593 - accuracy: 0.9827 - val_loss: 0.8314 - val_accuracy: 0.7934\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3674 - accuracy: 0.9770 - val_loss: 0.8528 - val_accuracy: 0.7975\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3699 - accuracy: 0.9752 - val_loss: 0.8285 - val_accuracy: 0.7882\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3719 - accuracy: 0.9705 - val_loss: 0.8675 - val_accuracy: 0.7924\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3673 - accuracy: 0.9778 - val_loss: 0.8418 - val_accuracy: 0.7996\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3726 - accuracy: 0.9695 - val_loss: 0.8428 - val_accuracy: 0.7913\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3570 - accuracy: 0.9814 - val_loss: 0.8383 - val_accuracy: 0.7913\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3572 - accuracy: 0.9827 - val_loss: 0.8413 - val_accuracy: 0.7903\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3520 - accuracy: 0.9840 - val_loss: 0.8399 - val_accuracy: 0.7924\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3522 - accuracy: 0.9829 - val_loss: 0.8494 - val_accuracy: 0.7913\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3597 - accuracy: 0.9755 - val_loss: 0.8393 - val_accuracy: 0.7913\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3490 - accuracy: 0.9832 - val_loss: 0.8462 - val_accuracy: 0.7903\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3483 - accuracy: 0.9845 - val_loss: 0.8583 - val_accuracy: 0.7944\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3594 - accuracy: 0.9783 - val_loss: 0.8521 - val_accuracy: 0.7882\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3576 - accuracy: 0.9773 - val_loss: 0.8850 - val_accuracy: 0.7800\n","{'loss': [0.5555709600448608, 0.5120692253112793, 0.5054013729095459, 0.501093327999115, 0.500666618347168, 0.4923929274082184, 0.48901256918907166, 0.503990650177002, 0.49025386571884155, 0.4908990263938904, 0.4831189811229706, 0.47264155745506287, 0.4698379635810852, 0.470243364572525, 0.478988915681839, 0.4713292419910431, 0.47835394740104675, 0.46585485339164734, 0.4689186215400696, 0.4615969657897949, 0.4591124951839447, 0.46606186032295227, 0.44953453540802, 0.4633481204509735, 0.44615548849105835, 0.44508323073387146, 0.445766419172287, 0.4407576620578766, 0.47218698263168335, 0.48324257135391235, 0.45089271664619446, 0.43608832359313965, 0.43431714177131653, 0.43462681770324707, 0.4317728877067566, 0.43365350365638733, 0.4375649392604828, 0.4328064024448395, 0.42532774806022644, 0.4247913062572479, 0.42309385538101196, 0.42787766456604004, 0.44282543659210205, 0.41462382674217224, 0.41369086503982544, 0.4239215850830078, 0.4629221260547638, 0.43027400970458984, 0.41431570053100586, 0.4117179214954376, 0.41539138555526733, 0.41130170226097107, 0.4027473032474518, 0.4090595841407776, 0.4265749454498291, 0.4217023551464081, 0.40119698643684387, 0.3964344561100006, 0.39462313055992126, 0.39575284719467163, 0.39643383026123047, 0.3938608765602112, 0.38726893067359924, 0.3893734812736511, 0.3917120397090912, 0.39159613847732544, 0.38701099157333374, 0.39418885111808777, 0.3871670067310333, 0.38758090138435364, 0.38783368468284607, 0.420566201210022, 0.3778725862503052, 0.378995418548584, 0.3765425384044647, 0.37416550517082214, 0.3942573070526123, 0.3794506788253784, 0.3819335103034973, 0.37407416105270386, 0.36920469999313354, 0.3820478618144989, 0.38447117805480957, 0.38601139187812805, 0.3673674464225769, 0.3592667877674103, 0.3674393892288208, 0.3698578476905823, 0.37193751335144043, 0.3672778308391571, 0.37258970737457275, 0.35695767402648926, 0.35720741748809814, 0.35195186734199524, 0.3521885871887207, 0.35969212651252747, 0.3489689826965332, 0.3482884466648102, 0.3594287931919098, 0.357585608959198], 'accuracy': [0.8795865774154663, 0.9080103635787964, 0.9147287011146545, 0.9126614928245544, 0.9149870872497559, 0.9219638109207153, 0.9281653761863708, 0.9124031066894531, 0.9191214442253113, 0.923514187335968, 0.9219638109207153, 0.9312661290168762, 0.9333333373069763, 0.9299741387367249, 0.9253230094909668, 0.9268733859062195, 0.9276486039161682, 0.933850109577179, 0.9289405941963196, 0.9333333373069763, 0.9361757040023804, 0.9291989803314209, 0.9441860318183899, 0.934883713722229, 0.948062002658844, 0.9452196359634399, 0.9485788345336914, 0.9467700123786926, 0.920671820640564, 0.9139534831047058, 0.9369509220123291, 0.9527131915092468, 0.948062002658844, 0.9521963596343994, 0.9545219540596008, 0.9498708248138428, 0.9431524276733398, 0.9540051817893982, 0.9534883499145508, 0.9550387859344482, 0.9550387859344482, 0.9496123790740967, 0.9397932887077332, 0.9625322818756104, 0.9607235193252563, 0.9537467956542969, 0.9193798303604126, 0.9447028636932373, 0.9614987373352051, 0.9586563110351562, 0.9578811526298523, 0.9591731429100037, 0.9674418568611145, 0.9602067470550537, 0.9410852789878845, 0.9501292109489441, 0.9645994901657104, 0.9677002429962158, 0.9684754610061646, 0.9669250845909119, 0.9653746485710144, 0.9695090651512146, 0.9731265902519226, 0.9695090651512146, 0.9677002429962158, 0.9695090651512146, 0.9718345999717712, 0.9643411040306091, 0.9687338471412659, 0.9677002429962158, 0.9692506194114685, 0.9444444179534912, 0.9739018082618713, 0.9731265902519226, 0.974418580532074, 0.9770025610923767, 0.9627906680107117, 0.9689922332763672, 0.9669250845909119, 0.9741601943969727, 0.9801033735275269, 0.9695090651512146, 0.9656330943107605, 0.9630491137504578, 0.9764857888221741, 0.9826873540878296, 0.9770025610923767, 0.9751937985420227, 0.9705426096916199, 0.9777777791023254, 0.9695090651512146, 0.9813953638076782, 0.9826873540878296, 0.983979344367981, 0.9829457402229309, 0.975452184677124, 0.9832041263580322, 0.9844961166381836, 0.9782945513725281, 0.9772610068321228], 'val_loss': [1.2184504270553589, 1.2102088928222656, 1.211883544921875, 1.214016079902649, 1.208250641822815, 1.2462759017944336, 1.319861650466919, 1.2851313352584839, 1.309285283088684, 1.1913772821426392, 1.2859612703323364, 1.189170002937317, 1.1020903587341309, 1.0970406532287598, 0.9426359534263611, 0.8115211129188538, 0.8114557266235352, 0.8116041421890259, 0.7847357392311096, 0.7642174959182739, 0.8331385850906372, 0.7469833493232727, 0.7788088917732239, 0.7418086528778076, 0.7577081322669983, 0.754622757434845, 0.7323476672172546, 0.8106391429901123, 0.9360027313232422, 0.8055182695388794, 0.7542840838432312, 0.7592959403991699, 0.7524123787879944, 0.7540794014930725, 0.7680763006210327, 0.7729655504226685, 0.7652392387390137, 0.7611068487167358, 0.7662437558174133, 0.7758436799049377, 0.7706482410430908, 0.7906889915466309, 0.7712687253952026, 0.7746767997741699, 0.7726814150810242, 0.7777027487754822, 0.7658498287200928, 0.7897639870643616, 0.7803943157196045, 0.7764652967453003, 0.7775919437408447, 0.7745267152786255, 0.7789908051490784, 0.7959484457969666, 0.7788159847259521, 0.7834376096725464, 0.7862498164176941, 0.7858283519744873, 0.7928985357284546, 0.7815850973129272, 0.7979995608329773, 0.7965905666351318, 0.7972095608711243, 0.8219746351242065, 0.8097614645957947, 0.7990697622299194, 0.8455196619033813, 0.798378586769104, 0.804502546787262, 0.8246241211891174, 0.8199025988578796, 0.8069073557853699, 0.8082059621810913, 0.8472985625267029, 0.8202242255210876, 0.850628674030304, 0.8342739939689636, 0.8453919887542725, 0.8172186613082886, 0.8261196613311768, 0.8537958860397339, 0.820257306098938, 0.9446618556976318, 0.8383700847625732, 0.8304291367530823, 0.8314415812492371, 0.8528383374214172, 0.8285276889801025, 0.8675099611282349, 0.8417852520942688, 0.8427674770355225, 0.8382792472839355, 0.841292679309845, 0.8399041295051575, 0.8494061827659607, 0.8392813801765442, 0.8462357521057129, 0.8583215475082397, 0.8521292805671692, 0.8849777579307556], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4886363744735718, 0.4927685856819153, 0.5072314143180847, 0.5030992031097412, 0.5258264541625977, 0.547520637512207, 0.5640496015548706, 0.6353305578231812, 0.7210744023323059, 0.7210744023323059, 0.7345041036605835, 0.7572314143180847, 0.7778925895690918, 0.7365702390670776, 0.7902892827987671, 0.7654958963394165, 0.7913222908973694, 0.7820248007774353, 0.7944214940071106, 0.7995867729187012, 0.7789255976676941, 0.7613636255264282, 0.7830578684806824, 0.7851239442825317, 0.8006198406219482, 0.78925621509552, 0.7933884263038635, 0.7985537052154541, 0.7944214940071106, 0.7933884263038635, 0.7985537052154541, 0.7964876294136047, 0.7964876294136047, 0.7995867729187012, 0.7954545617103577, 0.7985537052154541, 0.7944214940071106, 0.7944214940071106, 0.7923553586006165, 0.8006198406219482, 0.8006198406219482, 0.7923553586006165, 0.7954545617103577, 0.7923553586006165, 0.7923553586006165, 0.7954545617103577, 0.8037189841270447, 0.7933884263038635, 0.8006198406219482, 0.7954545617103577, 0.7964876294136047, 0.7923553586006165, 0.8026859760284424, 0.7964876294136047, 0.7933884263038635, 0.7923553586006165, 0.7840909361839294, 0.7944214940071106, 0.8037189841270447, 0.7840909361839294, 0.797520637512207, 0.7871900796890259, 0.7985537052154541, 0.7913222908973694, 0.7933884263038635, 0.788223147392273, 0.7923553586006165, 0.788223147392273, 0.7830578684806824, 0.7851239442825317, 0.7840909361839294, 0.7964876294136047, 0.78925621509552, 0.78925621509552, 0.7851239442825317, 0.7654958963394165, 0.797520637512207, 0.7913222908973694, 0.7933884263038635, 0.797520637512207, 0.788223147392273, 0.7923553586006165, 0.7995867729187012, 0.7913222908973694, 0.7913222908973694, 0.7902892827987671, 0.7923553586006165, 0.7913222908973694, 0.7913222908973694, 0.7902892827987671, 0.7944214940071106, 0.788223147392273, 0.7799586653709412]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.4981 - accuracy: 0.9044 - val_loss: 1.3963 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4169 - accuracy: 0.9453"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 10ms/step - loss: 0.4083 - accuracy: 0.9502 - val_loss: 1.3535 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3937 - accuracy: 0.9591 - val_loss: 1.3515 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3888 - accuracy: 0.9639 - val_loss: 1.3430 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3831 - accuracy: 0.9647 - val_loss: 1.3706 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3921 - accuracy: 0.9577 - val_loss: 1.3852 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3822 - accuracy: 0.9661 - val_loss: 1.3904 - val_accuracy: 0.4881\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3812 - accuracy: 0.9615 - val_loss: 1.4607 - val_accuracy: 0.4892\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3746 - accuracy: 0.9709 - val_loss: 1.4972 - val_accuracy: 0.4935\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3840 - accuracy: 0.9642 - val_loss: 1.5466 - val_accuracy: 0.4978\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3813 - accuracy: 0.9620 - val_loss: 1.4935 - val_accuracy: 0.5108\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3864 - accuracy: 0.9604 - val_loss: 1.4026 - val_accuracy: 0.5312\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3674 - accuracy: 0.9749 - val_loss: 1.2942 - val_accuracy: 0.5539\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3639 - accuracy: 0.9774 - val_loss: 1.0712 - val_accuracy: 0.6185\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3695 - accuracy: 0.9696 - val_loss: 0.9397 - val_accuracy: 0.6746\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3669 - accuracy: 0.9717 - val_loss: 0.9842 - val_accuracy: 0.6756\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3656 - accuracy: 0.9774 - val_loss: 0.8857 - val_accuracy: 0.7220\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3584 - accuracy: 0.9760 - val_loss: 0.8384 - val_accuracy: 0.7543\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3658 - accuracy: 0.9725 - val_loss: 0.8064 - val_accuracy: 0.7748\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3575 - accuracy: 0.9790 - val_loss: 0.7822 - val_accuracy: 0.7888\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3594 - accuracy: 0.9760 - val_loss: 0.7727 - val_accuracy: 0.7931\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3582 - accuracy: 0.9771 - val_loss: 0.7372 - val_accuracy: 0.8125\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3542 - accuracy: 0.9795 - val_loss: 0.7159 - val_accuracy: 0.8265\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3577 - accuracy: 0.9768 - val_loss: 0.7131 - val_accuracy: 0.8157\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3633 - accuracy: 0.9714 - val_loss: 0.6686 - val_accuracy: 0.8427\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3498 - accuracy: 0.9825 - val_loss: 0.6570 - val_accuracy: 0.8491\n","Epoch 27/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3456 - accuracy: 0.9844 - val_loss: 0.6564 - val_accuracy: 0.8545\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.9838 - val_loss: 0.6494 - val_accuracy: 0.8545\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3443 - accuracy: 0.9841 - val_loss: 0.6457 - val_accuracy: 0.8567\n","Epoch 30/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3569 - accuracy: 0.9766 - val_loss: 0.7078 - val_accuracy: 0.8190\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3883 - accuracy: 0.9596 - val_loss: 0.6548 - val_accuracy: 0.8578\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3497 - accuracy: 0.9798 - val_loss: 0.6478 - val_accuracy: 0.8556\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3432 - accuracy: 0.9849 - val_loss: 0.6315 - val_accuracy: 0.8567\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3374 - accuracy: 0.9860 - val_loss: 0.6592 - val_accuracy: 0.8545\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3352 - accuracy: 0.9892 - val_loss: 0.6494 - val_accuracy: 0.8545\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3390 - accuracy: 0.9841 - val_loss: 0.6435 - val_accuracy: 0.8588\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3392 - accuracy: 0.9871 - val_loss: 0.6775 - val_accuracy: 0.8502\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3437 - accuracy: 0.9793 - val_loss: 0.6473 - val_accuracy: 0.8567\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3373 - accuracy: 0.9857 - val_loss: 0.7038 - val_accuracy: 0.8319\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3343 - accuracy: 0.9865 - val_loss: 0.6611 - val_accuracy: 0.8524\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3399 - accuracy: 0.9852 - val_loss: 0.7227 - val_accuracy: 0.8222\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3420 - accuracy: 0.9809 - val_loss: 0.6541 - val_accuracy: 0.8578\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3374 - accuracy: 0.9855 - val_loss: 0.6660 - val_accuracy: 0.8470\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3313 - accuracy: 0.9895 - val_loss: 0.6552 - val_accuracy: 0.8642\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3299 - accuracy: 0.9881 - val_loss: 0.6985 - val_accuracy: 0.8438\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3283 - accuracy: 0.9900 - val_loss: 0.6939 - val_accuracy: 0.8405\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 0.9898 - val_loss: 0.6584 - val_accuracy: 0.8524\n","Epoch 48/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3301 - accuracy: 0.9860 - val_loss: 0.6644 - val_accuracy: 0.8567\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3455 - accuracy: 0.9774 - val_loss: 0.6701 - val_accuracy: 0.8556\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3360 - accuracy: 0.9830 - val_loss: 0.6564 - val_accuracy: 0.8524\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3287 - accuracy: 0.9879 - val_loss: 0.6672 - val_accuracy: 0.8459\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3279 - accuracy: 0.9884 - val_loss: 0.6608 - val_accuracy: 0.8599\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3295 - accuracy: 0.9855 - val_loss: 0.6724 - val_accuracy: 0.8481\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3202 - accuracy: 0.9919 - val_loss: 0.6619 - val_accuracy: 0.8567\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3229 - accuracy: 0.9900 - val_loss: 0.6679 - val_accuracy: 0.8567\n","Epoch 56/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3217 - accuracy: 0.9916 - val_loss: 0.6724 - val_accuracy: 0.8513\n","Epoch 57/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3200 - accuracy: 0.9922 - val_loss: 0.6697 - val_accuracy: 0.8567\n","Epoch 58/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3205 - accuracy: 0.9919 - val_loss: 0.6723 - val_accuracy: 0.8578\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3156 - accuracy: 0.9935 - val_loss: 0.6727 - val_accuracy: 0.8513\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3175 - accuracy: 0.9900 - val_loss: 0.6760 - val_accuracy: 0.8556\n","Epoch 61/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3195 - accuracy: 0.9908 - val_loss: 0.6743 - val_accuracy: 0.8578\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3127 - accuracy: 0.9949 - val_loss: 0.6859 - val_accuracy: 0.8578\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3261 - accuracy: 0.9879 - val_loss: 0.6900 - val_accuracy: 0.8491\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3196 - accuracy: 0.9908 - val_loss: 0.6730 - val_accuracy: 0.8578\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3173 - accuracy: 0.9927 - val_loss: 0.7357 - val_accuracy: 0.8287\n","Epoch 66/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3166 - accuracy: 0.9916 - val_loss: 0.6858 - val_accuracy: 0.8567\n","Epoch 67/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3165 - accuracy: 0.9903 - val_loss: 0.6842 - val_accuracy: 0.8448\n","Epoch 68/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3139 - accuracy: 0.9927 - val_loss: 0.6893 - val_accuracy: 0.8524\n","Epoch 69/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3108 - accuracy: 0.9935 - val_loss: 0.6988 - val_accuracy: 0.8405\n","Epoch 70/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3104 - accuracy: 0.9943 - val_loss: 0.6830 - val_accuracy: 0.8502\n","Epoch 71/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3094 - accuracy: 0.9935 - val_loss: 0.7050 - val_accuracy: 0.8373\n","Epoch 72/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3068 - accuracy: 0.9954 - val_loss: 0.6852 - val_accuracy: 0.8534\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3114 - accuracy: 0.9911 - val_loss: 0.8532 - val_accuracy: 0.8028\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3212 - accuracy: 0.9873 - val_loss: 0.7150 - val_accuracy: 0.8405\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3144 - accuracy: 0.9900 - val_loss: 0.6862 - val_accuracy: 0.8491\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3073 - accuracy: 0.9935 - val_loss: 0.7092 - val_accuracy: 0.8513\n","Epoch 77/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3222 - accuracy: 0.9860 - val_loss: 0.7559 - val_accuracy: 0.8287\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3154 - accuracy: 0.9890 - val_loss: 0.6888 - val_accuracy: 0.8481\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3090 - accuracy: 0.9919 - val_loss: 0.6914 - val_accuracy: 0.8513\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3179 - accuracy: 0.9865 - val_loss: 0.6849 - val_accuracy: 0.8534\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3134 - accuracy: 0.9898 - val_loss: 0.6910 - val_accuracy: 0.8545\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3130 - accuracy: 0.9892 - val_loss: 0.7453 - val_accuracy: 0.8287\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3021 - accuracy: 0.9957 - val_loss: 0.7039 - val_accuracy: 0.8373\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3013 - accuracy: 0.9957 - val_loss: 0.7161 - val_accuracy: 0.8373\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3017 - accuracy: 0.9946 - val_loss: 0.7555 - val_accuracy: 0.8308\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3066 - accuracy: 0.9922 - val_loss: 0.6977 - val_accuracy: 0.8556\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3040 - accuracy: 0.9935 - val_loss: 0.7039 - val_accuracy: 0.8556\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3086 - accuracy: 0.9933 - val_loss: 0.7069 - val_accuracy: 0.8416\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3075 - accuracy: 0.9919 - val_loss: 0.7214 - val_accuracy: 0.8448\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2979 - accuracy: 0.9954 - val_loss: 0.7077 - val_accuracy: 0.8438\n","Epoch 91/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2997 - accuracy: 0.9954 - val_loss: 0.7222 - val_accuracy: 0.8448\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2984 - accuracy: 0.9965 - val_loss: 0.7068 - val_accuracy: 0.8534\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2959 - accuracy: 0.9973 - val_loss: 0.7039 - val_accuracy: 0.8545\n","Epoch 94/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2994 - accuracy: 0.9954 - val_loss: 0.7273 - val_accuracy: 0.8502\n","Epoch 95/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2954 - accuracy: 0.9973 - val_loss: 0.7178 - val_accuracy: 0.8427\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3145 - accuracy: 0.9876 - val_loss: 0.8061 - val_accuracy: 0.8179\n","Epoch 97/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3288 - accuracy: 0.9766 - val_loss: 0.9453 - val_accuracy: 0.7888\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.9736 - val_loss: 0.6926 - val_accuracy: 0.8621\n","Epoch 99/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3000 - accuracy: 0.9935 - val_loss: 0.7387 - val_accuracy: 0.8384\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.9925 - val_loss: 0.7090 - val_accuracy: 0.8556\n","{'loss': [0.4980939030647278, 0.4082967936992645, 0.393656849861145, 0.3887738287448883, 0.38306134939193726, 0.39205265045166016, 0.38219889998435974, 0.38120391964912415, 0.37458670139312744, 0.3840121626853943, 0.38128215074539185, 0.386378675699234, 0.36741822957992554, 0.3638826608657837, 0.3695078492164612, 0.36687371134757996, 0.36557936668395996, 0.358361154794693, 0.3657621741294861, 0.35754916071891785, 0.3593674302101135, 0.3582009971141815, 0.3542414605617523, 0.3577306270599365, 0.3633434772491455, 0.3497522175312042, 0.3456065356731415, 0.34391364455223083, 0.34431201219558716, 0.35692235827445984, 0.388252317905426, 0.3497203290462494, 0.3431819677352905, 0.33735236525535583, 0.33518511056900024, 0.3389851450920105, 0.3391595184803009, 0.343708336353302, 0.33725783228874207, 0.33432140946388245, 0.3398597538471222, 0.3420104682445526, 0.33735427260398865, 0.3313499689102173, 0.3299039900302887, 0.32826167345046997, 0.33001425862312317, 0.33014681935310364, 0.34550800919532776, 0.33598777651786804, 0.3286564350128174, 0.3279018700122833, 0.3294799029827118, 0.320156991481781, 0.32288435101509094, 0.32165125012397766, 0.3199503719806671, 0.3205150365829468, 0.31556445360183716, 0.3174911141395569, 0.3194771111011505, 0.3127155005931854, 0.32609331607818604, 0.3196263611316681, 0.31731536984443665, 0.316617876291275, 0.31651538610458374, 0.31385865807533264, 0.3107556104660034, 0.31039878726005554, 0.3094319701194763, 0.3068081736564636, 0.31142276525497437, 0.3211679458618164, 0.3144199252128601, 0.3073230981826782, 0.32215315103530884, 0.31538835167884827, 0.30899205803871155, 0.3179349899291992, 0.3133596181869507, 0.313034325838089, 0.3020791709423065, 0.30130788683891296, 0.3017125725746155, 0.30658841133117676, 0.30399289727211, 0.3086078464984894, 0.3074928820133209, 0.29794710874557495, 0.2997416853904724, 0.2984097898006439, 0.2958871126174927, 0.2993602156639099, 0.29544970393180847, 0.31454625725746155, 0.3288406729698181, 0.3361988067626953, 0.30000215768814087, 0.30194640159606934], 'accuracy': [0.9043642282485962, 0.9501616358757019, 0.9590517282485962, 0.9639008641242981, 0.9647090435028076, 0.9577047228813171, 0.9660560488700867, 0.9614762663841248, 0.9709051847457886, 0.9641702771186829, 0.9620150923728943, 0.9603987336158752, 0.974946141242981, 0.9773706793785095, 0.9695581793785095, 0.9717133641242981, 0.9773706793785095, 0.9760237336158752, 0.9725215435028076, 0.9789870977401733, 0.9760237336158752, 0.9771012663841248, 0.9795258641242981, 0.9768319129943848, 0.9714439511299133, 0.9824892282485962, 0.984375, 0.9838362336158752, 0.9841055870056152, 0.9765625, 0.959590494632721, 0.9797952771186829, 0.9849137663841248, 0.985991358757019, 0.9892241358757019, 0.9841055870056152, 0.9870689511299133, 0.9792564511299133, 0.985722005367279, 0.9865301847457886, 0.9851831793785095, 0.9808728694915771, 0.9854525923728943, 0.9894935488700867, 0.9881465435028076, 0.9900323152542114, 0.9897629022598267, 0.985991358757019, 0.9773706793785095, 0.983027994632721, 0.9878771305084229, 0.9884159564971924, 0.9854525923728943, 0.9919180870056152, 0.9900323152542114, 0.9916487336158752, 0.9921875, 0.9919180870056152, 0.993534505367279, 0.9900323152542114, 0.990840494632721, 0.9948814511299133, 0.9878771305084229, 0.990840494632721, 0.9927262663841248, 0.9916487336158752, 0.9903017282485962, 0.9927262663841248, 0.993534505367279, 0.9943426847457886, 0.993534505367279, 0.9954202771186829, 0.9911099076271057, 0.9873383641242981, 0.9900323152542114, 0.993534505367279, 0.985991358757019, 0.9889547228813171, 0.9919180870056152, 0.9865301847457886, 0.9897629022598267, 0.9892241358757019, 0.9956896305084229, 0.9956896305084229, 0.9946120977401733, 0.9921875, 0.993534505367279, 0.9932650923728943, 0.9919180870056152, 0.9954202771186829, 0.9954202771186829, 0.9964978694915771, 0.9973060488700867, 0.9954202771186829, 0.9973060488700867, 0.9876077771186829, 0.9765625, 0.9735991358757019, 0.993534505367279, 0.9924569129943848], 'val_loss': [1.3963366746902466, 1.3534678220748901, 1.351460576057434, 1.342971682548523, 1.3706482648849487, 1.385177731513977, 1.3903974294662476, 1.4606777429580688, 1.4971973896026611, 1.5466364622116089, 1.4934885501861572, 1.4025509357452393, 1.294213056564331, 1.071172833442688, 0.9397449493408203, 0.9841839075088501, 0.8857468962669373, 0.8384232521057129, 0.8064371943473816, 0.7822105884552002, 0.7727223634719849, 0.7372027635574341, 0.7158976793289185, 0.7131017446517944, 0.6685854196548462, 0.6570082902908325, 0.65643709897995, 0.6493862867355347, 0.6456538438796997, 0.7077653408050537, 0.6547986268997192, 0.6478079557418823, 0.6315404772758484, 0.6592422723770142, 0.6493936777114868, 0.6434687376022339, 0.6774629354476929, 0.6473447680473328, 0.703788697719574, 0.6610615253448486, 0.7227389812469482, 0.6540783643722534, 0.6659883856773376, 0.6552097201347351, 0.6985175609588623, 0.6938814520835876, 0.6583632230758667, 0.6643651723861694, 0.6701260805130005, 0.6563540697097778, 0.6672406196594238, 0.6607614755630493, 0.6724075675010681, 0.6618514657020569, 0.6679147481918335, 0.6724344491958618, 0.6696662306785583, 0.6723438501358032, 0.6726958155632019, 0.6760285496711731, 0.6742792725563049, 0.68587726354599, 0.6899846196174622, 0.6729539036750793, 0.7356735467910767, 0.6858412623405457, 0.6841577291488647, 0.6892655491828918, 0.6987932920455933, 0.6830329895019531, 0.7050046324729919, 0.6851825714111328, 0.8531796932220459, 0.7149889469146729, 0.6861934065818787, 0.7092466950416565, 0.7559059262275696, 0.6888079643249512, 0.6914412975311279, 0.6849139928817749, 0.6910364627838135, 0.7453287243843079, 0.7038700580596924, 0.7161158919334412, 0.7555083632469177, 0.6977118253707886, 0.7038688063621521, 0.7069090008735657, 0.7214159369468689, 0.7077241539955139, 0.7221585512161255, 0.7067604660987854, 0.7038585543632507, 0.7272555232048035, 0.7177996635437012, 0.8061261773109436, 0.9453014135360718, 0.692575991153717, 0.7387241125106812, 0.7090280055999756], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4881465435028076, 0.4892241358757019, 0.49353447556495667, 0.4978448152542114, 0.5107758641242981, 0.53125, 0.5538793206214905, 0.618534505367279, 0.6745689511299133, 0.6756465435028076, 0.7219827771186829, 0.7543103694915771, 0.774784505367279, 0.7887930870056152, 0.7931034564971924, 0.8125, 0.826508641242981, 0.8157327771186829, 0.8426724076271057, 0.8491379022598267, 0.8545258641242981, 0.8545258641242981, 0.8566810488700867, 0.818965494632721, 0.857758641242981, 0.8556034564971924, 0.8566810488700867, 0.8545258641242981, 0.8545258641242981, 0.8588362336158752, 0.850215494632721, 0.8566810488700867, 0.8318965435028076, 0.8523706793785095, 0.8221982717514038, 0.857758641242981, 0.8469827771186829, 0.8642241358757019, 0.84375, 0.8405172228813171, 0.8523706793785095, 0.8566810488700867, 0.8556034564971924, 0.8523706793785095, 0.8459051847457886, 0.8599137663841248, 0.8480603694915771, 0.8566810488700867, 0.8566810488700867, 0.8512930870056152, 0.8566810488700867, 0.857758641242981, 0.8512930870056152, 0.8556034564971924, 0.857758641242981, 0.857758641242981, 0.8491379022598267, 0.857758641242981, 0.8286637663841248, 0.8566810488700867, 0.8448275923728943, 0.8523706793785095, 0.8405172228813171, 0.850215494632721, 0.837284505367279, 0.8534482717514038, 0.8028017282485962, 0.8405172228813171, 0.8491379022598267, 0.8512930870056152, 0.8286637663841248, 0.8480603694915771, 0.8512930870056152, 0.8534482717514038, 0.8545258641242981, 0.8286637663841248, 0.837284505367279, 0.837284505367279, 0.8308189511299133, 0.8556034564971924, 0.8556034564971924, 0.8415948152542114, 0.8448275923728943, 0.84375, 0.8448275923728943, 0.8534482717514038, 0.8545258641242981, 0.850215494632721, 0.8426724076271057, 0.8178879022598267, 0.7887930870056152, 0.8620689511299133, 0.8383620977401733, 0.8556034564971924]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 30ms/step - loss: 0.4969 - accuracy: 0.9083 - val_loss: 1.3578 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.4805 - accuracy: 0.9297"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 11ms/step - loss: 0.3970 - accuracy: 0.9564 - val_loss: 1.3475 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3865 - accuracy: 0.9612 - val_loss: 1.3178 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.9553 - val_loss: 1.3184 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3779 - accuracy: 0.9689 - val_loss: 1.3547 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3740 - accuracy: 0.9703 - val_loss: 1.3475 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3735 - accuracy: 0.9720 - val_loss: 1.3597 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3716 - accuracy: 0.9711 - val_loss: 1.3879 - val_accuracy: 0.4989\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3732 - accuracy: 0.9686 - val_loss: 1.4329 - val_accuracy: 0.5034\n","Epoch 10/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3637 - accuracy: 0.9779 - val_loss: 1.5405 - val_accuracy: 0.5034\n","Epoch 11/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3616 - accuracy: 0.9779 - val_loss: 1.4780 - val_accuracy: 0.5215\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3582 - accuracy: 0.9791 - val_loss: 1.4560 - val_accuracy: 0.5339\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3577 - accuracy: 0.9819 - val_loss: 1.3280 - val_accuracy: 0.5611\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3571 - accuracy: 0.9793 - val_loss: 1.3034 - val_accuracy: 0.5701\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3552 - accuracy: 0.9793 - val_loss: 1.2817 - val_accuracy: 0.5803\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3634 - accuracy: 0.9734 - val_loss: 0.9457 - val_accuracy: 0.6652\n","Epoch 17/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3618 - accuracy: 0.9720 - val_loss: 0.8604 - val_accuracy: 0.7251\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3583 - accuracy: 0.9771 - val_loss: 0.8942 - val_accuracy: 0.7161\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3456 - accuracy: 0.9870 - val_loss: 0.8305 - val_accuracy: 0.7500\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3452 - accuracy: 0.9859 - val_loss: 0.7933 - val_accuracy: 0.7771\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3461 - accuracy: 0.9842 - val_loss: 0.7891 - val_accuracy: 0.7794\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3408 - accuracy: 0.9881 - val_loss: 0.7658 - val_accuracy: 0.8009\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3455 - accuracy: 0.9853 - val_loss: 0.7422 - val_accuracy: 0.8190\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3413 - accuracy: 0.9861 - val_loss: 0.7737 - val_accuracy: 0.8054\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3475 - accuracy: 0.9825 - val_loss: 0.7082 - val_accuracy: 0.8314\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3423 - accuracy: 0.9870 - val_loss: 0.6845 - val_accuracy: 0.8348\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3382 - accuracy: 0.9890 - val_loss: 0.6922 - val_accuracy: 0.8382\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3371 - accuracy: 0.9878 - val_loss: 0.6862 - val_accuracy: 0.8382\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3391 - accuracy: 0.9850 - val_loss: 0.7099 - val_accuracy: 0.8258\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3486 - accuracy: 0.9791 - val_loss: 0.6721 - val_accuracy: 0.8360\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3336 - accuracy: 0.9904 - val_loss: 0.6814 - val_accuracy: 0.8416\n","Epoch 32/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3329 - accuracy: 0.9892 - val_loss: 0.6789 - val_accuracy: 0.8405\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3330 - accuracy: 0.9875 - val_loss: 0.6859 - val_accuracy: 0.8348\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3414 - accuracy: 0.9861 - val_loss: 0.6934 - val_accuracy: 0.8462\n","Epoch 35/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3305 - accuracy: 0.9909 - val_loss: 0.6836 - val_accuracy: 0.8428\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3324 - accuracy: 0.9892 - val_loss: 0.7023 - val_accuracy: 0.8416\n","Epoch 37/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3329 - accuracy: 0.9912 - val_loss: 0.6901 - val_accuracy: 0.8360\n","Epoch 38/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3393 - accuracy: 0.9825 - val_loss: 0.7281 - val_accuracy: 0.8314\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3399 - accuracy: 0.9816 - val_loss: 0.7152 - val_accuracy: 0.8303\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3359 - accuracy: 0.9847 - val_loss: 0.6955 - val_accuracy: 0.8371\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3215 - accuracy: 0.9955 - val_loss: 0.7208 - val_accuracy: 0.8326\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3231 - accuracy: 0.9938 - val_loss: 0.6929 - val_accuracy: 0.8394\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3209 - accuracy: 0.9926 - val_loss: 0.7082 - val_accuracy: 0.8405\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3290 - accuracy: 0.9875 - val_loss: 0.7243 - val_accuracy: 0.8337\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3196 - accuracy: 0.9946 - val_loss: 0.7543 - val_accuracy: 0.8292\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3217 - accuracy: 0.9924 - val_loss: 0.7065 - val_accuracy: 0.8348\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3256 - accuracy: 0.9907 - val_loss: 0.7011 - val_accuracy: 0.8371\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3212 - accuracy: 0.9935 - val_loss: 0.7115 - val_accuracy: 0.8450\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3193 - accuracy: 0.9932 - val_loss: 0.7115 - val_accuracy: 0.8382\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3240 - accuracy: 0.9907 - val_loss: 0.7316 - val_accuracy: 0.8360\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3309 - accuracy: 0.9861 - val_loss: 0.7119 - val_accuracy: 0.8348\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3156 - accuracy: 0.9949 - val_loss: 0.7219 - val_accuracy: 0.8371\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3218 - accuracy: 0.9890 - val_loss: 0.7212 - val_accuracy: 0.8382\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3153 - accuracy: 0.9943 - val_loss: 0.7125 - val_accuracy: 0.8337\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3095 - accuracy: 0.9975 - val_loss: 0.7478 - val_accuracy: 0.8292\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3105 - accuracy: 0.9966 - val_loss: 0.7176 - val_accuracy: 0.8382\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3117 - accuracy: 0.9963 - val_loss: 0.7595 - val_accuracy: 0.8269\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3123 - accuracy: 0.9949 - val_loss: 0.8177 - val_accuracy: 0.8043\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3154 - accuracy: 0.9924 - val_loss: 0.7184 - val_accuracy: 0.8326\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3154 - accuracy: 0.9921 - val_loss: 0.7349 - val_accuracy: 0.8292\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3079 - accuracy: 0.9980 - val_loss: 0.7243 - val_accuracy: 0.8450\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3045 - accuracy: 0.9975 - val_loss: 0.7217 - val_accuracy: 0.8394\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3047 - accuracy: 0.9975 - val_loss: 0.7488 - val_accuracy: 0.8314\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3157 - accuracy: 0.9924 - val_loss: 0.7332 - val_accuracy: 0.8303\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3042 - accuracy: 0.9969 - val_loss: 0.7415 - val_accuracy: 0.8314\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3025 - accuracy: 0.9977 - val_loss: 0.7285 - val_accuracy: 0.8428\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3014 - accuracy: 0.9989 - val_loss: 0.7378 - val_accuracy: 0.8416\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3052 - accuracy: 0.9952 - val_loss: 0.7318 - val_accuracy: 0.8428\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3061 - accuracy: 0.9958 - val_loss: 0.7408 - val_accuracy: 0.8269\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3008 - accuracy: 0.9975 - val_loss: 0.7453 - val_accuracy: 0.8303\n","Epoch 71/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3040 - accuracy: 0.9969 - val_loss: 0.7305 - val_accuracy: 0.8371\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3007 - accuracy: 0.9980 - val_loss: 0.7437 - val_accuracy: 0.8303\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3013 - accuracy: 0.9972 - val_loss: 0.7453 - val_accuracy: 0.8337\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.9975 - val_loss: 0.7722 - val_accuracy: 0.8247\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2974 - accuracy: 0.9986 - val_loss: 0.7476 - val_accuracy: 0.8360\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2975 - accuracy: 0.9977 - val_loss: 0.7438 - val_accuracy: 0.8371\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2962 - accuracy: 0.9983 - val_loss: 0.7545 - val_accuracy: 0.8360\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3006 - accuracy: 0.9966 - val_loss: 0.7437 - val_accuracy: 0.8360\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2945 - accuracy: 0.9992 - val_loss: 0.7706 - val_accuracy: 0.8303\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2960 - accuracy: 0.9983 - val_loss: 0.7487 - val_accuracy: 0.8371\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2934 - accuracy: 0.9986 - val_loss: 0.7599 - val_accuracy: 0.8416\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2955 - accuracy: 0.9977 - val_loss: 0.7710 - val_accuracy: 0.8326\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2960 - accuracy: 0.9975 - val_loss: 0.7836 - val_accuracy: 0.8360\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2932 - accuracy: 0.9983 - val_loss: 0.7638 - val_accuracy: 0.8337\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2974 - accuracy: 0.9969 - val_loss: 0.8071 - val_accuracy: 0.8224\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3068 - accuracy: 0.9912 - val_loss: 0.9077 - val_accuracy: 0.8100\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.9859 - val_loss: 0.7516 - val_accuracy: 0.8405\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2943 - accuracy: 0.9977 - val_loss: 0.7976 - val_accuracy: 0.8235\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3030 - accuracy: 0.9932 - val_loss: 0.7708 - val_accuracy: 0.8348\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2925 - accuracy: 0.9980 - val_loss: 0.7814 - val_accuracy: 0.8360\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2941 - accuracy: 0.9977 - val_loss: 0.7721 - val_accuracy: 0.8428\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2929 - accuracy: 0.9989 - val_loss: 0.7878 - val_accuracy: 0.8213\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2885 - accuracy: 0.9994 - val_loss: 0.8050 - val_accuracy: 0.8303\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2893 - accuracy: 0.9983 - val_loss: 0.7626 - val_accuracy: 0.8360\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2921 - accuracy: 0.9969 - val_loss: 0.7593 - val_accuracy: 0.8326\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2955 - accuracy: 0.9960 - val_loss: 0.8136 - val_accuracy: 0.8224\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2934 - accuracy: 0.9983 - val_loss: 0.7706 - val_accuracy: 0.8348\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2926 - accuracy: 0.9969 - val_loss: 0.7734 - val_accuracy: 0.8337\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2912 - accuracy: 0.9980 - val_loss: 0.8025 - val_accuracy: 0.8258\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2881 - accuracy: 0.9994 - val_loss: 0.7647 - val_accuracy: 0.8394\n","{'loss': [0.49691662192344666, 0.397044837474823, 0.38653382658958435, 0.3952319622039795, 0.37790530920028687, 0.3739624619483948, 0.37353914976119995, 0.37159305810928345, 0.37315794825553894, 0.3636939227581024, 0.36160531640052795, 0.3582477271556854, 0.3577461242675781, 0.35706406831741333, 0.35518965125083923, 0.36344006657600403, 0.3618357181549072, 0.3582763671875, 0.345593124628067, 0.3452232778072357, 0.3461168706417084, 0.34082090854644775, 0.3454921245574951, 0.34134769439697266, 0.3475387394428253, 0.34234562516212463, 0.3382274806499481, 0.33712488412857056, 0.3391232490539551, 0.34859344363212585, 0.33359360694885254, 0.332917183637619, 0.3330140709877014, 0.3414205312728882, 0.3305410146713257, 0.33235907554626465, 0.33292531967163086, 0.33925625681877136, 0.33985230326652527, 0.3358669877052307, 0.321505606174469, 0.3231012523174286, 0.32091403007507324, 0.3289668560028076, 0.31961163878440857, 0.3216596841812134, 0.32555246353149414, 0.3211839199066162, 0.3192744553089142, 0.3240434229373932, 0.3309078514575958, 0.31559261679649353, 0.3218478858470917, 0.31532493233680725, 0.3094857931137085, 0.31045061349868774, 0.31172746419906616, 0.3122554421424866, 0.31540679931640625, 0.3154419958591461, 0.3078896999359131, 0.3045142590999603, 0.3046688437461853, 0.31571218371391296, 0.30418968200683594, 0.30252984166145325, 0.3014024794101715, 0.30517464876174927, 0.30608800053596497, 0.30075860023498535, 0.30400845408439636, 0.30068325996398926, 0.30131304264068604, 0.30156585574150085, 0.29741808772087097, 0.2974866032600403, 0.2962016761302948, 0.3006187677383423, 0.29446250200271606, 0.29598310589790344, 0.29342928528785706, 0.2955411672592163, 0.29604437947273254, 0.2932281196117401, 0.29742431640625, 0.30675676465034485, 0.3162851333618164, 0.2943480610847473, 0.3029705584049225, 0.2925439774990082, 0.29406681656837463, 0.292878657579422, 0.2884659767150879, 0.2893015742301941, 0.2921477258205414, 0.29546692967414856, 0.29336538910865784, 0.29259762167930603, 0.29117634892463684, 0.288064569234848], 'accuracy': [0.9083191752433777, 0.9564233422279358, 0.9612337350845337, 0.9552914500236511, 0.9688737988471985, 0.9702886343002319, 0.9719864130020142, 0.971137523651123, 0.9685908555984497, 0.9779286980628967, 0.9779286980628967, 0.9790605306625366, 0.9818902015686035, 0.9793435335159302, 0.9793435335159302, 0.9734012484550476, 0.9719864130020142, 0.9770798087120056, 0.986983597278595, 0.9858517050743103, 0.9841539263725281, 0.9881154298782349, 0.9852858185768127, 0.9861347079277039, 0.9824561476707458, 0.986983597278595, 0.988964319229126, 0.9878324866294861, 0.9850028157234192, 0.9790605306625366, 0.9903791546821594, 0.9892473220825195, 0.9875495433807373, 0.9861347079277039, 0.9909451007843018, 0.9892473220825195, 0.9912280440330505, 0.9824561476707458, 0.9816072583198547, 0.9847198724746704, 0.9954725503921509, 0.9937747716903687, 0.992642879486084, 0.9875495433807373, 0.9946236610412598, 0.9923599362373352, 0.990662157535553, 0.9934917688369751, 0.9932088255882263, 0.990662157535553, 0.9861347079277039, 0.9949066042900085, 0.988964319229126, 0.994340717792511, 0.9974533319473267, 0.9966044425964355, 0.996321439743042, 0.9949066042900085, 0.9923599362373352, 0.9920769929885864, 0.9980192184448242, 0.9974533319473267, 0.9974533319473267, 0.9923599362373352, 0.9968873858451843, 0.9977362751960754, 0.9988681674003601, 0.9951896071434021, 0.9957554936408997, 0.9974533319473267, 0.9968873858451843, 0.9980192184448242, 0.9971703290939331, 0.9974533319473267, 0.9985851645469666, 0.9977362751960754, 0.9983022212982178, 0.9966044425964355, 0.9991511106491089, 0.9983022212982178, 0.9985851645469666, 0.9977362751960754, 0.9974533319473267, 0.9983022212982178, 0.9968873858451843, 0.9912280440330505, 0.9858517050743103, 0.9977362751960754, 0.9932088255882263, 0.9980192184448242, 0.9977362751960754, 0.9988681674003601, 0.9994340538978577, 0.9983022212982178, 0.9968873858451843, 0.9960384964942932, 0.9983022212982178, 0.9968873858451843, 0.9980192184448242, 0.9994340538978577], 'val_loss': [1.357785701751709, 1.3474628925323486, 1.3178222179412842, 1.3184195756912231, 1.3546795845031738, 1.3475321531295776, 1.3597468137741089, 1.387851357460022, 1.4329055547714233, 1.5405211448669434, 1.478027582168579, 1.456030011177063, 1.3279649019241333, 1.3033658266067505, 1.2816591262817383, 0.9456662535667419, 0.8603674173355103, 0.8942384123802185, 0.8304667472839355, 0.7933465838432312, 0.7890534996986389, 0.7657944560050964, 0.7421884536743164, 0.773681640625, 0.7082043290138245, 0.6844984889030457, 0.6921738982200623, 0.686201274394989, 0.7098971605300903, 0.6720727682113647, 0.681420087814331, 0.6788504123687744, 0.6859262585639954, 0.6933715343475342, 0.6836495399475098, 0.7022941708564758, 0.6900768280029297, 0.7281205654144287, 0.7151568531990051, 0.6954814791679382, 0.7207573652267456, 0.6929137706756592, 0.708168089389801, 0.7242509126663208, 0.7542957067489624, 0.7064707279205322, 0.7011264562606812, 0.7115063071250916, 0.7114904522895813, 0.7316167950630188, 0.7119454145431519, 0.7218570113182068, 0.7211681604385376, 0.7125411033630371, 0.7478336095809937, 0.7175746560096741, 0.7594640254974365, 0.8177317380905151, 0.7183534502983093, 0.7349404692649841, 0.7242596745491028, 0.7216756939888, 0.7487807273864746, 0.7332021594047546, 0.7414641976356506, 0.7284921407699585, 0.7378408908843994, 0.731849730014801, 0.740791916847229, 0.7452587485313416, 0.730518102645874, 0.7436834573745728, 0.7453465461730957, 0.7722326517105103, 0.7476111650466919, 0.7438026070594788, 0.7545109391212463, 0.7437293529510498, 0.7706024050712585, 0.7487040162086487, 0.7599427700042725, 0.7710402011871338, 0.7836003303527832, 0.7638441324234009, 0.8070631623268127, 0.9077386856079102, 0.7516343593597412, 0.7975979447364807, 0.7708390951156616, 0.7814175486564636, 0.7721297740936279, 0.7877621650695801, 0.8049798607826233, 0.7625707387924194, 0.7593227624893188, 0.8136373162269592, 0.7705815434455872, 0.7733855247497559, 0.8024989366531372, 0.7647101879119873], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49886876344680786, 0.5033936500549316, 0.5033936500549316, 0.5214931964874268, 0.5339366793632507, 0.5610859990119934, 0.570135772228241, 0.5803167223930359, 0.6651583909988403, 0.7251130938529968, 0.7160633206367493, 0.75, 0.7771493196487427, 0.779411792755127, 0.8009049892425537, 0.8190045356750488, 0.8054298758506775, 0.831447958946228, 0.8348416090011597, 0.8382353186607361, 0.8382353186607361, 0.8257918357849121, 0.8359728455543518, 0.8416289687156677, 0.8404977321624756, 0.8348416090011597, 0.8461538553237915, 0.8427602052688599, 0.8416289687156677, 0.8359728455543518, 0.831447958946228, 0.8303167223930359, 0.837104082107544, 0.8325791954994202, 0.8393664956092834, 0.8404977321624756, 0.8337104320526123, 0.8291855454444885, 0.8348416090011597, 0.837104082107544, 0.8450226187705994, 0.8382353186607361, 0.8359728455543518, 0.8348416090011597, 0.837104082107544, 0.8382353186607361, 0.8337104320526123, 0.8291855454444885, 0.8382353186607361, 0.8269230723381042, 0.8042986392974854, 0.8325791954994202, 0.8291855454444885, 0.8450226187705994, 0.8393664956092834, 0.831447958946228, 0.8303167223930359, 0.831447958946228, 0.8427602052688599, 0.8416289687156677, 0.8427602052688599, 0.8269230723381042, 0.8303167223930359, 0.837104082107544, 0.8303167223930359, 0.8337104320526123, 0.8246606588363647, 0.8359728455543518, 0.837104082107544, 0.8359728455543518, 0.8359728455543518, 0.8303167223930359, 0.837104082107544, 0.8416289687156677, 0.8325791954994202, 0.8359728455543518, 0.8337104320526123, 0.8223981857299805, 0.8099547624588013, 0.8404977321624756, 0.8235294222831726, 0.8348416090011597, 0.8359728455543518, 0.8427602052688599, 0.8212669491767883, 0.8303167223930359, 0.8359728455543518, 0.8325791954994202, 0.8223981857299805, 0.8348416090011597, 0.8337104320526123, 0.8257918357849121, 0.8393664956092834]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 27ms/step - loss: 0.5143 - accuracy: 0.9018 - val_loss: 1.3983 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.4289 - accuracy: 0.9453"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 11ms/step - loss: 0.4117 - accuracy: 0.9470 - val_loss: 1.3713 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4049 - accuracy: 0.9532 - val_loss: 1.3718 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4021 - accuracy: 0.9571 - val_loss: 1.3643 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4054 - accuracy: 0.9532 - val_loss: 1.3983 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3933 - accuracy: 0.9610 - val_loss: 1.4675 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3914 - accuracy: 0.9589 - val_loss: 1.4798 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3845 - accuracy: 0.9656 - val_loss: 1.4537 - val_accuracy: 0.4928\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3940 - accuracy: 0.9561 - val_loss: 1.6308 - val_accuracy: 0.4928\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4090 - accuracy: 0.9527 - val_loss: 1.5983 - val_accuracy: 0.4948\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3816 - accuracy: 0.9669 - val_loss: 1.6193 - val_accuracy: 0.5031\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3801 - accuracy: 0.9698 - val_loss: 1.3885 - val_accuracy: 0.5341\n","Epoch 13/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3724 - accuracy: 0.9736 - val_loss: 1.4596 - val_accuracy: 0.5341\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3730 - accuracy: 0.9718 - val_loss: 1.1740 - val_accuracy: 0.5919\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3708 - accuracy: 0.9711 - val_loss: 1.0588 - val_accuracy: 0.6436\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3708 - accuracy: 0.9726 - val_loss: 0.9146 - val_accuracy: 0.6901\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4061 - accuracy: 0.9452 - val_loss: 0.9280 - val_accuracy: 0.7014\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3742 - accuracy: 0.9680 - val_loss: 0.9087 - val_accuracy: 0.7159\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3647 - accuracy: 0.9752 - val_loss: 0.8548 - val_accuracy: 0.7448\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3944 - accuracy: 0.9566 - val_loss: 0.8287 - val_accuracy: 0.7831\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3696 - accuracy: 0.9718 - val_loss: 0.7953 - val_accuracy: 0.7893\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3679 - accuracy: 0.9711 - val_loss: 0.7720 - val_accuracy: 0.8058\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3608 - accuracy: 0.9762 - val_loss: 0.7505 - val_accuracy: 0.8140\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3596 - accuracy: 0.9760 - val_loss: 0.7679 - val_accuracy: 0.8130\n","Epoch 25/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3559 - accuracy: 0.9788 - val_loss: 0.7495 - val_accuracy: 0.8089\n","Epoch 26/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3690 - accuracy: 0.9711 - val_loss: 0.8003 - val_accuracy: 0.8027\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3636 - accuracy: 0.9731 - val_loss: 0.7350 - val_accuracy: 0.8161\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3623 - accuracy: 0.9749 - val_loss: 0.7341 - val_accuracy: 0.8161\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3499 - accuracy: 0.9817 - val_loss: 0.7446 - val_accuracy: 0.8192\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3548 - accuracy: 0.9809 - val_loss: 0.7497 - val_accuracy: 0.8192\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3509 - accuracy: 0.9822 - val_loss: 0.7467 - val_accuracy: 0.8264\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3512 - accuracy: 0.9791 - val_loss: 0.7820 - val_accuracy: 0.8079\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3836 - accuracy: 0.9566 - val_loss: 0.7449 - val_accuracy: 0.8223\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3722 - accuracy: 0.9638 - val_loss: 0.7441 - val_accuracy: 0.8233\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3464 - accuracy: 0.9835 - val_loss: 0.7972 - val_accuracy: 0.8048\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3478 - accuracy: 0.9806 - val_loss: 0.7612 - val_accuracy: 0.8213\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3526 - accuracy: 0.9778 - val_loss: 0.7596 - val_accuracy: 0.8161\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3422 - accuracy: 0.9860 - val_loss: 0.7545 - val_accuracy: 0.8213\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3403 - accuracy: 0.9853 - val_loss: 0.7587 - val_accuracy: 0.8233\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3435 - accuracy: 0.9811 - val_loss: 0.7551 - val_accuracy: 0.8161\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3429 - accuracy: 0.9819 - val_loss: 0.7573 - val_accuracy: 0.8202\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3468 - accuracy: 0.9806 - val_loss: 0.7666 - val_accuracy: 0.8233\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3387 - accuracy: 0.9850 - val_loss: 0.7796 - val_accuracy: 0.8223\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3458 - accuracy: 0.9793 - val_loss: 0.7659 - val_accuracy: 0.8171\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3452 - accuracy: 0.9798 - val_loss: 0.7643 - val_accuracy: 0.8182\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3407 - accuracy: 0.9827 - val_loss: 0.7981 - val_accuracy: 0.8027\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3384 - accuracy: 0.9845 - val_loss: 0.7784 - val_accuracy: 0.8223\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3329 - accuracy: 0.9891 - val_loss: 0.7963 - val_accuracy: 0.8048\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3394 - accuracy: 0.9822 - val_loss: 0.7729 - val_accuracy: 0.8223\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3348 - accuracy: 0.9879 - val_loss: 0.7798 - val_accuracy: 0.8151\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3355 - accuracy: 0.9819 - val_loss: 0.8374 - val_accuracy: 0.8058\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3396 - accuracy: 0.9829 - val_loss: 0.7712 - val_accuracy: 0.8202\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3423 - accuracy: 0.9796 - val_loss: 0.8059 - val_accuracy: 0.8140\n","Epoch 54/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3311 - accuracy: 0.9866 - val_loss: 0.7810 - val_accuracy: 0.8161\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3345 - accuracy: 0.9881 - val_loss: 0.8198 - val_accuracy: 0.8058\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3436 - accuracy: 0.9762 - val_loss: 0.8061 - val_accuracy: 0.8130\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3317 - accuracy: 0.9866 - val_loss: 0.8119 - val_accuracy: 0.8140\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3344 - accuracy: 0.9845 - val_loss: 0.7852 - val_accuracy: 0.8171\n","Epoch 59/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3244 - accuracy: 0.9889 - val_loss: 0.7993 - val_accuracy: 0.8161\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3235 - accuracy: 0.9894 - val_loss: 0.7905 - val_accuracy: 0.8151\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3323 - accuracy: 0.9860 - val_loss: 0.8648 - val_accuracy: 0.7986\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3348 - accuracy: 0.9832 - val_loss: 0.8076 - val_accuracy: 0.8192\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3244 - accuracy: 0.9902 - val_loss: 0.7924 - val_accuracy: 0.8223\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3216 - accuracy: 0.9910 - val_loss: 0.7969 - val_accuracy: 0.8192\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3283 - accuracy: 0.9863 - val_loss: 0.8226 - val_accuracy: 0.8048\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3376 - accuracy: 0.9804 - val_loss: 0.8207 - val_accuracy: 0.8161\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3367 - accuracy: 0.9804 - val_loss: 0.8113 - val_accuracy: 0.8089\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3238 - accuracy: 0.9894 - val_loss: 0.8486 - val_accuracy: 0.8089\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3402 - accuracy: 0.9793 - val_loss: 0.8034 - val_accuracy: 0.8182\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3186 - accuracy: 0.9912 - val_loss: 0.8191 - val_accuracy: 0.8089\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3150 - accuracy: 0.9917 - val_loss: 0.8052 - val_accuracy: 0.8171\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3188 - accuracy: 0.9902 - val_loss: 0.8496 - val_accuracy: 0.8192\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3195 - accuracy: 0.9891 - val_loss: 0.8064 - val_accuracy: 0.8182\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3151 - accuracy: 0.9930 - val_loss: 0.8167 - val_accuracy: 0.8171\n","Epoch 75/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3144 - accuracy: 0.9925 - val_loss: 0.8134 - val_accuracy: 0.8120\n","Epoch 76/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3224 - accuracy: 0.9871 - val_loss: 0.8370 - val_accuracy: 0.8089\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3213 - accuracy: 0.9902 - val_loss: 0.8424 - val_accuracy: 0.8151\n","Epoch 78/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3117 - accuracy: 0.9928 - val_loss: 0.8149 - val_accuracy: 0.8161\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3099 - accuracy: 0.9935 - val_loss: 0.8355 - val_accuracy: 0.8151\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3241 - accuracy: 0.9863 - val_loss: 0.8297 - val_accuracy: 0.8182\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3088 - accuracy: 0.9951 - val_loss: 0.8289 - val_accuracy: 0.8079\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3095 - accuracy: 0.9935 - val_loss: 0.8260 - val_accuracy: 0.8110\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3048 - accuracy: 0.9956 - val_loss: 0.8264 - val_accuracy: 0.8130\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3086 - accuracy: 0.9917 - val_loss: 0.8261 - val_accuracy: 0.8120\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3098 - accuracy: 0.9917 - val_loss: 0.8460 - val_accuracy: 0.8048\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3040 - accuracy: 0.9959 - val_loss: 0.8612 - val_accuracy: 0.8140\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3059 - accuracy: 0.9922 - val_loss: 0.8277 - val_accuracy: 0.8182\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3065 - accuracy: 0.9941 - val_loss: 0.8314 - val_accuracy: 0.8171\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3110 - accuracy: 0.9910 - val_loss: 0.8502 - val_accuracy: 0.8130\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3026 - accuracy: 0.9959 - val_loss: 0.8364 - val_accuracy: 0.8233\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3038 - accuracy: 0.9941 - val_loss: 0.8894 - val_accuracy: 0.8099\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3056 - accuracy: 0.9946 - val_loss: 0.8444 - val_accuracy: 0.8192\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3039 - accuracy: 0.9946 - val_loss: 0.8453 - val_accuracy: 0.8171\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3016 - accuracy: 0.9943 - val_loss: 0.9011 - val_accuracy: 0.8048\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3164 - accuracy: 0.9897 - val_loss: 0.8622 - val_accuracy: 0.8171\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2987 - accuracy: 0.9966 - val_loss: 0.8429 - val_accuracy: 0.8120\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3058 - accuracy: 0.9922 - val_loss: 0.8481 - val_accuracy: 0.8079\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3069 - accuracy: 0.9928 - val_loss: 0.8508 - val_accuracy: 0.8161\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3052 - accuracy: 0.9935 - val_loss: 0.8876 - val_accuracy: 0.8027\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3002 - accuracy: 0.9948 - val_loss: 0.9069 - val_accuracy: 0.8079\n","{'loss': [0.5143477320671082, 0.41172006726264954, 0.40493592619895935, 0.4021437466144562, 0.40538424253463745, 0.3932744562625885, 0.39138808846473694, 0.384548544883728, 0.39398786425590515, 0.4089711308479309, 0.3815610110759735, 0.3801392614841461, 0.3723844587802887, 0.3730243444442749, 0.3708476424217224, 0.3707563281059265, 0.40614187717437744, 0.3741816580295563, 0.364712655544281, 0.39438116550445557, 0.3695840537548065, 0.36786484718322754, 0.3607751131057739, 0.3596443235874176, 0.3559301793575287, 0.3690062463283539, 0.36364808678627014, 0.36233487725257874, 0.3499062657356262, 0.35476285219192505, 0.3508804142475128, 0.3512030243873596, 0.3835534155368805, 0.3721977770328522, 0.346364289522171, 0.34775716066360474, 0.3525508940219879, 0.34219539165496826, 0.3403438627719879, 0.3434503972530365, 0.3428603410720825, 0.3467860817909241, 0.33869707584381104, 0.345792293548584, 0.3451763391494751, 0.34074676036834717, 0.3383650779724121, 0.3328823745250702, 0.3394412100315094, 0.3348315358161926, 0.3354859948158264, 0.3396216034889221, 0.3422527313232422, 0.3311088979244232, 0.33451107144355774, 0.343576580286026, 0.33165010809898376, 0.3343992233276367, 0.3243899345397949, 0.32352933287620544, 0.3322657644748688, 0.33479681611061096, 0.32439693808555603, 0.32158541679382324, 0.32832443714141846, 0.33764559030532837, 0.33669212460517883, 0.3238176703453064, 0.3401593863964081, 0.31863006949424744, 0.3150061368942261, 0.318752259016037, 0.31946036219596863, 0.315147340297699, 0.31442990899086, 0.32243505120277405, 0.32131800055503845, 0.31170639395713806, 0.3099176287651062, 0.3241141438484192, 0.30875927209854126, 0.30946269631385803, 0.3048439621925354, 0.3085925579071045, 0.309799462556839, 0.3040357828140259, 0.3058548867702484, 0.30645957589149475, 0.3110308051109314, 0.3026350438594818, 0.3037928640842438, 0.3055838942527771, 0.3039017617702484, 0.30159199237823486, 0.3164222240447998, 0.2987326681613922, 0.3057994544506073, 0.3068663775920868, 0.30517297983169556, 0.3002394735813141], 'accuracy': [0.9018087983131409, 0.947028398513794, 0.9532299637794495, 0.9571059346199036, 0.9532299637794495, 0.9609819054603577, 0.9589147567749023, 0.9656330943107605, 0.9560723304748535, 0.9527131915092468, 0.9669250845909119, 0.9697674512863159, 0.97364342212677, 0.9718345999717712, 0.9710594415664673, 0.97260981798172, 0.9452196359634399, 0.9679586291313171, 0.9751937985420227, 0.9565891623497009, 0.9718345999717712, 0.9710594415664673, 0.9762274026870728, 0.9759690165519714, 0.9788113832473755, 0.9710594415664673, 0.9731265902519226, 0.9749354124069214, 0.9816537499427795, 0.9808785319328308, 0.9821705222129822, 0.9790697693824768, 0.9565891623497009, 0.9638242721557617, 0.9834625124931335, 0.9806201457977295, 0.9777777791023254, 0.9860464930534363, 0.9852713346481323, 0.9811369776725769, 0.9819121360778809, 0.9806201457977295, 0.985012948513031, 0.9793281555175781, 0.9798449873924255, 0.9826873540878296, 0.9844961166381836, 0.9891473054885864, 0.9821705222129822, 0.9878553152084351, 0.9819121360778809, 0.9829457402229309, 0.9795865416526794, 0.9865633249282837, 0.9881137013435364, 0.9762274026870728, 0.9865633249282837, 0.9844961166381836, 0.9888888597488403, 0.9894056916236877, 0.9860464930534363, 0.9832041263580322, 0.9901808500289917, 0.9909560680389404, 0.9863049387931824, 0.9803617596626282, 0.9803617596626282, 0.9894056916236877, 0.9793281555175781, 0.9912144541740417, 0.9917312860488892, 0.9901808500289917, 0.9891473054885864, 0.9930232763290405, 0.9925064444541931, 0.9870800971984863, 0.9901808500289917, 0.9927648305892944, 0.9935400485992432, 0.9863049387931824, 0.9950904250144958, 0.9935400485992432, 0.9956072568893433, 0.9917312860488892, 0.9917312860488892, 0.9958656430244446, 0.9922480583190918, 0.9940568208694458, 0.9909560680389404, 0.9958656430244446, 0.9940568208694458, 0.9945736527442932, 0.9945736527442932, 0.9943152666091919, 0.9896640777587891, 0.9966408014297485, 0.9922480583190918, 0.9927648305892944, 0.9935400485992432, 0.9948320388793945], 'val_loss': [1.3982757329940796, 1.371345043182373, 1.3717538118362427, 1.3643146753311157, 1.3982526063919067, 1.467490792274475, 1.479792594909668, 1.453735113143921, 1.6308058500289917, 1.598273754119873, 1.6193042993545532, 1.3884925842285156, 1.4596171379089355, 1.1739931106567383, 1.0588266849517822, 0.9146274328231812, 0.9280100464820862, 0.9087335467338562, 0.8548285365104675, 0.8287453651428223, 0.7953234314918518, 0.7720264196395874, 0.7505008578300476, 0.7678837180137634, 0.7494685649871826, 0.8002599477767944, 0.7349583506584167, 0.734108567237854, 0.7446138858795166, 0.7497375011444092, 0.7466568350791931, 0.782049834728241, 0.7449443936347961, 0.7441208362579346, 0.7971688508987427, 0.7612142562866211, 0.7596232891082764, 0.7544769048690796, 0.7587103843688965, 0.7550912499427795, 0.7573385834693909, 0.7666273713111877, 0.7796121835708618, 0.7658657431602478, 0.7642959356307983, 0.7981341481208801, 0.7784151434898376, 0.7963399291038513, 0.7728940844535828, 0.7797730565071106, 0.8373826742172241, 0.7712017297744751, 0.8059425950050354, 0.7810493111610413, 0.8198280930519104, 0.8060773015022278, 0.8119297623634338, 0.7852377891540527, 0.7993490695953369, 0.7905440330505371, 0.8648349642753601, 0.8076337575912476, 0.7924291491508484, 0.7969177961349487, 0.8226393461227417, 0.8206541538238525, 0.8113476037979126, 0.8485845327377319, 0.8033738732337952, 0.8190717101097107, 0.8052166104316711, 0.8496156930923462, 0.8064442873001099, 0.8167487382888794, 0.8134248852729797, 0.836973249912262, 0.8424066305160522, 0.8148930072784424, 0.8354536294937134, 0.8296718001365662, 0.8289049863815308, 0.8259626626968384, 0.826439619064331, 0.8261057734489441, 0.8460381627082825, 0.8612035512924194, 0.827729344367981, 0.8313941359519958, 0.8502414226531982, 0.8363943099975586, 0.889441192150116, 0.8443951606750488, 0.8452793955802917, 0.9011178016662598, 0.8622244596481323, 0.8429459929466248, 0.8481044173240662, 0.8507888317108154, 0.8875637650489807, 0.9068722128868103], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4927685856819153, 0.4927685856819153, 0.4948347210884094, 0.5030992031097412, 0.5340909361839294, 0.5340909361839294, 0.5919421315193176, 0.6435950398445129, 0.6900826692581177, 0.7014462947845459, 0.7159090638160706, 0.7448347210884094, 0.7830578684806824, 0.78925621509552, 0.8057851195335388, 0.8140496015548706, 0.8130165338516235, 0.80888432264328, 0.8026859760284424, 0.81611567735672, 0.81611567735672, 0.8192148804664612, 0.8192148804664612, 0.8264462947845459, 0.807851254940033, 0.8223140239715576, 0.8233470916748047, 0.8047520518302917, 0.8212810158729553, 0.81611567735672, 0.8212810158729553, 0.8233470916748047, 0.81611567735672, 0.8202479481697083, 0.8233470916748047, 0.8223140239715576, 0.817148745059967, 0.8181818127632141, 0.8026859760284424, 0.8223140239715576, 0.8047520518302917, 0.8223140239715576, 0.8150826692581177, 0.8057851195335388, 0.8202479481697083, 0.8140496015548706, 0.81611567735672, 0.8057851195335388, 0.8130165338516235, 0.8140496015548706, 0.817148745059967, 0.81611567735672, 0.8150826692581177, 0.7985537052154541, 0.8192148804664612, 0.8223140239715576, 0.8192148804664612, 0.8047520518302917, 0.81611567735672, 0.80888432264328, 0.80888432264328, 0.8181818127632141, 0.80888432264328, 0.817148745059967, 0.8192148804664612, 0.8181818127632141, 0.817148745059967, 0.8119834661483765, 0.80888432264328, 0.8150826692581177, 0.81611567735672, 0.8150826692581177, 0.8181818127632141, 0.807851254940033, 0.8109503984451294, 0.8130165338516235, 0.8119834661483765, 0.8047520518302917, 0.8140496015548706, 0.8181818127632141, 0.817148745059967, 0.8130165338516235, 0.8233470916748047, 0.8099173307418823, 0.8192148804664612, 0.817148745059967, 0.8047520518302917, 0.817148745059967, 0.8119834661483765, 0.807851254940033, 0.81611567735672, 0.8026859760284424, 0.807851254940033]}\n","32/32 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717499794566,"user_tz":-360,"elapsed":49,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"35f94522-8546-4c9a-d570-2b0a641ff3af"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.660      0.649   0.697  0.672        0.697        0.623   \n","1        1     0.712      0.776   0.596  0.674        0.596        0.828   \n","2        2     0.628      0.631   0.614  0.623        0.614        0.641   \n","3        0     0.697      0.676   0.757  0.714        0.757        0.637   \n","4        1     0.723      0.738   0.692  0.714        0.692        0.754   \n","5        2     0.692      0.702   0.667  0.684        0.667        0.717   \n","6        0     0.725      0.701   0.786  0.741        0.786        0.665   \n","7        1     0.749      0.744   0.760  0.752        0.760        0.739   \n","8        2     0.742      0.743   0.739  0.741        0.739        0.745   \n","9        0     0.761      0.764   0.755  0.760        0.755        0.767   \n","10       1     0.790      0.804   0.767  0.785        0.767        0.814   \n","11       2     0.766      0.718   0.878  0.790        0.878        0.655   \n","12       0     0.789      0.800   0.771  0.785        0.771        0.807   \n","13       1     0.807      0.831   0.771  0.800        0.771        0.843   \n","14       2     0.800      0.751   0.898  0.818        0.898        0.703   \n","\n","    Kappa  \n","0   0.320  \n","1   0.424  \n","2   0.255  \n","3   0.394  \n","4   0.446  \n","5   0.384  \n","6   0.451  \n","7   0.499  \n","8   0.484  \n","9   0.523  \n","10  0.581  \n","11  0.532  \n","12  0.578  \n","13  0.614  \n","14  0.600  "],"text/html":["\n","  <div id=\"df-cda6f902-f5dd-447e-945e-0e340d1884d9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.660</td>\n","      <td>0.649</td>\n","      <td>0.697</td>\n","      <td>0.672</td>\n","      <td>0.697</td>\n","      <td>0.623</td>\n","      <td>0.320</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.712</td>\n","      <td>0.776</td>\n","      <td>0.596</td>\n","      <td>0.674</td>\n","      <td>0.596</td>\n","      <td>0.828</td>\n","      <td>0.424</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.628</td>\n","      <td>0.631</td>\n","      <td>0.614</td>\n","      <td>0.623</td>\n","      <td>0.614</td>\n","      <td>0.641</td>\n","      <td>0.255</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.697</td>\n","      <td>0.676</td>\n","      <td>0.757</td>\n","      <td>0.714</td>\n","      <td>0.757</td>\n","      <td>0.637</td>\n","      <td>0.394</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.723</td>\n","      <td>0.738</td>\n","      <td>0.692</td>\n","      <td>0.714</td>\n","      <td>0.692</td>\n","      <td>0.754</td>\n","      <td>0.446</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.692</td>\n","      <td>0.702</td>\n","      <td>0.667</td>\n","      <td>0.684</td>\n","      <td>0.667</td>\n","      <td>0.717</td>\n","      <td>0.384</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.725</td>\n","      <td>0.701</td>\n","      <td>0.786</td>\n","      <td>0.741</td>\n","      <td>0.786</td>\n","      <td>0.665</td>\n","      <td>0.451</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.749</td>\n","      <td>0.744</td>\n","      <td>0.760</td>\n","      <td>0.752</td>\n","      <td>0.760</td>\n","      <td>0.739</td>\n","      <td>0.499</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.742</td>\n","      <td>0.743</td>\n","      <td>0.739</td>\n","      <td>0.741</td>\n","      <td>0.739</td>\n","      <td>0.745</td>\n","      <td>0.484</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.761</td>\n","      <td>0.764</td>\n","      <td>0.755</td>\n","      <td>0.760</td>\n","      <td>0.755</td>\n","      <td>0.767</td>\n","      <td>0.523</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.790</td>\n","      <td>0.804</td>\n","      <td>0.767</td>\n","      <td>0.785</td>\n","      <td>0.767</td>\n","      <td>0.814</td>\n","      <td>0.581</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.766</td>\n","      <td>0.718</td>\n","      <td>0.878</td>\n","      <td>0.790</td>\n","      <td>0.878</td>\n","      <td>0.655</td>\n","      <td>0.532</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.789</td>\n","      <td>0.800</td>\n","      <td>0.771</td>\n","      <td>0.785</td>\n","      <td>0.771</td>\n","      <td>0.807</td>\n","      <td>0.578</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.807</td>\n","      <td>0.831</td>\n","      <td>0.771</td>\n","      <td>0.800</td>\n","      <td>0.771</td>\n","      <td>0.843</td>\n","      <td>0.614</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.800</td>\n","      <td>0.751</td>\n","      <td>0.898</td>\n","      <td>0.818</td>\n","      <td>0.898</td>\n","      <td>0.703</td>\n","      <td>0.600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cda6f902-f5dd-447e-945e-0e340d1884d9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cda6f902-f5dd-447e-945e-0e340d1884d9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cda6f902-f5dd-447e-945e-0e340d1884d9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-01439330-d734-41f1-9c14-29870ee56473\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01439330-d734-41f1-9c14-29870ee56473')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-01439330-d734-41f1-9c14-29870ee56473 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0523415522815105,\n        \"min\": 0.628,\n        \"max\": 0.807,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.761,\n          0.766,\n          0.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056921248856895014,\n        \"min\": 0.631,\n        \"max\": 0.831,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.764,\n          0.718,\n          0.649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08264830825336268,\n        \"min\": 0.596,\n        \"max\": 0.898,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.755,\n          0.878,\n          0.697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05592707837209177,\n        \"min\": 0.623,\n        \"max\": 0.818,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.8,\n          0.79,\n          0.672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08264830825336268,\n        \"min\": 0.596,\n        \"max\": 0.898,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.755,\n          0.878,\n          0.697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07385623099741047,\n        \"min\": 0.623,\n        \"max\": 0.843,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.767,\n          0.655,\n          0.623\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1049419340578852,\n        \"min\": 0.255,\n        \"max\": 0.614,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.523,\n          0.532,\n          0.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN/Beta_time_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717499795347,"user_tz":-360,"elapsed":789,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"GPlWZUcV48bB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Beta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Beta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n","\n"],"metadata":{"id":"ieXSN-9PI4Dx","executionInfo":{"status":"ok","timestamp":1717499795348,"user_tz":-360,"elapsed":14,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD5S-Pvy5B-r","executionInfo":{"status":"ok","timestamp":1717500987920,"user_tz":-360,"elapsed":39415,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"4c23541e-1146-4eaf-baa8-668925aef562"},"execution_count":18,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.4305 - accuracy: 0.5023"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 50ms/step - loss: 1.4305 - accuracy: 0.5003 - val_loss: 1.4281 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4247 - accuracy: 0.5353 - val_loss: 1.4233 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4180 - accuracy: 0.5770 - val_loss: 1.4182 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4112 - accuracy: 0.5886 - val_loss: 1.4134 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4036 - accuracy: 0.6107 - val_loss: 1.4083 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3945 - accuracy: 0.6325 - val_loss: 1.4033 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3825 - accuracy: 0.6476 - val_loss: 1.3971 - val_accuracy: 0.5226\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3689 - accuracy: 0.6611 - val_loss: 1.3904 - val_accuracy: 0.5668\n","Epoch 9/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3519 - accuracy: 0.6695 - val_loss: 1.3816 - val_accuracy: 0.6552\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3359 - accuracy: 0.6716 - val_loss: 1.3752 - val_accuracy: 0.5269\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.3187 - accuracy: 0.6765 - val_loss: 1.3613 - val_accuracy: 0.6649\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.3001 - accuracy: 0.6853 - val_loss: 1.3479 - val_accuracy: 0.6713\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2866 - accuracy: 0.6948 - val_loss: 1.3384 - val_accuracy: 0.6336\n","Epoch 14/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2719 - accuracy: 0.6950 - val_loss: 1.3172 - val_accuracy: 0.6972\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2633 - accuracy: 0.6953 - val_loss: 1.3008 - val_accuracy: 0.6886\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2533 - accuracy: 0.7066 - val_loss: 1.2910 - val_accuracy: 0.6972\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2395 - accuracy: 0.7150 - val_loss: 1.2712 - val_accuracy: 0.7112\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2292 - accuracy: 0.7204 - val_loss: 1.2564 - val_accuracy: 0.7177\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2220 - accuracy: 0.7171 - val_loss: 1.2525 - val_accuracy: 0.7101\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2175 - accuracy: 0.7196 - val_loss: 1.2357 - val_accuracy: 0.7123\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2081 - accuracy: 0.7231 - val_loss: 1.2242 - val_accuracy: 0.7155\n","Epoch 22/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2005 - accuracy: 0.7279 - val_loss: 1.2189 - val_accuracy: 0.7101\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1945 - accuracy: 0.7249 - val_loss: 1.2114 - val_accuracy: 0.7144\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1890 - accuracy: 0.7301 - val_loss: 1.2037 - val_accuracy: 0.7155\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1840 - accuracy: 0.7233 - val_loss: 1.1980 - val_accuracy: 0.7220\n","Epoch 26/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.1818 - accuracy: 0.7252 - val_loss: 1.1921 - val_accuracy: 0.7231\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1734 - accuracy: 0.7341 - val_loss: 1.1887 - val_accuracy: 0.7188\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1693 - accuracy: 0.7301 - val_loss: 1.1837 - val_accuracy: 0.7209\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1624 - accuracy: 0.7303 - val_loss: 1.1795 - val_accuracy: 0.7166\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1530 - accuracy: 0.7381 - val_loss: 1.1739 - val_accuracy: 0.7231\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1506 - accuracy: 0.7314 - val_loss: 1.1708 - val_accuracy: 0.7198\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1455 - accuracy: 0.7363 - val_loss: 1.1633 - val_accuracy: 0.7306\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1411 - accuracy: 0.7449 - val_loss: 1.1596 - val_accuracy: 0.7220\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1321 - accuracy: 0.7427 - val_loss: 1.1625 - val_accuracy: 0.7231\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1301 - accuracy: 0.7478 - val_loss: 1.1511 - val_accuracy: 0.7209\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1283 - accuracy: 0.7460 - val_loss: 1.1567 - val_accuracy: 0.7231\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1227 - accuracy: 0.7454 - val_loss: 1.1425 - val_accuracy: 0.7231\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1190 - accuracy: 0.7422 - val_loss: 1.1391 - val_accuracy: 0.7241\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1152 - accuracy: 0.7457 - val_loss: 1.1324 - val_accuracy: 0.7284\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1076 - accuracy: 0.7446 - val_loss: 1.1304 - val_accuracy: 0.7220\n","Epoch 41/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.1056 - accuracy: 0.7449 - val_loss: 1.1245 - val_accuracy: 0.7349\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1007 - accuracy: 0.7508 - val_loss: 1.1206 - val_accuracy: 0.7263\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0988 - accuracy: 0.7462 - val_loss: 1.1164 - val_accuracy: 0.7306\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0950 - accuracy: 0.7516 - val_loss: 1.1127 - val_accuracy: 0.7284\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0855 - accuracy: 0.7505 - val_loss: 1.1107 - val_accuracy: 0.7263\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0836 - accuracy: 0.7516 - val_loss: 1.1092 - val_accuracy: 0.7241\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0757 - accuracy: 0.7546 - val_loss: 1.1021 - val_accuracy: 0.7317\n","Epoch 48/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0736 - accuracy: 0.7546 - val_loss: 1.0997 - val_accuracy: 0.7435\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0733 - accuracy: 0.7532 - val_loss: 1.0943 - val_accuracy: 0.7371\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0738 - accuracy: 0.7468 - val_loss: 1.1042 - val_accuracy: 0.7414\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0745 - accuracy: 0.7524 - val_loss: 1.1064 - val_accuracy: 0.7198\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0556 - accuracy: 0.7600 - val_loss: 1.0839 - val_accuracy: 0.7425\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0580 - accuracy: 0.7570 - val_loss: 1.0854 - val_accuracy: 0.7425\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0505 - accuracy: 0.7608 - val_loss: 1.0761 - val_accuracy: 0.7349\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0456 - accuracy: 0.7600 - val_loss: 1.0728 - val_accuracy: 0.7317\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0437 - accuracy: 0.7648 - val_loss: 1.0714 - val_accuracy: 0.7360\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0439 - accuracy: 0.7557 - val_loss: 1.0667 - val_accuracy: 0.7328\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0302 - accuracy: 0.7694 - val_loss: 1.0641 - val_accuracy: 0.7349\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0361 - accuracy: 0.7597 - val_loss: 1.0676 - val_accuracy: 0.7252\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0267 - accuracy: 0.7643 - val_loss: 1.0571 - val_accuracy: 0.7457\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0221 - accuracy: 0.7627 - val_loss: 1.0665 - val_accuracy: 0.7177\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0195 - accuracy: 0.7656 - val_loss: 1.0539 - val_accuracy: 0.7468\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0176 - accuracy: 0.7648 - val_loss: 1.0484 - val_accuracy: 0.7295\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0119 - accuracy: 0.7664 - val_loss: 1.0526 - val_accuracy: 0.7284\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0117 - accuracy: 0.7656 - val_loss: 1.0653 - val_accuracy: 0.7198\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0035 - accuracy: 0.7737 - val_loss: 1.0354 - val_accuracy: 0.7478\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0023 - accuracy: 0.7716 - val_loss: 1.0382 - val_accuracy: 0.7295\n","Epoch 68/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9988 - accuracy: 0.7702 - val_loss: 1.0291 - val_accuracy: 0.7489\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9958 - accuracy: 0.7713 - val_loss: 1.0297 - val_accuracy: 0.7328\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9991 - accuracy: 0.7683 - val_loss: 1.0225 - val_accuracy: 0.7478\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9958 - accuracy: 0.7662 - val_loss: 1.0412 - val_accuracy: 0.7188\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9866 - accuracy: 0.7753 - val_loss: 1.0161 - val_accuracy: 0.7425\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9808 - accuracy: 0.7734 - val_loss: 1.0140 - val_accuracy: 0.7381\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9761 - accuracy: 0.7740 - val_loss: 1.0111 - val_accuracy: 0.7392\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9712 - accuracy: 0.7751 - val_loss: 1.0128 - val_accuracy: 0.7306\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9689 - accuracy: 0.7753 - val_loss: 1.0099 - val_accuracy: 0.7338\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9716 - accuracy: 0.7764 - val_loss: 1.0244 - val_accuracy: 0.7231\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9658 - accuracy: 0.7756 - val_loss: 0.9975 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9588 - accuracy: 0.7815 - val_loss: 0.9988 - val_accuracy: 0.7317\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9569 - accuracy: 0.7780 - val_loss: 0.9983 - val_accuracy: 0.7284\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9545 - accuracy: 0.7780 - val_loss: 1.0002 - val_accuracy: 0.7338\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9469 - accuracy: 0.7848 - val_loss: 0.9855 - val_accuracy: 0.7478\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9453 - accuracy: 0.7807 - val_loss: 0.9942 - val_accuracy: 0.7349\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9424 - accuracy: 0.7786 - val_loss: 0.9871 - val_accuracy: 0.7284\n","Epoch 85/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9379 - accuracy: 0.7842 - val_loss: 0.9751 - val_accuracy: 0.7543\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9333 - accuracy: 0.7864 - val_loss: 0.9725 - val_accuracy: 0.7489\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9312 - accuracy: 0.7834 - val_loss: 0.9696 - val_accuracy: 0.7511\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9286 - accuracy: 0.7899 - val_loss: 0.9702 - val_accuracy: 0.7392\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9251 - accuracy: 0.7845 - val_loss: 0.9795 - val_accuracy: 0.7349\n","Epoch 90/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9199 - accuracy: 0.7920 - val_loss: 0.9617 - val_accuracy: 0.7554\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9142 - accuracy: 0.7909 - val_loss: 0.9608 - val_accuracy: 0.7425\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9158 - accuracy: 0.7839 - val_loss: 0.9749 - val_accuracy: 0.7500\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9153 - accuracy: 0.7812 - val_loss: 0.9667 - val_accuracy: 0.7554\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9090 - accuracy: 0.7918 - val_loss: 0.9523 - val_accuracy: 0.7586\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9073 - accuracy: 0.7874 - val_loss: 0.9479 - val_accuracy: 0.7511\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9011 - accuracy: 0.7939 - val_loss: 0.9464 - val_accuracy: 0.7478\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8985 - accuracy: 0.7934 - val_loss: 0.9528 - val_accuracy: 0.7360\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8922 - accuracy: 0.7947 - val_loss: 0.9391 - val_accuracy: 0.7500\n","Epoch 99/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8927 - accuracy: 0.7969 - val_loss: 0.9382 - val_accuracy: 0.7619\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8843 - accuracy: 0.8001 - val_loss: 0.9444 - val_accuracy: 0.7371\n","{'loss': [1.4304602146148682, 1.424656629562378, 1.4180107116699219, 1.411219835281372, 1.403643250465393, 1.394532561302185, 1.3825262784957886, 1.3688777685165405, 1.3518776893615723, 1.3358752727508545, 1.3186923265457153, 1.3001105785369873, 1.286649227142334, 1.271897554397583, 1.2632927894592285, 1.2532938718795776, 1.239533543586731, 1.229216456413269, 1.222044825553894, 1.2175370454788208, 1.2080857753753662, 1.2005473375320435, 1.1945316791534424, 1.1889837980270386, 1.1840238571166992, 1.1817617416381836, 1.173400640487671, 1.169315218925476, 1.1623886823654175, 1.152988076210022, 1.1505811214447021, 1.145475149154663, 1.1410646438598633, 1.1321018934249878, 1.1301329135894775, 1.1283118724822998, 1.1227476596832275, 1.1189558506011963, 1.1151537895202637, 1.1076157093048096, 1.105560064315796, 1.1007356643676758, 1.098796010017395, 1.094997525215149, 1.0855109691619873, 1.0836148262023926, 1.0756573677062988, 1.073571801185608, 1.0732884407043457, 1.0737885236740112, 1.074546217918396, 1.0556137561798096, 1.0580041408538818, 1.0504815578460693, 1.0455963611602783, 1.043684959411621, 1.0439406633377075, 1.0302345752716064, 1.0360716581344604, 1.026660442352295, 1.0220975875854492, 1.0194975137710571, 1.0176374912261963, 1.0118658542633057, 1.0116934776306152, 1.0034685134887695, 1.0023144483566284, 0.9988382458686829, 0.9957801699638367, 0.9990973472595215, 0.9958204627037048, 0.9865989089012146, 0.9807513952255249, 0.9760640263557434, 0.9712479710578918, 0.9688875079154968, 0.9716328978538513, 0.9657759666442871, 0.958770215511322, 0.9569405913352966, 0.9544782042503357, 0.9469318985939026, 0.9452658891677856, 0.9424028992652893, 0.9378814697265625, 0.9333462119102478, 0.9311984777450562, 0.9285896420478821, 0.9250524640083313, 0.9199251532554626, 0.9141876101493835, 0.9157783389091492, 0.915297269821167, 0.9089639186859131, 0.9073283672332764, 0.9010931253433228, 0.8984805941581726, 0.8922214508056641, 0.8926641345024109, 0.8843352198600769], 'accuracy': [0.5002694129943848, 0.5352909564971924, 0.5770474076271057, 0.5886314511299133, 0.610722005367279, 0.6325430870056152, 0.6476293206214905, 0.6610991358757019, 0.6694504022598267, 0.6716055870056152, 0.6764547228813171, 0.6853448152542114, 0.6947737336158752, 0.6950430870056152, 0.6953125, 0.7066271305084229, 0.7149784564971924, 0.720366358757019, 0.717133641242981, 0.7195581793785095, 0.7230603694915771, 0.727909505367279, 0.724946141242981, 0.7300646305084229, 0.7233297228813171, 0.725215494632721, 0.7341055870056152, 0.7300646305084229, 0.7303340435028076, 0.7381465435028076, 0.7314116358757019, 0.7362607717514038, 0.7448814511299133, 0.7427262663841248, 0.7478448152542114, 0.7459590435028076, 0.7454202771186829, 0.7421875, 0.7456896305084229, 0.7446120977401733, 0.7448814511299133, 0.7508081793785095, 0.7462284564971924, 0.751616358757019, 0.7505387663841248, 0.751616358757019, 0.7545797228813171, 0.7545797228813171, 0.7532327771186829, 0.7467672228813171, 0.7524245977401733, 0.7599676847457886, 0.7570043206214905, 0.7607758641242981, 0.7599676847457886, 0.7648168206214905, 0.7556573152542114, 0.7693965435028076, 0.7596982717514038, 0.764277994632721, 0.7626616358757019, 0.765625, 0.7648168206214905, 0.7664331793785095, 0.765625, 0.7737069129943848, 0.7715517282485962, 0.7702047228813171, 0.7712823152542114, 0.7683189511299133, 0.7661637663841248, 0.7753232717514038, 0.7734375, 0.7739762663841248, 0.775053858757019, 0.7753232717514038, 0.7764008641242981, 0.7755926847457886, 0.7815194129943848, 0.7780172228813171, 0.7780172228813171, 0.7847521305084229, 0.7807112336158752, 0.7785560488700867, 0.7842133641242981, 0.7863685488700867, 0.7834051847457886, 0.7898706793785095, 0.7844827771186829, 0.7920258641242981, 0.7909482717514038, 0.7839439511299133, 0.78125, 0.7917564511299133, 0.787446141242981, 0.7939116358757019, 0.7933728694915771, 0.7947198152542114, 0.796875, 0.8001077771186829], 'val_loss': [1.42813241481781, 1.4232510328292847, 1.418249249458313, 1.4133583307266235, 1.408328652381897, 1.4032553434371948, 1.397100806236267, 1.390439748764038, 1.3816380500793457, 1.375184178352356, 1.3613165616989136, 1.347941517829895, 1.3383508920669556, 1.3172329664230347, 1.3007735013961792, 1.290985107421875, 1.2712152004241943, 1.256365418434143, 1.2525113821029663, 1.235668420791626, 1.2241971492767334, 1.2189478874206543, 1.2114485502243042, 1.2036643028259277, 1.197953224182129, 1.192126750946045, 1.1886638402938843, 1.183699131011963, 1.1794793605804443, 1.1739171743392944, 1.1707663536071777, 1.163329005241394, 1.159602403640747, 1.1625263690948486, 1.1511496305465698, 1.156653881072998, 1.1425180435180664, 1.1391414403915405, 1.1324212551116943, 1.130446195602417, 1.1245499849319458, 1.1206250190734863, 1.1164029836654663, 1.1127036809921265, 1.110670804977417, 1.1091892719268799, 1.1020622253417969, 1.0996710062026978, 1.094252109527588, 1.1042176485061646, 1.1064008474349976, 1.0839452743530273, 1.0853904485702515, 1.076053261756897, 1.0727840662002563, 1.071418285369873, 1.0667157173156738, 1.0640891790390015, 1.0675898790359497, 1.0570698976516724, 1.066461443901062, 1.05387282371521, 1.0483797788619995, 1.052550196647644, 1.0652761459350586, 1.0354324579238892, 1.0382325649261475, 1.029096007347107, 1.0297123193740845, 1.0224553346633911, 1.0412002801895142, 1.0161347389221191, 1.0140222311019897, 1.011089563369751, 1.0128194093704224, 1.0099444389343262, 1.0243699550628662, 0.997491180896759, 0.9987836480140686, 0.9982908964157104, 1.000215768814087, 0.9854893684387207, 0.9941507577896118, 0.9870699048042297, 0.9750988483428955, 0.9725436568260193, 0.9695743918418884, 0.9702135324478149, 0.9794631600379944, 0.9617385864257812, 0.9608421325683594, 0.974884569644928, 0.9667439460754395, 0.9522770643234253, 0.9478785395622253, 0.9463655948638916, 0.952815592288971, 0.9391077160835266, 0.9382026791572571, 0.9444057941436768], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48491379618644714, 0.5226293206214905, 0.5668103694915771, 0.6551724076271057, 0.5269396305084229, 0.6648706793785095, 0.6713362336158752, 0.6336206793785095, 0.6971982717514038, 0.6885775923728943, 0.6971982717514038, 0.7112069129943848, 0.7176724076271057, 0.7101293206214905, 0.712284505367279, 0.7155172228813171, 0.7101293206214905, 0.7144396305084229, 0.7155172228813171, 0.7219827771186829, 0.7230603694915771, 0.71875, 0.7209051847457886, 0.7165948152542114, 0.7230603694915771, 0.7198275923728943, 0.7306034564971924, 0.7219827771186829, 0.7230603694915771, 0.7209051847457886, 0.7230603694915771, 0.7230603694915771, 0.7241379022598267, 0.7284482717514038, 0.7219827771186829, 0.7349137663841248, 0.7262930870056152, 0.7306034564971924, 0.7284482717514038, 0.7262930870056152, 0.7241379022598267, 0.7316810488700867, 0.743534505367279, 0.7370689511299133, 0.7413793206214905, 0.7198275923728943, 0.7424569129943848, 0.7424569129943848, 0.7349137663841248, 0.7316810488700867, 0.735991358757019, 0.732758641242981, 0.7349137663841248, 0.725215494632721, 0.7456896305084229, 0.7176724076271057, 0.7467672228813171, 0.7295258641242981, 0.7284482717514038, 0.7198275923728943, 0.7478448152542114, 0.7295258641242981, 0.7489224076271057, 0.732758641242981, 0.7478448152542114, 0.71875, 0.7424569129943848, 0.7381465435028076, 0.7392241358757019, 0.7306034564971924, 0.7338362336158752, 0.7230603694915771, 0.743534505367279, 0.7316810488700867, 0.7284482717514038, 0.7338362336158752, 0.7478448152542114, 0.7349137663841248, 0.7284482717514038, 0.7543103694915771, 0.7489224076271057, 0.7510775923728943, 0.7392241358757019, 0.7349137663841248, 0.7553879022598267, 0.7424569129943848, 0.75, 0.7553879022598267, 0.7586206793785095, 0.7510775923728943, 0.7478448152542114, 0.735991358757019, 0.75, 0.7618534564971924, 0.7370689511299133]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 1.4308 - accuracy: 0.5210"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 54ms/step - loss: 1.4306 - accuracy: 0.5238 - val_loss: 1.4284 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4250 - accuracy: 0.5269 - val_loss: 1.4237 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4197 - accuracy: 0.5456 - val_loss: 1.4190 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4145 - accuracy: 0.5600 - val_loss: 1.4142 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4077 - accuracy: 0.5894 - val_loss: 1.4094 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4013 - accuracy: 0.5806 - val_loss: 1.4042 - val_accuracy: 0.6584\n","Epoch 7/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3931 - accuracy: 0.6183 - val_loss: 1.3992 - val_accuracy: 0.5192\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3840 - accuracy: 0.6415 - val_loss: 1.3940 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3729 - accuracy: 0.6522 - val_loss: 1.3871 - val_accuracy: 0.5916\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3628 - accuracy: 0.6392 - val_loss: 1.3805 - val_accuracy: 0.5396\n","Epoch 11/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3467 - accuracy: 0.6596 - val_loss: 1.3701 - val_accuracy: 0.6719\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3328 - accuracy: 0.6658 - val_loss: 1.3595 - val_accuracy: 0.6697\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3159 - accuracy: 0.6808 - val_loss: 1.3460 - val_accuracy: 0.6776\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2995 - accuracy: 0.6805 - val_loss: 1.3314 - val_accuracy: 0.6810\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2875 - accuracy: 0.6876 - val_loss: 1.3176 - val_accuracy: 0.6753\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2716 - accuracy: 0.6944 - val_loss: 1.3004 - val_accuracy: 0.6878\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2617 - accuracy: 0.6961 - val_loss: 1.2850 - val_accuracy: 0.6934\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2544 - accuracy: 0.7015 - val_loss: 1.2843 - val_accuracy: 0.6618\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2499 - accuracy: 0.6944 - val_loss: 1.2689 - val_accuracy: 0.6674\n","Epoch 20/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2367 - accuracy: 0.7100 - val_loss: 1.2429 - val_accuracy: 0.7048\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.2257 - accuracy: 0.7142 - val_loss: 1.2318 - val_accuracy: 0.7149\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2174 - accuracy: 0.7125 - val_loss: 1.2279 - val_accuracy: 0.6867\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2129 - accuracy: 0.7156 - val_loss: 1.2137 - val_accuracy: 0.7081\n","Epoch 24/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2074 - accuracy: 0.7162 - val_loss: 1.2065 - val_accuracy: 0.7025\n","Epoch 25/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1996 - accuracy: 0.7162 - val_loss: 1.1997 - val_accuracy: 0.7036\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1928 - accuracy: 0.7182 - val_loss: 1.1944 - val_accuracy: 0.7002\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1903 - accuracy: 0.7134 - val_loss: 1.1927 - val_accuracy: 0.7308\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1816 - accuracy: 0.7241 - val_loss: 1.1842 - val_accuracy: 0.7240\n","Epoch 29/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1759 - accuracy: 0.7278 - val_loss: 1.1898 - val_accuracy: 0.7274\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1697 - accuracy: 0.7289 - val_loss: 1.1792 - val_accuracy: 0.6934\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1718 - accuracy: 0.7184 - val_loss: 1.1692 - val_accuracy: 0.7240\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1612 - accuracy: 0.7278 - val_loss: 1.1640 - val_accuracy: 0.7161\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1556 - accuracy: 0.7303 - val_loss: 1.1629 - val_accuracy: 0.7002\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1501 - accuracy: 0.7295 - val_loss: 1.1552 - val_accuracy: 0.7195\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1423 - accuracy: 0.7346 - val_loss: 1.1526 - val_accuracy: 0.7104\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1323 - accuracy: 0.7405 - val_loss: 1.1470 - val_accuracy: 0.7195\n","Epoch 37/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1314 - accuracy: 0.7397 - val_loss: 1.1476 - val_accuracy: 0.7342\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1252 - accuracy: 0.7436 - val_loss: 1.1386 - val_accuracy: 0.7296\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1195 - accuracy: 0.7383 - val_loss: 1.1456 - val_accuracy: 0.7002\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1178 - accuracy: 0.7391 - val_loss: 1.1306 - val_accuracy: 0.7251\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1121 - accuracy: 0.7445 - val_loss: 1.1289 - val_accuracy: 0.7149\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1066 - accuracy: 0.7467 - val_loss: 1.1279 - val_accuracy: 0.7127\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1024 - accuracy: 0.7490 - val_loss: 1.1209 - val_accuracy: 0.7217\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0944 - accuracy: 0.7499 - val_loss: 1.1197 - val_accuracy: 0.7432\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0915 - accuracy: 0.7507 - val_loss: 1.1175 - val_accuracy: 0.7172\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0845 - accuracy: 0.7499 - val_loss: 1.1095 - val_accuracy: 0.7376\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0875 - accuracy: 0.7467 - val_loss: 1.1069 - val_accuracy: 0.7240\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0780 - accuracy: 0.7513 - val_loss: 1.1057 - val_accuracy: 0.7206\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0773 - accuracy: 0.7490 - val_loss: 1.1033 - val_accuracy: 0.7387\n","Epoch 50/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0731 - accuracy: 0.7544 - val_loss: 1.0945 - val_accuracy: 0.7330\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0633 - accuracy: 0.7581 - val_loss: 1.0903 - val_accuracy: 0.7398\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0580 - accuracy: 0.7547 - val_loss: 1.0903 - val_accuracy: 0.7172\n","Epoch 53/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0572 - accuracy: 0.7547 - val_loss: 1.0833 - val_accuracy: 0.7296\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0595 - accuracy: 0.7558 - val_loss: 1.0796 - val_accuracy: 0.7432\n","Epoch 55/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0595 - accuracy: 0.7496 - val_loss: 1.0782 - val_accuracy: 0.7455\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0497 - accuracy: 0.7606 - val_loss: 1.0845 - val_accuracy: 0.7443\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0464 - accuracy: 0.7564 - val_loss: 1.0707 - val_accuracy: 0.7387\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0382 - accuracy: 0.7592 - val_loss: 1.0682 - val_accuracy: 0.7443\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0440 - accuracy: 0.7550 - val_loss: 1.0975 - val_accuracy: 0.7296\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0335 - accuracy: 0.7558 - val_loss: 1.0694 - val_accuracy: 0.7093\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0310 - accuracy: 0.7615 - val_loss: 1.0632 - val_accuracy: 0.7161\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0204 - accuracy: 0.7705 - val_loss: 1.0566 - val_accuracy: 0.7353\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0195 - accuracy: 0.7566 - val_loss: 1.0545 - val_accuracy: 0.7477\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0153 - accuracy: 0.7620 - val_loss: 1.0543 - val_accuracy: 0.7432\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0127 - accuracy: 0.7637 - val_loss: 1.0482 - val_accuracy: 0.7455\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0064 - accuracy: 0.7711 - val_loss: 1.0533 - val_accuracy: 0.7115\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0062 - accuracy: 0.7612 - val_loss: 1.0448 - val_accuracy: 0.7296\n","Epoch 68/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0045 - accuracy: 0.7668 - val_loss: 1.0518 - val_accuracy: 0.7127\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9937 - accuracy: 0.7714 - val_loss: 1.0371 - val_accuracy: 0.7421\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9919 - accuracy: 0.7705 - val_loss: 1.0336 - val_accuracy: 0.7398\n","Epoch 71/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9858 - accuracy: 0.7818 - val_loss: 1.0317 - val_accuracy: 0.7455\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9865 - accuracy: 0.7719 - val_loss: 1.0320 - val_accuracy: 0.7240\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9770 - accuracy: 0.7759 - val_loss: 1.0596 - val_accuracy: 0.7025\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9842 - accuracy: 0.7736 - val_loss: 1.0202 - val_accuracy: 0.7443\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9742 - accuracy: 0.7793 - val_loss: 1.0207 - val_accuracy: 0.7477\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9658 - accuracy: 0.7773 - val_loss: 1.0345 - val_accuracy: 0.7443\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9683 - accuracy: 0.7725 - val_loss: 1.0144 - val_accuracy: 0.7511\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9641 - accuracy: 0.7776 - val_loss: 1.0299 - val_accuracy: 0.7104\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9534 - accuracy: 0.7847 - val_loss: 1.0093 - val_accuracy: 0.7477\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9596 - accuracy: 0.7776 - val_loss: 1.0135 - val_accuracy: 0.7161\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9485 - accuracy: 0.7869 - val_loss: 1.0050 - val_accuracy: 0.7466\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9482 - accuracy: 0.7832 - val_loss: 1.0139 - val_accuracy: 0.7455\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9605 - accuracy: 0.7691 - val_loss: 1.0012 - val_accuracy: 0.7466\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9398 - accuracy: 0.7847 - val_loss: 1.0016 - val_accuracy: 0.7477\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9365 - accuracy: 0.7852 - val_loss: 0.9940 - val_accuracy: 0.7489\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9296 - accuracy: 0.7917 - val_loss: 0.9910 - val_accuracy: 0.7477\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9280 - accuracy: 0.7869 - val_loss: 1.0021 - val_accuracy: 0.7477\n","Epoch 88/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9266 - accuracy: 0.7883 - val_loss: 0.9889 - val_accuracy: 0.7489\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9180 - accuracy: 0.7858 - val_loss: 0.9956 - val_accuracy: 0.7500\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9186 - accuracy: 0.7906 - val_loss: 0.9850 - val_accuracy: 0.7523\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9144 - accuracy: 0.7909 - val_loss: 0.9851 - val_accuracy: 0.7455\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9074 - accuracy: 0.7917 - val_loss: 0.9792 - val_accuracy: 0.7466\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9051 - accuracy: 0.7943 - val_loss: 0.9840 - val_accuracy: 0.7262\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9061 - accuracy: 0.7909 - val_loss: 0.9733 - val_accuracy: 0.7500\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8978 - accuracy: 0.7912 - val_loss: 0.9850 - val_accuracy: 0.7251\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8959 - accuracy: 0.7974 - val_loss: 0.9791 - val_accuracy: 0.7274\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8949 - accuracy: 0.7926 - val_loss: 0.9668 - val_accuracy: 0.7466\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8865 - accuracy: 0.8002 - val_loss: 0.9647 - val_accuracy: 0.7432\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8861 - accuracy: 0.7943 - val_loss: 0.9613 - val_accuracy: 0.7511\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8831 - accuracy: 0.7971 - val_loss: 0.9638 - val_accuracy: 0.7364\n","{'loss': [1.430560827255249, 1.4250378608703613, 1.4197278022766113, 1.4145311117172241, 1.407717227935791, 1.401323914527893, 1.3930718898773193, 1.384008526802063, 1.3728832006454468, 1.3628239631652832, 1.3466796875, 1.3327640295028687, 1.3159130811691284, 1.2995129823684692, 1.2874531745910645, 1.2715771198272705, 1.2616959810256958, 1.254409670829773, 1.249855637550354, 1.2366701364517212, 1.225742220878601, 1.217415452003479, 1.2129348516464233, 1.2073582410812378, 1.1995813846588135, 1.192805290222168, 1.1902813911437988, 1.1815681457519531, 1.1758793592453003, 1.1697437763214111, 1.1717727184295654, 1.1612268686294556, 1.1556127071380615, 1.1501033306121826, 1.1423496007919312, 1.1323351860046387, 1.131384015083313, 1.1252423524856567, 1.1194571256637573, 1.1178193092346191, 1.112146258354187, 1.106624722480774, 1.102401614189148, 1.0943870544433594, 1.0915298461914062, 1.084506869316101, 1.0875393152236938, 1.078027367591858, 1.077341914176941, 1.0730618238449097, 1.0633326768875122, 1.0580296516418457, 1.057167649269104, 1.059544324874878, 1.0594956874847412, 1.0496718883514404, 1.0464140176773071, 1.0381604433059692, 1.043956995010376, 1.0334609746932983, 1.0309847593307495, 1.0203585624694824, 1.0194758176803589, 1.015285611152649, 1.0126806497573853, 1.0063681602478027, 1.0062059164047241, 1.004480004310608, 0.9937273859977722, 0.9918769001960754, 0.9857839345932007, 0.9864532947540283, 0.9769678115844727, 0.9842308163642883, 0.9741693139076233, 0.9657558798789978, 0.9683108329772949, 0.9641152024269104, 0.9534417986869812, 0.9596189260482788, 0.9485046863555908, 0.948188841342926, 0.9604549407958984, 0.9398316144943237, 0.9364917278289795, 0.9296135902404785, 0.928016722202301, 0.926621675491333, 0.9180142879486084, 0.9185717701911926, 0.9143966436386108, 0.907362163066864, 0.9050901532173157, 0.9060550332069397, 0.8977564573287964, 0.8958882689476013, 0.8948882818222046, 0.8865084648132324, 0.8860755562782288, 0.8831446766853333], 'accuracy': [0.5237690806388855, 0.5268816947937012, 0.54555743932724, 0.5599886775016785, 0.5894170999526978, 0.5806451439857483, 0.6182795763015747, 0.6414827108383179, 0.6522354483604431, 0.6392189860343933, 0.6595925092697144, 0.6658177971839905, 0.6808149218559265, 0.6805319786071777, 0.6876060962677002, 0.6943972706794739, 0.6960950493812561, 0.7014714479446411, 0.6943972706794739, 0.709960401058197, 0.7142048478126526, 0.7125070691108704, 0.715619683265686, 0.7161856293678284, 0.7161856293678284, 0.7181664109230042, 0.7133559584617615, 0.7241086363792419, 0.7277871966362, 0.7289190888404846, 0.7184493541717529, 0.7277871966362, 0.7303339242935181, 0.7294849753379822, 0.7345783710479736, 0.7405206561088562, 0.7396717667579651, 0.7436332702636719, 0.7382569313049316, 0.7391058206558228, 0.744482159614563, 0.7467458844184875, 0.7490096092224121, 0.7498584985733032, 0.7507073879241943, 0.7498584985733032, 0.7467458844184875, 0.7512733340263367, 0.7490096092224121, 0.7543859481811523, 0.7580645084381104, 0.7546689510345459, 0.7546689510345459, 0.7558007836341858, 0.7495755553245544, 0.7606111764907837, 0.7563667297363281, 0.759196400642395, 0.7549518942832947, 0.7558007836341858, 0.7614601254463196, 0.7705150246620178, 0.7566496729850769, 0.7620260119438171, 0.7637238502502441, 0.7710809111595154, 0.761177122592926, 0.7668364644050598, 0.7713639140129089, 0.7705150246620178, 0.7818335890769958, 0.7719298005104065, 0.7758913636207581, 0.7736276388168335, 0.7792869210243225, 0.7773061394691467, 0.7724957466125488, 0.7775891423225403, 0.7846632599830627, 0.7775891423225403, 0.7869269847869873, 0.7832484245300293, 0.7691001892089844, 0.7846632599830627, 0.7852292060852051, 0.79173743724823, 0.7869269847869873, 0.7883418202400208, 0.7857951521873474, 0.7906055450439453, 0.7908884882926941, 0.79173743724823, 0.7942841053009033, 0.7908884882926941, 0.7911714911460876, 0.797396719455719, 0.7925863265991211, 0.8002263903617859, 0.7942841053009033, 0.7971137762069702], 'val_loss': [1.4283596277236938, 1.4236979484558105, 1.4189602136611938, 1.4141912460327148, 1.4094350337982178, 1.4042351245880127, 1.3991953134536743, 1.3939669132232666, 1.3871128559112549, 1.3805478811264038, 1.3701413869857788, 1.3594785928726196, 1.3460272550582886, 1.3313636779785156, 1.317641019821167, 1.3004257678985596, 1.284999966621399, 1.284342646598816, 1.2688653469085693, 1.242878794670105, 1.2318470478057861, 1.227851152420044, 1.2137266397476196, 1.2065340280532837, 1.1997439861297607, 1.194358468055725, 1.1926562786102295, 1.1841756105422974, 1.189753770828247, 1.179164171218872, 1.1692184209823608, 1.1639821529388428, 1.1629401445388794, 1.1552281379699707, 1.1525511741638184, 1.1469924449920654, 1.1475818157196045, 1.1385945081710815, 1.1456326246261597, 1.1306331157684326, 1.1289453506469727, 1.1279053688049316, 1.1208670139312744, 1.119716763496399, 1.1174535751342773, 1.109531283378601, 1.106919288635254, 1.1056835651397705, 1.103270411491394, 1.0944790840148926, 1.0903126001358032, 1.0902632474899292, 1.0832852125167847, 1.0796372890472412, 1.0781660079956055, 1.0844554901123047, 1.0707494020462036, 1.0681995153427124, 1.0974522829055786, 1.0694423913955688, 1.0631957054138184, 1.0566377639770508, 1.0545347929000854, 1.0543131828308105, 1.0481895208358765, 1.0533031225204468, 1.0448174476623535, 1.0517781972885132, 1.037087082862854, 1.0335551500320435, 1.031735897064209, 1.0320453643798828, 1.0596482753753662, 1.0201932191848755, 1.0207499265670776, 1.0345255136489868, 1.0144044160842896, 1.029909610748291, 1.009254813194275, 1.013541340827942, 1.0049874782562256, 1.013946294784546, 1.001163363456726, 1.0015827417373657, 0.9939627647399902, 0.9910112619400024, 1.002057671546936, 0.9889360070228577, 0.9956339597702026, 0.9849924445152283, 0.9850584864616394, 0.979178249835968, 0.9839572906494141, 0.9732744693756104, 0.9850428104400635, 0.9791133999824524, 0.9667820334434509, 0.9646973609924316, 0.9613088369369507, 0.9638375043869019], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.6583710312843323, 0.5192307829856873, 0.4954751133918762, 0.5916289687156677, 0.5395927429199219, 0.6719456911087036, 0.6696832776069641, 0.6776018142700195, 0.6809954643249512, 0.6753393411636353, 0.6877828240394592, 0.6934388875961304, 0.6617646813392639, 0.6674208045005798, 0.7047511339187622, 0.7149321436882019, 0.6866515874862671, 0.7081447839736938, 0.7024886608123779, 0.7036198973655701, 0.7002262473106384, 0.7307692170143127, 0.7239819169044495, 0.7273755669593811, 0.6934388875961304, 0.7239819169044495, 0.7160633206367493, 0.7002262473106384, 0.7194570302963257, 0.7104072570800781, 0.7194570302963257, 0.7341628670692444, 0.7296379804611206, 0.7002262473106384, 0.7251130938529968, 0.7149321436882019, 0.7126696705818176, 0.7217194437980652, 0.7432126402854919, 0.7171945571899414, 0.7375565767288208, 0.7239819169044495, 0.720588207244873, 0.7386877536773682, 0.733031690120697, 0.7398189902305603, 0.7171945571899414, 0.7296379804611206, 0.7432126402854919, 0.7454751133918762, 0.7443438768386841, 0.7386877536773682, 0.7443438768386841, 0.7296379804611206, 0.709276020526886, 0.7160633206367493, 0.7352941036224365, 0.7477375268936157, 0.7432126402854919, 0.7454751133918762, 0.7115384340286255, 0.7296379804611206, 0.7126696705818176, 0.7420814633369446, 0.7398189902305603, 0.7454751133918762, 0.7239819169044495, 0.7024886608123779, 0.7443438768386841, 0.7477375268936157, 0.7443438768386841, 0.7511312365531921, 0.7104072570800781, 0.7477375268936157, 0.7160633206367493, 0.7466063499450684, 0.7454751133918762, 0.7466063499450684, 0.7477375268936157, 0.7488687634468079, 0.7477375268936157, 0.7477375268936157, 0.7488687634468079, 0.75, 0.7522624731063843, 0.7454751133918762, 0.7466063499450684, 0.726244330406189, 0.75, 0.7251130938529968, 0.7273755669593811, 0.7466063499450684, 0.7432126402854919, 0.7511312365531921, 0.7364253401756287]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/31 [=========================>....] - ETA: 0s - loss: 1.4309 - accuracy: 0.5009"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 51ms/step - loss: 1.4306 - accuracy: 0.5047 - val_loss: 1.4279 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4245 - accuracy: 0.5292 - val_loss: 1.4227 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4177 - accuracy: 0.5607 - val_loss: 1.4174 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4111 - accuracy: 0.5884 - val_loss: 1.4122 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4031 - accuracy: 0.6083 - val_loss: 1.4068 - val_accuracy: 0.4835\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3940 - accuracy: 0.6385 - val_loss: 1.4014 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3828 - accuracy: 0.6403 - val_loss: 1.3949 - val_accuracy: 0.5424\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3693 - accuracy: 0.6563 - val_loss: 1.3881 - val_accuracy: 0.5062\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3522 - accuracy: 0.6685 - val_loss: 1.3801 - val_accuracy: 0.5041\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3325 - accuracy: 0.6703 - val_loss: 1.3688 - val_accuracy: 0.5940\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3117 - accuracy: 0.6897 - val_loss: 1.3578 - val_accuracy: 0.5661\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2919 - accuracy: 0.6884 - val_loss: 1.3403 - val_accuracy: 0.6508\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2722 - accuracy: 0.6966 - val_loss: 1.3198 - val_accuracy: 0.7056\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2587 - accuracy: 0.7062 - val_loss: 1.3078 - val_accuracy: 0.6643\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2411 - accuracy: 0.7140 - val_loss: 1.2840 - val_accuracy: 0.7180\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2314 - accuracy: 0.7194 - val_loss: 1.2698 - val_accuracy: 0.7149\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2205 - accuracy: 0.7181 - val_loss: 1.2707 - val_accuracy: 0.6550\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2125 - accuracy: 0.7186 - val_loss: 1.2427 - val_accuracy: 0.7149\n","Epoch 19/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.2058 - accuracy: 0.7266 - val_loss: 1.2317 - val_accuracy: 0.7221\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1987 - accuracy: 0.7287 - val_loss: 1.2211 - val_accuracy: 0.7221\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1944 - accuracy: 0.7230 - val_loss: 1.2133 - val_accuracy: 0.7283\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1847 - accuracy: 0.7310 - val_loss: 1.2124 - val_accuracy: 0.7190\n","Epoch 23/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.1769 - accuracy: 0.7349 - val_loss: 1.2013 - val_accuracy: 0.7324\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1756 - accuracy: 0.7227 - val_loss: 1.1992 - val_accuracy: 0.7190\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1662 - accuracy: 0.7336 - val_loss: 1.1966 - val_accuracy: 0.7107\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1635 - accuracy: 0.7318 - val_loss: 1.1867 - val_accuracy: 0.7324\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1556 - accuracy: 0.7328 - val_loss: 1.1861 - val_accuracy: 0.7252\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1502 - accuracy: 0.7388 - val_loss: 1.1772 - val_accuracy: 0.7304\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1439 - accuracy: 0.7411 - val_loss: 1.1783 - val_accuracy: 0.7200\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1376 - accuracy: 0.7385 - val_loss: 1.1699 - val_accuracy: 0.7366\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1318 - accuracy: 0.7426 - val_loss: 1.1658 - val_accuracy: 0.7355\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1287 - accuracy: 0.7393 - val_loss: 1.1688 - val_accuracy: 0.7221\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1243 - accuracy: 0.7357 - val_loss: 1.1683 - val_accuracy: 0.7128\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1163 - accuracy: 0.7444 - val_loss: 1.1706 - val_accuracy: 0.7200\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1138 - accuracy: 0.7460 - val_loss: 1.1507 - val_accuracy: 0.7335\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1060 - accuracy: 0.7434 - val_loss: 1.1451 - val_accuracy: 0.7407\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1025 - accuracy: 0.7519 - val_loss: 1.1408 - val_accuracy: 0.7428\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0983 - accuracy: 0.7452 - val_loss: 1.1429 - val_accuracy: 0.7366\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0928 - accuracy: 0.7468 - val_loss: 1.1575 - val_accuracy: 0.6994\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0883 - accuracy: 0.7509 - val_loss: 1.1340 - val_accuracy: 0.7386\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0827 - accuracy: 0.7532 - val_loss: 1.1247 - val_accuracy: 0.7386\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0776 - accuracy: 0.7537 - val_loss: 1.1236 - val_accuracy: 0.7304\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0752 - accuracy: 0.7491 - val_loss: 1.1183 - val_accuracy: 0.7376\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0688 - accuracy: 0.7522 - val_loss: 1.1148 - val_accuracy: 0.7469\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0690 - accuracy: 0.7496 - val_loss: 1.1184 - val_accuracy: 0.7417\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0624 - accuracy: 0.7566 - val_loss: 1.1067 - val_accuracy: 0.7469\n","Epoch 47/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0555 - accuracy: 0.7537 - val_loss: 1.1028 - val_accuracy: 0.7490\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0508 - accuracy: 0.7599 - val_loss: 1.0997 - val_accuracy: 0.7397\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0478 - accuracy: 0.7643 - val_loss: 1.1039 - val_accuracy: 0.7438\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0461 - accuracy: 0.7605 - val_loss: 1.0943 - val_accuracy: 0.7438\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0425 - accuracy: 0.7519 - val_loss: 1.0894 - val_accuracy: 0.7386\n","Epoch 52/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0335 - accuracy: 0.7589 - val_loss: 1.0854 - val_accuracy: 0.7500\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0330 - accuracy: 0.7594 - val_loss: 1.0931 - val_accuracy: 0.7469\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0344 - accuracy: 0.7625 - val_loss: 1.0801 - val_accuracy: 0.7459\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0228 - accuracy: 0.7656 - val_loss: 1.0816 - val_accuracy: 0.7490\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0202 - accuracy: 0.7615 - val_loss: 1.0712 - val_accuracy: 0.7490\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0148 - accuracy: 0.7605 - val_loss: 1.0730 - val_accuracy: 0.7531\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0155 - accuracy: 0.7656 - val_loss: 1.0696 - val_accuracy: 0.7324\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0079 - accuracy: 0.7643 - val_loss: 1.0621 - val_accuracy: 0.7521\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0097 - accuracy: 0.7584 - val_loss: 1.0624 - val_accuracy: 0.7386\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0000 - accuracy: 0.7680 - val_loss: 1.0561 - val_accuracy: 0.7448\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9924 - accuracy: 0.7695 - val_loss: 1.0748 - val_accuracy: 0.7076\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9979 - accuracy: 0.7649 - val_loss: 1.0570 - val_accuracy: 0.7314\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9926 - accuracy: 0.7651 - val_loss: 1.0492 - val_accuracy: 0.7386\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9848 - accuracy: 0.7700 - val_loss: 1.0431 - val_accuracy: 0.7479\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9800 - accuracy: 0.7711 - val_loss: 1.0441 - val_accuracy: 0.7366\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9770 - accuracy: 0.7695 - val_loss: 1.0415 - val_accuracy: 0.7552\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9760 - accuracy: 0.7690 - val_loss: 1.0369 - val_accuracy: 0.7417\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9681 - accuracy: 0.7742 - val_loss: 1.0336 - val_accuracy: 0.7417\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9644 - accuracy: 0.7767 - val_loss: 1.0308 - val_accuracy: 0.7469\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9635 - accuracy: 0.7677 - val_loss: 1.0364 - val_accuracy: 0.7221\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9573 - accuracy: 0.7734 - val_loss: 1.0431 - val_accuracy: 0.7531\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9659 - accuracy: 0.7695 - val_loss: 1.0201 - val_accuracy: 0.7479\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9540 - accuracy: 0.7742 - val_loss: 1.0201 - val_accuracy: 0.7562\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9446 - accuracy: 0.7721 - val_loss: 1.0147 - val_accuracy: 0.7521\n","Epoch 76/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9414 - accuracy: 0.7804 - val_loss: 1.0139 - val_accuracy: 0.7572\n","Epoch 77/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9402 - accuracy: 0.7780 - val_loss: 1.0122 - val_accuracy: 0.7583\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9354 - accuracy: 0.7814 - val_loss: 1.0067 - val_accuracy: 0.7552\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9326 - accuracy: 0.7788 - val_loss: 1.0046 - val_accuracy: 0.7500\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9248 - accuracy: 0.7817 - val_loss: 1.0012 - val_accuracy: 0.7510\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9227 - accuracy: 0.7835 - val_loss: 1.0000 - val_accuracy: 0.7510\n","Epoch 82/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9230 - accuracy: 0.7798 - val_loss: 0.9966 - val_accuracy: 0.7593\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9188 - accuracy: 0.7806 - val_loss: 0.9931 - val_accuracy: 0.7479\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9160 - accuracy: 0.7850 - val_loss: 1.0007 - val_accuracy: 0.7293\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9129 - accuracy: 0.7824 - val_loss: 0.9896 - val_accuracy: 0.7479\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9067 - accuracy: 0.7798 - val_loss: 0.9876 - val_accuracy: 0.7603\n","Epoch 87/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9059 - accuracy: 0.7910 - val_loss: 0.9965 - val_accuracy: 0.7614\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9006 - accuracy: 0.7842 - val_loss: 0.9818 - val_accuracy: 0.7500\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8945 - accuracy: 0.7876 - val_loss: 0.9796 - val_accuracy: 0.7459\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8961 - accuracy: 0.7863 - val_loss: 0.9763 - val_accuracy: 0.7603\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8885 - accuracy: 0.7897 - val_loss: 0.9811 - val_accuracy: 0.7386\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8877 - accuracy: 0.7894 - val_loss: 0.9717 - val_accuracy: 0.7562\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8915 - accuracy: 0.7819 - val_loss: 0.9689 - val_accuracy: 0.7614\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8894 - accuracy: 0.7853 - val_loss: 0.9687 - val_accuracy: 0.7510\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8780 - accuracy: 0.7879 - val_loss: 0.9618 - val_accuracy: 0.7583\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8764 - accuracy: 0.7891 - val_loss: 0.9639 - val_accuracy: 0.7624\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8746 - accuracy: 0.7930 - val_loss: 0.9597 - val_accuracy: 0.7603\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8655 - accuracy: 0.7948 - val_loss: 0.9557 - val_accuracy: 0.7634\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8637 - accuracy: 0.7992 - val_loss: 0.9548 - val_accuracy: 0.7603\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8562 - accuracy: 0.7961 - val_loss: 0.9717 - val_accuracy: 0.7252\n","{'loss': [1.4305546283721924, 1.4245166778564453, 1.417741060256958, 1.4111464023590088, 1.4031319618225098, 1.3940285444259644, 1.382763147354126, 1.3693363666534424, 1.3522493839263916, 1.332526445388794, 1.3116730451583862, 1.2919098138809204, 1.2722207307815552, 1.2586954832077026, 1.2410966157913208, 1.2313954830169678, 1.220456600189209, 1.2124698162078857, 1.2058318853378296, 1.1987359523773193, 1.1943589448928833, 1.184702754020691, 1.1768848896026611, 1.1755728721618652, 1.1662425994873047, 1.1634798049926758, 1.1556463241577148, 1.1501884460449219, 1.1439462900161743, 1.1376460790634155, 1.1318358182907104, 1.1287413835525513, 1.1243133544921875, 1.1163147687911987, 1.1138399839401245, 1.1059595346450806, 1.102465271949768, 1.0982882976531982, 1.0928312540054321, 1.0883325338363647, 1.082654356956482, 1.0775866508483887, 1.0752171277999878, 1.0687588453292847, 1.0689599514007568, 1.0623561143875122, 1.0555214881896973, 1.0507913827896118, 1.0478211641311646, 1.0460597276687622, 1.0424762964248657, 1.0334937572479248, 1.0330153703689575, 1.0344328880310059, 1.0228087902069092, 1.0201680660247803, 1.0147733688354492, 1.015456199645996, 1.0078532695770264, 1.0096712112426758, 0.9999530911445618, 0.9924395084381104, 0.9978960156440735, 0.9925591349601746, 0.9848485589027405, 0.9800003170967102, 0.9769657850265503, 0.97600919008255, 0.9680690169334412, 0.9643659591674805, 0.963456928730011, 0.9572596549987793, 0.9658936858177185, 0.954018771648407, 0.9446240067481995, 0.9414222836494446, 0.9401827454566956, 0.9353885650634766, 0.9326049089431763, 0.9248236417770386, 0.9226914048194885, 0.923039972782135, 0.9187968373298645, 0.9160341024398804, 0.9129181504249573, 0.9067407846450806, 0.9059052467346191, 0.9005786776542664, 0.8944618105888367, 0.896124541759491, 0.8885155916213989, 0.8877176642417908, 0.8915320038795471, 0.8893609642982483, 0.8779829144477844, 0.8764368295669556, 0.8745660185813904, 0.8654907941818237, 0.8636668920516968, 0.8562448620796204], 'accuracy': [0.5046511888504028, 0.529198944568634, 0.5607235431671143, 0.5883721113204956, 0.6082687377929688, 0.6385012865066528, 0.6403100490570068, 0.6563307642936707, 0.6684754490852356, 0.6702842116355896, 0.6896640658378601, 0.6883720755577087, 0.6966408491134644, 0.7062015533447266, 0.7139534950256348, 0.7193798422813416, 0.7180878520011902, 0.7186046242713928, 0.7266150116920471, 0.7286821603775024, 0.7229974269866943, 0.7310077548027039, 0.734883725643158, 0.722739040851593, 0.7335917353630066, 0.7317829728126526, 0.7328165173530579, 0.7387596964836121, 0.7410852909088135, 0.7385013103485107, 0.7426356673240662, 0.7392764687538147, 0.7356589436531067, 0.7444444298744202, 0.7459948062896729, 0.7434108257293701, 0.751937985420227, 0.7452196478843689, 0.7467700242996216, 0.750904381275177, 0.7532299757003784, 0.753746747970581, 0.749095618724823, 0.7521963715553284, 0.7496123909950256, 0.7565891742706299, 0.753746747970581, 0.7599483132362366, 0.7643410563468933, 0.760465145111084, 0.751937985420227, 0.7589147090911865, 0.7594315409660339, 0.7625322937965393, 0.7656330466270447, 0.7614986896514893, 0.760465145111084, 0.7656330466270447, 0.7643410563468933, 0.7583979368209839, 0.7679586410522461, 0.7695090174674988, 0.7648578882217407, 0.765116274356842, 0.7700258493423462, 0.7710594534873962, 0.7695090174674988, 0.7689922451972961, 0.7741602063179016, 0.7767441868782043, 0.7677002549171448, 0.7733849883079529, 0.7695090174674988, 0.7741602063179016, 0.7720929980278015, 0.7803617715835571, 0.7780361771583557, 0.7813953757286072, 0.7788113951683044, 0.7816537618637085, 0.7834625244140625, 0.7798449397087097, 0.7806201577186584, 0.7850129008293152, 0.7824289202690125, 0.7798449397087097, 0.7909560799598694, 0.7842377424240112, 0.7875968813896179, 0.7863048911094666, 0.789664089679718, 0.7894057035446167, 0.7819121479988098, 0.7852713465690613, 0.7878552675247192, 0.7891472578048706, 0.7930232286453247, 0.7948320508003235, 0.7992247939109802, 0.7961240410804749], 'val_loss': [1.4278836250305176, 1.4226715564727783, 1.4174469709396362, 1.4122397899627686, 1.4067819118499756, 1.4013738632202148, 1.3949106931686401, 1.3880919218063354, 1.380089521408081, 1.3688453435897827, 1.3578276634216309, 1.3402901887893677, 1.3197999000549316, 1.3078495264053345, 1.284027338027954, 1.269809365272522, 1.270695447921753, 1.2427144050598145, 1.2316945791244507, 1.2210590839385986, 1.2132837772369385, 1.2123596668243408, 1.2012542486190796, 1.1992090940475464, 1.1966094970703125, 1.186668872833252, 1.1861003637313843, 1.1772218942642212, 1.1783438920974731, 1.169919490814209, 1.1657817363739014, 1.1688122749328613, 1.1683249473571777, 1.1706312894821167, 1.1507487297058105, 1.145134687423706, 1.1408194303512573, 1.1428840160369873, 1.1574909687042236, 1.1340289115905762, 1.1247462034225464, 1.1235790252685547, 1.1183160543441772, 1.1147814989089966, 1.1184073686599731, 1.1067497730255127, 1.1028379201889038, 1.099722981452942, 1.1039413213729858, 1.0942645072937012, 1.0894348621368408, 1.0854424238204956, 1.0931174755096436, 1.0801035165786743, 1.0816092491149902, 1.0712368488311768, 1.0729548931121826, 1.069630742073059, 1.0620715618133545, 1.0624216794967651, 1.0560804605484009, 1.0748143196105957, 1.0570151805877686, 1.0492185354232788, 1.043109655380249, 1.0440599918365479, 1.0414714813232422, 1.0368534326553345, 1.0336291790008545, 1.030801773071289, 1.0363625288009644, 1.0430653095245361, 1.0201177597045898, 1.0201044082641602, 1.0146567821502686, 1.0138510465621948, 1.0121675729751587, 1.0067322254180908, 1.004592776298523, 1.0012190341949463, 1.0000215768814087, 0.9966087937355042, 0.9931384921073914, 1.0007294416427612, 0.9895524978637695, 0.9875551462173462, 0.9964891076087952, 0.9817692041397095, 0.9795814752578735, 0.9762666821479797, 0.9810571074485779, 0.9717079401016235, 0.9688825011253357, 0.9686737656593323, 0.9618156552314758, 0.9639405012130737, 0.9597069621086121, 0.9557449817657471, 0.9548165798187256, 0.9717480540275574], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4834710657596588, 0.48553720116615295, 0.5423553586006165, 0.5061983466148376, 0.5041322112083435, 0.5940082669258118, 0.56611567735672, 0.6508264541625977, 0.7055785059928894, 0.66425621509552, 0.7179751992225647, 0.7148760557174683, 0.6549586653709412, 0.7148760557174683, 0.7221074104309082, 0.7221074104309082, 0.7283057570457458, 0.7190082669258118, 0.7324380278587341, 0.7190082669258118, 0.71074378490448, 0.7324380278587341, 0.7252066135406494, 0.73037189245224, 0.7200413346290588, 0.7365702390670776, 0.7355371713638306, 0.7221074104309082, 0.7128099203109741, 0.7200413346290588, 0.7334710955619812, 0.7407024502754211, 0.7427685856819153, 0.7365702390670776, 0.6993801593780518, 0.7386363744735718, 0.7386363744735718, 0.73037189245224, 0.7376033067703247, 0.7469007968902588, 0.7417355179786682, 0.7469007968902588, 0.7489669322967529, 0.7396694421768188, 0.7438016533851624, 0.7438016533851624, 0.7386363744735718, 0.75, 0.7469007968902588, 0.7458677887916565, 0.7489669322967529, 0.7489669322967529, 0.7530992031097412, 0.7324380278587341, 0.7520661354064941, 0.7386363744735718, 0.7448347210884094, 0.7076446413993835, 0.7314049601554871, 0.7386363744735718, 0.7479338645935059, 0.7365702390670776, 0.7551652789115906, 0.7417355179786682, 0.7417355179786682, 0.7469007968902588, 0.7221074104309082, 0.7530992031097412, 0.7479338645935059, 0.7561983466148376, 0.7520661354064941, 0.7572314143180847, 0.7582644820213318, 0.7551652789115906, 0.75, 0.7510330677032471, 0.7510330677032471, 0.7592975497245789, 0.7479338645935059, 0.7293388247489929, 0.7479338645935059, 0.7603305578231812, 0.7613636255264282, 0.75, 0.7458677887916565, 0.7603305578231812, 0.7386363744735718, 0.7561983466148376, 0.7613636255264282, 0.7510330677032471, 0.7582644820213318, 0.7623966932296753, 0.7603305578231812, 0.7634297609329224, 0.7603305578231812, 0.7252066135406494]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 8s 52ms/step - loss: 0.9281 - accuracy: 0.7656 - val_loss: 1.1372 - val_accuracy: 0.4849\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 0s 13ms/step - loss: 0.9236 - accuracy: 0.7621 - val_loss: 1.1284 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9154 - accuracy: 0.7694 - val_loss: 1.1206 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9114 - accuracy: 0.7732 - val_loss: 1.1107 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9070 - accuracy: 0.7707 - val_loss: 1.0988 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9010 - accuracy: 0.7716 - val_loss: 1.0856 - val_accuracy: 0.5011\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8954 - accuracy: 0.7753 - val_loss: 1.0701 - val_accuracy: 0.5948\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8918 - accuracy: 0.7767 - val_loss: 1.0618 - val_accuracy: 0.6088\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8885 - accuracy: 0.7737 - val_loss: 1.0568 - val_accuracy: 0.5700\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8840 - accuracy: 0.7756 - val_loss: 1.0322 - val_accuracy: 0.7231\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8824 - accuracy: 0.7812 - val_loss: 1.0224 - val_accuracy: 0.7058\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8738 - accuracy: 0.7810 - val_loss: 1.0145 - val_accuracy: 0.7026\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8764 - accuracy: 0.7799 - val_loss: 0.9908 - val_accuracy: 0.7511\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8704 - accuracy: 0.7853 - val_loss: 0.9779 - val_accuracy: 0.7414\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8655 - accuracy: 0.7812 - val_loss: 0.9640 - val_accuracy: 0.7371\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8636 - accuracy: 0.7826 - val_loss: 0.9448 - val_accuracy: 0.7511\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8579 - accuracy: 0.7823 - val_loss: 0.9299 - val_accuracy: 0.7522\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8550 - accuracy: 0.7802 - val_loss: 0.9226 - val_accuracy: 0.7371\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8512 - accuracy: 0.7885 - val_loss: 0.9011 - val_accuracy: 0.7532\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8495 - accuracy: 0.7872 - val_loss: 0.8898 - val_accuracy: 0.7532\n","Epoch 21/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.8421 - accuracy: 0.7823 - val_loss: 0.8843 - val_accuracy: 0.7575\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8462 - accuracy: 0.7831 - val_loss: 0.8708 - val_accuracy: 0.7597\n","Epoch 23/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8442 - accuracy: 0.7759 - val_loss: 0.8706 - val_accuracy: 0.7619\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8388 - accuracy: 0.7928 - val_loss: 0.8575 - val_accuracy: 0.7597\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8310 - accuracy: 0.7923 - val_loss: 0.8511 - val_accuracy: 0.7683\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8274 - accuracy: 0.7971 - val_loss: 0.8561 - val_accuracy: 0.7672\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8247 - accuracy: 0.7915 - val_loss: 0.8531 - val_accuracy: 0.7651\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8386 - accuracy: 0.7777 - val_loss: 0.8523 - val_accuracy: 0.7640\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8222 - accuracy: 0.7942 - val_loss: 0.8501 - val_accuracy: 0.7662\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8165 - accuracy: 0.7928 - val_loss: 0.8386 - val_accuracy: 0.7716\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8079 - accuracy: 0.8039 - val_loss: 0.8368 - val_accuracy: 0.7651\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8081 - accuracy: 0.7969 - val_loss: 0.8355 - val_accuracy: 0.7672\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8021 - accuracy: 0.7996 - val_loss: 0.8302 - val_accuracy: 0.7748\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7968 - accuracy: 0.8028 - val_loss: 0.8328 - val_accuracy: 0.7683\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7972 - accuracy: 0.8041 - val_loss: 0.8266 - val_accuracy: 0.7683\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7936 - accuracy: 0.8028 - val_loss: 0.8239 - val_accuracy: 0.7694\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7888 - accuracy: 0.8071 - val_loss: 0.8222 - val_accuracy: 0.7672\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7959 - accuracy: 0.8036 - val_loss: 0.8219 - val_accuracy: 0.7716\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7801 - accuracy: 0.8060 - val_loss: 0.8182 - val_accuracy: 0.7672\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7859 - accuracy: 0.8017 - val_loss: 0.8475 - val_accuracy: 0.7392\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7813 - accuracy: 0.8031 - val_loss: 0.8127 - val_accuracy: 0.7748\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7764 - accuracy: 0.8050 - val_loss: 0.8126 - val_accuracy: 0.7705\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7754 - accuracy: 0.8090 - val_loss: 0.8101 - val_accuracy: 0.7705\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7701 - accuracy: 0.8085 - val_loss: 0.8101 - val_accuracy: 0.7705\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7651 - accuracy: 0.8138 - val_loss: 0.8102 - val_accuracy: 0.7834\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7657 - accuracy: 0.8103 - val_loss: 0.8057 - val_accuracy: 0.7737\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7585 - accuracy: 0.8141 - val_loss: 0.8280 - val_accuracy: 0.7511\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7748 - accuracy: 0.7974 - val_loss: 0.8299 - val_accuracy: 0.7759\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7601 - accuracy: 0.8106 - val_loss: 0.8181 - val_accuracy: 0.7522\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7538 - accuracy: 0.8144 - val_loss: 0.7984 - val_accuracy: 0.7726\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7527 - accuracy: 0.8109 - val_loss: 0.7928 - val_accuracy: 0.7769\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7440 - accuracy: 0.8179 - val_loss: 0.8108 - val_accuracy: 0.7554\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7410 - accuracy: 0.8203 - val_loss: 0.8217 - val_accuracy: 0.7662\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7472 - accuracy: 0.8101 - val_loss: 0.8120 - val_accuracy: 0.7554\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7393 - accuracy: 0.8198 - val_loss: 0.8004 - val_accuracy: 0.7834\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7459 - accuracy: 0.8117 - val_loss: 0.8170 - val_accuracy: 0.7543\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7356 - accuracy: 0.8152 - val_loss: 0.8153 - val_accuracy: 0.7748\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7369 - accuracy: 0.8152 - val_loss: 0.7816 - val_accuracy: 0.7802\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7229 - accuracy: 0.8214 - val_loss: 0.7840 - val_accuracy: 0.7748\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7196 - accuracy: 0.8249 - val_loss: 0.7808 - val_accuracy: 0.7769\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7154 - accuracy: 0.8281 - val_loss: 0.7948 - val_accuracy: 0.7769\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7170 - accuracy: 0.8289 - val_loss: 0.7785 - val_accuracy: 0.7769\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7124 - accuracy: 0.8305 - val_loss: 0.7776 - val_accuracy: 0.7769\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7060 - accuracy: 0.8300 - val_loss: 0.7781 - val_accuracy: 0.7759\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7050 - accuracy: 0.8289 - val_loss: 0.7739 - val_accuracy: 0.7759\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7102 - accuracy: 0.8252 - val_loss: 0.7958 - val_accuracy: 0.7662\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7038 - accuracy: 0.8305 - val_loss: 0.7716 - val_accuracy: 0.7834\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6948 - accuracy: 0.8319 - val_loss: 0.7750 - val_accuracy: 0.7856\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6968 - accuracy: 0.8343 - val_loss: 0.7713 - val_accuracy: 0.7856\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6886 - accuracy: 0.8338 - val_loss: 0.7766 - val_accuracy: 0.7780\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.8421 - val_loss: 0.7686 - val_accuracy: 0.7834\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6905 - accuracy: 0.8308 - val_loss: 0.7687 - val_accuracy: 0.7856\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.8327 - val_loss: 0.7814 - val_accuracy: 0.7716\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6731 - accuracy: 0.8421 - val_loss: 0.7690 - val_accuracy: 0.7791\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6776 - accuracy: 0.8362 - val_loss: 0.7759 - val_accuracy: 0.7694\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6735 - accuracy: 0.8365 - val_loss: 0.7769 - val_accuracy: 0.7759\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6817 - accuracy: 0.8295 - val_loss: 0.7604 - val_accuracy: 0.7899\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6755 - accuracy: 0.8357 - val_loss: 0.7704 - val_accuracy: 0.7866\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6614 - accuracy: 0.8456 - val_loss: 0.7609 - val_accuracy: 0.7909\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6632 - accuracy: 0.8408 - val_loss: 0.7784 - val_accuracy: 0.7705\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6586 - accuracy: 0.8473 - val_loss: 0.7570 - val_accuracy: 0.7802\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6514 - accuracy: 0.8489 - val_loss: 0.7575 - val_accuracy: 0.7888\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6502 - accuracy: 0.8499 - val_loss: 0.7601 - val_accuracy: 0.7791\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6519 - accuracy: 0.8435 - val_loss: 0.7604 - val_accuracy: 0.7899\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6472 - accuracy: 0.8489 - val_loss: 0.7834 - val_accuracy: 0.7780\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6578 - accuracy: 0.8438 - val_loss: 0.7540 - val_accuracy: 0.7812\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6365 - accuracy: 0.8486 - val_loss: 0.7690 - val_accuracy: 0.7834\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6422 - accuracy: 0.8481 - val_loss: 0.7771 - val_accuracy: 0.7769\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6287 - accuracy: 0.8537 - val_loss: 0.7563 - val_accuracy: 0.7866\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6259 - accuracy: 0.8553 - val_loss: 0.7521 - val_accuracy: 0.7845\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6292 - accuracy: 0.8570 - val_loss: 0.7595 - val_accuracy: 0.7845\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6324 - accuracy: 0.8559 - val_loss: 0.7566 - val_accuracy: 0.7899\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6388 - accuracy: 0.8473 - val_loss: 0.7472 - val_accuracy: 0.7856\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6171 - accuracy: 0.8586 - val_loss: 0.7510 - val_accuracy: 0.7812\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6179 - accuracy: 0.8540 - val_loss: 0.7563 - val_accuracy: 0.7856\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6111 - accuracy: 0.8640 - val_loss: 0.7524 - val_accuracy: 0.7909\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6099 - accuracy: 0.8615 - val_loss: 0.7552 - val_accuracy: 0.7823\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6121 - accuracy: 0.8578 - val_loss: 0.7516 - val_accuracy: 0.7856\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6087 - accuracy: 0.8626 - val_loss: 0.7602 - val_accuracy: 0.7716\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6070 - accuracy: 0.8567 - val_loss: 0.7707 - val_accuracy: 0.7651\n","{'loss': [0.9281385540962219, 0.9236036539077759, 0.9154309034347534, 0.9113714098930359, 0.907010018825531, 0.9009770750999451, 0.8953872323036194, 0.8918418288230896, 0.8884863257408142, 0.8839526772499084, 0.8823697566986084, 0.8738299608230591, 0.8764292001724243, 0.8704012036323547, 0.8655285835266113, 0.8635649085044861, 0.8579177856445312, 0.855026125907898, 0.8512462973594666, 0.8495185971260071, 0.8420656323432922, 0.8461534976959229, 0.8442189693450928, 0.8388360738754272, 0.8309954404830933, 0.8273561596870422, 0.8246846795082092, 0.8385997414588928, 0.8221578001976013, 0.816540539264679, 0.8079274296760559, 0.8081104755401611, 0.8021367192268372, 0.7968468070030212, 0.7972247004508972, 0.7935855984687805, 0.788751482963562, 0.7959339618682861, 0.7800791263580322, 0.7858749032020569, 0.7813103199005127, 0.7764248251914978, 0.7754154801368713, 0.7700728178024292, 0.7651128172874451, 0.7656979560852051, 0.7585487961769104, 0.7748141288757324, 0.760064959526062, 0.7537555694580078, 0.7527037262916565, 0.744026243686676, 0.7409825921058655, 0.7472267746925354, 0.7392642498016357, 0.7458705902099609, 0.7356210350990295, 0.7368503212928772, 0.7228878736495972, 0.7195852994918823, 0.715377688407898, 0.7169910073280334, 0.7123506665229797, 0.7060261368751526, 0.7049695253372192, 0.7102221250534058, 0.7038313746452332, 0.6948277950286865, 0.6968238949775696, 0.6885979175567627, 0.6823621392250061, 0.6905266046524048, 0.6888073682785034, 0.6731229424476624, 0.6776000261306763, 0.6735059022903442, 0.6817155480384827, 0.6755343675613403, 0.6614441275596619, 0.6631777286529541, 0.6586006283760071, 0.6513917446136475, 0.65019291639328, 0.6519181728363037, 0.6472064256668091, 0.657829225063324, 0.6365345120429993, 0.6421650052070618, 0.6287220120429993, 0.6258929967880249, 0.6292164921760559, 0.6323843598365784, 0.6387631893157959, 0.6170935034751892, 0.6178532838821411, 0.6111387610435486, 0.6098665595054626, 0.6120550036430359, 0.6086592674255371, 0.6069639921188354], 'accuracy': [0.765625, 0.7621228694915771, 0.7693965435028076, 0.7731680870056152, 0.7707435488700867, 0.7715517282485962, 0.7753232717514038, 0.7766702771186829, 0.7737069129943848, 0.7755926847457886, 0.78125, 0.7809805870056152, 0.779902994632721, 0.7852909564971924, 0.78125, 0.782597005367279, 0.7823275923728943, 0.7801724076271057, 0.7885237336158752, 0.7871767282485962, 0.7823275923728943, 0.7831357717514038, 0.7758620977401733, 0.7928340435028076, 0.7922952771186829, 0.7971444129943848, 0.7914870977401733, 0.7777478694915771, 0.7941810488700867, 0.7928340435028076, 0.8038793206214905, 0.796875, 0.7995689511299133, 0.8028017282485962, 0.8041487336158752, 0.8028017282485962, 0.8071120977401733, 0.8036099076271057, 0.806034505367279, 0.8017241358757019, 0.803071141242981, 0.8049569129943848, 0.8089978694915771, 0.8084590435028076, 0.813847005367279, 0.8103448152542114, 0.814116358757019, 0.7974137663841248, 0.8106142282485962, 0.8143857717514038, 0.810883641242981, 0.8178879022598267, 0.8203125, 0.8100754022598267, 0.8197737336158752, 0.8116918206214905, 0.8151939511299133, 0.8151939511299133, 0.8213900923728943, 0.8248922228813171, 0.828125, 0.8289331793785095, 0.8305495977401733, 0.8300107717514038, 0.8289331793785095, 0.8251616358757019, 0.8305495977401733, 0.8318965435028076, 0.834321141242981, 0.8337823152542114, 0.842133641242981, 0.8308189511299133, 0.8327047228813171, 0.842133641242981, 0.8362069129943848, 0.8364762663841248, 0.829472005367279, 0.8356680870056152, 0.8456357717514038, 0.8407866358757019, 0.8472521305084229, 0.8488685488700867, 0.849946141242981, 0.8434805870056152, 0.8488685488700867, 0.84375, 0.8485991358757019, 0.8480603694915771, 0.8537176847457886, 0.8553340435028076, 0.8569504022598267, 0.8558728694915771, 0.8472521305084229, 0.8585668206214905, 0.8539870977401733, 0.8639547228813171, 0.8615301847457886, 0.857758641242981, 0.8626077771186829, 0.8566810488700867], 'val_loss': [1.1372489929199219, 1.1283901929855347, 1.1206108331680298, 1.1107250452041626, 1.0987783670425415, 1.0856071710586548, 1.070080280303955, 1.0618408918380737, 1.0568069219589233, 1.0322047472000122, 1.0224357843399048, 1.014479637145996, 0.9908165335655212, 0.9779252409934998, 0.9640442132949829, 0.944829523563385, 0.9299177527427673, 0.922566831111908, 0.9011054635047913, 0.889793336391449, 0.8843036890029907, 0.8707911372184753, 0.8705592751502991, 0.8575120568275452, 0.8511232733726501, 0.856055498123169, 0.8530666828155518, 0.8522630929946899, 0.8500531315803528, 0.8386135697364807, 0.8368353843688965, 0.8354930281639099, 0.8302003145217896, 0.8327959775924683, 0.8265584111213684, 0.8239016532897949, 0.8221964836120605, 0.8219056129455566, 0.8182213306427002, 0.8474630117416382, 0.8126733303070068, 0.8125795722007751, 0.8100797533988953, 0.8101043105125427, 0.8101601004600525, 0.805700421333313, 0.8279700875282288, 0.8298729062080383, 0.818084180355072, 0.7984094023704529, 0.792842447757721, 0.810754656791687, 0.8216778039932251, 0.8120039105415344, 0.8003588318824768, 0.8169981837272644, 0.8153393268585205, 0.7816237211227417, 0.7839713096618652, 0.7807761430740356, 0.7947635650634766, 0.7784671783447266, 0.7775577306747437, 0.7780967950820923, 0.7739275693893433, 0.7958269715309143, 0.7715796232223511, 0.7749541997909546, 0.7712543606758118, 0.7766106128692627, 0.7686461806297302, 0.768726110458374, 0.7813836336135864, 0.76902836561203, 0.7759350538253784, 0.7769172787666321, 0.760402500629425, 0.7703851461410522, 0.7609102129936218, 0.7783635854721069, 0.756969690322876, 0.7575448751449585, 0.7601030468940735, 0.7603839635848999, 0.7834036350250244, 0.753984272480011, 0.7689695954322815, 0.7770680785179138, 0.7562858462333679, 0.7521260380744934, 0.7595130801200867, 0.7566277980804443, 0.7471578121185303, 0.7510253190994263, 0.7562635540962219, 0.7523666024208069, 0.7551981806755066, 0.7516334652900696, 0.7602005004882812, 0.770677387714386], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.5010775923728943, 0.5948275923728943, 0.6088362336158752, 0.5700430870056152, 0.7230603694915771, 0.7058189511299133, 0.7025862336158752, 0.7510775923728943, 0.7413793206214905, 0.7370689511299133, 0.7510775923728943, 0.7521551847457886, 0.7370689511299133, 0.7532327771186829, 0.7532327771186829, 0.7575430870056152, 0.7596982717514038, 0.7618534564971924, 0.7596982717514038, 0.7683189511299133, 0.767241358757019, 0.7650862336158752, 0.764008641242981, 0.7661637663841248, 0.7715517282485962, 0.7650862336158752, 0.767241358757019, 0.774784505367279, 0.7683189511299133, 0.7683189511299133, 0.7693965435028076, 0.767241358757019, 0.7715517282485962, 0.767241358757019, 0.7392241358757019, 0.774784505367279, 0.7704741358757019, 0.7704741358757019, 0.7704741358757019, 0.7834051847457886, 0.7737069129943848, 0.7510775923728943, 0.7758620977401733, 0.7521551847457886, 0.7726293206214905, 0.7769396305084229, 0.7553879022598267, 0.7661637663841248, 0.7553879022598267, 0.7834051847457886, 0.7543103694915771, 0.774784505367279, 0.7801724076271057, 0.774784505367279, 0.7769396305084229, 0.7769396305084229, 0.7769396305084229, 0.7769396305084229, 0.7758620977401733, 0.7758620977401733, 0.7661637663841248, 0.7834051847457886, 0.7855603694915771, 0.7855603694915771, 0.7780172228813171, 0.7834051847457886, 0.7855603694915771, 0.7715517282485962, 0.7790948152542114, 0.7693965435028076, 0.7758620977401733, 0.7898706793785095, 0.7866379022598267, 0.7909482717514038, 0.7704741358757019, 0.7801724076271057, 0.7887930870056152, 0.7790948152542114, 0.7898706793785095, 0.7780172228813171, 0.78125, 0.7834051847457886, 0.7769396305084229, 0.7866379022598267, 0.7844827771186829, 0.7844827771186829, 0.7898706793785095, 0.7855603694915771, 0.78125, 0.7855603694915771, 0.7909482717514038, 0.7823275923728943, 0.7855603694915771, 0.7715517282485962, 0.7650862336158752]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.9453 - accuracy: 0.7525"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 77ms/step - loss: 0.9430 - accuracy: 0.7555 - val_loss: 1.1365 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9335 - accuracy: 0.7547 - val_loss: 1.1332 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9235 - accuracy: 0.7629 - val_loss: 1.1175 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9209 - accuracy: 0.7634 - val_loss: 1.1070 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9094 - accuracy: 0.7668 - val_loss: 1.0995 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9093 - accuracy: 0.7651 - val_loss: 1.0844 - val_accuracy: 0.5362\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8975 - accuracy: 0.7722 - val_loss: 1.0806 - val_accuracy: 0.5215\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8929 - accuracy: 0.7733 - val_loss: 1.0707 - val_accuracy: 0.5464\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8892 - accuracy: 0.7756 - val_loss: 1.0589 - val_accuracy: 0.5860\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8897 - accuracy: 0.7716 - val_loss: 1.0511 - val_accuracy: 0.5860\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8831 - accuracy: 0.7756 - val_loss: 1.0452 - val_accuracy: 0.5758\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8851 - accuracy: 0.7759 - val_loss: 1.0177 - val_accuracy: 0.7025\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8748 - accuracy: 0.7804 - val_loss: 1.0037 - val_accuracy: 0.7251\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8727 - accuracy: 0.7799 - val_loss: 0.9903 - val_accuracy: 0.7274\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8689 - accuracy: 0.7852 - val_loss: 0.9786 - val_accuracy: 0.7172\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8600 - accuracy: 0.7847 - val_loss: 0.9601 - val_accuracy: 0.7274\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8564 - accuracy: 0.7864 - val_loss: 0.9605 - val_accuracy: 0.6968\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8666 - accuracy: 0.7804 - val_loss: 0.9420 - val_accuracy: 0.7195\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8516 - accuracy: 0.7855 - val_loss: 0.9324 - val_accuracy: 0.7172\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8509 - accuracy: 0.7886 - val_loss: 0.9085 - val_accuracy: 0.7579\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8423 - accuracy: 0.7965 - val_loss: 0.9000 - val_accuracy: 0.7590\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8422 - accuracy: 0.7929 - val_loss: 0.9173 - val_accuracy: 0.7376\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8513 - accuracy: 0.7813 - val_loss: 0.9052 - val_accuracy: 0.7489\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8406 - accuracy: 0.7861 - val_loss: 0.9020 - val_accuracy: 0.7511\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8406 - accuracy: 0.7892 - val_loss: 0.8905 - val_accuracy: 0.7500\n","Epoch 26/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8231 - accuracy: 0.8011 - val_loss: 0.8775 - val_accuracy: 0.7579\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8183 - accuracy: 0.8016 - val_loss: 0.8729 - val_accuracy: 0.7590\n","Epoch 28/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8194 - accuracy: 0.7946 - val_loss: 0.8771 - val_accuracy: 0.7602\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8232 - accuracy: 0.7946 - val_loss: 0.8723 - val_accuracy: 0.7557\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8110 - accuracy: 0.7965 - val_loss: 0.8709 - val_accuracy: 0.7557\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8085 - accuracy: 0.7951 - val_loss: 0.8658 - val_accuracy: 0.7602\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8045 - accuracy: 0.8028 - val_loss: 0.8630 - val_accuracy: 0.7602\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7999 - accuracy: 0.8022 - val_loss: 0.8645 - val_accuracy: 0.7568\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7995 - accuracy: 0.8005 - val_loss: 0.8673 - val_accuracy: 0.7489\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7932 - accuracy: 0.8039 - val_loss: 0.8634 - val_accuracy: 0.7557\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7946 - accuracy: 0.8062 - val_loss: 0.8639 - val_accuracy: 0.7568\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7922 - accuracy: 0.8048 - val_loss: 0.8587 - val_accuracy: 0.7557\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7841 - accuracy: 0.8093 - val_loss: 0.8741 - val_accuracy: 0.7545\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7849 - accuracy: 0.8079 - val_loss: 0.8575 - val_accuracy: 0.7511\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7854 - accuracy: 0.8042 - val_loss: 0.8715 - val_accuracy: 0.7534\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7820 - accuracy: 0.8070 - val_loss: 0.8545 - val_accuracy: 0.7579\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7796 - accuracy: 0.8053 - val_loss: 0.8472 - val_accuracy: 0.7590\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7698 - accuracy: 0.8138 - val_loss: 0.8553 - val_accuracy: 0.7466\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7662 - accuracy: 0.8183 - val_loss: 0.8452 - val_accuracy: 0.7568\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7615 - accuracy: 0.8147 - val_loss: 0.8710 - val_accuracy: 0.7545\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7604 - accuracy: 0.8107 - val_loss: 0.8445 - val_accuracy: 0.7511\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7645 - accuracy: 0.8079 - val_loss: 0.8554 - val_accuracy: 0.7568\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7618 - accuracy: 0.8065 - val_loss: 0.8433 - val_accuracy: 0.7545\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7559 - accuracy: 0.8183 - val_loss: 0.8751 - val_accuracy: 0.7523\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7517 - accuracy: 0.8217 - val_loss: 0.8463 - val_accuracy: 0.7579\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7485 - accuracy: 0.8141 - val_loss: 0.8478 - val_accuracy: 0.7500\n","Epoch 52/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7457 - accuracy: 0.8200 - val_loss: 0.8361 - val_accuracy: 0.7624\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7402 - accuracy: 0.8192 - val_loss: 0.8393 - val_accuracy: 0.7455\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7379 - accuracy: 0.8189 - val_loss: 0.8350 - val_accuracy: 0.7477\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7283 - accuracy: 0.8271 - val_loss: 0.8325 - val_accuracy: 0.7511\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7367 - accuracy: 0.8141 - val_loss: 0.8565 - val_accuracy: 0.7602\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7437 - accuracy: 0.8115 - val_loss: 0.8338 - val_accuracy: 0.7477\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7225 - accuracy: 0.8285 - val_loss: 0.8328 - val_accuracy: 0.7557\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7183 - accuracy: 0.8311 - val_loss: 0.8392 - val_accuracy: 0.7613\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7214 - accuracy: 0.8214 - val_loss: 0.8297 - val_accuracy: 0.7410\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7152 - accuracy: 0.8297 - val_loss: 0.8303 - val_accuracy: 0.7410\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7138 - accuracy: 0.8280 - val_loss: 0.8277 - val_accuracy: 0.7489\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7103 - accuracy: 0.8285 - val_loss: 0.8490 - val_accuracy: 0.7579\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7169 - accuracy: 0.8212 - val_loss: 0.8422 - val_accuracy: 0.7364\n","Epoch 65/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7104 - accuracy: 0.8268 - val_loss: 0.8291 - val_accuracy: 0.7670\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7050 - accuracy: 0.8288 - val_loss: 0.8366 - val_accuracy: 0.7432\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7100 - accuracy: 0.8285 - val_loss: 0.8168 - val_accuracy: 0.7590\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6988 - accuracy: 0.8291 - val_loss: 0.8287 - val_accuracy: 0.7477\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.8370 - val_loss: 0.8174 - val_accuracy: 0.7466\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6921 - accuracy: 0.8415 - val_loss: 0.8198 - val_accuracy: 0.7489\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.8347 - val_loss: 0.8195 - val_accuracy: 0.7534\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6872 - accuracy: 0.8370 - val_loss: 0.8176 - val_accuracy: 0.7489\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6880 - accuracy: 0.8314 - val_loss: 0.8639 - val_accuracy: 0.7410\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6946 - accuracy: 0.8214 - val_loss: 0.8483 - val_accuracy: 0.7466\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6724 - accuracy: 0.8455 - val_loss: 0.8238 - val_accuracy: 0.7579\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6789 - accuracy: 0.8362 - val_loss: 0.8153 - val_accuracy: 0.7613\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6725 - accuracy: 0.8418 - val_loss: 0.8112 - val_accuracy: 0.7557\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6742 - accuracy: 0.8362 - val_loss: 0.8123 - val_accuracy: 0.7545\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6710 - accuracy: 0.8384 - val_loss: 0.8237 - val_accuracy: 0.7443\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6546 - accuracy: 0.8529 - val_loss: 0.8245 - val_accuracy: 0.7590\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6648 - accuracy: 0.8390 - val_loss: 0.8119 - val_accuracy: 0.7466\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6577 - accuracy: 0.8444 - val_loss: 0.8142 - val_accuracy: 0.7477\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6548 - accuracy: 0.8483 - val_loss: 0.8074 - val_accuracy: 0.7557\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.8529 - val_loss: 0.8232 - val_accuracy: 0.7658\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6458 - accuracy: 0.8461 - val_loss: 0.8064 - val_accuracy: 0.7590\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6425 - accuracy: 0.8551 - val_loss: 0.8196 - val_accuracy: 0.7466\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6385 - accuracy: 0.8568 - val_loss: 0.8102 - val_accuracy: 0.7557\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6341 - accuracy: 0.8571 - val_loss: 0.8096 - val_accuracy: 0.7624\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6391 - accuracy: 0.8551 - val_loss: 0.8264 - val_accuracy: 0.7410\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6252 - accuracy: 0.8594 - val_loss: 0.8245 - val_accuracy: 0.7568\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6313 - accuracy: 0.8619 - val_loss: 0.8057 - val_accuracy: 0.7523\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6268 - accuracy: 0.8591 - val_loss: 0.8070 - val_accuracy: 0.7500\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6208 - accuracy: 0.8613 - val_loss: 0.8122 - val_accuracy: 0.7590\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6313 - accuracy: 0.8509 - val_loss: 0.8027 - val_accuracy: 0.7421\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6281 - accuracy: 0.8543 - val_loss: 0.8466 - val_accuracy: 0.7398\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6336 - accuracy: 0.8432 - val_loss: 0.8929 - val_accuracy: 0.7195\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6450 - accuracy: 0.8390 - val_loss: 0.8253 - val_accuracy: 0.7489\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6131 - accuracy: 0.8622 - val_loss: 0.7926 - val_accuracy: 0.7421\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6021 - accuracy: 0.8679 - val_loss: 0.7965 - val_accuracy: 0.7523\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.8599 - val_loss: 0.8039 - val_accuracy: 0.7557\n","{'loss': [0.9430264830589294, 0.9335141181945801, 0.9235089421272278, 0.9208698868751526, 0.9094005227088928, 0.9093228578567505, 0.897502601146698, 0.8928735852241516, 0.8891554474830627, 0.8896819353103638, 0.8831142783164978, 0.8850979804992676, 0.8748258948326111, 0.8726511597633362, 0.8688685894012451, 0.8600482940673828, 0.8563790321350098, 0.8666420578956604, 0.8516251444816589, 0.85085129737854, 0.8422936797142029, 0.8421993255615234, 0.8512634634971619, 0.8406156301498413, 0.8405848741531372, 0.8231483101844788, 0.8182708621025085, 0.8193798065185547, 0.8232086300849915, 0.810952365398407, 0.8084946870803833, 0.8044736981391907, 0.7998508214950562, 0.7994893193244934, 0.7931719422340393, 0.7945961952209473, 0.7922289371490479, 0.7840545773506165, 0.7849122881889343, 0.7853556275367737, 0.7820148468017578, 0.7795881032943726, 0.7697969675064087, 0.7661561369895935, 0.7615431547164917, 0.7603886127471924, 0.7645063996315002, 0.7617636322975159, 0.7558728456497192, 0.751714289188385, 0.7485278844833374, 0.7457118034362793, 0.7401623725891113, 0.7378684282302856, 0.7283458709716797, 0.736650288105011, 0.7436662912368774, 0.7225277423858643, 0.7182915210723877, 0.7214378714561462, 0.7152155637741089, 0.7138386368751526, 0.7103077173233032, 0.7168879508972168, 0.7104183435440063, 0.7049998044967651, 0.7099611163139343, 0.6987925171852112, 0.6909376978874207, 0.6921018362045288, 0.6834204792976379, 0.6871510148048401, 0.6880009770393372, 0.6946068406105042, 0.6724050641059875, 0.6789226531982422, 0.6724590063095093, 0.6741855144500732, 0.670961320400238, 0.6545816659927368, 0.6647627353668213, 0.6576961278915405, 0.6547703742980957, 0.6466770768165588, 0.6457934975624084, 0.6425004005432129, 0.6384725570678711, 0.6341437101364136, 0.6391216516494751, 0.6251881718635559, 0.6313327550888062, 0.6268085837364197, 0.6208261847496033, 0.6313353180885315, 0.6280577778816223, 0.6336440443992615, 0.6449601054191589, 0.6131404638290405, 0.6020541191101074, 0.6089838743209839], 'accuracy': [0.755517840385437, 0.7546689510345459, 0.7628749012947083, 0.7634408473968506, 0.7668364644050598, 0.7651386260986328, 0.7722128033638, 0.7733446359634399, 0.7756083607673645, 0.7716468572616577, 0.7756083607673645, 0.7758913636207581, 0.7804188132286072, 0.7798528671264648, 0.7852292060852051, 0.7846632599830627, 0.786361038684845, 0.7804188132286072, 0.7855121493339539, 0.7886247634887695, 0.7965478301048279, 0.7928692698478699, 0.7812677025794983, 0.7860780954360962, 0.7891907095909119, 0.801075279712677, 0.8016412258148193, 0.7945670485496521, 0.7945670485496521, 0.7965478301048279, 0.7951329946517944, 0.8027730584144592, 0.8022071123123169, 0.8005093336105347, 0.8039049506187439, 0.8061686754226685, 0.804753839969635, 0.8092812895774841, 0.8078664541244507, 0.8041878938674927, 0.8070175647735596, 0.8053197264671326, 0.8138087391853333, 0.8183361887931824, 0.8146576285362244, 0.8106960654258728, 0.8078664541244507, 0.8064516186714172, 0.8183361887931824, 0.8217317461967468, 0.814091682434082, 0.8200339674949646, 0.8191850781440735, 0.8189020752906799, 0.8271080851554871, 0.814091682434082, 0.8115450143814087, 0.8285229206085205, 0.8310695886611938, 0.821448802947998, 0.8296547532081604, 0.8279569745063782, 0.8285229206085205, 0.8211658000946045, 0.8268251419067383, 0.8288058638572693, 0.8285229206085205, 0.8290888667106628, 0.8370118737220764, 0.8415393233299255, 0.8347481489181519, 0.8370118737220764, 0.8313525915145874, 0.821448802947998, 0.8455008268356323, 0.8361629843711853, 0.8418223261833191, 0.8361629843711853, 0.8384267091751099, 0.8528579473495483, 0.8389926552772522, 0.8443689942359924, 0.8483304977416992, 0.8528579473495483, 0.8460667729377747, 0.8551216721534729, 0.8568194508552551, 0.8571024537086487, 0.8551216721534729, 0.8593661785125732, 0.8619128465652466, 0.8590831756591797, 0.8613469004631042, 0.8508771657943726, 0.8542727828025818, 0.8432371020317078, 0.8389926552772522, 0.8621957898139954, 0.8678551316261292, 0.8599320650100708], 'val_loss': [1.1365448236465454, 1.133183240890503, 1.117458462715149, 1.1070069074630737, 1.0994665622711182, 1.0843602418899536, 1.0805572271347046, 1.0707058906555176, 1.0588716268539429, 1.0511412620544434, 1.045240879058838, 1.0176507234573364, 1.0037106275558472, 0.9903468489646912, 0.9785535931587219, 0.9600578546524048, 0.9604888558387756, 0.9420331716537476, 0.9323890805244446, 0.9085445404052734, 0.8999898433685303, 0.9173149466514587, 0.9052473902702332, 0.9020179510116577, 0.8905218243598938, 0.8774697184562683, 0.8728668689727783, 0.8770865201950073, 0.8723492622375488, 0.8708856105804443, 0.8657792806625366, 0.8630236983299255, 0.8645313382148743, 0.8673200607299805, 0.8634237051010132, 0.8639458417892456, 0.8586996793746948, 0.8741455674171448, 0.8574981689453125, 0.8714746236801147, 0.8545461893081665, 0.847168505191803, 0.8552829027175903, 0.8452467918395996, 0.8710114359855652, 0.8445045948028564, 0.8553975224494934, 0.8433345556259155, 0.8751227855682373, 0.8462650775909424, 0.8477964997291565, 0.8360884785652161, 0.8392612934112549, 0.8350408673286438, 0.8324528932571411, 0.856514573097229, 0.8337559103965759, 0.8328490853309631, 0.8391794562339783, 0.8296650052070618, 0.8302531242370605, 0.827710747718811, 0.8490166068077087, 0.8422242999076843, 0.829145073890686, 0.836624026298523, 0.8168348670005798, 0.8286635875701904, 0.8173925876617432, 0.8197963833808899, 0.819531261920929, 0.817643404006958, 0.8639203906059265, 0.8483067750930786, 0.8237888216972351, 0.8152861595153809, 0.8111733794212341, 0.8122997879981995, 0.8237489461898804, 0.8245418071746826, 0.8119146823883057, 0.8141842484474182, 0.8074194192886353, 0.8232123851776123, 0.8064348697662354, 0.8195769786834717, 0.8102269768714905, 0.8096454739570618, 0.8264124393463135, 0.8244768977165222, 0.805682361125946, 0.8070108890533447, 0.8122302889823914, 0.802686870098114, 0.8466296792030334, 0.8928664326667786, 0.825281023979187, 0.7925529479980469, 0.796480119228363, 0.8038945198059082], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5361990928649902, 0.5214931964874268, 0.5463801026344299, 0.5859728455543518, 0.5859728455543518, 0.5757918357849121, 0.7024886608123779, 0.7251130938529968, 0.7273755669593811, 0.7171945571899414, 0.7273755669593811, 0.6968325972557068, 0.7194570302963257, 0.7171945571899414, 0.7579185366630554, 0.7590497732162476, 0.7375565767288208, 0.7488687634468079, 0.7511312365531921, 0.75, 0.7579185366630554, 0.7590497732162476, 0.7601810097694397, 0.7556561231613159, 0.7556561231613159, 0.7601810097694397, 0.7601810097694397, 0.7567873597145081, 0.7488687634468079, 0.7556561231613159, 0.7567873597145081, 0.7556561231613159, 0.7545248866081238, 0.7511312365531921, 0.7533936500549316, 0.7579185366630554, 0.7590497732162476, 0.7466063499450684, 0.7567873597145081, 0.7545248866081238, 0.7511312365531921, 0.7567873597145081, 0.7545248866081238, 0.7522624731063843, 0.7579185366630554, 0.75, 0.7624434232711792, 0.7454751133918762, 0.7477375268936157, 0.7511312365531921, 0.7601810097694397, 0.7477375268936157, 0.7556561231613159, 0.7613122463226318, 0.7409502267837524, 0.7409502267837524, 0.7488687634468079, 0.7579185366630554, 0.7364253401756287, 0.766968309879303, 0.7432126402854919, 0.7590497732162476, 0.7477375268936157, 0.7466063499450684, 0.7488687634468079, 0.7533936500549316, 0.7488687634468079, 0.7409502267837524, 0.7466063499450684, 0.7579185366630554, 0.7613122463226318, 0.7556561231613159, 0.7545248866081238, 0.7443438768386841, 0.7590497732162476, 0.7466063499450684, 0.7477375268936157, 0.7556561231613159, 0.7658371329307556, 0.7590497732162476, 0.7466063499450684, 0.7556561231613159, 0.7624434232711792, 0.7409502267837524, 0.7567873597145081, 0.7522624731063843, 0.75, 0.7590497732162476, 0.7420814633369446, 0.7398189902305603, 0.7194570302963257, 0.7488687634468079, 0.7420814633369446, 0.7522624731063843, 0.7556561231613159]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.7607"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 57ms/step - loss: 0.9215 - accuracy: 0.7607 - val_loss: 1.1394 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9095 - accuracy: 0.7654 - val_loss: 1.1328 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9064 - accuracy: 0.7659 - val_loss: 1.1228 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8989 - accuracy: 0.7695 - val_loss: 1.1072 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8952 - accuracy: 0.7700 - val_loss: 1.1016 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8936 - accuracy: 0.7721 - val_loss: 1.0958 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.8861 - accuracy: 0.7749 - val_loss: 1.0854 - val_accuracy: 0.4907\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8791 - accuracy: 0.7762 - val_loss: 1.0766 - val_accuracy: 0.4979\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8843 - accuracy: 0.7656 - val_loss: 1.0569 - val_accuracy: 0.5475\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8711 - accuracy: 0.7804 - val_loss: 1.0449 - val_accuracy: 0.5671\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8680 - accuracy: 0.7762 - val_loss: 1.0336 - val_accuracy: 0.5868\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8651 - accuracy: 0.7793 - val_loss: 1.0111 - val_accuracy: 0.6643\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8612 - accuracy: 0.7817 - val_loss: 1.0057 - val_accuracy: 0.6519\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8610 - accuracy: 0.7817 - val_loss: 0.9991 - val_accuracy: 0.6519\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8569 - accuracy: 0.7793 - val_loss: 0.9706 - val_accuracy: 0.7004\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8473 - accuracy: 0.7879 - val_loss: 0.9443 - val_accuracy: 0.7273\n","Epoch 17/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.8481 - accuracy: 0.7842 - val_loss: 0.9327 - val_accuracy: 0.7314\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8408 - accuracy: 0.7879 - val_loss: 0.9237 - val_accuracy: 0.7283\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8392 - accuracy: 0.7829 - val_loss: 0.9139 - val_accuracy: 0.7293\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8393 - accuracy: 0.7879 - val_loss: 0.9051 - val_accuracy: 0.7376\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8344 - accuracy: 0.7891 - val_loss: 0.9006 - val_accuracy: 0.7717\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8290 - accuracy: 0.7894 - val_loss: 0.8929 - val_accuracy: 0.7655\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8250 - accuracy: 0.7941 - val_loss: 0.8904 - val_accuracy: 0.7562\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8238 - accuracy: 0.7915 - val_loss: 0.8916 - val_accuracy: 0.7665\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8142 - accuracy: 0.7953 - val_loss: 0.9013 - val_accuracy: 0.7696\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8143 - accuracy: 0.7966 - val_loss: 0.9037 - val_accuracy: 0.7314\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8155 - accuracy: 0.7953 - val_loss: 0.8816 - val_accuracy: 0.7665\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8098 - accuracy: 0.8031 - val_loss: 0.8791 - val_accuracy: 0.7717\n","Epoch 29/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8079 - accuracy: 0.7910 - val_loss: 0.8813 - val_accuracy: 0.7727\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7992 - accuracy: 0.8034 - val_loss: 0.8756 - val_accuracy: 0.7686\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7979 - accuracy: 0.7992 - val_loss: 0.8768 - val_accuracy: 0.7634\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8038 - accuracy: 0.7912 - val_loss: 0.8782 - val_accuracy: 0.7521\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8017 - accuracy: 0.7858 - val_loss: 0.8692 - val_accuracy: 0.7696\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7903 - accuracy: 0.7982 - val_loss: 0.8716 - val_accuracy: 0.7717\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7869 - accuracy: 0.8010 - val_loss: 0.8881 - val_accuracy: 0.7665\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7856 - accuracy: 0.8034 - val_loss: 0.8869 - val_accuracy: 0.7665\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7813 - accuracy: 0.8054 - val_loss: 0.8693 - val_accuracy: 0.7490\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7767 - accuracy: 0.8036 - val_loss: 0.8613 - val_accuracy: 0.7645\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7762 - accuracy: 0.8065 - val_loss: 0.8650 - val_accuracy: 0.7645\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7717 - accuracy: 0.8034 - val_loss: 0.8605 - val_accuracy: 0.7614\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7674 - accuracy: 0.8078 - val_loss: 0.8634 - val_accuracy: 0.7469\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7671 - accuracy: 0.8049 - val_loss: 0.8599 - val_accuracy: 0.7696\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7575 - accuracy: 0.8132 - val_loss: 0.8564 - val_accuracy: 0.7634\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7571 - accuracy: 0.8111 - val_loss: 0.8543 - val_accuracy: 0.7655\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7603 - accuracy: 0.8044 - val_loss: 0.8511 - val_accuracy: 0.7645\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7472 - accuracy: 0.8129 - val_loss: 0.8848 - val_accuracy: 0.7200\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7536 - accuracy: 0.8078 - val_loss: 0.8505 - val_accuracy: 0.7603\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7465 - accuracy: 0.8119 - val_loss: 0.8509 - val_accuracy: 0.7624\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7453 - accuracy: 0.8103 - val_loss: 0.8464 - val_accuracy: 0.7624\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7473 - accuracy: 0.8119 - val_loss: 0.8434 - val_accuracy: 0.7614\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7355 - accuracy: 0.8178 - val_loss: 0.8434 - val_accuracy: 0.7614\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7344 - accuracy: 0.8155 - val_loss: 0.8413 - val_accuracy: 0.7572\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7255 - accuracy: 0.8227 - val_loss: 0.8410 - val_accuracy: 0.7572\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7319 - accuracy: 0.8155 - val_loss: 0.8564 - val_accuracy: 0.7676\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7494 - accuracy: 0.7961 - val_loss: 0.8480 - val_accuracy: 0.7438\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7207 - accuracy: 0.8225 - val_loss: 0.8343 - val_accuracy: 0.7624\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7244 - accuracy: 0.8160 - val_loss: 0.8372 - val_accuracy: 0.7614\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7173 - accuracy: 0.8222 - val_loss: 0.8360 - val_accuracy: 0.7624\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7166 - accuracy: 0.8220 - val_loss: 0.8457 - val_accuracy: 0.7686\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7218 - accuracy: 0.8189 - val_loss: 0.8317 - val_accuracy: 0.7707\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7116 - accuracy: 0.8212 - val_loss: 0.8261 - val_accuracy: 0.7531\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7071 - accuracy: 0.8222 - val_loss: 0.8371 - val_accuracy: 0.7634\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7062 - accuracy: 0.8233 - val_loss: 0.8275 - val_accuracy: 0.7541\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7046 - accuracy: 0.8261 - val_loss: 0.8392 - val_accuracy: 0.7490\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7110 - accuracy: 0.8196 - val_loss: 0.8226 - val_accuracy: 0.7593\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.8302 - val_loss: 0.8335 - val_accuracy: 0.7634\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.8289 - val_loss: 0.8330 - val_accuracy: 0.7510\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.8253 - val_loss: 0.8455 - val_accuracy: 0.7407\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7022 - accuracy: 0.8256 - val_loss: 0.8218 - val_accuracy: 0.7562\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.8289 - val_loss: 0.8220 - val_accuracy: 0.7552\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6789 - accuracy: 0.8398 - val_loss: 0.8258 - val_accuracy: 0.7634\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6796 - accuracy: 0.8287 - val_loss: 0.8193 - val_accuracy: 0.7531\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6790 - accuracy: 0.8341 - val_loss: 0.8261 - val_accuracy: 0.7645\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6757 - accuracy: 0.8333 - val_loss: 0.8241 - val_accuracy: 0.7686\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6759 - accuracy: 0.8320 - val_loss: 0.8188 - val_accuracy: 0.7541\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6731 - accuracy: 0.8364 - val_loss: 0.8184 - val_accuracy: 0.7541\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6670 - accuracy: 0.8349 - val_loss: 0.8273 - val_accuracy: 0.7521\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6710 - accuracy: 0.8292 - val_loss: 0.8242 - val_accuracy: 0.7707\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6610 - accuracy: 0.8413 - val_loss: 0.8276 - val_accuracy: 0.7634\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6562 - accuracy: 0.8406 - val_loss: 0.8278 - val_accuracy: 0.7634\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6567 - accuracy: 0.8388 - val_loss: 0.8138 - val_accuracy: 0.7624\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6504 - accuracy: 0.8429 - val_loss: 0.8103 - val_accuracy: 0.7562\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6568 - accuracy: 0.8393 - val_loss: 0.8091 - val_accuracy: 0.7521\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6582 - accuracy: 0.8382 - val_loss: 0.8036 - val_accuracy: 0.7552\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6439 - accuracy: 0.8421 - val_loss: 0.8072 - val_accuracy: 0.7521\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6426 - accuracy: 0.8460 - val_loss: 0.8197 - val_accuracy: 0.7676\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6434 - accuracy: 0.8411 - val_loss: 0.8153 - val_accuracy: 0.7645\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6341 - accuracy: 0.8491 - val_loss: 0.8070 - val_accuracy: 0.7541\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6433 - accuracy: 0.8393 - val_loss: 0.8076 - val_accuracy: 0.7583\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6376 - accuracy: 0.8473 - val_loss: 0.8189 - val_accuracy: 0.7541\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6375 - accuracy: 0.8452 - val_loss: 0.8185 - val_accuracy: 0.7696\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6423 - accuracy: 0.8390 - val_loss: 0.7982 - val_accuracy: 0.7603\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6324 - accuracy: 0.8429 - val_loss: 0.8170 - val_accuracy: 0.7552\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6246 - accuracy: 0.8527 - val_loss: 0.8169 - val_accuracy: 0.7459\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6186 - accuracy: 0.8452 - val_loss: 0.8247 - val_accuracy: 0.7438\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6188 - accuracy: 0.8535 - val_loss: 0.8142 - val_accuracy: 0.7490\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6137 - accuracy: 0.8501 - val_loss: 0.8101 - val_accuracy: 0.7500\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6082 - accuracy: 0.8568 - val_loss: 0.8035 - val_accuracy: 0.7552\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6052 - accuracy: 0.8599 - val_loss: 0.8053 - val_accuracy: 0.7665\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5983 - accuracy: 0.8563 - val_loss: 0.8057 - val_accuracy: 0.7624\n","{'loss': [0.9214684367179871, 0.9095354676246643, 0.9064397811889648, 0.8988838195800781, 0.8951749801635742, 0.8936091661453247, 0.8861401677131653, 0.8791211247444153, 0.884250819683075, 0.8711190223693848, 0.868003785610199, 0.8651148676872253, 0.8612298369407654, 0.8609815239906311, 0.8568562269210815, 0.8473304510116577, 0.8481153845787048, 0.8407664895057678, 0.839172899723053, 0.8392664790153503, 0.8343615531921387, 0.8290014266967773, 0.8249685764312744, 0.8237552642822266, 0.8141653537750244, 0.8142527937889099, 0.8154520988464355, 0.8097739815711975, 0.8079049587249756, 0.7992075681686401, 0.7979449033737183, 0.8037624359130859, 0.8016660213470459, 0.7902870178222656, 0.7869397401809692, 0.7856032252311707, 0.78132563829422, 0.7767077088356018, 0.7762347459793091, 0.771659255027771, 0.7674187421798706, 0.767135500907898, 0.7575007677078247, 0.7571390271186829, 0.760336697101593, 0.7472223043441772, 0.7535865902900696, 0.7465273141860962, 0.7452623844146729, 0.7473335266113281, 0.7354711890220642, 0.7344196438789368, 0.7254741787910461, 0.7319356799125671, 0.7494028806686401, 0.7206945419311523, 0.724383533000946, 0.7172755002975464, 0.7166194915771484, 0.7217715382575989, 0.7115822434425354, 0.7070527076721191, 0.706240177154541, 0.7045546770095825, 0.7110077738761902, 0.6912737488746643, 0.6942822933197021, 0.6931236982345581, 0.702215850353241, 0.6824063658714294, 0.6789142489433289, 0.6795808672904968, 0.6790164709091187, 0.6757352948188782, 0.6759387850761414, 0.6730822324752808, 0.6669996380805969, 0.6710066795349121, 0.6609727144241333, 0.656180739402771, 0.656710147857666, 0.6503797173500061, 0.6567628979682922, 0.6582216024398804, 0.6439147591590881, 0.6425776481628418, 0.6433933973312378, 0.6340901851654053, 0.643275260925293, 0.637645959854126, 0.637454092502594, 0.6423428058624268, 0.6324441432952881, 0.6245527267456055, 0.6186425089836121, 0.6187628507614136, 0.6136775612831116, 0.6081811189651489, 0.6051944494247437, 0.5983406901359558], 'accuracy': [0.7607235312461853, 0.7653746604919434, 0.7658914923667908, 0.7695090174674988, 0.7700258493423462, 0.7720929980278015, 0.7749354243278503, 0.7762274146080017, 0.7656330466270447, 0.7803617715835571, 0.7762274146080017, 0.7793281674385071, 0.7816537618637085, 0.7816537618637085, 0.7793281674385071, 0.7878552675247192, 0.7842377424240112, 0.7878552675247192, 0.7829457521438599, 0.7878552675247192, 0.7891472578048706, 0.7894057035446167, 0.7940568327903748, 0.791472852230072, 0.7953488230705261, 0.7966408133506775, 0.7953488230705261, 0.8031007647514343, 0.7909560799598694, 0.8033591508865356, 0.7992247939109802, 0.7912144660949707, 0.7857881188392639, 0.7981911897659302, 0.801033616065979, 0.8033591508865356, 0.8054263591766357, 0.8036175966262817, 0.8064599633216858, 0.8033591508865356, 0.8077519536018372, 0.8049095869064331, 0.813178300857544, 0.8111110925674438, 0.8043927550315857, 0.8129199147224426, 0.8077519536018372, 0.8118863105773926, 0.8103359341621399, 0.8118863105773926, 0.817829430103302, 0.8155038952827454, 0.8227390050888062, 0.8155038952827454, 0.7961240410804749, 0.8224806189537048, 0.816020667552948, 0.8222222328186035, 0.8219638466835022, 0.818863034248352, 0.8211886286735535, 0.8222222328186035, 0.8232558369636536, 0.8260982036590576, 0.8196382522583008, 0.830232560634613, 0.8289405703544617, 0.8253229856491089, 0.8255813717842102, 0.8289405703544617, 0.8397932648658752, 0.8286821842193604, 0.8341085314750671, 0.8333333134651184, 0.832041323184967, 0.8364341259002686, 0.8348837494850159, 0.829198956489563, 0.8413436412811279, 0.840568482875824, 0.8387596607208252, 0.8428940773010254, 0.8392764925956726, 0.8382428884506226, 0.8421188592910767, 0.8459948301315308, 0.8410852551460266, 0.8490955829620361, 0.8392764925956726, 0.8472868204116821, 0.845219612121582, 0.8390181064605713, 0.8428940773010254, 0.8527131676673889, 0.845219612121582, 0.8534883856773376, 0.8501291871070862, 0.8568475246429443, 0.8599483370780945, 0.8563307523727417], 'val_loss': [1.1394020318984985, 1.1327605247497559, 1.1228463649749756, 1.1072313785552979, 1.1016285419464111, 1.0957685708999634, 1.085418701171875, 1.076621651649475, 1.056900978088379, 1.0448734760284424, 1.033591628074646, 1.011089563369751, 1.0056965351104736, 0.999093770980835, 0.9706206917762756, 0.9442923069000244, 0.93266761302948, 0.9236983060836792, 0.9139138460159302, 0.9051101207733154, 0.9006301760673523, 0.8928738236427307, 0.8904154300689697, 0.8915886282920837, 0.9013322591781616, 0.9036603569984436, 0.8816002607345581, 0.8790653347969055, 0.8812593221664429, 0.8756160140037537, 0.8767812252044678, 0.8782207369804382, 0.8691513538360596, 0.871597170829773, 0.8881455659866333, 0.886872410774231, 0.8693077564239502, 0.8612916469573975, 0.8649852275848389, 0.8605256080627441, 0.8633660078048706, 0.8599202036857605, 0.85640949010849, 0.8542684316635132, 0.8511083722114563, 0.8847829699516296, 0.8504571914672852, 0.8509493470191956, 0.846449613571167, 0.8433749079704285, 0.8433889150619507, 0.8413095474243164, 0.8410168886184692, 0.8564057350158691, 0.847969651222229, 0.8342870473861694, 0.8371763825416565, 0.8359742164611816, 0.8456519246101379, 0.8317363262176514, 0.826090395450592, 0.837082028388977, 0.8274511098861694, 0.8391695618629456, 0.8225519061088562, 0.8335427641868591, 0.832996129989624, 0.8455307483673096, 0.8218400478363037, 0.8219980001449585, 0.825827956199646, 0.8192524909973145, 0.8260793685913086, 0.8241128325462341, 0.8187556266784668, 0.81843501329422, 0.8273289203643799, 0.824194610118866, 0.8276345133781433, 0.827809751033783, 0.8137544989585876, 0.8103156685829163, 0.809149980545044, 0.8036198616027832, 0.8072481751441956, 0.8197158575057983, 0.81531822681427, 0.806969940662384, 0.8075802326202393, 0.8189303874969482, 0.8184844851493835, 0.7981836199760437, 0.8169658780097961, 0.8168964385986328, 0.8246808648109436, 0.8141734600067139, 0.8100730180740356, 0.8034788966178894, 0.8053304553031921, 0.805677056312561], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.49070248007774353, 0.49793389439582825, 0.547520637512207, 0.567148745059967, 0.586776852607727, 0.66425621509552, 0.6518595218658447, 0.6518595218658447, 0.7004132270812988, 0.7272727489471436, 0.7314049601554871, 0.7283057570457458, 0.7293388247489929, 0.7376033067703247, 0.7716942429542542, 0.7654958963394165, 0.7561983466148376, 0.7665289044380188, 0.76962810754776, 0.7314049601554871, 0.7665289044380188, 0.7716942429542542, 0.7727272510528564, 0.7685950398445129, 0.7634297609329224, 0.7520661354064941, 0.76962810754776, 0.7716942429542542, 0.7665289044380188, 0.7665289044380188, 0.7489669322967529, 0.7644628286361694, 0.7644628286361694, 0.7613636255264282, 0.7469007968902588, 0.76962810754776, 0.7634297609329224, 0.7654958963394165, 0.7644628286361694, 0.7200413346290588, 0.7603305578231812, 0.7623966932296753, 0.7623966932296753, 0.7613636255264282, 0.7613636255264282, 0.7572314143180847, 0.7572314143180847, 0.7675619721412659, 0.7438016533851624, 0.7623966932296753, 0.7613636255264282, 0.7623966932296753, 0.7685950398445129, 0.7706611752510071, 0.7530992031097412, 0.7634297609329224, 0.7541322112083435, 0.7489669322967529, 0.7592975497245789, 0.7634297609329224, 0.7510330677032471, 0.7407024502754211, 0.7561983466148376, 0.7551652789115906, 0.7634297609329224, 0.7530992031097412, 0.7644628286361694, 0.7685950398445129, 0.7541322112083435, 0.7541322112083435, 0.7520661354064941, 0.7706611752510071, 0.7634297609329224, 0.7634297609329224, 0.7623966932296753, 0.7561983466148376, 0.7520661354064941, 0.7551652789115906, 0.7520661354064941, 0.7675619721412659, 0.7644628286361694, 0.7541322112083435, 0.7582644820213318, 0.7541322112083435, 0.76962810754776, 0.7603305578231812, 0.7551652789115906, 0.7458677887916565, 0.7438016533851624, 0.7489669322967529, 0.75, 0.7551652789115906, 0.7665289044380188, 0.7623966932296753]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.6869 - accuracy: 0.8179"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 50ms/step - loss: 0.6852 - accuracy: 0.8198 - val_loss: 1.0196 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6651 - accuracy: 0.8273 - val_loss: 1.0199 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6535 - accuracy: 0.8289 - val_loss: 0.9901 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6503 - accuracy: 0.8373 - val_loss: 0.9719 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6503 - accuracy: 0.8314 - val_loss: 0.9656 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6483 - accuracy: 0.8346 - val_loss: 0.9450 - val_accuracy: 0.4968\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6472 - accuracy: 0.8351 - val_loss: 0.9332 - val_accuracy: 0.5065\n","Epoch 8/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6341 - accuracy: 0.8429 - val_loss: 0.9273 - val_accuracy: 0.5183\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6344 - accuracy: 0.8429 - val_loss: 0.9149 - val_accuracy: 0.5377\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6399 - accuracy: 0.8346 - val_loss: 0.8998 - val_accuracy: 0.5754\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6390 - accuracy: 0.8314 - val_loss: 0.8639 - val_accuracy: 0.6821\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6279 - accuracy: 0.8389 - val_loss: 0.8711 - val_accuracy: 0.6358\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6176 - accuracy: 0.8513 - val_loss: 0.8532 - val_accuracy: 0.6627\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6192 - accuracy: 0.8427 - val_loss: 0.8237 - val_accuracy: 0.7144\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6101 - accuracy: 0.8561 - val_loss: 0.8524 - val_accuracy: 0.6358\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6110 - accuracy: 0.8578 - val_loss: 0.7786 - val_accuracy: 0.7532\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6135 - accuracy: 0.8483 - val_loss: 0.8022 - val_accuracy: 0.7166\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6096 - accuracy: 0.8543 - val_loss: 0.7893 - val_accuracy: 0.7284\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6063 - accuracy: 0.8534 - val_loss: 0.7281 - val_accuracy: 0.7759\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6027 - accuracy: 0.8473 - val_loss: 0.7155 - val_accuracy: 0.7845\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6021 - accuracy: 0.8521 - val_loss: 0.7084 - val_accuracy: 0.7812\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5977 - accuracy: 0.8615 - val_loss: 0.6944 - val_accuracy: 0.7953\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5910 - accuracy: 0.8572 - val_loss: 0.6890 - val_accuracy: 0.8006\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5879 - accuracy: 0.8596 - val_loss: 0.6879 - val_accuracy: 0.8017\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5995 - accuracy: 0.8478 - val_loss: 0.7297 - val_accuracy: 0.7683\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6011 - accuracy: 0.8491 - val_loss: 0.6836 - val_accuracy: 0.8017\n","Epoch 27/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.5890 - accuracy: 0.8534 - val_loss: 0.6693 - val_accuracy: 0.8071\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5726 - accuracy: 0.8680 - val_loss: 0.6818 - val_accuracy: 0.8071\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5797 - accuracy: 0.8626 - val_loss: 0.6637 - val_accuracy: 0.8244\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5818 - accuracy: 0.8631 - val_loss: 0.6780 - val_accuracy: 0.8103\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5858 - accuracy: 0.8532 - val_loss: 0.6642 - val_accuracy: 0.8244\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5660 - accuracy: 0.8693 - val_loss: 0.6696 - val_accuracy: 0.8103\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5636 - accuracy: 0.8640 - val_loss: 0.6676 - val_accuracy: 0.8157\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5709 - accuracy: 0.8672 - val_loss: 0.6923 - val_accuracy: 0.8028\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5682 - accuracy: 0.8583 - val_loss: 0.6889 - val_accuracy: 0.8103\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5623 - accuracy: 0.8683 - val_loss: 0.6883 - val_accuracy: 0.7996\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5552 - accuracy: 0.8702 - val_loss: 0.6652 - val_accuracy: 0.8200\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5645 - accuracy: 0.8610 - val_loss: 0.7020 - val_accuracy: 0.7877\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5701 - accuracy: 0.8642 - val_loss: 0.6983 - val_accuracy: 0.7856\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5475 - accuracy: 0.8745 - val_loss: 0.6650 - val_accuracy: 0.8157\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5468 - accuracy: 0.8750 - val_loss: 0.6638 - val_accuracy: 0.8211\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5472 - accuracy: 0.8680 - val_loss: 0.6967 - val_accuracy: 0.7974\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5443 - accuracy: 0.8745 - val_loss: 0.6674 - val_accuracy: 0.8190\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5606 - accuracy: 0.8637 - val_loss: 0.6987 - val_accuracy: 0.8039\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5413 - accuracy: 0.8755 - val_loss: 0.6663 - val_accuracy: 0.8190\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5361 - accuracy: 0.8769 - val_loss: 0.6825 - val_accuracy: 0.8103\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5358 - accuracy: 0.8780 - val_loss: 0.6698 - val_accuracy: 0.8136\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5210 - accuracy: 0.8863 - val_loss: 0.6719 - val_accuracy: 0.8093\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5274 - accuracy: 0.8747 - val_loss: 0.6625 - val_accuracy: 0.8147\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5308 - accuracy: 0.8788 - val_loss: 0.6969 - val_accuracy: 0.7953\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5165 - accuracy: 0.8871 - val_loss: 0.6711 - val_accuracy: 0.8147\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5190 - accuracy: 0.8804 - val_loss: 0.6853 - val_accuracy: 0.8006\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5237 - accuracy: 0.8801 - val_loss: 0.6643 - val_accuracy: 0.8244\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5282 - accuracy: 0.8739 - val_loss: 0.6620 - val_accuracy: 0.8136\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5061 - accuracy: 0.8930 - val_loss: 0.6651 - val_accuracy: 0.8157\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5153 - accuracy: 0.8885 - val_loss: 0.6629 - val_accuracy: 0.8125\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5105 - accuracy: 0.8850 - val_loss: 0.6790 - val_accuracy: 0.8200\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5108 - accuracy: 0.8850 - val_loss: 0.6647 - val_accuracy: 0.8200\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5100 - accuracy: 0.8858 - val_loss: 0.6689 - val_accuracy: 0.8190\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4953 - accuracy: 0.9006 - val_loss: 0.6717 - val_accuracy: 0.8190\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4952 - accuracy: 0.8922 - val_loss: 0.7051 - val_accuracy: 0.7953\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4990 - accuracy: 0.8909 - val_loss: 0.6718 - val_accuracy: 0.8222\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4940 - accuracy: 0.8928 - val_loss: 0.6682 - val_accuracy: 0.8244\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4907 - accuracy: 0.8925 - val_loss: 0.6675 - val_accuracy: 0.8179\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4850 - accuracy: 0.8979 - val_loss: 0.6852 - val_accuracy: 0.8136\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4901 - accuracy: 0.8917 - val_loss: 0.7127 - val_accuracy: 0.7953\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4906 - accuracy: 0.8966 - val_loss: 0.6727 - val_accuracy: 0.8147\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4818 - accuracy: 0.8974 - val_loss: 0.6757 - val_accuracy: 0.8211\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4793 - accuracy: 0.9017 - val_loss: 0.6770 - val_accuracy: 0.8222\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4791 - accuracy: 0.8984 - val_loss: 0.6880 - val_accuracy: 0.8103\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4823 - accuracy: 0.8909 - val_loss: 0.6866 - val_accuracy: 0.8114\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4750 - accuracy: 0.9022 - val_loss: 0.6772 - val_accuracy: 0.8157\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4965 - accuracy: 0.8842 - val_loss: 0.6754 - val_accuracy: 0.8103\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4639 - accuracy: 0.9068 - val_loss: 0.6902 - val_accuracy: 0.8114\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.8952 - val_loss: 0.6753 - val_accuracy: 0.8168\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4619 - accuracy: 0.9052 - val_loss: 0.6782 - val_accuracy: 0.8147\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4648 - accuracy: 0.8987 - val_loss: 0.6737 - val_accuracy: 0.8190\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4551 - accuracy: 0.9092 - val_loss: 0.7101 - val_accuracy: 0.8114\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4600 - accuracy: 0.9038 - val_loss: 0.6942 - val_accuracy: 0.8103\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4476 - accuracy: 0.9130 - val_loss: 0.7120 - val_accuracy: 0.8093\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4597 - accuracy: 0.9009 - val_loss: 0.6826 - val_accuracy: 0.8028\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4565 - accuracy: 0.9046 - val_loss: 0.6867 - val_accuracy: 0.8179\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4713 - accuracy: 0.8987 - val_loss: 0.6854 - val_accuracy: 0.8082\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4439 - accuracy: 0.9154 - val_loss: 0.6837 - val_accuracy: 0.8200\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4385 - accuracy: 0.9141 - val_loss: 0.6890 - val_accuracy: 0.8222\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4316 - accuracy: 0.9211 - val_loss: 0.6906 - val_accuracy: 0.8125\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4331 - accuracy: 0.9149 - val_loss: 0.6984 - val_accuracy: 0.8125\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4473 - accuracy: 0.9103 - val_loss: 0.6924 - val_accuracy: 0.8190\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4435 - accuracy: 0.9092 - val_loss: 0.6931 - val_accuracy: 0.8147\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4375 - accuracy: 0.9141 - val_loss: 0.6877 - val_accuracy: 0.8190\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4281 - accuracy: 0.9154 - val_loss: 0.7138 - val_accuracy: 0.8136\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4342 - accuracy: 0.9157 - val_loss: 0.7313 - val_accuracy: 0.7931\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4297 - accuracy: 0.9195 - val_loss: 0.6992 - val_accuracy: 0.8179\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4229 - accuracy: 0.9243 - val_loss: 0.7020 - val_accuracy: 0.8114\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4223 - accuracy: 0.9224 - val_loss: 0.7018 - val_accuracy: 0.8168\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4205 - accuracy: 0.9203 - val_loss: 0.7399 - val_accuracy: 0.7909\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4198 - accuracy: 0.9254 - val_loss: 0.7024 - val_accuracy: 0.8093\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4173 - accuracy: 0.9211 - val_loss: 0.7208 - val_accuracy: 0.8114\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4125 - accuracy: 0.9230 - val_loss: 0.7124 - val_accuracy: 0.8093\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4137 - accuracy: 0.9243 - val_loss: 0.7132 - val_accuracy: 0.8050\n","{'loss': [0.6851679086685181, 0.6651368141174316, 0.6534909009933472, 0.6502915620803833, 0.6502639055252075, 0.6482504606246948, 0.6471704244613647, 0.6340687870979309, 0.6344411373138428, 0.6399396061897278, 0.6389656066894531, 0.6279440522193909, 0.6175886392593384, 0.6192154288291931, 0.6101242303848267, 0.610951840877533, 0.6134801506996155, 0.6096376180648804, 0.6063491106033325, 0.6026955246925354, 0.6020810604095459, 0.597667932510376, 0.5909770727157593, 0.5879173874855042, 0.5995147824287415, 0.6010644435882568, 0.588972270488739, 0.5726393461227417, 0.579703688621521, 0.5817589163780212, 0.5858141779899597, 0.5660164952278137, 0.5636091828346252, 0.5709090828895569, 0.5681754946708679, 0.5623498558998108, 0.5551694631576538, 0.564538836479187, 0.5701139569282532, 0.5475185513496399, 0.5467524528503418, 0.5472462177276611, 0.5442630648612976, 0.5606465935707092, 0.5413263440132141, 0.5361316800117493, 0.5358388423919678, 0.5209709405899048, 0.5273534655570984, 0.5308379530906677, 0.5164856910705566, 0.5189945101737976, 0.5237311124801636, 0.5282053351402283, 0.506080150604248, 0.5153378844261169, 0.5104817748069763, 0.5107680559158325, 0.5100439786911011, 0.4953269958496094, 0.49523138999938965, 0.4989788234233856, 0.4940110445022583, 0.4907200336456299, 0.48499903082847595, 0.49008870124816895, 0.49059998989105225, 0.4818481206893921, 0.4792715311050415, 0.4791116416454315, 0.4822682738304138, 0.4750034213066101, 0.4965496063232422, 0.463851660490036, 0.4718473255634308, 0.4618785083293915, 0.4648416042327881, 0.45508795976638794, 0.46000704169273376, 0.44762805104255676, 0.459712415933609, 0.4565492570400238, 0.47132399678230286, 0.44389432668685913, 0.4384763538837433, 0.4315582513809204, 0.4331153333187103, 0.447319895029068, 0.44348275661468506, 0.4374828040599823, 0.4281461834907532, 0.43421226739883423, 0.4296686053276062, 0.42286112904548645, 0.42227140069007874, 0.42048877477645874, 0.41981175541877747, 0.4172608256340027, 0.4125496447086334, 0.41371625661849976], 'accuracy': [0.8197737336158752, 0.8273168206214905, 0.8289331793785095, 0.837284505367279, 0.8313577771186829, 0.834590494632721, 0.8351293206214905, 0.8429418206214905, 0.8429418206214905, 0.834590494632721, 0.8313577771186829, 0.8389008641242981, 0.8512930870056152, 0.8426724076271057, 0.8561422228813171, 0.857758641242981, 0.8483297228813171, 0.8542564511299133, 0.8534482717514038, 0.8472521305084229, 0.8521012663841248, 0.8615301847457886, 0.8572198152542114, 0.8596444129943848, 0.8477909564971924, 0.8491379022598267, 0.8534482717514038, 0.8679956793785095, 0.8626077771186829, 0.8631465435028076, 0.853178858757019, 0.8693426847457886, 0.8639547228813171, 0.8671875, 0.8582974076271057, 0.8682650923728943, 0.8701508641242981, 0.860991358757019, 0.8642241358757019, 0.8744612336158752, 0.875, 0.8679956793785095, 0.8744612336158752, 0.8636853694915771, 0.8755387663841248, 0.8768857717514038, 0.8779633641242981, 0.8863146305084229, 0.8747305870056152, 0.8787715435028076, 0.8871228694915771, 0.8803879022598267, 0.8801185488700867, 0.8739224076271057, 0.8930495977401733, 0.8884698152542114, 0.8849676847457886, 0.8849676847457886, 0.8857758641242981, 0.9005926847457886, 0.892241358757019, 0.8908944129943848, 0.8927801847457886, 0.8925107717514038, 0.8978987336158752, 0.8917025923728943, 0.8965517282485962, 0.8973599076271057, 0.9016702771186829, 0.8984375, 0.8908944129943848, 0.9022090435028076, 0.884159505367279, 0.9067887663841248, 0.8952047228813171, 0.9051724076271057, 0.8987069129943848, 0.9092133641242981, 0.9038254022598267, 0.9129849076271057, 0.9008620977401733, 0.904633641242981, 0.8987069129943848, 0.915409505367279, 0.9140625, 0.9210668206214905, 0.9148706793785095, 0.9102909564971924, 0.9092133641242981, 0.9140625, 0.915409505367279, 0.915678858757019, 0.9194504022598267, 0.9242995977401733, 0.9224137663841248, 0.920258641242981, 0.9253771305084229, 0.9210668206214905, 0.9229525923728943, 0.9242995977401733], 'val_loss': [1.0195913314819336, 1.0198991298675537, 0.9900947213172913, 0.9719213843345642, 0.9656059741973877, 0.9449954628944397, 0.9331837892532349, 0.927314817905426, 0.9149380326271057, 0.8998170495033264, 0.8639158606529236, 0.8710958957672119, 0.8532143831253052, 0.8237271308898926, 0.8524015545845032, 0.7786250114440918, 0.8021602630615234, 0.7893198132514954, 0.728134274482727, 0.7155341506004333, 0.7083877325057983, 0.6943842768669128, 0.6890118718147278, 0.6878612637519836, 0.7296924591064453, 0.6835975646972656, 0.6693335175514221, 0.6817641258239746, 0.6636888980865479, 0.6779667139053345, 0.6642137169837952, 0.6695936918258667, 0.6675807237625122, 0.6923078894615173, 0.6889247894287109, 0.6883286833763123, 0.665225625038147, 0.7019909620285034, 0.6982582807540894, 0.6649905443191528, 0.6638247966766357, 0.6966848969459534, 0.6674073934555054, 0.6986691951751709, 0.6662622094154358, 0.6824713349342346, 0.6698423624038696, 0.671868622303009, 0.6625058650970459, 0.6969301700592041, 0.6711386442184448, 0.6853238344192505, 0.6643319129943848, 0.6619606614112854, 0.6651499271392822, 0.6629124283790588, 0.6789981722831726, 0.6646999716758728, 0.6688526272773743, 0.6717485785484314, 0.7050790190696716, 0.671773374080658, 0.6681514382362366, 0.6674803495407104, 0.685197114944458, 0.7127229571342468, 0.6726736426353455, 0.6756798028945923, 0.67695552110672, 0.687974214553833, 0.6865831613540649, 0.677161693572998, 0.6753525733947754, 0.6902459859848022, 0.675323486328125, 0.6782342195510864, 0.6736903786659241, 0.7100783586502075, 0.6942268013954163, 0.712047815322876, 0.6825643181800842, 0.6867255568504333, 0.6853715777397156, 0.6837261915206909, 0.6889871954917908, 0.6905674338340759, 0.6984134316444397, 0.6923846006393433, 0.6931201815605164, 0.6876591444015503, 0.7137847542762756, 0.7312908172607422, 0.699233889579773, 0.7020252346992493, 0.7018135786056519, 0.7399497032165527, 0.7023724317550659, 0.720767617225647, 0.7124342322349548, 0.7132216691970825], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4967672526836395, 0.506465494632721, 0.5183189511299133, 0.537715494632721, 0.5754310488700867, 0.6821120977401733, 0.6357758641242981, 0.662715494632721, 0.7144396305084229, 0.6357758641242981, 0.7532327771186829, 0.7165948152542114, 0.7284482717514038, 0.7758620977401733, 0.7844827771186829, 0.78125, 0.795258641242981, 0.8006465435028076, 0.8017241358757019, 0.7683189511299133, 0.8017241358757019, 0.8071120977401733, 0.8071120977401733, 0.8243534564971924, 0.8103448152542114, 0.8243534564971924, 0.8103448152542114, 0.8157327771186829, 0.8028017282485962, 0.8103448152542114, 0.7995689511299133, 0.8200430870056152, 0.787715494632721, 0.7855603694915771, 0.8157327771186829, 0.8211206793785095, 0.7974137663841248, 0.818965494632721, 0.8038793206214905, 0.818965494632721, 0.8103448152542114, 0.8135775923728943, 0.8092672228813171, 0.8146551847457886, 0.795258641242981, 0.8146551847457886, 0.8006465435028076, 0.8243534564971924, 0.8135775923728943, 0.8157327771186829, 0.8125, 0.8200430870056152, 0.8200430870056152, 0.818965494632721, 0.818965494632721, 0.795258641242981, 0.8221982717514038, 0.8243534564971924, 0.8178879022598267, 0.8135775923728943, 0.795258641242981, 0.8146551847457886, 0.8211206793785095, 0.8221982717514038, 0.8103448152542114, 0.8114224076271057, 0.8157327771186829, 0.8103448152542114, 0.8114224076271057, 0.8168103694915771, 0.8146551847457886, 0.818965494632721, 0.8114224076271057, 0.8103448152542114, 0.8092672228813171, 0.8028017282485962, 0.8178879022598267, 0.8081896305084229, 0.8200430870056152, 0.8221982717514038, 0.8125, 0.8125, 0.818965494632721, 0.8146551847457886, 0.818965494632721, 0.8135775923728943, 0.7931034564971924, 0.8178879022598267, 0.8114224076271057, 0.8168103694915771, 0.7909482717514038, 0.8092672228813171, 0.8114224076271057, 0.8092672228813171, 0.8049569129943848]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.6849 - accuracy: 0.8122"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 10s 54ms/step - loss: 0.6781 - accuracy: 0.8152 - val_loss: 1.0125 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6537 - accuracy: 0.8345 - val_loss: 1.0097 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6510 - accuracy: 0.8342 - val_loss: 1.0015 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6449 - accuracy: 0.8379 - val_loss: 0.9741 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6418 - accuracy: 0.8387 - val_loss: 0.9715 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6356 - accuracy: 0.8396 - val_loss: 0.9489 - val_accuracy: 0.5011\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6322 - accuracy: 0.8418 - val_loss: 0.9544 - val_accuracy: 0.4989\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6356 - accuracy: 0.8328 - val_loss: 0.9326 - val_accuracy: 0.5170\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6233 - accuracy: 0.8432 - val_loss: 0.9450 - val_accuracy: 0.5090\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6188 - accuracy: 0.8486 - val_loss: 0.9138 - val_accuracy: 0.5509\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6219 - accuracy: 0.8463 - val_loss: 0.9198 - val_accuracy: 0.5509\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6113 - accuracy: 0.8526 - val_loss: 0.9563 - val_accuracy: 0.5249\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6162 - accuracy: 0.8497 - val_loss: 0.9104 - val_accuracy: 0.5735\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6038 - accuracy: 0.8568 - val_loss: 0.9220 - val_accuracy: 0.5679\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6045 - accuracy: 0.8520 - val_loss: 0.8698 - val_accuracy: 0.6233\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6012 - accuracy: 0.8531 - val_loss: 0.9024 - val_accuracy: 0.5962\n","Epoch 17/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5967 - accuracy: 0.8605 - val_loss: 0.8231 - val_accuracy: 0.6833\n","Epoch 18/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5981 - accuracy: 0.8565 - val_loss: 0.8006 - val_accuracy: 0.7036\n","Epoch 19/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5910 - accuracy: 0.8605 - val_loss: 0.7716 - val_accuracy: 0.7376\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5888 - accuracy: 0.8616 - val_loss: 0.7672 - val_accuracy: 0.7398\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5934 - accuracy: 0.8520 - val_loss: 0.7544 - val_accuracy: 0.7511\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5864 - accuracy: 0.8616 - val_loss: 0.7317 - val_accuracy: 0.7658\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5780 - accuracy: 0.8596 - val_loss: 0.7179 - val_accuracy: 0.7794\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5825 - accuracy: 0.8599 - val_loss: 0.7030 - val_accuracy: 0.7930\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5777 - accuracy: 0.8647 - val_loss: 0.7118 - val_accuracy: 0.7726\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5714 - accuracy: 0.8633 - val_loss: 0.7055 - val_accuracy: 0.7817\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5746 - accuracy: 0.8611 - val_loss: 0.6989 - val_accuracy: 0.7873\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5634 - accuracy: 0.8715 - val_loss: 0.6987 - val_accuracy: 0.7873\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5731 - accuracy: 0.8653 - val_loss: 0.7252 - val_accuracy: 0.7805\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5798 - accuracy: 0.8540 - val_loss: 0.7377 - val_accuracy: 0.7805\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5597 - accuracy: 0.8724 - val_loss: 0.7206 - val_accuracy: 0.7873\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5617 - accuracy: 0.8698 - val_loss: 0.7377 - val_accuracy: 0.7828\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5578 - accuracy: 0.8724 - val_loss: 0.7153 - val_accuracy: 0.7692\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5536 - accuracy: 0.8713 - val_loss: 0.7119 - val_accuracy: 0.7839\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5496 - accuracy: 0.8763 - val_loss: 0.7179 - val_accuracy: 0.7771\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5540 - accuracy: 0.8713 - val_loss: 0.7060 - val_accuracy: 0.7907\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5488 - accuracy: 0.8701 - val_loss: 0.7094 - val_accuracy: 0.7839\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5449 - accuracy: 0.8741 - val_loss: 0.7959 - val_accuracy: 0.7658\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5492 - accuracy: 0.8749 - val_loss: 0.7274 - val_accuracy: 0.7862\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5479 - accuracy: 0.8735 - val_loss: 0.7191 - val_accuracy: 0.7738\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5314 - accuracy: 0.8829 - val_loss: 0.7176 - val_accuracy: 0.7783\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5415 - accuracy: 0.8786 - val_loss: 0.7251 - val_accuracy: 0.7692\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5374 - accuracy: 0.8803 - val_loss: 0.7341 - val_accuracy: 0.7817\n","Epoch 44/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5283 - accuracy: 0.8865 - val_loss: 0.7233 - val_accuracy: 0.7952\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5244 - accuracy: 0.8831 - val_loss: 0.7172 - val_accuracy: 0.7941\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5257 - accuracy: 0.8846 - val_loss: 0.7237 - val_accuracy: 0.7794\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5207 - accuracy: 0.8894 - val_loss: 0.7132 - val_accuracy: 0.7749\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5120 - accuracy: 0.8846 - val_loss: 0.7161 - val_accuracy: 0.7738\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5120 - accuracy: 0.8908 - val_loss: 0.7200 - val_accuracy: 0.7794\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5167 - accuracy: 0.8854 - val_loss: 0.7221 - val_accuracy: 0.7885\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5039 - accuracy: 0.8885 - val_loss: 0.7229 - val_accuracy: 0.7885\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5095 - accuracy: 0.8874 - val_loss: 0.7453 - val_accuracy: 0.7783\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5184 - accuracy: 0.8820 - val_loss: 0.7280 - val_accuracy: 0.7749\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5060 - accuracy: 0.8919 - val_loss: 0.7189 - val_accuracy: 0.7783\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5003 - accuracy: 0.8933 - val_loss: 0.7164 - val_accuracy: 0.7805\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4973 - accuracy: 0.8976 - val_loss: 0.7274 - val_accuracy: 0.7704\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4953 - accuracy: 0.8945 - val_loss: 0.7298 - val_accuracy: 0.7760\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5025 - accuracy: 0.8922 - val_loss: 0.7221 - val_accuracy: 0.7885\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4967 - accuracy: 0.8998 - val_loss: 0.7224 - val_accuracy: 0.7738\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4913 - accuracy: 0.8959 - val_loss: 0.7166 - val_accuracy: 0.7726\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5049 - accuracy: 0.8913 - val_loss: 0.7600 - val_accuracy: 0.7760\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4841 - accuracy: 0.9024 - val_loss: 0.7239 - val_accuracy: 0.7907\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4744 - accuracy: 0.9010 - val_loss: 0.7379 - val_accuracy: 0.7817\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4753 - accuracy: 0.9086 - val_loss: 0.7330 - val_accuracy: 0.7692\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4745 - accuracy: 0.9004 - val_loss: 0.7261 - val_accuracy: 0.7828\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4800 - accuracy: 0.8993 - val_loss: 0.7494 - val_accuracy: 0.7726\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4870 - accuracy: 0.8964 - val_loss: 0.7258 - val_accuracy: 0.7862\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4755 - accuracy: 0.9018 - val_loss: 0.7334 - val_accuracy: 0.7862\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4759 - accuracy: 0.9021 - val_loss: 0.7330 - val_accuracy: 0.7760\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4856 - accuracy: 0.9012 - val_loss: 0.7490 - val_accuracy: 0.7952\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4711 - accuracy: 0.8993 - val_loss: 0.7225 - val_accuracy: 0.7794\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4691 - accuracy: 0.9035 - val_loss: 0.7241 - val_accuracy: 0.7771\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4586 - accuracy: 0.9083 - val_loss: 0.7248 - val_accuracy: 0.7817\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4734 - accuracy: 0.9015 - val_loss: 0.7279 - val_accuracy: 0.7828\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4648 - accuracy: 0.9066 - val_loss: 0.7249 - val_accuracy: 0.7771\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4644 - accuracy: 0.9063 - val_loss: 0.8062 - val_accuracy: 0.7715\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4668 - accuracy: 0.9004 - val_loss: 0.8187 - val_accuracy: 0.7579\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4556 - accuracy: 0.9131 - val_loss: 0.7271 - val_accuracy: 0.7771\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4445 - accuracy: 0.9182 - val_loss: 0.7678 - val_accuracy: 0.7919\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4522 - accuracy: 0.9128 - val_loss: 0.7310 - val_accuracy: 0.7851\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4479 - accuracy: 0.9128 - val_loss: 0.7410 - val_accuracy: 0.7715\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4383 - accuracy: 0.9199 - val_loss: 0.7664 - val_accuracy: 0.7873\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4412 - accuracy: 0.9185 - val_loss: 0.7427 - val_accuracy: 0.7828\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4338 - accuracy: 0.9222 - val_loss: 0.7459 - val_accuracy: 0.7760\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4360 - accuracy: 0.9126 - val_loss: 0.7448 - val_accuracy: 0.7738\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4339 - accuracy: 0.9185 - val_loss: 0.8285 - val_accuracy: 0.7738\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4378 - accuracy: 0.9134 - val_loss: 0.7422 - val_accuracy: 0.7794\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.9261 - val_loss: 0.7425 - val_accuracy: 0.7783\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.9194 - val_loss: 0.7857 - val_accuracy: 0.7896\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4159 - accuracy: 0.9267 - val_loss: 0.7574 - val_accuracy: 0.7851\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4177 - accuracy: 0.9301 - val_loss: 0.7685 - val_accuracy: 0.7862\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.9256 - val_loss: 0.7519 - val_accuracy: 0.7805\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4591 - accuracy: 0.9018 - val_loss: 0.7492 - val_accuracy: 0.7794\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4264 - accuracy: 0.9211 - val_loss: 0.7541 - val_accuracy: 0.7885\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4294 - accuracy: 0.9205 - val_loss: 0.8299 - val_accuracy: 0.7534\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4271 - accuracy: 0.9199 - val_loss: 0.7543 - val_accuracy: 0.7771\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4167 - accuracy: 0.9253 - val_loss: 0.7480 - val_accuracy: 0.7726\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4108 - accuracy: 0.9270 - val_loss: 0.7599 - val_accuracy: 0.7783\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4021 - accuracy: 0.9329 - val_loss: 0.7606 - val_accuracy: 0.7738\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3939 - accuracy: 0.9366 - val_loss: 0.7780 - val_accuracy: 0.7692\n","{'loss': [0.6780862212181091, 0.6537490487098694, 0.6509993672370911, 0.644851803779602, 0.6417700052261353, 0.6356040239334106, 0.6322190761566162, 0.6356043219566345, 0.6232887506484985, 0.6188206076622009, 0.6218896508216858, 0.6113182902336121, 0.6161679029464722, 0.6037852764129639, 0.6044996976852417, 0.6012248396873474, 0.5966762900352478, 0.5980744957923889, 0.5910232663154602, 0.5887714624404907, 0.5934413075447083, 0.5864056348800659, 0.578045666217804, 0.5824642181396484, 0.5776854753494263, 0.5713804364204407, 0.5746389031410217, 0.563433051109314, 0.5730501413345337, 0.5798423290252686, 0.5597016215324402, 0.5616827011108398, 0.5578204989433289, 0.5535821914672852, 0.5496290922164917, 0.5540171265602112, 0.5487513542175293, 0.5448756814002991, 0.5491803288459778, 0.5478945970535278, 0.5314170122146606, 0.5415493845939636, 0.5373601913452148, 0.5283297300338745, 0.5244380831718445, 0.525671124458313, 0.5206628441810608, 0.5120137929916382, 0.5119893550872803, 0.5167128443717957, 0.5039427876472473, 0.5095362067222595, 0.518409788608551, 0.5059714913368225, 0.5003435015678406, 0.4972756505012512, 0.49534717202186584, 0.5025162100791931, 0.49671754240989685, 0.491295725107193, 0.5049341320991516, 0.48409172892570496, 0.474359393119812, 0.47528842091560364, 0.47450655698776245, 0.48003771901130676, 0.4869690537452698, 0.4754990339279175, 0.47592899203300476, 0.48555177450180054, 0.47111108899116516, 0.4691019356250763, 0.45864272117614746, 0.4733550250530243, 0.464771032333374, 0.4643939733505249, 0.4667634069919586, 0.4555824100971222, 0.444539874792099, 0.452168345451355, 0.44785499572753906, 0.43825986981391907, 0.44124117493629456, 0.43378785252571106, 0.43599575757980347, 0.43388885259628296, 0.43779537081718445, 0.4277445673942566, 0.42770108580589294, 0.41593655943870544, 0.41768085956573486, 0.4232111871242523, 0.4590856432914734, 0.42641645669937134, 0.42943114042282104, 0.42708244919776917, 0.41667628288269043, 0.41080284118652344, 0.40206632018089294, 0.3938615620136261], 'accuracy': [0.8152235150337219, 0.8344652056694031, 0.8341822028160095, 0.8378607630729675, 0.8387096524238586, 0.8395586013793945, 0.8418223261833191, 0.8327674269676208, 0.8432371020317078, 0.848613440990448, 0.8463497161865234, 0.8525750041007996, 0.8497453331947327, 0.8568194508552551, 0.8520090579986572, 0.8531408905982971, 0.8604980111122131, 0.8565365076065063, 0.8604980111122131, 0.8616299033164978, 0.8520090579986572, 0.8616299033164978, 0.859649121761322, 0.8599320650100708, 0.8647425174713135, 0.86332768201828, 0.8610639572143555, 0.8715336918830872, 0.865308403968811, 0.853989839553833, 0.8723825812339783, 0.8698358535766602, 0.8723825812339783, 0.8712506890296936, 0.8763440847396851, 0.8712506890296936, 0.8701188564300537, 0.8740803599357605, 0.8749292492866516, 0.8735144138336182, 0.88285231590271, 0.8786078095436096, 0.8803055882453918, 0.8865308165550232, 0.8831352591514587, 0.8845500946044922, 0.8893604874610901, 0.8845500946044922, 0.8907753229141235, 0.8853989839553833, 0.888511598110199, 0.8873797655105591, 0.8820033669471741, 0.8919072151184082, 0.8933219909667969, 0.8975664973258972, 0.8944538831710815, 0.892190158367157, 0.8998302221298218, 0.895868718624115, 0.8913412690162659, 0.9023768901824951, 0.9009620547294617, 0.9086021780967712, 0.9003961682319641, 0.8992642760276794, 0.8964346647262573, 0.9018110036849976, 0.9020939469337463, 0.9012450575828552, 0.8992642760276794, 0.9035087823867798, 0.9083191752433777, 0.901528000831604, 0.9066213965415955, 0.9063384532928467, 0.9003961682319641, 0.9131296277046204, 0.918222963809967, 0.9128466248512268, 0.9128466248512268, 0.9199207425117493, 0.9185059666633606, 0.9221844673156738, 0.912563681602478, 0.9185059666633606, 0.9134125709533691, 0.9261460304260254, 0.9193548560142517, 0.926711916923523, 0.9301075339317322, 0.9255800843238831, 0.9018110036849976, 0.9210526347160339, 0.9204866886138916, 0.9199207425117493, 0.9252971410751343, 0.9269949197769165, 0.9329372048377991, 0.9366157054901123], 'val_loss': [1.01250422000885, 1.0097349882125854, 1.0015223026275635, 0.9741107225418091, 0.9714895486831665, 0.9489308595657349, 0.954386293888092, 0.9326201677322388, 0.9450376629829407, 0.9138363003730774, 0.9198480844497681, 0.9563039541244507, 0.9104350805282593, 0.9219585657119751, 0.8697656393051147, 0.9023873209953308, 0.8231221437454224, 0.8006243109703064, 0.7715510725975037, 0.7671607732772827, 0.7543566823005676, 0.7316939234733582, 0.7178594470024109, 0.7030450701713562, 0.7117549180984497, 0.7055031657218933, 0.6989266872406006, 0.6987302899360657, 0.7251996994018555, 0.7376787662506104, 0.7205961346626282, 0.7376568913459778, 0.7153311967849731, 0.7119176387786865, 0.7179054021835327, 0.7059702277183533, 0.709425151348114, 0.7959110736846924, 0.7273980975151062, 0.7190632820129395, 0.7176225185394287, 0.725111722946167, 0.7340890765190125, 0.7233359813690186, 0.717207670211792, 0.7237151861190796, 0.7132088541984558, 0.716140866279602, 0.7200103998184204, 0.7220694422721863, 0.7229065895080566, 0.7452780604362488, 0.7279680967330933, 0.7188650965690613, 0.7164371609687805, 0.7274177670478821, 0.7297793626785278, 0.7221216559410095, 0.7224491238594055, 0.7166228294372559, 0.7600162625312805, 0.7239235043525696, 0.7378954291343689, 0.7329803109169006, 0.7260691523551941, 0.7494205832481384, 0.7257887721061707, 0.7334308624267578, 0.7330336570739746, 0.7490311861038208, 0.7224739789962769, 0.7241345047950745, 0.7248347997665405, 0.727888286113739, 0.7249374985694885, 0.8061500191688538, 0.8186970949172974, 0.7270699739456177, 0.7677825093269348, 0.7309500575065613, 0.7410458326339722, 0.7664200663566589, 0.7427135705947876, 0.7459122538566589, 0.7447918653488159, 0.828497052192688, 0.742222011089325, 0.7424694299697876, 0.7857047319412231, 0.7573580741882324, 0.7685102224349976, 0.7519097924232483, 0.7492258548736572, 0.7540742754936218, 0.8299280405044556, 0.7543481588363647, 0.7480268478393555, 0.7598728537559509, 0.7606114745140076, 0.778029203414917], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5011312365531921, 0.49886876344680786, 0.516968309879303, 0.5090497732162476, 0.5509049892425537, 0.5509049892425537, 0.5248869061470032, 0.5735294222831726, 0.5678732991218567, 0.6233031749725342, 0.5961538553237915, 0.6832579374313354, 0.7036198973655701, 0.7375565767288208, 0.7398189902305603, 0.7511312365531921, 0.7658371329307556, 0.779411792755127, 0.7929864525794983, 0.7726244330406189, 0.7816742062568665, 0.7873303294181824, 0.7873303294181824, 0.7805429697036743, 0.7805429697036743, 0.7873303294181824, 0.7828054428100586, 0.7692307829856873, 0.7839366793632507, 0.7771493196487427, 0.790723979473114, 0.7839366793632507, 0.7658371329307556, 0.7861990928649902, 0.773755669593811, 0.7782805562019348, 0.7692307829856873, 0.7816742062568665, 0.7952488660812378, 0.7941176295280457, 0.779411792755127, 0.7748869061470032, 0.773755669593811, 0.779411792755127, 0.7884615659713745, 0.7884615659713745, 0.7782805562019348, 0.7748869061470032, 0.7782805562019348, 0.7805429697036743, 0.7703620195388794, 0.7760180830955505, 0.7884615659713745, 0.773755669593811, 0.7726244330406189, 0.7760180830955505, 0.790723979473114, 0.7816742062568665, 0.7692307829856873, 0.7828054428100586, 0.7726244330406189, 0.7861990928649902, 0.7861990928649902, 0.7760180830955505, 0.7952488660812378, 0.779411792755127, 0.7771493196487427, 0.7816742062568665, 0.7828054428100586, 0.7771493196487427, 0.7714931964874268, 0.7579185366630554, 0.7771493196487427, 0.7918552160263062, 0.7850678563117981, 0.7714931964874268, 0.7873303294181824, 0.7828054428100586, 0.7760180830955505, 0.773755669593811, 0.773755669593811, 0.779411792755127, 0.7782805562019348, 0.7895927429199219, 0.7850678563117981, 0.7861990928649902, 0.7805429697036743, 0.779411792755127, 0.7884615659713745, 0.7533936500549316, 0.7771493196487427, 0.7726244330406189, 0.7782805562019348, 0.773755669593811, 0.7692307829856873]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 49ms/step - loss: 0.6805 - accuracy: 0.8171 - val_loss: 1.0212 - val_accuracy: 0.4855\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6625 - accuracy: 0.8261 - val_loss: 1.0196 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6515 - accuracy: 0.8276 - val_loss: 1.0121 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6625 - accuracy: 0.8225 - val_loss: 0.9783 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6443 - accuracy: 0.8344 - val_loss: 0.9717 - val_accuracy: 0.4866\n","Epoch 6/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6389 - accuracy: 0.8388 - val_loss: 0.9574 - val_accuracy: 0.4907\n","Epoch 7/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6373 - accuracy: 0.8411 - val_loss: 0.9529 - val_accuracy: 0.4938\n","Epoch 8/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6381 - accuracy: 0.8300 - val_loss: 0.9423 - val_accuracy: 0.4959\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6296 - accuracy: 0.8439 - val_loss: 0.9451 - val_accuracy: 0.5000\n","Epoch 10/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6244 - accuracy: 0.8447 - val_loss: 0.9058 - val_accuracy: 0.5579\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6328 - accuracy: 0.8323 - val_loss: 0.8878 - val_accuracy: 0.5909\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6262 - accuracy: 0.8406 - val_loss: 0.9365 - val_accuracy: 0.5320\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6204 - accuracy: 0.8398 - val_loss: 0.9484 - val_accuracy: 0.5403\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6298 - accuracy: 0.8393 - val_loss: 0.9105 - val_accuracy: 0.5764\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6074 - accuracy: 0.8514 - val_loss: 0.8935 - val_accuracy: 0.6023\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6141 - accuracy: 0.8488 - val_loss: 0.8134 - val_accuracy: 0.6880\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6132 - accuracy: 0.8496 - val_loss: 0.7908 - val_accuracy: 0.7045\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6106 - accuracy: 0.8380 - val_loss: 0.7855 - val_accuracy: 0.7107\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6054 - accuracy: 0.8465 - val_loss: 0.7873 - val_accuracy: 0.7159\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6002 - accuracy: 0.8499 - val_loss: 0.7654 - val_accuracy: 0.7366\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6310 - accuracy: 0.8331 - val_loss: 0.7592 - val_accuracy: 0.7469\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6110 - accuracy: 0.8416 - val_loss: 0.7386 - val_accuracy: 0.7665\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5968 - accuracy: 0.8478 - val_loss: 0.7331 - val_accuracy: 0.7665\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5894 - accuracy: 0.8597 - val_loss: 0.7259 - val_accuracy: 0.7758\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5910 - accuracy: 0.8532 - val_loss: 0.7411 - val_accuracy: 0.7779\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5956 - accuracy: 0.8522 - val_loss: 0.7237 - val_accuracy: 0.7851\n","Epoch 27/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5985 - accuracy: 0.8450 - val_loss: 0.7463 - val_accuracy: 0.7862\n","Epoch 28/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5828 - accuracy: 0.8561 - val_loss: 0.7247 - val_accuracy: 0.7903\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5870 - accuracy: 0.8556 - val_loss: 0.7533 - val_accuracy: 0.7800\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5829 - accuracy: 0.8589 - val_loss: 0.7206 - val_accuracy: 0.7903\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5807 - accuracy: 0.8568 - val_loss: 0.7307 - val_accuracy: 0.7738\n","Epoch 32/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5761 - accuracy: 0.8584 - val_loss: 0.7387 - val_accuracy: 0.7913\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5706 - accuracy: 0.8612 - val_loss: 0.7254 - val_accuracy: 0.7882\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5690 - accuracy: 0.8592 - val_loss: 0.7384 - val_accuracy: 0.7820\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5630 - accuracy: 0.8698 - val_loss: 0.7261 - val_accuracy: 0.7903\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5586 - accuracy: 0.8682 - val_loss: 0.7285 - val_accuracy: 0.7882\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5649 - accuracy: 0.8576 - val_loss: 0.7236 - val_accuracy: 0.7893\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5665 - accuracy: 0.8641 - val_loss: 0.7254 - val_accuracy: 0.7841\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5709 - accuracy: 0.8584 - val_loss: 0.7340 - val_accuracy: 0.7717\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5546 - accuracy: 0.8651 - val_loss: 0.7257 - val_accuracy: 0.7882\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5448 - accuracy: 0.8747 - val_loss: 0.7620 - val_accuracy: 0.7696\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5786 - accuracy: 0.8519 - val_loss: 0.7263 - val_accuracy: 0.7820\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5726 - accuracy: 0.8545 - val_loss: 0.7317 - val_accuracy: 0.7913\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5514 - accuracy: 0.8687 - val_loss: 0.7284 - val_accuracy: 0.7862\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5434 - accuracy: 0.8695 - val_loss: 0.7313 - val_accuracy: 0.7789\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5536 - accuracy: 0.8661 - val_loss: 0.7165 - val_accuracy: 0.7944\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5371 - accuracy: 0.8798 - val_loss: 0.7293 - val_accuracy: 0.7810\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5305 - accuracy: 0.8757 - val_loss: 0.7297 - val_accuracy: 0.7820\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5339 - accuracy: 0.8716 - val_loss: 0.7252 - val_accuracy: 0.7862\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5303 - accuracy: 0.8755 - val_loss: 0.7321 - val_accuracy: 0.7789\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5348 - accuracy: 0.8713 - val_loss: 0.7353 - val_accuracy: 0.7738\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5292 - accuracy: 0.8786 - val_loss: 0.7330 - val_accuracy: 0.7944\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5327 - accuracy: 0.8791 - val_loss: 0.7323 - val_accuracy: 0.7769\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5202 - accuracy: 0.8791 - val_loss: 0.7270 - val_accuracy: 0.7831\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5187 - accuracy: 0.8801 - val_loss: 0.7523 - val_accuracy: 0.7831\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5132 - accuracy: 0.8824 - val_loss: 0.7277 - val_accuracy: 0.7851\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5168 - accuracy: 0.8755 - val_loss: 0.7304 - val_accuracy: 0.7872\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5163 - accuracy: 0.8801 - val_loss: 0.7312 - val_accuracy: 0.7882\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5184 - accuracy: 0.8788 - val_loss: 0.7454 - val_accuracy: 0.7634\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5183 - accuracy: 0.8773 - val_loss: 0.7274 - val_accuracy: 0.7851\n","Epoch 61/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5134 - accuracy: 0.8840 - val_loss: 0.7235 - val_accuracy: 0.7975\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5067 - accuracy: 0.8891 - val_loss: 0.7722 - val_accuracy: 0.7510\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5094 - accuracy: 0.8842 - val_loss: 0.7773 - val_accuracy: 0.7758\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5169 - accuracy: 0.8770 - val_loss: 0.7327 - val_accuracy: 0.7862\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5019 - accuracy: 0.8876 - val_loss: 0.7356 - val_accuracy: 0.7913\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4963 - accuracy: 0.8889 - val_loss: 0.7425 - val_accuracy: 0.7903\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4932 - accuracy: 0.8910 - val_loss: 0.7347 - val_accuracy: 0.7862\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4945 - accuracy: 0.8899 - val_loss: 0.7294 - val_accuracy: 0.7872\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4946 - accuracy: 0.8897 - val_loss: 0.7583 - val_accuracy: 0.7893\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4909 - accuracy: 0.8907 - val_loss: 0.7304 - val_accuracy: 0.7903\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4959 - accuracy: 0.8886 - val_loss: 0.7566 - val_accuracy: 0.7810\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4887 - accuracy: 0.8897 - val_loss: 0.7465 - val_accuracy: 0.7934\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4927 - accuracy: 0.8868 - val_loss: 0.7426 - val_accuracy: 0.7820\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4781 - accuracy: 0.8948 - val_loss: 0.7330 - val_accuracy: 0.7872\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4761 - accuracy: 0.8964 - val_loss: 0.7359 - val_accuracy: 0.7851\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4829 - accuracy: 0.8941 - val_loss: 0.7893 - val_accuracy: 0.7707\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4794 - accuracy: 0.8951 - val_loss: 0.7996 - val_accuracy: 0.7593\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4877 - accuracy: 0.8881 - val_loss: 0.7554 - val_accuracy: 0.7769\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4701 - accuracy: 0.8997 - val_loss: 0.7436 - val_accuracy: 0.7789\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4657 - accuracy: 0.9010 - val_loss: 0.7441 - val_accuracy: 0.7944\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4694 - accuracy: 0.9005 - val_loss: 0.7565 - val_accuracy: 0.7903\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 0.9059 - val_loss: 0.7476 - val_accuracy: 0.7831\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4570 - accuracy: 0.9034 - val_loss: 0.7673 - val_accuracy: 0.7800\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4630 - accuracy: 0.9067 - val_loss: 0.7527 - val_accuracy: 0.7841\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4630 - accuracy: 0.9008 - val_loss: 0.7474 - val_accuracy: 0.7862\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4551 - accuracy: 0.9072 - val_loss: 0.7488 - val_accuracy: 0.7913\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4502 - accuracy: 0.9059 - val_loss: 0.7717 - val_accuracy: 0.7810\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4561 - accuracy: 0.9057 - val_loss: 0.7498 - val_accuracy: 0.7913\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4540 - accuracy: 0.9078 - val_loss: 0.7529 - val_accuracy: 0.7882\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4532 - accuracy: 0.9106 - val_loss: 0.7620 - val_accuracy: 0.7769\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4803 - accuracy: 0.8925 - val_loss: 0.8342 - val_accuracy: 0.7531\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4509 - accuracy: 0.9106 - val_loss: 0.7563 - val_accuracy: 0.7872\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4428 - accuracy: 0.9114 - val_loss: 0.7553 - val_accuracy: 0.7862\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4370 - accuracy: 0.9132 - val_loss: 0.7514 - val_accuracy: 0.7851\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4375 - accuracy: 0.9124 - val_loss: 0.7698 - val_accuracy: 0.7820\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4342 - accuracy: 0.9165 - val_loss: 0.7603 - val_accuracy: 0.7779\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4343 - accuracy: 0.9150 - val_loss: 0.7789 - val_accuracy: 0.7738\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.9072 - val_loss: 0.7638 - val_accuracy: 0.7913\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4310 - accuracy: 0.9173 - val_loss: 0.7668 - val_accuracy: 0.7862\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4295 - accuracy: 0.9212 - val_loss: 0.7869 - val_accuracy: 0.7686\n","{'loss': [0.6805331707000732, 0.6624546051025391, 0.651495635509491, 0.6624506115913391, 0.6442837119102478, 0.6389398574829102, 0.6372707486152649, 0.6380710005760193, 0.6295806765556335, 0.6244425773620605, 0.6327544450759888, 0.6261857748031616, 0.6203814744949341, 0.6298307180404663, 0.6073723435401917, 0.614070475101471, 0.6132251620292664, 0.610580325126648, 0.6054445505142212, 0.6002081632614136, 0.6310259699821472, 0.6110193729400635, 0.5967754125595093, 0.589407205581665, 0.5910328030586243, 0.5956097841262817, 0.5984625220298767, 0.5828149318695068, 0.5869516730308533, 0.5829393863677979, 0.58067786693573, 0.5761056542396545, 0.5706179738044739, 0.5690106749534607, 0.5629687905311584, 0.5586103200912476, 0.5649101734161377, 0.566533625125885, 0.5709364414215088, 0.5545521974563599, 0.5447747111320496, 0.5785718560218811, 0.5725806951522827, 0.5513979196548462, 0.5433600544929504, 0.553571879863739, 0.5370848178863525, 0.5305389761924744, 0.533894956111908, 0.5303305983543396, 0.5348362326622009, 0.5292226076126099, 0.5326651930809021, 0.5202032923698425, 0.5186989903450012, 0.5131650567054749, 0.5168167948722839, 0.5163367986679077, 0.5183508396148682, 0.5183458924293518, 0.5134487152099609, 0.506708025932312, 0.5093510150909424, 0.5168694257736206, 0.5018584132194519, 0.4963383376598358, 0.4932403862476349, 0.494512677192688, 0.49455487728118896, 0.4908975660800934, 0.4959370195865631, 0.48871877789497375, 0.49272480607032776, 0.4781305193901062, 0.4760732650756836, 0.4829362630844116, 0.47936952114105225, 0.48771852254867554, 0.4700503349304199, 0.4657458961009979, 0.46936091780662537, 0.4589816927909851, 0.45695558190345764, 0.46296244859695435, 0.4629735052585602, 0.45513322949409485, 0.4502272605895996, 0.4561083912849426, 0.4540390372276306, 0.45324963331222534, 0.4803176522254944, 0.4508668780326843, 0.4428456425666809, 0.43695467710494995, 0.4374966025352478, 0.4342323839664459, 0.4342885911464691, 0.43963098526000977, 0.4310263693332672, 0.4294564127922058], 'accuracy': [0.817054271697998, 0.8260982036590576, 0.8276485800743103, 0.8224806189537048, 0.8343669176101685, 0.8387596607208252, 0.8410852551460266, 0.8299741744995117, 0.8439276218414307, 0.8447028398513794, 0.8322997689247131, 0.840568482875824, 0.8397932648658752, 0.8392764925956726, 0.8514211773872375, 0.8488371968269348, 0.8496124148368835, 0.8379845023155212, 0.8465116024017334, 0.8498708009719849, 0.8330749273300171, 0.841602087020874, 0.8478035926818848, 0.8596899509429932, 0.8532299995422363, 0.8521963953971863, 0.8449612259864807, 0.8560723662376404, 0.855555534362793, 0.8589147329330444, 0.8568475246429443, 0.8583979606628418, 0.8612403273582458, 0.8591731190681458, 0.869767427444458, 0.8682170510292053, 0.8576227426528931, 0.8640826940536499, 0.8583979606628418, 0.8651162981987, 0.8746770024299622, 0.851938009262085, 0.8545219898223877, 0.868733823299408, 0.8695090413093567, 0.8661498427391052, 0.8798449635505676, 0.8757106065750122, 0.8715762495994568, 0.8754522204399109, 0.8713178038597107, 0.8785529732704163, 0.8790697455406189, 0.8790697455406189, 0.880103349685669, 0.8824289441108704, 0.8754522204399109, 0.880103349685669, 0.8788113594055176, 0.8772609829902649, 0.883979320526123, 0.8891472816467285, 0.8842377066612244, 0.8770025968551636, 0.8875969052314758, 0.8888888955116272, 0.8909560441970825, 0.8899224996566772, 0.8896640539169312, 0.8906976580619812, 0.8886305093765259, 0.8896640539169312, 0.8868216872215271, 0.8948320150375366, 0.8963824510574341, 0.8940568566322327, 0.8950904607772827, 0.8881136775016785, 0.8997415900230408, 0.9010335803031921, 0.9005168080329895, 0.9059431552886963, 0.9033591747283936, 0.906718373298645, 0.9007751941680908, 0.9072351455688477, 0.9059431552886963, 0.905684769153595, 0.9077519178390503, 0.9105943441390991, 0.89250648021698, 0.9105943441390991, 0.9113695025444031, 0.9131782650947571, 0.9124031066894531, 0.9165374636650085, 0.9149870872497559, 0.9072351455688477, 0.9173126816749573, 0.9211886525154114], 'val_loss': [1.0211927890777588, 1.0196254253387451, 1.012078046798706, 0.9782800674438477, 0.9717114567756653, 0.9574244618415833, 0.9528504610061646, 0.9422992467880249, 0.9451119899749756, 0.9057665467262268, 0.8878021836280823, 0.9365373253822327, 0.9483649730682373, 0.9104971885681152, 0.8934578895568848, 0.8133527636528015, 0.7907727956771851, 0.7855211496353149, 0.7872804403305054, 0.765358567237854, 0.759168803691864, 0.7385708689689636, 0.7331312298774719, 0.7259098291397095, 0.7411119341850281, 0.7236803770065308, 0.746293842792511, 0.7247443199157715, 0.7532689571380615, 0.7205846905708313, 0.7307160496711731, 0.7387160658836365, 0.7253727912902832, 0.7384231686592102, 0.7260712385177612, 0.7285056710243225, 0.7235537171363831, 0.7253506779670715, 0.7340409755706787, 0.7256643772125244, 0.7620328664779663, 0.7262650728225708, 0.7316902875900269, 0.7283705472946167, 0.731346070766449, 0.7164605259895325, 0.7293492555618286, 0.7296906113624573, 0.7251683473587036, 0.7320917248725891, 0.7352708578109741, 0.7329608798027039, 0.7322819232940674, 0.7270310521125793, 0.7522839903831482, 0.727729320526123, 0.7303978800773621, 0.7311736941337585, 0.7453550696372986, 0.7273997664451599, 0.7235084772109985, 0.7721710205078125, 0.7772740125656128, 0.7327046394348145, 0.7355855703353882, 0.7425331473350525, 0.7347316741943359, 0.7294465899467468, 0.7583087086677551, 0.7304261922836304, 0.7566262483596802, 0.7465037107467651, 0.7425933480262756, 0.7329578995704651, 0.7358658313751221, 0.7893349528312683, 0.7995995879173279, 0.7554311752319336, 0.7436288595199585, 0.7441213130950928, 0.7564719319343567, 0.7476235032081604, 0.7672573924064636, 0.7527320981025696, 0.7474064230918884, 0.748845636844635, 0.7716578841209412, 0.7497813701629639, 0.7528543472290039, 0.7620258927345276, 0.8341894745826721, 0.75629723072052, 0.7552669644355774, 0.751412034034729, 0.7698425054550171, 0.7603479027748108, 0.7788915634155273, 0.7637994885444641, 0.7667712569236755, 0.7868515253067017], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.49070248007774353, 0.49380165338516235, 0.4958677589893341, 0.5, 0.557851254940033, 0.5909090638160706, 0.5320248007774353, 0.5402892827987671, 0.5764462947845459, 0.6022727489471436, 0.6880165338516235, 0.7045454382896423, 0.71074378490448, 0.7159090638160706, 0.7365702390670776, 0.7469007968902588, 0.7665289044380188, 0.7665289044380188, 0.7758264541625977, 0.7778925895690918, 0.7851239442825317, 0.7861570119857788, 0.7902892827987671, 0.7799586653709412, 0.7902892827987671, 0.7737603187561035, 0.7913222908973694, 0.788223147392273, 0.7820248007774353, 0.7902892827987671, 0.788223147392273, 0.78925621509552, 0.7840909361839294, 0.7716942429542542, 0.788223147392273, 0.76962810754776, 0.7820248007774353, 0.7913222908973694, 0.7861570119857788, 0.7789255976676941, 0.7944214940071106, 0.7809917330741882, 0.7820248007774353, 0.7861570119857788, 0.7789255976676941, 0.7737603187561035, 0.7944214940071106, 0.7768595218658447, 0.7830578684806824, 0.7830578684806824, 0.7851239442825317, 0.7871900796890259, 0.788223147392273, 0.7634297609329224, 0.7851239442825317, 0.797520637512207, 0.7510330677032471, 0.7758264541625977, 0.7861570119857788, 0.7913222908973694, 0.7902892827987671, 0.7861570119857788, 0.7871900796890259, 0.78925621509552, 0.7902892827987671, 0.7809917330741882, 0.7933884263038635, 0.7820248007774353, 0.7871900796890259, 0.7851239442825317, 0.7706611752510071, 0.7592975497245789, 0.7768595218658447, 0.7789255976676941, 0.7944214940071106, 0.7902892827987671, 0.7830578684806824, 0.7799586653709412, 0.7840909361839294, 0.7861570119857788, 0.7913222908973694, 0.7809917330741882, 0.7913222908973694, 0.788223147392273, 0.7768595218658447, 0.7530992031097412, 0.7871900796890259, 0.7861570119857788, 0.7851239442825317, 0.7820248007774353, 0.7778925895690918, 0.7737603187561035, 0.7913222908973694, 0.7861570119857788, 0.7685950398445129]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 7s 48ms/step - loss: 0.5179 - accuracy: 0.8790 - val_loss: 1.0260 - val_accuracy: 0.4849\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 0s 12ms/step - loss: 0.4885 - accuracy: 0.8847 - val_loss: 1.0263 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4846 - accuracy: 0.8844 - val_loss: 1.0137 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4703 - accuracy: 0.8955 - val_loss: 1.0029 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4639 - accuracy: 0.8974 - val_loss: 1.0033 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4571 - accuracy: 0.9033 - val_loss: 0.9866 - val_accuracy: 0.4881\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4588 - accuracy: 0.8990 - val_loss: 1.0020 - val_accuracy: 0.4903\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4583 - accuracy: 0.9071 - val_loss: 1.0085 - val_accuracy: 0.4957\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4645 - accuracy: 0.8963 - val_loss: 0.9924 - val_accuracy: 0.5022\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4544 - accuracy: 0.9062 - val_loss: 0.9287 - val_accuracy: 0.5388\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4534 - accuracy: 0.9006 - val_loss: 1.0115 - val_accuracy: 0.5119\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4518 - accuracy: 0.8984 - val_loss: 1.0765 - val_accuracy: 0.5086\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4470 - accuracy: 0.9036 - val_loss: 1.0017 - val_accuracy: 0.5496\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4419 - accuracy: 0.9092 - val_loss: 1.1385 - val_accuracy: 0.5323\n","Epoch 15/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4453 - accuracy: 0.9049 - val_loss: 0.9997 - val_accuracy: 0.5711\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4485 - accuracy: 0.9033 - val_loss: 0.9428 - val_accuracy: 0.5991\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4337 - accuracy: 0.9098 - val_loss: 0.9477 - val_accuracy: 0.6099\n","Epoch 18/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.4352 - accuracy: 0.9159 - val_loss: 0.8518 - val_accuracy: 0.6552\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4299 - accuracy: 0.9157 - val_loss: 0.7925 - val_accuracy: 0.7037\n","Epoch 20/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4310 - accuracy: 0.9095 - val_loss: 0.7268 - val_accuracy: 0.7489\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4264 - accuracy: 0.9165 - val_loss: 0.6420 - val_accuracy: 0.7996\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4246 - accuracy: 0.9122 - val_loss: 0.6184 - val_accuracy: 0.8308\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4139 - accuracy: 0.9189 - val_loss: 0.6075 - val_accuracy: 0.8341\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4145 - accuracy: 0.9192 - val_loss: 0.6147 - val_accuracy: 0.8297\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4215 - accuracy: 0.9133 - val_loss: 0.5982 - val_accuracy: 0.8405\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4236 - accuracy: 0.9168 - val_loss: 0.5962 - val_accuracy: 0.8416\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4127 - accuracy: 0.9251 - val_loss: 0.6038 - val_accuracy: 0.8330\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.9176 - val_loss: 0.6323 - val_accuracy: 0.8308\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4131 - accuracy: 0.9189 - val_loss: 0.6010 - val_accuracy: 0.8448\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4155 - accuracy: 0.9157 - val_loss: 0.5940 - val_accuracy: 0.8416\n","Epoch 31/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4081 - accuracy: 0.9235 - val_loss: 0.6086 - val_accuracy: 0.8459\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3985 - accuracy: 0.9248 - val_loss: 0.5992 - val_accuracy: 0.8459\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4096 - accuracy: 0.9192 - val_loss: 0.6284 - val_accuracy: 0.8308\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3934 - accuracy: 0.9240 - val_loss: 0.6128 - val_accuracy: 0.8330\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3982 - accuracy: 0.9240 - val_loss: 0.5976 - val_accuracy: 0.8416\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3969 - accuracy: 0.9224 - val_loss: 0.6088 - val_accuracy: 0.8438\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4004 - accuracy: 0.9267 - val_loss: 0.6110 - val_accuracy: 0.8384\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3979 - accuracy: 0.9224 - val_loss: 0.6960 - val_accuracy: 0.8190\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3991 - accuracy: 0.9254 - val_loss: 0.6025 - val_accuracy: 0.8405\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3918 - accuracy: 0.9283 - val_loss: 0.6388 - val_accuracy: 0.8330\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3941 - accuracy: 0.9262 - val_loss: 0.6470 - val_accuracy: 0.8308\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3868 - accuracy: 0.9318 - val_loss: 0.6177 - val_accuracy: 0.8427\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3790 - accuracy: 0.9367 - val_loss: 0.6385 - val_accuracy: 0.8287\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3975 - accuracy: 0.9238 - val_loss: 0.6307 - val_accuracy: 0.8330\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3910 - accuracy: 0.9232 - val_loss: 0.6114 - val_accuracy: 0.8405\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3747 - accuracy: 0.9351 - val_loss: 0.6216 - val_accuracy: 0.8416\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3747 - accuracy: 0.9348 - val_loss: 0.6215 - val_accuracy: 0.8427\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3863 - accuracy: 0.9327 - val_loss: 0.6730 - val_accuracy: 0.8190\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3847 - accuracy: 0.9275 - val_loss: 0.6476 - val_accuracy: 0.8427\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3701 - accuracy: 0.9423 - val_loss: 0.6092 - val_accuracy: 0.8394\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3767 - accuracy: 0.9316 - val_loss: 0.6148 - val_accuracy: 0.8405\n","Epoch 52/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3681 - accuracy: 0.9380 - val_loss: 0.6400 - val_accuracy: 0.8470\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3709 - accuracy: 0.9383 - val_loss: 0.6396 - val_accuracy: 0.8448\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3908 - accuracy: 0.9251 - val_loss: 0.6439 - val_accuracy: 0.8373\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3630 - accuracy: 0.9367 - val_loss: 0.6210 - val_accuracy: 0.8427\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3575 - accuracy: 0.9421 - val_loss: 0.6794 - val_accuracy: 0.8211\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3661 - accuracy: 0.9405 - val_loss: 0.6566 - val_accuracy: 0.8427\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3591 - accuracy: 0.9402 - val_loss: 0.6274 - val_accuracy: 0.8373\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3563 - accuracy: 0.9448 - val_loss: 0.6322 - val_accuracy: 0.8448\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3579 - accuracy: 0.9405 - val_loss: 0.6568 - val_accuracy: 0.8319\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3634 - accuracy: 0.9399 - val_loss: 0.6400 - val_accuracy: 0.8362\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3605 - accuracy: 0.9399 - val_loss: 0.6974 - val_accuracy: 0.8136\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3585 - accuracy: 0.9450 - val_loss: 0.6564 - val_accuracy: 0.8416\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3536 - accuracy: 0.9423 - val_loss: 0.6448 - val_accuracy: 0.8459\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3537 - accuracy: 0.9426 - val_loss: 0.6508 - val_accuracy: 0.8341\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3390 - accuracy: 0.9523 - val_loss: 0.6474 - val_accuracy: 0.8384\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3399 - accuracy: 0.9485 - val_loss: 0.6361 - val_accuracy: 0.8394\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3390 - accuracy: 0.9502 - val_loss: 0.6805 - val_accuracy: 0.8416\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3400 - accuracy: 0.9450 - val_loss: 0.6485 - val_accuracy: 0.8427\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3537 - accuracy: 0.9418 - val_loss: 0.6909 - val_accuracy: 0.8384\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3488 - accuracy: 0.9467 - val_loss: 0.6679 - val_accuracy: 0.8362\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3425 - accuracy: 0.9477 - val_loss: 0.6727 - val_accuracy: 0.8287\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.9507 - val_loss: 0.6754 - val_accuracy: 0.8373\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3488 - accuracy: 0.9429 - val_loss: 0.6697 - val_accuracy: 0.8448\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3493 - accuracy: 0.9410 - val_loss: 0.6681 - val_accuracy: 0.8297\n","Epoch 76/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3359 - accuracy: 0.9491 - val_loss: 0.6521 - val_accuracy: 0.8481\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3312 - accuracy: 0.9504 - val_loss: 0.6561 - val_accuracy: 0.8438\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3461 - accuracy: 0.9429 - val_loss: 0.7768 - val_accuracy: 0.8114\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3431 - accuracy: 0.9456 - val_loss: 0.8673 - val_accuracy: 0.7608\n","Epoch 80/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3486 - accuracy: 0.9413 - val_loss: 0.6739 - val_accuracy: 0.8394\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3451 - accuracy: 0.9499 - val_loss: 0.7043 - val_accuracy: 0.8179\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3408 - accuracy: 0.9432 - val_loss: 0.6434 - val_accuracy: 0.8405\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3259 - accuracy: 0.9547 - val_loss: 0.6496 - val_accuracy: 0.8438\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3221 - accuracy: 0.9531 - val_loss: 0.6616 - val_accuracy: 0.8384\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3156 - accuracy: 0.9577 - val_loss: 0.6785 - val_accuracy: 0.8330\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3265 - accuracy: 0.9564 - val_loss: 0.6774 - val_accuracy: 0.8330\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3344 - accuracy: 0.9477 - val_loss: 0.7588 - val_accuracy: 0.8006\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3456 - accuracy: 0.9429 - val_loss: 0.6723 - val_accuracy: 0.8384\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3166 - accuracy: 0.9607 - val_loss: 0.6694 - val_accuracy: 0.8373\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3116 - accuracy: 0.9607 - val_loss: 0.6773 - val_accuracy: 0.8427\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3139 - accuracy: 0.9593 - val_loss: 0.7301 - val_accuracy: 0.8200\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3193 - accuracy: 0.9547 - val_loss: 0.6636 - val_accuracy: 0.8459\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3208 - accuracy: 0.9561 - val_loss: 0.6789 - val_accuracy: 0.8384\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3072 - accuracy: 0.9585 - val_loss: 0.6718 - val_accuracy: 0.8384\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3178 - accuracy: 0.9537 - val_loss: 0.6685 - val_accuracy: 0.8384\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3087 - accuracy: 0.9585 - val_loss: 0.6806 - val_accuracy: 0.8438\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3086 - accuracy: 0.9572 - val_loss: 0.6935 - val_accuracy: 0.8438\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3175 - accuracy: 0.9561 - val_loss: 0.7601 - val_accuracy: 0.7985\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3253 - accuracy: 0.9531 - val_loss: 0.7596 - val_accuracy: 0.8093\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3122 - accuracy: 0.9591 - val_loss: 0.6912 - val_accuracy: 0.8416\n","{'loss': [0.5178622007369995, 0.4885098338127136, 0.4846304655075073, 0.47031423449516296, 0.4638972580432892, 0.4570535719394684, 0.45876821875572205, 0.45828187465667725, 0.46445655822753906, 0.45441192388534546, 0.4534228444099426, 0.45180416107177734, 0.44702500104904175, 0.4418860673904419, 0.4452715814113617, 0.4484926760196686, 0.43373143672943115, 0.4351966381072998, 0.4298880398273468, 0.43097493052482605, 0.4263927936553955, 0.424615740776062, 0.4139257073402405, 0.41454583406448364, 0.42148029804229736, 0.42363855242729187, 0.4126700758934021, 0.41089141368865967, 0.413058876991272, 0.41553187370300293, 0.4081355035305023, 0.3985368609428406, 0.4096318483352661, 0.3934497833251953, 0.3982313275337219, 0.39694225788116455, 0.40038755536079407, 0.39788171648979187, 0.399128258228302, 0.3918265998363495, 0.3941430151462555, 0.3868430256843567, 0.37897583842277527, 0.397539347410202, 0.3910117745399475, 0.37465766072273254, 0.3746858537197113, 0.38628607988357544, 0.38472846150398254, 0.3700715899467468, 0.3766847550868988, 0.3681284487247467, 0.37085607647895813, 0.39081233739852905, 0.36302632093429565, 0.35746797919273376, 0.36606693267822266, 0.3591259717941284, 0.35625725984573364, 0.35792118310928345, 0.36336445808410645, 0.36050158739089966, 0.35849621891975403, 0.35355865955352783, 0.35371625423431396, 0.33895450830459595, 0.33989429473876953, 0.33899426460266113, 0.3399994373321533, 0.3537144064903259, 0.3487822115421295, 0.3424942195415497, 0.3340454697608948, 0.348842054605484, 0.3493186831474304, 0.3359076678752899, 0.3312014937400818, 0.34610867500305176, 0.3431187570095062, 0.34856221079826355, 0.3450721502304077, 0.3407596945762634, 0.3259288966655731, 0.3221141993999481, 0.31556612253189087, 0.3264833390712738, 0.33440497517585754, 0.34560853242874146, 0.3165985643863678, 0.31160011887550354, 0.3138721287250519, 0.31934186816215515, 0.32078656554222107, 0.3071965277194977, 0.317791223526001, 0.30869579315185547, 0.30857524275779724, 0.3174991011619568, 0.3252940773963928, 0.3122010827064514], 'accuracy': [0.8790409564971924, 0.8846982717514038, 0.884428858757019, 0.8954741358757019, 0.8973599076271057, 0.9032866358757019, 0.8989762663841248, 0.9070581793785095, 0.8962823152542114, 0.90625, 0.9005926847457886, 0.8984375, 0.9035560488700867, 0.9092133641242981, 0.904902994632721, 0.9032866358757019, 0.9097521305084229, 0.9159482717514038, 0.915678858757019, 0.9094827771186829, 0.9164870977401733, 0.9121767282485962, 0.9189116358757019, 0.9191810488700867, 0.9132543206214905, 0.9167564511299133, 0.9251077771186829, 0.9175646305084229, 0.9189116358757019, 0.915678858757019, 0.923491358757019, 0.9248383641242981, 0.9191810488700867, 0.9240301847457886, 0.9240301847457886, 0.9224137663841248, 0.9267241358757019, 0.9224137663841248, 0.9253771305084229, 0.928340494632721, 0.9261853694915771, 0.9318426847457886, 0.9366918206214905, 0.9237607717514038, 0.923222005367279, 0.9350754022598267, 0.9348060488700867, 0.9326508641242981, 0.9275323152542114, 0.9423491358757019, 0.9315732717514038, 0.9380387663841248, 0.9383081793785095, 0.9251077771186829, 0.9366918206214905, 0.9420797228813171, 0.9404633641242981, 0.9401939511299133, 0.9447737336158752, 0.9404633641242981, 0.9399245977401733, 0.9399245977401733, 0.9450430870056152, 0.9423491358757019, 0.9426185488700867, 0.9523168206214905, 0.9485452771186829, 0.9501616358757019, 0.9450430870056152, 0.9418103694915771, 0.946659505367279, 0.9477370977401733, 0.9507004022598267, 0.9428879022598267, 0.9410021305084229, 0.9490840435028076, 0.9504310488700867, 0.9428879022598267, 0.9455819129943848, 0.9412715435028076, 0.9498922228813171, 0.9431573152542114, 0.954741358757019, 0.953125, 0.9577047228813171, 0.9563577771186829, 0.9477370977401733, 0.9428879022598267, 0.9606680870056152, 0.9606680870056152, 0.959321141242981, 0.954741358757019, 0.9560883641242981, 0.9585129022598267, 0.9536637663841248, 0.9585129022598267, 0.9571659564971924, 0.9560883641242981, 0.953125, 0.9590517282485962], 'val_loss': [1.0260428190231323, 1.0263291597366333, 1.0137145519256592, 1.0029491186141968, 1.0032575130462646, 0.9866210222244263, 1.0019577741622925, 1.008500337600708, 0.9923985600471497, 0.9287263751029968, 1.0115054845809937, 1.0764540433883667, 1.0016593933105469, 1.1385118961334229, 0.9997168779373169, 0.942803144454956, 0.947709321975708, 0.8517723083496094, 0.7924895882606506, 0.7268309593200684, 0.6419792175292969, 0.6184473633766174, 0.6075160503387451, 0.6147004961967468, 0.5981730222702026, 0.5961529016494751, 0.6038323640823364, 0.6323190331459045, 0.6009907722473145, 0.5939684510231018, 0.6086428165435791, 0.5992136597633362, 0.628395676612854, 0.6128495335578918, 0.5976231098175049, 0.6087741851806641, 0.6110482215881348, 0.6959964036941528, 0.6024585366249084, 0.6387674808502197, 0.6469815373420715, 0.6177258491516113, 0.6385393738746643, 0.6306874752044678, 0.6113985776901245, 0.6215810179710388, 0.6214938163757324, 0.6730276346206665, 0.6475628614425659, 0.6092053651809692, 0.6148179769515991, 0.6400154829025269, 0.6395801901817322, 0.6439043283462524, 0.6210376024246216, 0.6793872117996216, 0.6565642952919006, 0.6273881793022156, 0.6322039365768433, 0.6568084955215454, 0.6400010585784912, 0.697395920753479, 0.6563509106636047, 0.6447593569755554, 0.6507775783538818, 0.647408664226532, 0.6360503435134888, 0.6805392503738403, 0.6485152840614319, 0.690903902053833, 0.6678799986839294, 0.6727414727210999, 0.6754268407821655, 0.6696595549583435, 0.6681413054466248, 0.6521301865577698, 0.6561316847801208, 0.776847779750824, 0.8673180937767029, 0.6739153861999512, 0.7042505145072937, 0.6433964371681213, 0.6495958566665649, 0.6616244316101074, 0.6784678101539612, 0.6774057745933533, 0.7588265538215637, 0.6722628474235535, 0.669411838054657, 0.6772976517677307, 0.7301455736160278, 0.6635727882385254, 0.6788508296012878, 0.6718363165855408, 0.668476939201355, 0.6805865168571472, 0.6935228705406189, 0.7600922584533691, 0.7596409320831299, 0.691183865070343], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4881465435028076, 0.4903017282485962, 0.49568966031074524, 0.5021551847457886, 0.5387930870056152, 0.5118534564971924, 0.5086206793785095, 0.5495689511299133, 0.5323275923728943, 0.5711206793785095, 0.5991379022598267, 0.6099137663841248, 0.6551724076271057, 0.7036637663841248, 0.7489224076271057, 0.7995689511299133, 0.8308189511299133, 0.8340517282485962, 0.829741358757019, 0.8405172228813171, 0.8415948152542114, 0.8329741358757019, 0.8308189511299133, 0.8448275923728943, 0.8415948152542114, 0.8459051847457886, 0.8459051847457886, 0.8308189511299133, 0.8329741358757019, 0.8415948152542114, 0.84375, 0.8383620977401733, 0.818965494632721, 0.8405172228813171, 0.8329741358757019, 0.8308189511299133, 0.8426724076271057, 0.8286637663841248, 0.8329741358757019, 0.8405172228813171, 0.8415948152542114, 0.8426724076271057, 0.818965494632721, 0.8426724076271057, 0.8394396305084229, 0.8405172228813171, 0.8469827771186829, 0.8448275923728943, 0.837284505367279, 0.8426724076271057, 0.8211206793785095, 0.8426724076271057, 0.837284505367279, 0.8448275923728943, 0.8318965435028076, 0.8362069129943848, 0.8135775923728943, 0.8415948152542114, 0.8459051847457886, 0.8340517282485962, 0.8383620977401733, 0.8394396305084229, 0.8415948152542114, 0.8426724076271057, 0.8383620977401733, 0.8362069129943848, 0.8286637663841248, 0.837284505367279, 0.8448275923728943, 0.829741358757019, 0.8480603694915771, 0.84375, 0.8114224076271057, 0.7607758641242981, 0.8394396305084229, 0.8178879022598267, 0.8405172228813171, 0.84375, 0.8383620977401733, 0.8329741358757019, 0.8329741358757019, 0.8006465435028076, 0.8383620977401733, 0.837284505367279, 0.8426724076271057, 0.8200430870056152, 0.8459051847457886, 0.8383620977401733, 0.8383620977401733, 0.8383620977401733, 0.84375, 0.84375, 0.798491358757019, 0.8092672228813171, 0.8415948152542114]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.5113 - accuracy: 0.8831"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 53ms/step - loss: 0.5084 - accuracy: 0.8823 - val_loss: 1.0146 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4723 - accuracy: 0.8939 - val_loss: 1.0151 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4693 - accuracy: 0.8936 - val_loss: 1.0121 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4652 - accuracy: 0.8956 - val_loss: 0.9981 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4586 - accuracy: 0.9038 - val_loss: 0.9985 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4528 - accuracy: 0.9063 - val_loss: 0.9934 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4500 - accuracy: 0.9052 - val_loss: 0.9948 - val_accuracy: 0.4989\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4440 - accuracy: 0.9078 - val_loss: 1.0373 - val_accuracy: 0.4977\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4616 - accuracy: 0.8987 - val_loss: 0.9817 - val_accuracy: 0.5136\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4433 - accuracy: 0.9063 - val_loss: 1.0433 - val_accuracy: 0.5090\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.9103 - val_loss: 1.1018 - val_accuracy: 0.5090\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4411 - accuracy: 0.9061 - val_loss: 1.1548 - val_accuracy: 0.5102\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4324 - accuracy: 0.9165 - val_loss: 1.1692 - val_accuracy: 0.5204\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4425 - accuracy: 0.9078 - val_loss: 1.1647 - val_accuracy: 0.5283\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4365 - accuracy: 0.9100 - val_loss: 1.1067 - val_accuracy: 0.5588\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4281 - accuracy: 0.9157 - val_loss: 0.9224 - val_accuracy: 0.6222\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4289 - accuracy: 0.9131 - val_loss: 0.9122 - val_accuracy: 0.6391\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4189 - accuracy: 0.9179 - val_loss: 0.9883 - val_accuracy: 0.6210\n","Epoch 19/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4315 - accuracy: 0.9131 - val_loss: 0.8217 - val_accuracy: 0.6889\n","Epoch 20/100\n","28/28 [==============================] - 2s 55ms/step - loss: 0.4242 - accuracy: 0.9188 - val_loss: 0.8118 - val_accuracy: 0.7014\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4184 - accuracy: 0.9202 - val_loss: 0.7353 - val_accuracy: 0.7477\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4098 - accuracy: 0.9264 - val_loss: 0.7228 - val_accuracy: 0.7534\n","Epoch 23/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4229 - accuracy: 0.9179 - val_loss: 0.6461 - val_accuracy: 0.7941\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.9250 - val_loss: 0.6669 - val_accuracy: 0.7919\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4073 - accuracy: 0.9273 - val_loss: 0.6385 - val_accuracy: 0.8156\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4058 - accuracy: 0.9239 - val_loss: 0.6965 - val_accuracy: 0.7885\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4002 - accuracy: 0.9310 - val_loss: 0.6275 - val_accuracy: 0.8247\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4019 - accuracy: 0.9276 - val_loss: 0.6636 - val_accuracy: 0.8066\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3882 - accuracy: 0.9346 - val_loss: 0.6584 - val_accuracy: 0.8111\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3958 - accuracy: 0.9290 - val_loss: 0.6447 - val_accuracy: 0.8190\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3954 - accuracy: 0.9270 - val_loss: 0.6489 - val_accuracy: 0.8111\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3877 - accuracy: 0.9335 - val_loss: 0.6645 - val_accuracy: 0.8247\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3981 - accuracy: 0.9318 - val_loss: 0.6549 - val_accuracy: 0.8190\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3927 - accuracy: 0.9270 - val_loss: 0.6324 - val_accuracy: 0.8167\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3956 - accuracy: 0.9261 - val_loss: 0.6481 - val_accuracy: 0.8100\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3960 - accuracy: 0.9332 - val_loss: 0.7377 - val_accuracy: 0.7930\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3934 - accuracy: 0.9344 - val_loss: 0.6601 - val_accuracy: 0.8145\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3812 - accuracy: 0.9344 - val_loss: 0.6579 - val_accuracy: 0.8111\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3996 - accuracy: 0.9216 - val_loss: 0.6510 - val_accuracy: 0.8111\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3812 - accuracy: 0.9341 - val_loss: 0.6774 - val_accuracy: 0.7986\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3858 - accuracy: 0.9298 - val_loss: 0.6613 - val_accuracy: 0.8088\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3760 - accuracy: 0.9375 - val_loss: 0.6529 - val_accuracy: 0.8213\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3964 - accuracy: 0.9256 - val_loss: 0.6500 - val_accuracy: 0.8156\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3894 - accuracy: 0.9312 - val_loss: 0.7267 - val_accuracy: 0.7930\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3775 - accuracy: 0.9332 - val_loss: 0.6503 - val_accuracy: 0.8145\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3773 - accuracy: 0.9312 - val_loss: 0.6788 - val_accuracy: 0.8100\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3679 - accuracy: 0.9397 - val_loss: 0.6430 - val_accuracy: 0.8122\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3650 - accuracy: 0.9397 - val_loss: 0.6751 - val_accuracy: 0.8156\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3659 - accuracy: 0.9397 - val_loss: 0.6713 - val_accuracy: 0.8122\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3650 - accuracy: 0.9411 - val_loss: 0.6699 - val_accuracy: 0.8179\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3639 - accuracy: 0.9392 - val_loss: 0.7113 - val_accuracy: 0.8020\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3593 - accuracy: 0.9443 - val_loss: 0.6824 - val_accuracy: 0.8088\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3734 - accuracy: 0.9327 - val_loss: 0.6811 - val_accuracy: 0.8167\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3785 - accuracy: 0.9358 - val_loss: 0.7031 - val_accuracy: 0.8133\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3824 - accuracy: 0.9242 - val_loss: 0.6855 - val_accuracy: 0.8133\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3571 - accuracy: 0.9372 - val_loss: 0.7428 - val_accuracy: 0.8009\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3654 - accuracy: 0.9423 - val_loss: 0.6837 - val_accuracy: 0.8043\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3633 - accuracy: 0.9400 - val_loss: 0.6798 - val_accuracy: 0.8077\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3544 - accuracy: 0.9468 - val_loss: 0.6827 - val_accuracy: 0.8020\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3514 - accuracy: 0.9491 - val_loss: 0.6810 - val_accuracy: 0.8167\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3453 - accuracy: 0.9519 - val_loss: 0.6914 - val_accuracy: 0.8054\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3474 - accuracy: 0.9493 - val_loss: 0.7014 - val_accuracy: 0.8133\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3352 - accuracy: 0.9573 - val_loss: 0.7032 - val_accuracy: 0.8156\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3380 - accuracy: 0.9516 - val_loss: 0.6797 - val_accuracy: 0.8100\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3427 - accuracy: 0.9499 - val_loss: 0.7252 - val_accuracy: 0.8077\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3313 - accuracy: 0.9559 - val_loss: 0.7275 - val_accuracy: 0.7998\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3482 - accuracy: 0.9428 - val_loss: 0.7021 - val_accuracy: 0.8077\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3339 - accuracy: 0.9544 - val_loss: 0.7412 - val_accuracy: 0.7998\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3340 - accuracy: 0.9567 - val_loss: 0.7089 - val_accuracy: 0.8145\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3366 - accuracy: 0.9527 - val_loss: 0.6997 - val_accuracy: 0.8066\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3337 - accuracy: 0.9519 - val_loss: 0.7160 - val_accuracy: 0.8009\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3468 - accuracy: 0.9477 - val_loss: 0.7197 - val_accuracy: 0.8043\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3261 - accuracy: 0.9576 - val_loss: 0.6928 - val_accuracy: 0.8179\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.9553 - val_loss: 0.7080 - val_accuracy: 0.8122\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3278 - accuracy: 0.9570 - val_loss: 0.7486 - val_accuracy: 0.7941\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3327 - accuracy: 0.9539 - val_loss: 0.7025 - val_accuracy: 0.8167\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3197 - accuracy: 0.9595 - val_loss: 0.7043 - val_accuracy: 0.8066\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3323 - accuracy: 0.9525 - val_loss: 0.7103 - val_accuracy: 0.8054\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3232 - accuracy: 0.9553 - val_loss: 0.7085 - val_accuracy: 0.8043\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3161 - accuracy: 0.9612 - val_loss: 0.7151 - val_accuracy: 0.8100\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3169 - accuracy: 0.9595 - val_loss: 0.7336 - val_accuracy: 0.8020\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3220 - accuracy: 0.9544 - val_loss: 0.8840 - val_accuracy: 0.7805\n","Epoch 83/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3497 - accuracy: 0.9451 - val_loss: 0.6999 - val_accuracy: 0.8167\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3197 - accuracy: 0.9612 - val_loss: 0.7276 - val_accuracy: 0.8054\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3118 - accuracy: 0.9621 - val_loss: 0.7629 - val_accuracy: 0.7941\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3118 - accuracy: 0.9635 - val_loss: 0.7188 - val_accuracy: 0.8145\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3174 - accuracy: 0.9590 - val_loss: 0.7178 - val_accuracy: 0.8111\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3034 - accuracy: 0.9683 - val_loss: 0.7665 - val_accuracy: 0.8066\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3226 - accuracy: 0.9584 - val_loss: 0.8294 - val_accuracy: 0.7839\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3245 - accuracy: 0.9522 - val_loss: 0.7160 - val_accuracy: 0.8111\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3084 - accuracy: 0.9652 - val_loss: 0.8317 - val_accuracy: 0.7873\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3241 - accuracy: 0.9513 - val_loss: 0.7523 - val_accuracy: 0.8054\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3272 - accuracy: 0.9522 - val_loss: 0.7627 - val_accuracy: 0.7907\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3025 - accuracy: 0.9672 - val_loss: 0.7508 - val_accuracy: 0.8088\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3077 - accuracy: 0.9632 - val_loss: 0.7997 - val_accuracy: 0.7975\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3027 - accuracy: 0.9669 - val_loss: 0.7936 - val_accuracy: 0.7998\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3015 - accuracy: 0.9643 - val_loss: 0.7519 - val_accuracy: 0.8077\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2915 - accuracy: 0.9728 - val_loss: 0.7421 - val_accuracy: 0.8156\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3017 - accuracy: 0.9635 - val_loss: 0.7888 - val_accuracy: 0.8020\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3038 - accuracy: 0.9646 - val_loss: 0.7555 - val_accuracy: 0.8009\n","{'loss': [0.5083719491958618, 0.4722540080547333, 0.46926259994506836, 0.4651850163936615, 0.45863577723503113, 0.4527609646320343, 0.4500024914741516, 0.44398412108421326, 0.461619108915329, 0.4433257281780243, 0.4385460317134857, 0.44108816981315613, 0.43240293860435486, 0.442503422498703, 0.4364507496356964, 0.42806774377822876, 0.428866446018219, 0.4188789129257202, 0.43151751160621643, 0.4242078363895416, 0.41840502619743347, 0.4097936451435089, 0.422897607088089, 0.4107184410095215, 0.40733563899993896, 0.4058341085910797, 0.40015846490859985, 0.40191012620925903, 0.3881625533103943, 0.3957519829273224, 0.3954032063484192, 0.3877354860305786, 0.3980692923069, 0.39273563027381897, 0.3955632448196411, 0.3959803879261017, 0.3934451639652252, 0.3811533451080322, 0.39958009123802185, 0.3812396824359894, 0.3857600688934326, 0.37604695558547974, 0.39644330739974976, 0.3893546462059021, 0.3774541914463043, 0.3773188292980194, 0.3678872883319855, 0.3650338351726532, 0.3658944368362427, 0.3650343120098114, 0.3638777732849121, 0.3592911958694458, 0.37336423993110657, 0.37852293252944946, 0.38237908482551575, 0.3571397066116333, 0.3653533458709717, 0.36331701278686523, 0.3543991446495056, 0.3513989746570587, 0.3453354835510254, 0.34737786650657654, 0.33520978689193726, 0.3380359709262848, 0.34273529052734375, 0.3312934637069702, 0.3482102155685425, 0.3338773846626282, 0.33397147059440613, 0.33660975098609924, 0.33368226885795593, 0.34680867195129395, 0.3260997533798218, 0.33035197854042053, 0.3277522921562195, 0.33270418643951416, 0.31970494985580444, 0.3322547376155853, 0.3231602609157562, 0.31614062190055847, 0.3168661594390869, 0.32204800844192505, 0.34967613220214844, 0.31972089409828186, 0.31178370118141174, 0.31182947754859924, 0.31740325689315796, 0.30336952209472656, 0.3225792646408081, 0.3245181441307068, 0.30841222405433655, 0.32408955693244934, 0.32719260454177856, 0.3024911880493164, 0.3076532185077667, 0.3027383089065552, 0.3014833331108093, 0.2914959490299225, 0.3016515076160431, 0.3037550747394562], 'accuracy': [0.8822863698005676, 0.8938879370689392, 0.8936049938201904, 0.8955857157707214, 0.9037917256355286, 0.9063384532928467, 0.905206561088562, 0.9077532291412354, 0.8986983299255371, 0.9063384532928467, 0.9102999567985535, 0.9060554504394531, 0.9165251851081848, 0.9077532291412354, 0.9100169539451599, 0.9156762957572937, 0.9131296277046204, 0.9179400205612183, 0.9131296277046204, 0.9187889099121094, 0.9202037453651428, 0.9264289736747742, 0.9179400205612183, 0.9250141382217407, 0.9272778630256653, 0.9238823056221008, 0.9309564232826233, 0.9275608658790588, 0.9346349835395813, 0.9289756417274475, 0.9269949197769165, 0.9335030913352966, 0.9318053126335144, 0.9269949197769165, 0.9261460304260254, 0.9332201480865479, 0.9343519806861877, 0.9343519806861877, 0.9216185808181763, 0.934069037437439, 0.9298245906829834, 0.9374646544456482, 0.9255800843238831, 0.9312393665313721, 0.9332201480865479, 0.9312393665313721, 0.9397283792495728, 0.9397283792495728, 0.9397283792495728, 0.9411431550979614, 0.9391624331474304, 0.9442558288574219, 0.9326542019844055, 0.9357668161392212, 0.9241652488708496, 0.9371816515922546, 0.9422750473022461, 0.9400113224983215, 0.9468024969100952, 0.9490662217140198, 0.9518958926200867, 0.9493491649627686, 0.9572722315788269, 0.9516128897666931, 0.9499151110649109, 0.9558573961257935, 0.9428409934043884, 0.95444256067276, 0.9567062854766846, 0.9527447819709778, 0.9518958926200867, 0.9476513862609863, 0.9575551748275757, 0.9552914500236511, 0.9569892287254333, 0.9538766145706177, 0.9595359563827515, 0.9524617791175842, 0.9552914500236511, 0.9612337350845337, 0.9595359563827515, 0.95444256067276, 0.945104718208313, 0.9612337350845337, 0.9620826244354248, 0.9634974598884583, 0.9589700102806091, 0.9683078527450562, 0.9584040641784668, 0.9521788358688354, 0.9651952385902405, 0.9513299465179443, 0.9521788358688354, 0.9671760201454163, 0.9632145166397095, 0.9668930172920227, 0.9643463492393494, 0.9728353023529053, 0.9634974598884583, 0.9646292924880981], 'val_loss': [1.014614224433899, 1.0151387453079224, 1.0121408700942993, 0.9981365203857422, 0.9984859228134155, 0.9934208989143372, 0.9947872161865234, 1.0373135805130005, 0.9817242622375488, 1.0433423519134521, 1.1018083095550537, 1.1547808647155762, 1.1691795587539673, 1.16474187374115, 1.1066783666610718, 0.9224193692207336, 0.9122412204742432, 0.9882957935333252, 0.8217105269432068, 0.8118075132369995, 0.735292375087738, 0.7227810621261597, 0.6461058855056763, 0.6668857932090759, 0.6384599804878235, 0.6965270042419434, 0.6274911165237427, 0.6636161804199219, 0.6584064364433289, 0.6446704268455505, 0.6489230394363403, 0.6645299196243286, 0.6548883318901062, 0.6323952078819275, 0.648059606552124, 0.7377179861068726, 0.6601027846336365, 0.657945454120636, 0.6509659290313721, 0.6773578524589539, 0.661288321018219, 0.6529372334480286, 0.6500208377838135, 0.7266975045204163, 0.6503000855445862, 0.6787647008895874, 0.6430083513259888, 0.6751487255096436, 0.6713128685951233, 0.6699352264404297, 0.7113134860992432, 0.6823798418045044, 0.6811310052871704, 0.7030988931655884, 0.6854864358901978, 0.7427738308906555, 0.6836856603622437, 0.6798338890075684, 0.6826709508895874, 0.6809749007225037, 0.6913576722145081, 0.7014032006263733, 0.7032440304756165, 0.6797052025794983, 0.7251778244972229, 0.7274532914161682, 0.7020713686943054, 0.7412112355232239, 0.7088642120361328, 0.6997352838516235, 0.7160234451293945, 0.7197417616844177, 0.6927831172943115, 0.7079814672470093, 0.7485913634300232, 0.7025167942047119, 0.7043449878692627, 0.7103496789932251, 0.7085363268852234, 0.7151482105255127, 0.7335621118545532, 0.8839606642723083, 0.699869692325592, 0.7276333570480347, 0.7628961801528931, 0.7187957167625427, 0.7178465127944946, 0.7664989829063416, 0.829423189163208, 0.7160471081733704, 0.8316686153411865, 0.7523320317268372, 0.7626761198043823, 0.7507501244544983, 0.7996768951416016, 0.7936304211616516, 0.7519374489784241, 0.7421033382415771, 0.7888470888137817, 0.7555449604988098], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49886876344680786, 0.4977375566959381, 0.5135746598243713, 0.5090497732162476, 0.5090497732162476, 0.5101810097694397, 0.5203620195388794, 0.5282805562019348, 0.5588235259056091, 0.622171938419342, 0.639140248298645, 0.6210407018661499, 0.6889140009880066, 0.7013574838638306, 0.7477375268936157, 0.7533936500549316, 0.7941176295280457, 0.7918552160263062, 0.8156108856201172, 0.7884615659713745, 0.8246606588363647, 0.8065611124038696, 0.8110859990119934, 0.8190045356750488, 0.8110859990119934, 0.8246606588363647, 0.8190045356750488, 0.8167420625686646, 0.8099547624588013, 0.7929864525794983, 0.814479649066925, 0.8110859990119934, 0.8110859990119934, 0.7986425161361694, 0.8088235259056091, 0.8212669491767883, 0.8156108856201172, 0.7929864525794983, 0.814479649066925, 0.8099547624588013, 0.8122171759605408, 0.8156108856201172, 0.8122171759605408, 0.8178732991218567, 0.8020362257957458, 0.8088235259056091, 0.8167420625686646, 0.8133484125137329, 0.8133484125137329, 0.8009049892425537, 0.8042986392974854, 0.807692289352417, 0.8020362257957458, 0.8167420625686646, 0.8054298758506775, 0.8133484125137329, 0.8156108856201172, 0.8099547624588013, 0.807692289352417, 0.7997737526893616, 0.807692289352417, 0.7997737526893616, 0.814479649066925, 0.8065611124038696, 0.8009049892425537, 0.8042986392974854, 0.8178732991218567, 0.8122171759605408, 0.7941176295280457, 0.8167420625686646, 0.8065611124038696, 0.8054298758506775, 0.8042986392974854, 0.8099547624588013, 0.8020362257957458, 0.7805429697036743, 0.8167420625686646, 0.8054298758506775, 0.7941176295280457, 0.814479649066925, 0.8110859990119934, 0.8065611124038696, 0.7839366793632507, 0.8110859990119934, 0.7873303294181824, 0.8054298758506775, 0.790723979473114, 0.8088235259056091, 0.7975113391876221, 0.7997737526893616, 0.807692289352417, 0.8156108856201172, 0.8020362257957458, 0.8009049892425537]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.5224 - accuracy: 0.8740"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 50ms/step - loss: 0.5208 - accuracy: 0.8749 - val_loss: 1.0212 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4913 - accuracy: 0.8876 - val_loss: 1.0204 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4872 - accuracy: 0.8886 - val_loss: 1.0123 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4835 - accuracy: 0.8894 - val_loss: 1.0017 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4953 - accuracy: 0.8835 - val_loss: 0.9672 - val_accuracy: 0.4866\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4876 - accuracy: 0.8850 - val_loss: 1.0057 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4730 - accuracy: 0.8917 - val_loss: 1.0292 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4648 - accuracy: 0.8946 - val_loss: 1.0175 - val_accuracy: 0.4917\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4820 - accuracy: 0.8804 - val_loss: 1.0651 - val_accuracy: 0.4917\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4708 - accuracy: 0.8902 - val_loss: 1.1113 - val_accuracy: 0.4938\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4642 - accuracy: 0.8984 - val_loss: 1.0926 - val_accuracy: 0.5052\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4685 - accuracy: 0.8850 - val_loss: 1.1057 - val_accuracy: 0.5114\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4576 - accuracy: 0.9016 - val_loss: 1.0579 - val_accuracy: 0.5310\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4672 - accuracy: 0.8972 - val_loss: 1.0278 - val_accuracy: 0.5475\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4592 - accuracy: 0.8972 - val_loss: 1.1910 - val_accuracy: 0.5331\n","Epoch 16/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4476 - accuracy: 0.9026 - val_loss: 1.1038 - val_accuracy: 0.5640\n","Epoch 17/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4509 - accuracy: 0.9031 - val_loss: 0.9089 - val_accuracy: 0.6343\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4422 - accuracy: 0.9065 - val_loss: 0.7924 - val_accuracy: 0.6880\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4490 - accuracy: 0.9003 - val_loss: 0.8598 - val_accuracy: 0.6829\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4511 - accuracy: 0.8982 - val_loss: 0.7773 - val_accuracy: 0.7190\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4427 - accuracy: 0.9085 - val_loss: 0.6890 - val_accuracy: 0.7934\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4486 - accuracy: 0.9075 - val_loss: 0.7324 - val_accuracy: 0.7676\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4430 - accuracy: 0.9041 - val_loss: 0.6970 - val_accuracy: 0.7779\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4450 - accuracy: 0.9031 - val_loss: 0.7202 - val_accuracy: 0.7810\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4415 - accuracy: 0.9057 - val_loss: 0.6620 - val_accuracy: 0.8048\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4336 - accuracy: 0.9088 - val_loss: 0.6726 - val_accuracy: 0.8089\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4378 - accuracy: 0.9103 - val_loss: 0.6501 - val_accuracy: 0.8130\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4332 - accuracy: 0.9098 - val_loss: 0.6438 - val_accuracy: 0.8161\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4228 - accuracy: 0.9145 - val_loss: 0.6667 - val_accuracy: 0.8089\n","Epoch 30/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4321 - accuracy: 0.9059 - val_loss: 0.6530 - val_accuracy: 0.8244\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4225 - accuracy: 0.9171 - val_loss: 0.6781 - val_accuracy: 0.8110\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4238 - accuracy: 0.9134 - val_loss: 0.6690 - val_accuracy: 0.8058\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4273 - accuracy: 0.9129 - val_loss: 0.6672 - val_accuracy: 0.8202\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4191 - accuracy: 0.9181 - val_loss: 0.7170 - val_accuracy: 0.7934\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4400 - accuracy: 0.9059 - val_loss: 0.7004 - val_accuracy: 0.8037\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4352 - accuracy: 0.9047 - val_loss: 0.6625 - val_accuracy: 0.8192\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4184 - accuracy: 0.9168 - val_loss: 0.6603 - val_accuracy: 0.8192\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4104 - accuracy: 0.9202 - val_loss: 0.6753 - val_accuracy: 0.8161\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4090 - accuracy: 0.9230 - val_loss: 0.6744 - val_accuracy: 0.8171\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4089 - accuracy: 0.9142 - val_loss: 0.6656 - val_accuracy: 0.8233\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3977 - accuracy: 0.9276 - val_loss: 0.6783 - val_accuracy: 0.8151\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4047 - accuracy: 0.9191 - val_loss: 0.6803 - val_accuracy: 0.8171\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3942 - accuracy: 0.9261 - val_loss: 0.6847 - val_accuracy: 0.8130\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3980 - accuracy: 0.9271 - val_loss: 0.6887 - val_accuracy: 0.8130\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3941 - accuracy: 0.9269 - val_loss: 0.6894 - val_accuracy: 0.8182\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3982 - accuracy: 0.9271 - val_loss: 0.7131 - val_accuracy: 0.8048\n","Epoch 47/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3908 - accuracy: 0.9271 - val_loss: 0.6865 - val_accuracy: 0.8099\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3872 - accuracy: 0.9274 - val_loss: 0.6854 - val_accuracy: 0.8120\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3926 - accuracy: 0.9279 - val_loss: 0.6950 - val_accuracy: 0.8151\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3862 - accuracy: 0.9354 - val_loss: 0.6923 - val_accuracy: 0.8120\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3957 - accuracy: 0.9256 - val_loss: 0.7346 - val_accuracy: 0.7841\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3977 - accuracy: 0.9186 - val_loss: 0.7496 - val_accuracy: 0.7903\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3949 - accuracy: 0.9274 - val_loss: 0.7220 - val_accuracy: 0.7986\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3862 - accuracy: 0.9295 - val_loss: 0.7043 - val_accuracy: 0.8151\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3836 - accuracy: 0.9302 - val_loss: 0.6830 - val_accuracy: 0.8171\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3788 - accuracy: 0.9323 - val_loss: 0.7589 - val_accuracy: 0.7893\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4170 - accuracy: 0.9147 - val_loss: 0.7487 - val_accuracy: 0.7903\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.9328 - val_loss: 0.7021 - val_accuracy: 0.8099\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3843 - accuracy: 0.9258 - val_loss: 0.7547 - val_accuracy: 0.7862\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3864 - accuracy: 0.9266 - val_loss: 0.7255 - val_accuracy: 0.8089\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3714 - accuracy: 0.9313 - val_loss: 0.7415 - val_accuracy: 0.7975\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.9315 - val_loss: 0.7113 - val_accuracy: 0.8089\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3720 - accuracy: 0.9362 - val_loss: 0.7641 - val_accuracy: 0.7851\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3681 - accuracy: 0.9393 - val_loss: 0.7000 - val_accuracy: 0.8079\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3602 - accuracy: 0.9408 - val_loss: 0.7155 - val_accuracy: 0.8110\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3646 - accuracy: 0.9395 - val_loss: 0.7336 - val_accuracy: 0.8027\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3590 - accuracy: 0.9411 - val_loss: 0.7294 - val_accuracy: 0.8079\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3687 - accuracy: 0.9357 - val_loss: 0.7183 - val_accuracy: 0.8110\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.9421 - val_loss: 0.7245 - val_accuracy: 0.8037\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3572 - accuracy: 0.9413 - val_loss: 0.7235 - val_accuracy: 0.8068\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3582 - accuracy: 0.9421 - val_loss: 0.7133 - val_accuracy: 0.8089\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3738 - accuracy: 0.9315 - val_loss: 0.8376 - val_accuracy: 0.7655\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3647 - accuracy: 0.9370 - val_loss: 0.7304 - val_accuracy: 0.8089\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3446 - accuracy: 0.9470 - val_loss: 0.7334 - val_accuracy: 0.8110\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3727 - accuracy: 0.9351 - val_loss: 0.7635 - val_accuracy: 0.7955\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3656 - accuracy: 0.9351 - val_loss: 0.7154 - val_accuracy: 0.8120\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3484 - accuracy: 0.9465 - val_loss: 0.7278 - val_accuracy: 0.8068\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3368 - accuracy: 0.9494 - val_loss: 0.7327 - val_accuracy: 0.8048\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3452 - accuracy: 0.9437 - val_loss: 0.7257 - val_accuracy: 0.8130\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3514 - accuracy: 0.9413 - val_loss: 0.7486 - val_accuracy: 0.8099\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3482 - accuracy: 0.9434 - val_loss: 0.7758 - val_accuracy: 0.7944\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3501 - accuracy: 0.9442 - val_loss: 0.7423 - val_accuracy: 0.8068\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3405 - accuracy: 0.9483 - val_loss: 0.8393 - val_accuracy: 0.7841\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3509 - accuracy: 0.9429 - val_loss: 0.7556 - val_accuracy: 0.8027\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3425 - accuracy: 0.9488 - val_loss: 0.7827 - val_accuracy: 0.8027\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3372 - accuracy: 0.9499 - val_loss: 0.7455 - val_accuracy: 0.8058\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3417 - accuracy: 0.9444 - val_loss: 0.7386 - val_accuracy: 0.8048\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3311 - accuracy: 0.9501 - val_loss: 0.7498 - val_accuracy: 0.8017\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3263 - accuracy: 0.9550 - val_loss: 0.7980 - val_accuracy: 0.7924\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3362 - accuracy: 0.9491 - val_loss: 0.7648 - val_accuracy: 0.8027\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3289 - accuracy: 0.9545 - val_loss: 0.7509 - val_accuracy: 0.8017\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3515 - accuracy: 0.9408 - val_loss: 0.9187 - val_accuracy: 0.7748\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3383 - accuracy: 0.9494 - val_loss: 0.7566 - val_accuracy: 0.8068\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3229 - accuracy: 0.9517 - val_loss: 0.7691 - val_accuracy: 0.8006\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3235 - accuracy: 0.9514 - val_loss: 0.7657 - val_accuracy: 0.8079\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3205 - accuracy: 0.9587 - val_loss: 0.7458 - val_accuracy: 0.8068\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3340 - accuracy: 0.9491 - val_loss: 0.8260 - val_accuracy: 0.7862\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3295 - accuracy: 0.9486 - val_loss: 0.7609 - val_accuracy: 0.7996\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3186 - accuracy: 0.9545 - val_loss: 0.8166 - val_accuracy: 0.7934\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3164 - accuracy: 0.9556 - val_loss: 0.7896 - val_accuracy: 0.8058\n","{'loss': [0.5207891464233398, 0.4913071393966675, 0.4872268736362457, 0.4835446774959564, 0.49527010321617126, 0.4876124858856201, 0.4729653596878052, 0.4647897779941559, 0.4819677174091339, 0.4708178639411926, 0.464167058467865, 0.46854808926582336, 0.4575595557689667, 0.46720802783966064, 0.4591687321662903, 0.4475812315940857, 0.4509446620941162, 0.44222497940063477, 0.44896358251571655, 0.4511219561100006, 0.44266268610954285, 0.44859233498573303, 0.44297242164611816, 0.4450390040874481, 0.44148626923561096, 0.4336498975753784, 0.4377744197845459, 0.433208703994751, 0.4227781593799591, 0.4321199059486389, 0.42246198654174805, 0.4237857460975647, 0.4273154139518738, 0.4191489517688751, 0.4400123953819275, 0.4351668059825897, 0.41841456294059753, 0.4103868305683136, 0.4090138375759125, 0.4089442789554596, 0.3977391719818115, 0.40467196702957153, 0.39417585730552673, 0.3980313539505005, 0.3940548896789551, 0.39824989438056946, 0.3907533586025238, 0.38722237944602966, 0.39257386326789856, 0.38615933060646057, 0.3957454562187195, 0.39773818850517273, 0.3948653042316437, 0.38618189096450806, 0.3835878372192383, 0.3788282871246338, 0.41698968410491943, 0.37926772236824036, 0.3842710852622986, 0.38636264204978943, 0.3714427649974823, 0.37575316429138184, 0.3720030188560486, 0.36812731623649597, 0.3602255880832672, 0.3645972013473511, 0.35895782709121704, 0.3687257170677185, 0.3617348372936249, 0.35722845792770386, 0.35820358991622925, 0.3738086521625519, 0.3647264838218689, 0.34458741545677185, 0.37268051505088806, 0.36560115218162537, 0.34840109944343567, 0.3367998003959656, 0.34521904587745667, 0.35136547684669495, 0.34816309809684753, 0.35009923577308655, 0.34052982926368713, 0.3509030342102051, 0.34251105785369873, 0.33716902136802673, 0.3416678011417389, 0.33107316493988037, 0.3263210356235504, 0.33619412779808044, 0.32886895537376404, 0.351472407579422, 0.3382670283317566, 0.3229237198829651, 0.32351604104042053, 0.32048681378364563, 0.3339787423610687, 0.32950347661972046, 0.31859517097473145, 0.3164252042770386], 'accuracy': [0.8749353885650635, 0.8875969052314758, 0.8886305093765259, 0.8894056677818298, 0.8834625482559204, 0.8850129246711731, 0.8917312622070312, 0.8945736289024353, 0.8803617358207703, 0.8901808857917786, 0.8984495997428894, 0.8850129246711731, 0.9015504121780396, 0.897157609462738, 0.897157609462738, 0.9025839567184448, 0.9031007885932922, 0.9064599275588989, 0.9002584218978882, 0.8981912136077881, 0.908527135848999, 0.907493531703949, 0.9041343927383423, 0.9031007885932922, 0.905684769153595, 0.9087855219841003, 0.910335898399353, 0.9098191261291504, 0.9144702553749084, 0.9059431552886963, 0.9170542359352112, 0.9134367108345032, 0.9129198789596558, 0.9180878400802612, 0.9059431552886963, 0.9046511650085449, 0.9167958498001099, 0.9201550483703613, 0.9229974150657654, 0.9142118692398071, 0.9276486039161682, 0.9191214442253113, 0.9260981678962708, 0.9271317720413208, 0.9268733859062195, 0.9271317720413208, 0.9271317720413208, 0.9273901581764221, 0.9279069900512695, 0.9354005455970764, 0.9255813956260681, 0.9186046719551086, 0.9273901581764221, 0.9294573664665222, 0.930232584476471, 0.9322997331619263, 0.9147287011146545, 0.9328165650367737, 0.9258397817611694, 0.9266149997711182, 0.9312661290168762, 0.9315245747566223, 0.9361757040023804, 0.9392764568328857, 0.9408268928527832, 0.9395349025726318, 0.9410852789878845, 0.9356589317321777, 0.9421188831329346, 0.9413436651229858, 0.9421188831329346, 0.9315245747566223, 0.9369509220123291, 0.947028398513794, 0.9351420998573303, 0.9351420998573303, 0.9465116262435913, 0.9493539929389954, 0.9436692595481873, 0.9413436651229858, 0.9434108734130859, 0.9441860318183899, 0.9483203887939453, 0.9428940415382385, 0.9488372206687927, 0.9498708248138428, 0.9444444179534912, 0.9501292109489441, 0.9550387859344482, 0.949095606803894, 0.9545219540596008, 0.9408268928527832, 0.9493539929389954, 0.9516795873641968, 0.9514212012290955, 0.9586563110351562, 0.949095606803894, 0.9485788345336914, 0.9545219540596008, 0.9555555582046509], 'val_loss': [1.0211849212646484, 1.0204193592071533, 1.012316346168518, 1.0017273426055908, 0.9671612977981567, 1.0057339668273926, 1.0291740894317627, 1.0175397396087646, 1.0650858879089355, 1.1112948656082153, 1.0925790071487427, 1.105654239654541, 1.0578960180282593, 1.0278394222259521, 1.190967082977295, 1.1037719249725342, 0.9088627696037292, 0.7923519611358643, 0.8597955703735352, 0.7773041725158691, 0.6890378594398499, 0.7323510050773621, 0.6970097422599792, 0.7201719880104065, 0.6619616150856018, 0.6725873947143555, 0.6501079201698303, 0.6438001990318298, 0.6667383909225464, 0.6530114412307739, 0.6781125068664551, 0.6689876317977905, 0.667221188545227, 0.7170310020446777, 0.7004199624061584, 0.6624972820281982, 0.6602901220321655, 0.6752671003341675, 0.6743586659431458, 0.6656345725059509, 0.6782860159873962, 0.6802741885185242, 0.684704601764679, 0.688663125038147, 0.6894097924232483, 0.7131195068359375, 0.686527669429779, 0.685397744178772, 0.6950119733810425, 0.6923181414604187, 0.7345527410507202, 0.7495593428611755, 0.7219898104667664, 0.7042713165283203, 0.6830456852912903, 0.7588993906974792, 0.7486788034439087, 0.7020952105522156, 0.7547091245651245, 0.7255023717880249, 0.7414708137512207, 0.711265504360199, 0.7641384601593018, 0.69998699426651, 0.715529203414917, 0.733601987361908, 0.7293581962585449, 0.7182580828666687, 0.7245092988014221, 0.723522961139679, 0.7133349776268005, 0.83757483959198, 0.7303587794303894, 0.7334095239639282, 0.7634990215301514, 0.7154037356376648, 0.7277593016624451, 0.732657790184021, 0.7256535291671753, 0.7485729455947876, 0.7758320569992065, 0.742325484752655, 0.8392580151557922, 0.7556021213531494, 0.7826550602912903, 0.7455332279205322, 0.7385661005973816, 0.7497788071632385, 0.7979618906974792, 0.7647752165794373, 0.7508663535118103, 0.9187466502189636, 0.7566322684288025, 0.7691279053688049, 0.7657376527786255, 0.7458236813545227, 0.8260235786437988, 0.7608660459518433, 0.816588282585144, 0.789584219455719], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.4917355477809906, 0.4917355477809906, 0.49380165338516235, 0.5051652789115906, 0.5113636255264282, 0.5309917330741882, 0.547520637512207, 0.5330578684806824, 0.5640496015548706, 0.6342975497245789, 0.6880165338516235, 0.682851254940033, 0.7190082669258118, 0.7933884263038635, 0.7675619721412659, 0.7778925895690918, 0.7809917330741882, 0.8047520518302917, 0.80888432264328, 0.8130165338516235, 0.81611567735672, 0.80888432264328, 0.8243801593780518, 0.8109503984451294, 0.8057851195335388, 0.8202479481697083, 0.7933884263038635, 0.8037189841270447, 0.8192148804664612, 0.8192148804664612, 0.81611567735672, 0.817148745059967, 0.8233470916748047, 0.8150826692581177, 0.817148745059967, 0.8130165338516235, 0.8130165338516235, 0.8181818127632141, 0.8047520518302917, 0.8099173307418823, 0.8119834661483765, 0.8150826692581177, 0.8119834661483765, 0.7840909361839294, 0.7902892827987671, 0.7985537052154541, 0.8150826692581177, 0.817148745059967, 0.78925621509552, 0.7902892827987671, 0.8099173307418823, 0.7861570119857788, 0.80888432264328, 0.797520637512207, 0.80888432264328, 0.7851239442825317, 0.807851254940033, 0.8109503984451294, 0.8026859760284424, 0.807851254940033, 0.8109503984451294, 0.8037189841270447, 0.8068181872367859, 0.80888432264328, 0.7654958963394165, 0.80888432264328, 0.8109503984451294, 0.7954545617103577, 0.8119834661483765, 0.8068181872367859, 0.8047520518302917, 0.8130165338516235, 0.8099173307418823, 0.7944214940071106, 0.8068181872367859, 0.7840909361839294, 0.8026859760284424, 0.8026859760284424, 0.8057851195335388, 0.8047520518302917, 0.8016529083251953, 0.7923553586006165, 0.8026859760284424, 0.8016529083251953, 0.7747933864593506, 0.8068181872367859, 0.8006198406219482, 0.807851254940033, 0.8068181872367859, 0.7861570119857788, 0.7995867729187012, 0.7933884263038635, 0.8057851195335388]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.4249 - accuracy: 0.9107"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 59ms/step - loss: 0.4240 - accuracy: 0.9111 - val_loss: 1.0842 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3573 - accuracy: 0.9348 - val_loss: 1.0800 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3616 - accuracy: 0.9343 - val_loss: 1.0595 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3519 - accuracy: 0.9394 - val_loss: 1.0495 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3482 - accuracy: 0.9397 - val_loss: 1.0517 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3516 - accuracy: 0.9415 - val_loss: 1.0480 - val_accuracy: 0.4903\n","Epoch 7/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3579 - accuracy: 0.9380 - val_loss: 1.0938 - val_accuracy: 0.4925\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3338 - accuracy: 0.9504 - val_loss: 1.1383 - val_accuracy: 0.4946\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3512 - accuracy: 0.9391 - val_loss: 1.2354 - val_accuracy: 0.4935\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3407 - accuracy: 0.9461 - val_loss: 1.1855 - val_accuracy: 0.5065\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3377 - accuracy: 0.9440 - val_loss: 1.3048 - val_accuracy: 0.5032\n","Epoch 12/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3473 - accuracy: 0.9394 - val_loss: 1.2643 - val_accuracy: 0.5183\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3523 - accuracy: 0.9394 - val_loss: 1.4325 - val_accuracy: 0.5140\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3523 - accuracy: 0.9356 - val_loss: 1.3776 - val_accuracy: 0.5312\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3236 - accuracy: 0.9539 - val_loss: 1.4423 - val_accuracy: 0.5399\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3202 - accuracy: 0.9553 - val_loss: 1.2613 - val_accuracy: 0.5851\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3341 - accuracy: 0.9472 - val_loss: 1.2685 - val_accuracy: 0.5916\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3359 - accuracy: 0.9442 - val_loss: 1.0194 - val_accuracy: 0.6476\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3244 - accuracy: 0.9545 - val_loss: 0.9135 - val_accuracy: 0.6940\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3215 - accuracy: 0.9537 - val_loss: 0.9333 - val_accuracy: 0.6929\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3237 - accuracy: 0.9526 - val_loss: 0.6366 - val_accuracy: 0.8114\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3147 - accuracy: 0.9529 - val_loss: 0.6377 - val_accuracy: 0.8297\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3310 - accuracy: 0.9507 - val_loss: 0.5865 - val_accuracy: 0.8513\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3282 - accuracy: 0.9480 - val_loss: 0.5840 - val_accuracy: 0.8513\n","Epoch 25/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3267 - accuracy: 0.9461 - val_loss: 0.5483 - val_accuracy: 0.8610\n","Epoch 26/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3168 - accuracy: 0.9547 - val_loss: 0.5711 - val_accuracy: 0.8685\n","Epoch 27/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3219 - accuracy: 0.9520 - val_loss: 0.5366 - val_accuracy: 0.8782\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3124 - accuracy: 0.9601 - val_loss: 0.5427 - val_accuracy: 0.8707\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3150 - accuracy: 0.9545 - val_loss: 0.5439 - val_accuracy: 0.8772\n","Epoch 30/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3038 - accuracy: 0.9628 - val_loss: 0.5443 - val_accuracy: 0.8804\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3034 - accuracy: 0.9628 - val_loss: 0.5462 - val_accuracy: 0.8761\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3065 - accuracy: 0.9566 - val_loss: 0.5466 - val_accuracy: 0.8804\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3132 - accuracy: 0.9545 - val_loss: 0.5547 - val_accuracy: 0.8750\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3036 - accuracy: 0.9620 - val_loss: 0.5512 - val_accuracy: 0.8772\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3319 - accuracy: 0.9467 - val_loss: 0.5519 - val_accuracy: 0.8728\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3025 - accuracy: 0.9615 - val_loss: 0.5660 - val_accuracy: 0.8696\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3035 - accuracy: 0.9593 - val_loss: 0.5789 - val_accuracy: 0.8707\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2984 - accuracy: 0.9607 - val_loss: 0.5803 - val_accuracy: 0.8707\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3077 - accuracy: 0.9582 - val_loss: 0.5687 - val_accuracy: 0.8739\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3102 - accuracy: 0.9518 - val_loss: 0.6125 - val_accuracy: 0.8545\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2986 - accuracy: 0.9617 - val_loss: 0.5621 - val_accuracy: 0.8707\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3143 - accuracy: 0.9504 - val_loss: 0.5834 - val_accuracy: 0.8578\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3010 - accuracy: 0.9599 - val_loss: 0.5692 - val_accuracy: 0.8707\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2895 - accuracy: 0.9658 - val_loss: 0.5758 - val_accuracy: 0.8621\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3002 - accuracy: 0.9596 - val_loss: 0.6576 - val_accuracy: 0.8481\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2945 - accuracy: 0.9644 - val_loss: 0.5816 - val_accuracy: 0.8707\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2931 - accuracy: 0.9631 - val_loss: 0.5898 - val_accuracy: 0.8739\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2891 - accuracy: 0.9647 - val_loss: 0.5823 - val_accuracy: 0.8707\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3004 - accuracy: 0.9609 - val_loss: 0.5794 - val_accuracy: 0.8825\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2973 - accuracy: 0.9539 - val_loss: 0.5925 - val_accuracy: 0.8664\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2917 - accuracy: 0.9609 - val_loss: 0.5884 - val_accuracy: 0.8642\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2873 - accuracy: 0.9628 - val_loss: 0.6022 - val_accuracy: 0.8772\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2816 - accuracy: 0.9669 - val_loss: 0.5966 - val_accuracy: 0.8696\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.9628 - val_loss: 0.5852 - val_accuracy: 0.8642\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2817 - accuracy: 0.9706 - val_loss: 0.6043 - val_accuracy: 0.8718\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2832 - accuracy: 0.9674 - val_loss: 0.6046 - val_accuracy: 0.8642\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2892 - accuracy: 0.9647 - val_loss: 0.6275 - val_accuracy: 0.8588\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2808 - accuracy: 0.9671 - val_loss: 0.5968 - val_accuracy: 0.8739\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2874 - accuracy: 0.9647 - val_loss: 0.6125 - val_accuracy: 0.8567\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2781 - accuracy: 0.9693 - val_loss: 0.6053 - val_accuracy: 0.8631\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2829 - accuracy: 0.9669 - val_loss: 0.6062 - val_accuracy: 0.8664\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2736 - accuracy: 0.9698 - val_loss: 0.6058 - val_accuracy: 0.8664\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2891 - accuracy: 0.9601 - val_loss: 0.6376 - val_accuracy: 0.8513\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3265 - accuracy: 0.9402 - val_loss: 0.6459 - val_accuracy: 0.8341\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2903 - accuracy: 0.9634 - val_loss: 0.5924 - val_accuracy: 0.8642\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2797 - accuracy: 0.9698 - val_loss: 0.6439 - val_accuracy: 0.8481\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2656 - accuracy: 0.9749 - val_loss: 0.5966 - val_accuracy: 0.8718\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2712 - accuracy: 0.9706 - val_loss: 0.5973 - val_accuracy: 0.8685\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2701 - accuracy: 0.9733 - val_loss: 0.6157 - val_accuracy: 0.8610\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2652 - accuracy: 0.9736 - val_loss: 0.6009 - val_accuracy: 0.8707\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2831 - accuracy: 0.9663 - val_loss: 0.6550 - val_accuracy: 0.8567\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2751 - accuracy: 0.9669 - val_loss: 0.6399 - val_accuracy: 0.8578\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2614 - accuracy: 0.9758 - val_loss: 0.6018 - val_accuracy: 0.8718\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2640 - accuracy: 0.9741 - val_loss: 0.6639 - val_accuracy: 0.8470\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2862 - accuracy: 0.9639 - val_loss: 0.6356 - val_accuracy: 0.8556\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2767 - accuracy: 0.9655 - val_loss: 0.7333 - val_accuracy: 0.8222\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2766 - accuracy: 0.9671 - val_loss: 0.6033 - val_accuracy: 0.8664\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2681 - accuracy: 0.9741 - val_loss: 0.7431 - val_accuracy: 0.8351\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2836 - accuracy: 0.9623 - val_loss: 0.6786 - val_accuracy: 0.8513\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3169 - accuracy: 0.9475 - val_loss: 0.7330 - val_accuracy: 0.8351\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2719 - accuracy: 0.9688 - val_loss: 0.6038 - val_accuracy: 0.8739\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2576 - accuracy: 0.9795 - val_loss: 0.6329 - val_accuracy: 0.8642\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2620 - accuracy: 0.9755 - val_loss: 0.6205 - val_accuracy: 0.8675\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2599 - accuracy: 0.9749 - val_loss: 0.6316 - val_accuracy: 0.8642\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2642 - accuracy: 0.9712 - val_loss: 0.6219 - val_accuracy: 0.8696\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2520 - accuracy: 0.9793 - val_loss: 0.6317 - val_accuracy: 0.8631\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2513 - accuracy: 0.9814 - val_loss: 0.6587 - val_accuracy: 0.8545\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2533 - accuracy: 0.9774 - val_loss: 0.6418 - val_accuracy: 0.8621\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2539 - accuracy: 0.9768 - val_loss: 0.7072 - val_accuracy: 0.8578\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2513 - accuracy: 0.9768 - val_loss: 0.6623 - val_accuracy: 0.8631\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2460 - accuracy: 0.9803 - val_loss: 0.6430 - val_accuracy: 0.8642\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2466 - accuracy: 0.9793 - val_loss: 0.6642 - val_accuracy: 0.8675\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2591 - accuracy: 0.9717 - val_loss: 0.6404 - val_accuracy: 0.8621\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2601 - accuracy: 0.9755 - val_loss: 0.6311 - val_accuracy: 0.8599\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2546 - accuracy: 0.9758 - val_loss: 0.6276 - val_accuracy: 0.8675\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2561 - accuracy: 0.9736 - val_loss: 0.6341 - val_accuracy: 0.8631\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2669 - accuracy: 0.9685 - val_loss: 0.6484 - val_accuracy: 0.8588\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2534 - accuracy: 0.9752 - val_loss: 0.6771 - val_accuracy: 0.8567\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2517 - accuracy: 0.9776 - val_loss: 0.6527 - val_accuracy: 0.8664\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2552 - accuracy: 0.9771 - val_loss: 0.6328 - val_accuracy: 0.8642\n","{'loss': [0.42397886514663696, 0.357329785823822, 0.36164018511772156, 0.35185521841049194, 0.3482361435890198, 0.3515629470348358, 0.3578517436981201, 0.3337596654891968, 0.35118210315704346, 0.3407488465309143, 0.337688148021698, 0.347305029630661, 0.3522549271583557, 0.3523365557193756, 0.3236386775970459, 0.32023927569389343, 0.33409953117370605, 0.33585938811302185, 0.3243570625782013, 0.3215042054653168, 0.3236587345600128, 0.3147294819355011, 0.33099958300590515, 0.32817336916923523, 0.3267465829849243, 0.3167814612388611, 0.3219280242919922, 0.31241875886917114, 0.31496793031692505, 0.30376890301704407, 0.30339622497558594, 0.30653566122055054, 0.3132079541683197, 0.30363839864730835, 0.33194851875305176, 0.30249524116516113, 0.3035323917865753, 0.29836082458496094, 0.30765727162361145, 0.31024593114852905, 0.29857149720191956, 0.31427937746047974, 0.30104172229766846, 0.289473295211792, 0.30020231008529663, 0.2944701313972473, 0.29307135939598083, 0.2890825867652893, 0.3004409968852997, 0.29731664061546326, 0.2917366027832031, 0.2873378098011017, 0.28159022331237793, 0.28771302103996277, 0.2817332148551941, 0.28319746255874634, 0.28923651576042175, 0.28078269958496094, 0.28742051124572754, 0.27805209159851074, 0.2828618884086609, 0.27359074354171753, 0.28912633657455444, 0.32651785016059875, 0.29033228754997253, 0.27970513701438904, 0.26559150218963623, 0.2712114155292511, 0.27011895179748535, 0.26521193981170654, 0.28314995765686035, 0.27508631348609924, 0.26136091351509094, 0.2640266716480255, 0.2862245738506317, 0.2766861617565155, 0.27662408351898193, 0.268057256937027, 0.2836466431617737, 0.31690800189971924, 0.2719496786594391, 0.25755196809768677, 0.26199474930763245, 0.2599392533302307, 0.26415273547172546, 0.25195786356925964, 0.2513029873371124, 0.2533330023288727, 0.2538797855377197, 0.2513001263141632, 0.24602387845516205, 0.2465517222881317, 0.2590852379798889, 0.2600822448730469, 0.25455403327941895, 0.25612735748291016, 0.26688352227211, 0.25344768166542053, 0.2517421245574951, 0.2552335262298584], 'accuracy': [0.9110991358757019, 0.9348060488700867, 0.9342672228813171, 0.9393857717514038, 0.9396551847457886, 0.9415409564971924, 0.9380387663841248, 0.9504310488700867, 0.939116358757019, 0.9461206793785095, 0.943965494632721, 0.9393857717514038, 0.9393857717514038, 0.9356142282485962, 0.9539331793785095, 0.9552801847457886, 0.9471982717514038, 0.9442349076271057, 0.954472005367279, 0.9536637663841248, 0.9525862336158752, 0.9528555870056152, 0.9507004022598267, 0.9480064511299133, 0.9461206793785095, 0.954741358757019, 0.9520474076271057, 0.9601293206214905, 0.954472005367279, 0.9628232717514038, 0.9628232717514038, 0.9566271305084229, 0.954472005367279, 0.9620150923728943, 0.946659505367279, 0.9614762663841248, 0.959321141242981, 0.9606680870056152, 0.9582435488700867, 0.951777994632721, 0.9617456793785095, 0.9504310488700867, 0.9598599076271057, 0.9657866358757019, 0.959590494632721, 0.9644396305084229, 0.9630926847457886, 0.9647090435028076, 0.9609375, 0.9539331793785095, 0.9609375, 0.9628232717514038, 0.9668642282485962, 0.9628232717514038, 0.9706357717514038, 0.967402994632721, 0.9647090435028076, 0.967133641242981, 0.9647090435028076, 0.9692887663841248, 0.9668642282485962, 0.9698275923728943, 0.9601293206214905, 0.9401939511299133, 0.9633620977401733, 0.9698275923728943, 0.974946141242981, 0.9706357717514038, 0.9733297228813171, 0.9735991358757019, 0.9663254022598267, 0.9668642282485962, 0.9757543206214905, 0.9741379022598267, 0.9639008641242981, 0.9655172228813171, 0.967133641242981, 0.9741379022598267, 0.962284505367279, 0.9474676847457886, 0.96875, 0.9795258641242981, 0.9754849076271057, 0.974946141242981, 0.9711745977401733, 0.9792564511299133, 0.9814116358757019, 0.9773706793785095, 0.9768319129943848, 0.9768319129943848, 0.9803340435028076, 0.9792564511299133, 0.9717133641242981, 0.9754849076271057, 0.9757543206214905, 0.9735991358757019, 0.9684805870056152, 0.975215494632721, 0.9776400923728943, 0.9771012663841248], 'val_loss': [1.0842466354370117, 1.0799530744552612, 1.059452772140503, 1.0494954586029053, 1.051672339439392, 1.0480377674102783, 1.093824028968811, 1.1382591724395752, 1.2354282140731812, 1.1855071783065796, 1.304762601852417, 1.2643393278121948, 1.4325217008590698, 1.3775537014007568, 1.4422746896743774, 1.2613047361373901, 1.268481969833374, 1.0193778276443481, 0.9134505987167358, 0.9332974553108215, 0.6365987062454224, 0.637701153755188, 0.5865043997764587, 0.583988606929779, 0.5482674837112427, 0.5711073279380798, 0.5365885496139526, 0.5427088737487793, 0.5439063310623169, 0.5442893505096436, 0.5462091565132141, 0.5466424822807312, 0.5546655058860779, 0.5512498617172241, 0.5519317388534546, 0.5660062432289124, 0.5789273977279663, 0.580255925655365, 0.5686964392662048, 0.6124559640884399, 0.562055230140686, 0.5833842754364014, 0.5692443251609802, 0.5758442282676697, 0.6576089262962341, 0.5815905928611755, 0.5897938013076782, 0.5822919607162476, 0.5794097185134888, 0.5924972295761108, 0.5884338021278381, 0.6022368669509888, 0.5965735912322998, 0.5851696133613586, 0.6043434739112854, 0.604585587978363, 0.6275197267532349, 0.596759021282196, 0.6125296950340271, 0.6052937507629395, 0.6061904430389404, 0.605781614780426, 0.6375685334205627, 0.6458607316017151, 0.592436671257019, 0.6438654661178589, 0.5966356992721558, 0.5973140001296997, 0.615696370601654, 0.6009437441825867, 0.6550033688545227, 0.639851450920105, 0.6017886400222778, 0.6639030575752258, 0.635647177696228, 0.7332577109336853, 0.6032639741897583, 0.7431284189224243, 0.6786004304885864, 0.7330493330955505, 0.6038097739219666, 0.6329178214073181, 0.6205430626869202, 0.6316398978233337, 0.621935248374939, 0.6317232251167297, 0.658723771572113, 0.6418126821517944, 0.707217812538147, 0.6622545719146729, 0.6429550647735596, 0.664151132106781, 0.6404271721839905, 0.6310727596282959, 0.6276325583457947, 0.6341195702552795, 0.6484056711196899, 0.6770800948143005, 0.6527169346809387, 0.6327977180480957], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4903017282485962, 0.4924568831920624, 0.49461206793785095, 0.49353447556495667, 0.506465494632721, 0.5032327771186829, 0.5183189511299133, 0.514008641242981, 0.53125, 0.5398706793785095, 0.5851293206214905, 0.5915948152542114, 0.6476293206214905, 0.693965494632721, 0.6928879022598267, 0.8114224076271057, 0.829741358757019, 0.8512930870056152, 0.8512930870056152, 0.860991358757019, 0.868534505367279, 0.8782327771186829, 0.8706896305084229, 0.8771551847457886, 0.8803879022598267, 0.8760775923728943, 0.8803879022598267, 0.875, 0.8771551847457886, 0.8728448152542114, 0.8696120977401733, 0.8706896305084229, 0.8706896305084229, 0.8739224076271057, 0.8545258641242981, 0.8706896305084229, 0.857758641242981, 0.8706896305084229, 0.8620689511299133, 0.8480603694915771, 0.8706896305084229, 0.8739224076271057, 0.8706896305084229, 0.8825430870056152, 0.8663793206214905, 0.8642241358757019, 0.8771551847457886, 0.8696120977401733, 0.8642241358757019, 0.8717672228813171, 0.8642241358757019, 0.8588362336158752, 0.8739224076271057, 0.8566810488700867, 0.8631465435028076, 0.8663793206214905, 0.8663793206214905, 0.8512930870056152, 0.8340517282485962, 0.8642241358757019, 0.8480603694915771, 0.8717672228813171, 0.868534505367279, 0.860991358757019, 0.8706896305084229, 0.8566810488700867, 0.857758641242981, 0.8717672228813171, 0.8469827771186829, 0.8556034564971924, 0.8221982717514038, 0.8663793206214905, 0.8351293206214905, 0.8512930870056152, 0.8351293206214905, 0.8739224076271057, 0.8642241358757019, 0.8674569129943848, 0.8642241358757019, 0.8696120977401733, 0.8631465435028076, 0.8545258641242981, 0.8620689511299133, 0.857758641242981, 0.8631465435028076, 0.8642241358757019, 0.8674569129943848, 0.8620689511299133, 0.8599137663841248, 0.8674569129943848, 0.8631465435028076, 0.8588362336158752, 0.8566810488700867, 0.8663793206214905, 0.8642241358757019]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4019 - accuracy: 0.9201"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 73ms/step - loss: 0.3979 - accuracy: 0.9216 - val_loss: 1.0678 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3636 - accuracy: 0.9366 - val_loss: 1.0626 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3438 - accuracy: 0.9448 - val_loss: 1.0479 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3417 - accuracy: 0.9474 - val_loss: 1.0471 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3367 - accuracy: 0.9508 - val_loss: 1.0635 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3547 - accuracy: 0.9400 - val_loss: 1.0629 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3437 - accuracy: 0.9474 - val_loss: 1.0926 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3431 - accuracy: 0.9445 - val_loss: 1.1467 - val_accuracy: 0.5000\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3405 - accuracy: 0.9460 - val_loss: 1.1294 - val_accuracy: 0.5090\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3475 - accuracy: 0.9411 - val_loss: 1.2385 - val_accuracy: 0.5068\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3319 - accuracy: 0.9516 - val_loss: 1.3785 - val_accuracy: 0.5045\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3391 - accuracy: 0.9485 - val_loss: 1.4242 - val_accuracy: 0.5068\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3288 - accuracy: 0.9505 - val_loss: 1.4890 - val_accuracy: 0.5147\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3252 - accuracy: 0.9539 - val_loss: 1.4037 - val_accuracy: 0.5339\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3271 - accuracy: 0.9593 - val_loss: 1.4699 - val_accuracy: 0.5407\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3148 - accuracy: 0.9590 - val_loss: 1.3242 - val_accuracy: 0.5814\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3224 - accuracy: 0.9553 - val_loss: 1.2691 - val_accuracy: 0.6052\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3260 - accuracy: 0.9496 - val_loss: 1.2895 - val_accuracy: 0.6131\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3190 - accuracy: 0.9539 - val_loss: 1.0238 - val_accuracy: 0.6674\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3242 - accuracy: 0.9510 - val_loss: 1.0118 - val_accuracy: 0.6844\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3210 - accuracy: 0.9527 - val_loss: 0.6656 - val_accuracy: 0.7919\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3514 - accuracy: 0.9377 - val_loss: 0.8033 - val_accuracy: 0.7466\n","Epoch 23/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3081 - accuracy: 0.9621 - val_loss: 0.6090 - val_accuracy: 0.8394\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3123 - accuracy: 0.9612 - val_loss: 0.6514 - val_accuracy: 0.7998\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3208 - accuracy: 0.9539 - val_loss: 0.5907 - val_accuracy: 0.8529\n","Epoch 26/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3002 - accuracy: 0.9638 - val_loss: 0.5911 - val_accuracy: 0.8462\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3112 - accuracy: 0.9598 - val_loss: 0.6009 - val_accuracy: 0.8382\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3105 - accuracy: 0.9576 - val_loss: 0.6110 - val_accuracy: 0.8348\n","Epoch 29/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3134 - accuracy: 0.9570 - val_loss: 0.5776 - val_accuracy: 0.8575\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3428 - accuracy: 0.9358 - val_loss: 0.5865 - val_accuracy: 0.8371\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3169 - accuracy: 0.9559 - val_loss: 0.5892 - val_accuracy: 0.8405\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3021 - accuracy: 0.9643 - val_loss: 0.5802 - val_accuracy: 0.8450\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3036 - accuracy: 0.9598 - val_loss: 0.5774 - val_accuracy: 0.8507\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3034 - accuracy: 0.9615 - val_loss: 0.6513 - val_accuracy: 0.8337\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3037 - accuracy: 0.9610 - val_loss: 0.5990 - val_accuracy: 0.8450\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2967 - accuracy: 0.9646 - val_loss: 0.5933 - val_accuracy: 0.8428\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3056 - accuracy: 0.9584 - val_loss: 0.5977 - val_accuracy: 0.8473\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2959 - accuracy: 0.9649 - val_loss: 0.6121 - val_accuracy: 0.8495\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2930 - accuracy: 0.9663 - val_loss: 0.6220 - val_accuracy: 0.8405\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2888 - accuracy: 0.9677 - val_loss: 0.6066 - val_accuracy: 0.8495\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2880 - accuracy: 0.9686 - val_loss: 0.6212 - val_accuracy: 0.8416\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2920 - accuracy: 0.9683 - val_loss: 0.6547 - val_accuracy: 0.8326\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2960 - accuracy: 0.9649 - val_loss: 0.6476 - val_accuracy: 0.8326\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2895 - accuracy: 0.9677 - val_loss: 0.6084 - val_accuracy: 0.8473\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2986 - accuracy: 0.9632 - val_loss: 0.7721 - val_accuracy: 0.8088\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3378 - accuracy: 0.9423 - val_loss: 0.6471 - val_accuracy: 0.8371\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2822 - accuracy: 0.9728 - val_loss: 0.6045 - val_accuracy: 0.8382\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2785 - accuracy: 0.9723 - val_loss: 0.6291 - val_accuracy: 0.8382\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2794 - accuracy: 0.9743 - val_loss: 0.6495 - val_accuracy: 0.8326\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2735 - accuracy: 0.9717 - val_loss: 0.6209 - val_accuracy: 0.8473\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2881 - accuracy: 0.9663 - val_loss: 0.6418 - val_accuracy: 0.8462\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2779 - accuracy: 0.9709 - val_loss: 0.6167 - val_accuracy: 0.8405\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2738 - accuracy: 0.9726 - val_loss: 0.6130 - val_accuracy: 0.8484\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2724 - accuracy: 0.9748 - val_loss: 0.6700 - val_accuracy: 0.8314\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2780 - accuracy: 0.9700 - val_loss: 0.6623 - val_accuracy: 0.8348\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2765 - accuracy: 0.9711 - val_loss: 0.6661 - val_accuracy: 0.8360\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2845 - accuracy: 0.9683 - val_loss: 0.6952 - val_accuracy: 0.8269\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2720 - accuracy: 0.9734 - val_loss: 0.6281 - val_accuracy: 0.8439\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2707 - accuracy: 0.9734 - val_loss: 0.6302 - val_accuracy: 0.8439\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2723 - accuracy: 0.9728 - val_loss: 0.6896 - val_accuracy: 0.8269\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2728 - accuracy: 0.9737 - val_loss: 0.6658 - val_accuracy: 0.8314\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2660 - accuracy: 0.9771 - val_loss: 0.6662 - val_accuracy: 0.8292\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2635 - accuracy: 0.9743 - val_loss: 0.6583 - val_accuracy: 0.8382\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2888 - accuracy: 0.9584 - val_loss: 0.7043 - val_accuracy: 0.8235\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2665 - accuracy: 0.9748 - val_loss: 0.6744 - val_accuracy: 0.8314\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2789 - accuracy: 0.9663 - val_loss: 0.7780 - val_accuracy: 0.8077\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2639 - accuracy: 0.9745 - val_loss: 0.7271 - val_accuracy: 0.8247\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2738 - accuracy: 0.9672 - val_loss: 0.6626 - val_accuracy: 0.8382\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2630 - accuracy: 0.9762 - val_loss: 0.6730 - val_accuracy: 0.8405\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2648 - accuracy: 0.9754 - val_loss: 0.7108 - val_accuracy: 0.8326\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2729 - accuracy: 0.9686 - val_loss: 0.7169 - val_accuracy: 0.8269\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2647 - accuracy: 0.9720 - val_loss: 0.6525 - val_accuracy: 0.8439\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2610 - accuracy: 0.9782 - val_loss: 0.6823 - val_accuracy: 0.8382\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2544 - accuracy: 0.9782 - val_loss: 0.7550 - val_accuracy: 0.8235\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2474 - accuracy: 0.9822 - val_loss: 0.6882 - val_accuracy: 0.8428\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2834 - accuracy: 0.9677 - val_loss: 0.7036 - val_accuracy: 0.8348\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2652 - accuracy: 0.9740 - val_loss: 0.6896 - val_accuracy: 0.8337\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2539 - accuracy: 0.9796 - val_loss: 0.7121 - val_accuracy: 0.8281\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2841 - accuracy: 0.9629 - val_loss: 0.6886 - val_accuracy: 0.8292\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2504 - accuracy: 0.9802 - val_loss: 0.6641 - val_accuracy: 0.8360\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2517 - accuracy: 0.9782 - val_loss: 0.6741 - val_accuracy: 0.8382\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2462 - accuracy: 0.9825 - val_loss: 0.6897 - val_accuracy: 0.8326\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2552 - accuracy: 0.9779 - val_loss: 0.6694 - val_accuracy: 0.8382\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2593 - accuracy: 0.9737 - val_loss: 0.6935 - val_accuracy: 0.8371\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2529 - accuracy: 0.9810 - val_loss: 0.6773 - val_accuracy: 0.8337\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2459 - accuracy: 0.9839 - val_loss: 0.7106 - val_accuracy: 0.8303\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2470 - accuracy: 0.9825 - val_loss: 0.6825 - val_accuracy: 0.8416\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2643 - accuracy: 0.9731 - val_loss: 0.6830 - val_accuracy: 0.8348\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2659 - accuracy: 0.9714 - val_loss: 0.7099 - val_accuracy: 0.8269\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2464 - accuracy: 0.9833 - val_loss: 0.7191 - val_accuracy: 0.8348\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2575 - accuracy: 0.9748 - val_loss: 0.7032 - val_accuracy: 0.8337\n","Epoch 92/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2482 - accuracy: 0.9808 - val_loss: 0.7049 - val_accuracy: 0.8247\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2361 - accuracy: 0.9878 - val_loss: 0.7213 - val_accuracy: 0.8190\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2366 - accuracy: 0.9859 - val_loss: 0.7138 - val_accuracy: 0.8258\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2469 - accuracy: 0.9799 - val_loss: 0.9271 - val_accuracy: 0.7998\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2650 - accuracy: 0.9714 - val_loss: 0.7115 - val_accuracy: 0.8314\n","Epoch 97/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2448 - accuracy: 0.9810 - val_loss: 0.7114 - val_accuracy: 0.8303\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2499 - accuracy: 0.9743 - val_loss: 0.6970 - val_accuracy: 0.8292\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2450 - accuracy: 0.9808 - val_loss: 0.7089 - val_accuracy: 0.8281\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2340 - accuracy: 0.9853 - val_loss: 0.7183 - val_accuracy: 0.8360\n","{'loss': [0.39787593483924866, 0.36360323429107666, 0.3437967300415039, 0.341694176197052, 0.33670422434806824, 0.3546822965145111, 0.34369951486587524, 0.3430749773979187, 0.3405342996120453, 0.3474953770637512, 0.3318776488304138, 0.3390921354293823, 0.32879120111465454, 0.325164258480072, 0.32706108689308167, 0.31482306122779846, 0.32238686084747314, 0.326034814119339, 0.3190422058105469, 0.3241525888442993, 0.32098472118377686, 0.3514103293418884, 0.30809876322746277, 0.31231728196144104, 0.3208281099796295, 0.30020251870155334, 0.31118181347846985, 0.3104649484157562, 0.31335899233818054, 0.34278011322021484, 0.3169460892677307, 0.30206912755966187, 0.30363547801971436, 0.30341410636901855, 0.30372241139411926, 0.29674002528190613, 0.3056095838546753, 0.29592806100845337, 0.293030709028244, 0.28879880905151367, 0.2879766523838043, 0.2919875681400299, 0.2960466146469116, 0.28950241208076477, 0.2985966205596924, 0.33777230978012085, 0.2821770906448364, 0.278484582901001, 0.2793501615524292, 0.27352476119995117, 0.28814420104026794, 0.27786388993263245, 0.27378639578819275, 0.272393137216568, 0.2780313193798065, 0.27646970748901367, 0.28452691435813904, 0.27197661995887756, 0.2706760764122009, 0.27227604389190674, 0.27279722690582275, 0.2659789025783539, 0.26353368163108826, 0.2887732684612274, 0.2665368616580963, 0.2788715660572052, 0.26390454173088074, 0.273815780878067, 0.2630234956741333, 0.2648341655731201, 0.2729444205760956, 0.2647152841091156, 0.2610262632369995, 0.254382848739624, 0.2474398910999298, 0.28344881534576416, 0.2652248442173004, 0.2538524568080902, 0.2840718924999237, 0.2503794729709625, 0.25165659189224243, 0.24616661667823792, 0.2551722228527069, 0.25934454798698425, 0.2528931200504303, 0.24591919779777527, 0.24704088270664215, 0.26432275772094727, 0.2658936083316803, 0.24642662703990936, 0.2575441002845764, 0.24815991520881653, 0.2361154705286026, 0.2366439700126648, 0.24685654044151306, 0.2650340497493744, 0.2448047250509262, 0.24989712238311768, 0.24499458074569702, 0.23395805060863495], 'accuracy': [0.9216185808181763, 0.9366157054901123, 0.9448217153549194, 0.9473684430122375, 0.950764000415802, 0.9400113224983215, 0.9473684430122375, 0.9445387721061707, 0.9459536075592041, 0.9411431550979614, 0.9516128897666931, 0.9485002756118774, 0.9504810571670532, 0.9538766145706177, 0.9592529535293579, 0.9589700102806091, 0.9552914500236511, 0.9496321678161621, 0.9538766145706177, 0.9510469436645508, 0.9527447819709778, 0.937747597694397, 0.9620826244354248, 0.9612337350845337, 0.9538766145706177, 0.963780403137207, 0.9598188996315002, 0.9575551748275757, 0.9569892287254333, 0.9357668161392212, 0.9558573961257935, 0.9643463492393494, 0.9598188996315002, 0.9615166783332825, 0.9609507918357849, 0.9646292924880981, 0.9584040641784668, 0.9649122953414917, 0.9663271307945251, 0.9677419066429138, 0.9685908555984497, 0.9683078527450562, 0.9649122953414917, 0.9677419066429138, 0.9632145166397095, 0.9422750473022461, 0.9728353023529053, 0.9722693562507629, 0.9742501378059387, 0.9717034697532654, 0.9663271307945251, 0.9708545804023743, 0.9725523591041565, 0.974816083908081, 0.9700056314468384, 0.971137523651123, 0.9683078527450562, 0.9734012484550476, 0.9734012484550476, 0.9728353023529053, 0.9736841917037964, 0.9770798087120056, 0.9742501378059387, 0.9584040641784668, 0.974816083908081, 0.9663271307945251, 0.9745330810546875, 0.9671760201454163, 0.9762309193611145, 0.9753820300102234, 0.9685908555984497, 0.9719864130020142, 0.9782116413116455, 0.9782116413116455, 0.9821732044219971, 0.9677419066429138, 0.9739671945571899, 0.979626476764679, 0.9629315137863159, 0.9801924228668213, 0.9782116413116455, 0.9824561476707458, 0.9779286980628967, 0.9736841917037964, 0.9810413122177124, 0.9838709831237793, 0.9824561476707458, 0.9731183052062988, 0.9714204668998718, 0.983305037021637, 0.974816083908081, 0.9807583689689636, 0.9878324866294861, 0.9858517050743103, 0.9799094796180725, 0.9714204668998718, 0.9810413122177124, 0.9742501378059387, 0.9807583689689636, 0.9852858185768127], 'val_loss': [1.0677565336227417, 1.0625869035720825, 1.0478595495224, 1.047073483467102, 1.0634700059890747, 1.062851071357727, 1.0926198959350586, 1.1466699838638306, 1.1293926239013672, 1.2384865283966064, 1.3784959316253662, 1.424243688583374, 1.4889813661575317, 1.4037023782730103, 1.4699383974075317, 1.3242197036743164, 1.269080638885498, 1.2895126342773438, 1.0238312482833862, 1.0118074417114258, 0.6655802726745605, 0.8032567501068115, 0.6089810729026794, 0.6513777375221252, 0.5907037854194641, 0.59112149477005, 0.600857675075531, 0.6110303997993469, 0.5776413679122925, 0.5864572525024414, 0.5891711115837097, 0.5801969766616821, 0.5773866176605225, 0.6513038277626038, 0.5989786386489868, 0.5932523012161255, 0.5976598858833313, 0.6120732426643372, 0.6220473647117615, 0.606587827205658, 0.6211919784545898, 0.6547017693519592, 0.6475649476051331, 0.608359158039093, 0.7721402049064636, 0.6470732688903809, 0.6044532656669617, 0.6291070580482483, 0.6495391726493835, 0.6208562254905701, 0.6418491005897522, 0.6167162656784058, 0.6129835247993469, 0.6700294613838196, 0.6622841358184814, 0.6661360263824463, 0.6951791048049927, 0.6280760765075684, 0.6301708817481995, 0.6895546317100525, 0.6657515168190002, 0.6661508083343506, 0.6582894921302795, 0.7043439149856567, 0.6744243502616882, 0.7779766321182251, 0.7271125316619873, 0.6626468896865845, 0.6730421185493469, 0.7108063101768494, 0.7169424891471863, 0.6525409817695618, 0.6823458671569824, 0.7549987435340881, 0.6881741881370544, 0.7036129236221313, 0.6896182894706726, 0.7120671272277832, 0.6886259317398071, 0.664122998714447, 0.6740610003471375, 0.6897481083869934, 0.6694449186325073, 0.6934841871261597, 0.6772711277008057, 0.7105869650840759, 0.6824538111686707, 0.683040976524353, 0.7099332213401794, 0.7191022634506226, 0.7031993865966797, 0.7049153447151184, 0.721282958984375, 0.7137929201126099, 0.9270580410957336, 0.7114976048469543, 0.7114167213439941, 0.6969771981239319, 0.708853542804718, 0.7183261513710022], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.5, 0.5090497732162476, 0.5067873597145081, 0.5045248866081238, 0.5067873597145081, 0.5147058963775635, 0.5339366793632507, 0.540723979473114, 0.581447958946228, 0.6052036285400391, 0.6131221652030945, 0.6674208045005798, 0.6843891143798828, 0.7918552160263062, 0.7466063499450684, 0.8393664956092834, 0.7997737526893616, 0.8529411554336548, 0.8461538553237915, 0.8382353186607361, 0.8348416090011597, 0.8574660420417786, 0.837104082107544, 0.8404977321624756, 0.8450226187705994, 0.8506787419319153, 0.8337104320526123, 0.8450226187705994, 0.8427602052688599, 0.8472850918769836, 0.8495475053787231, 0.8404977321624756, 0.8495475053787231, 0.8416289687156677, 0.8325791954994202, 0.8325791954994202, 0.8472850918769836, 0.8088235259056091, 0.837104082107544, 0.8382353186607361, 0.8382353186607361, 0.8325791954994202, 0.8472850918769836, 0.8461538553237915, 0.8404977321624756, 0.848416268825531, 0.831447958946228, 0.8348416090011597, 0.8359728455543518, 0.8269230723381042, 0.8438913822174072, 0.8438913822174072, 0.8269230723381042, 0.831447958946228, 0.8291855454444885, 0.8382353186607361, 0.8235294222831726, 0.831447958946228, 0.807692289352417, 0.8246606588363647, 0.8382353186607361, 0.8404977321624756, 0.8325791954994202, 0.8269230723381042, 0.8438913822174072, 0.8382353186607361, 0.8235294222831726, 0.8427602052688599, 0.8348416090011597, 0.8337104320526123, 0.8280543088912964, 0.8291855454444885, 0.8359728455543518, 0.8382353186607361, 0.8325791954994202, 0.8382353186607361, 0.837104082107544, 0.8337104320526123, 0.8303167223930359, 0.8416289687156677, 0.8348416090011597, 0.8269230723381042, 0.8348416090011597, 0.8337104320526123, 0.8246606588363647, 0.8190045356750488, 0.8257918357849121, 0.7997737526893616, 0.831447958946228, 0.8303167223930359, 0.8291855454444885, 0.8280543088912964, 0.8359728455543518]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.4458 - accuracy: 0.9071"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 7s 49ms/step - loss: 0.4455 - accuracy: 0.9072 - val_loss: 1.0816 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3855 - accuracy: 0.9233 - val_loss: 1.0779 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3820 - accuracy: 0.9233 - val_loss: 1.0578 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3710 - accuracy: 0.9336 - val_loss: 1.0530 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3804 - accuracy: 0.9289 - val_loss: 1.0843 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3642 - accuracy: 0.9359 - val_loss: 1.1200 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3603 - accuracy: 0.9370 - val_loss: 1.1440 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3663 - accuracy: 0.9328 - val_loss: 1.2401 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3595 - accuracy: 0.9364 - val_loss: 1.2480 - val_accuracy: 0.4917\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3590 - accuracy: 0.9328 - val_loss: 1.2847 - val_accuracy: 0.5000\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3683 - accuracy: 0.9341 - val_loss: 1.3859 - val_accuracy: 0.5021\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3611 - accuracy: 0.9388 - val_loss: 1.4836 - val_accuracy: 0.5031\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3549 - accuracy: 0.9401 - val_loss: 1.2900 - val_accuracy: 0.5269\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3615 - accuracy: 0.9377 - val_loss: 1.6462 - val_accuracy: 0.5155\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3482 - accuracy: 0.9413 - val_loss: 1.4252 - val_accuracy: 0.5331\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3714 - accuracy: 0.9266 - val_loss: 1.2407 - val_accuracy: 0.5816\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3627 - accuracy: 0.9331 - val_loss: 1.2181 - val_accuracy: 0.5961\n","Epoch 18/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3576 - accuracy: 0.9380 - val_loss: 1.1940 - val_accuracy: 0.6136\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3392 - accuracy: 0.9444 - val_loss: 1.0338 - val_accuracy: 0.6508\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3408 - accuracy: 0.9463 - val_loss: 0.7297 - val_accuracy: 0.7634\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3354 - accuracy: 0.9499 - val_loss: 0.6962 - val_accuracy: 0.8017\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3584 - accuracy: 0.9331 - val_loss: 0.6988 - val_accuracy: 0.7851\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3403 - accuracy: 0.9450 - val_loss: 0.6240 - val_accuracy: 0.8275\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3398 - accuracy: 0.9450 - val_loss: 0.6670 - val_accuracy: 0.8089\n","Epoch 25/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3336 - accuracy: 0.9481 - val_loss: 0.6348 - val_accuracy: 0.8357\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3551 - accuracy: 0.9346 - val_loss: 0.6245 - val_accuracy: 0.8285\n","Epoch 27/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3378 - accuracy: 0.9455 - val_loss: 0.6172 - val_accuracy: 0.8409\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3347 - accuracy: 0.9442 - val_loss: 0.6612 - val_accuracy: 0.8347\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3350 - accuracy: 0.9475 - val_loss: 0.6302 - val_accuracy: 0.8326\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3229 - accuracy: 0.9499 - val_loss: 0.6334 - val_accuracy: 0.8388\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3302 - accuracy: 0.9463 - val_loss: 0.6233 - val_accuracy: 0.8409\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3149 - accuracy: 0.9568 - val_loss: 0.6754 - val_accuracy: 0.8295\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3349 - accuracy: 0.9444 - val_loss: 0.6613 - val_accuracy: 0.8233\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3142 - accuracy: 0.9558 - val_loss: 0.6616 - val_accuracy: 0.8368\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3253 - accuracy: 0.9488 - val_loss: 0.6254 - val_accuracy: 0.8399\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3117 - accuracy: 0.9563 - val_loss: 0.6479 - val_accuracy: 0.8337\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3156 - accuracy: 0.9558 - val_loss: 0.6892 - val_accuracy: 0.8306\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3176 - accuracy: 0.9532 - val_loss: 0.6514 - val_accuracy: 0.8409\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3282 - accuracy: 0.9457 - val_loss: 0.7309 - val_accuracy: 0.8037\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3315 - accuracy: 0.9434 - val_loss: 0.6462 - val_accuracy: 0.8347\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3140 - accuracy: 0.9509 - val_loss: 0.6811 - val_accuracy: 0.8244\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3096 - accuracy: 0.9581 - val_loss: 0.6770 - val_accuracy: 0.8244\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3102 - accuracy: 0.9566 - val_loss: 0.7292 - val_accuracy: 0.8171\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3087 - accuracy: 0.9543 - val_loss: 0.6799 - val_accuracy: 0.8275\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3050 - accuracy: 0.9566 - val_loss: 0.6625 - val_accuracy: 0.8316\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3078 - accuracy: 0.9556 - val_loss: 0.6720 - val_accuracy: 0.8316\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3038 - accuracy: 0.9584 - val_loss: 0.6907 - val_accuracy: 0.8347\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2994 - accuracy: 0.9599 - val_loss: 0.6836 - val_accuracy: 0.8264\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2984 - accuracy: 0.9584 - val_loss: 0.6965 - val_accuracy: 0.8337\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3258 - accuracy: 0.9452 - val_loss: 0.7852 - val_accuracy: 0.8089\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3098 - accuracy: 0.9558 - val_loss: 0.7051 - val_accuracy: 0.8316\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3066 - accuracy: 0.9563 - val_loss: 0.6790 - val_accuracy: 0.8295\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3209 - accuracy: 0.9494 - val_loss: 0.6725 - val_accuracy: 0.8254\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2951 - accuracy: 0.9612 - val_loss: 0.7076 - val_accuracy: 0.8254\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3125 - accuracy: 0.9491 - val_loss: 0.7580 - val_accuracy: 0.8079\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3236 - accuracy: 0.9504 - val_loss: 0.8734 - val_accuracy: 0.7562\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3184 - accuracy: 0.9501 - val_loss: 0.6583 - val_accuracy: 0.8337\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2947 - accuracy: 0.9636 - val_loss: 0.6589 - val_accuracy: 0.8388\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2887 - accuracy: 0.9643 - val_loss: 0.6972 - val_accuracy: 0.8316\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2964 - accuracy: 0.9584 - val_loss: 0.6814 - val_accuracy: 0.8295\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2999 - accuracy: 0.9599 - val_loss: 0.7226 - val_accuracy: 0.8213\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2914 - accuracy: 0.9643 - val_loss: 0.6898 - val_accuracy: 0.8285\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2903 - accuracy: 0.9636 - val_loss: 0.7136 - val_accuracy: 0.8316\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2824 - accuracy: 0.9693 - val_loss: 0.7016 - val_accuracy: 0.8306\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2856 - accuracy: 0.9656 - val_loss: 0.7696 - val_accuracy: 0.8213\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2943 - accuracy: 0.9594 - val_loss: 0.6981 - val_accuracy: 0.8306\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2811 - accuracy: 0.9677 - val_loss: 0.6879 - val_accuracy: 0.8264\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2883 - accuracy: 0.9625 - val_loss: 0.8662 - val_accuracy: 0.7924\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3037 - accuracy: 0.9540 - val_loss: 0.7092 - val_accuracy: 0.8254\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2807 - accuracy: 0.9667 - val_loss: 0.7164 - val_accuracy: 0.8347\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2796 - accuracy: 0.9633 - val_loss: 0.6935 - val_accuracy: 0.8368\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2759 - accuracy: 0.9680 - val_loss: 0.8158 - val_accuracy: 0.8058\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2804 - accuracy: 0.9661 - val_loss: 0.8303 - val_accuracy: 0.7872\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2749 - accuracy: 0.9718 - val_loss: 0.7299 - val_accuracy: 0.8337\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2809 - accuracy: 0.9612 - val_loss: 0.7448 - val_accuracy: 0.8264\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.9703 - val_loss: 0.8344 - val_accuracy: 0.7872\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3022 - accuracy: 0.9532 - val_loss: 0.7219 - val_accuracy: 0.8285\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2849 - accuracy: 0.9620 - val_loss: 0.7282 - val_accuracy: 0.8264\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2828 - accuracy: 0.9690 - val_loss: 0.7340 - val_accuracy: 0.8192\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2914 - accuracy: 0.9592 - val_loss: 0.7556 - val_accuracy: 0.8213\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2728 - accuracy: 0.9682 - val_loss: 0.7151 - val_accuracy: 0.8316\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2798 - accuracy: 0.9659 - val_loss: 0.7417 - val_accuracy: 0.8213\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2750 - accuracy: 0.9687 - val_loss: 0.7167 - val_accuracy: 0.8275\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2808 - accuracy: 0.9612 - val_loss: 0.7780 - val_accuracy: 0.8130\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2747 - accuracy: 0.9695 - val_loss: 0.7128 - val_accuracy: 0.8202\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2767 - accuracy: 0.9646 - val_loss: 0.7284 - val_accuracy: 0.8275\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2739 - accuracy: 0.9664 - val_loss: 0.7587 - val_accuracy: 0.8254\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2632 - accuracy: 0.9731 - val_loss: 0.7433 - val_accuracy: 0.8295\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2599 - accuracy: 0.9780 - val_loss: 0.7493 - val_accuracy: 0.8254\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2612 - accuracy: 0.9705 - val_loss: 0.7849 - val_accuracy: 0.8110\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2722 - accuracy: 0.9674 - val_loss: 0.7997 - val_accuracy: 0.8233\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2691 - accuracy: 0.9667 - val_loss: 0.7515 - val_accuracy: 0.8285\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2606 - accuracy: 0.9718 - val_loss: 0.7863 - val_accuracy: 0.8285\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2587 - accuracy: 0.9747 - val_loss: 0.7774 - val_accuracy: 0.8264\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2636 - accuracy: 0.9729 - val_loss: 0.7986 - val_accuracy: 0.8244\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2607 - accuracy: 0.9711 - val_loss: 0.8317 - val_accuracy: 0.8202\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2618 - accuracy: 0.9724 - val_loss: 0.7429 - val_accuracy: 0.8244\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2564 - accuracy: 0.9742 - val_loss: 0.7888 - val_accuracy: 0.8233\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2764 - accuracy: 0.9661 - val_loss: 0.7669 - val_accuracy: 0.8316\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2577 - accuracy: 0.9742 - val_loss: 0.7503 - val_accuracy: 0.8244\n","{'loss': [0.44551098346710205, 0.38552922010421753, 0.38195207715034485, 0.37098824977874756, 0.38044193387031555, 0.3641667366027832, 0.3603065311908722, 0.3663328289985657, 0.3594740927219391, 0.35895416140556335, 0.3683329224586487, 0.3611047565937042, 0.354892760515213, 0.3615211248397827, 0.3482062518596649, 0.3714211881160736, 0.36268681287765503, 0.35761749744415283, 0.33916857838630676, 0.34077951312065125, 0.33536937832832336, 0.3584391474723816, 0.340316504240036, 0.3397987186908722, 0.33356085419654846, 0.35509344935417175, 0.3378054201602936, 0.3346869647502899, 0.33500635623931885, 0.32285627722740173, 0.3301684260368347, 0.314939022064209, 0.33492329716682434, 0.31422343850135803, 0.32534080743789673, 0.3117049038410187, 0.31561538577079773, 0.31756216287612915, 0.32823458313941956, 0.33149009943008423, 0.3140043020248413, 0.309574156999588, 0.3101874589920044, 0.3086812496185303, 0.3050079643726349, 0.30782976746559143, 0.30384376645088196, 0.2994498014450073, 0.2984068989753723, 0.325779527425766, 0.30984678864479065, 0.3065722584724426, 0.3208702802658081, 0.2951129078865051, 0.3124980330467224, 0.32358407974243164, 0.3183536231517792, 0.2946581542491913, 0.2886522114276886, 0.29641520977020264, 0.29989737272262573, 0.29144731163978577, 0.290304034948349, 0.28238192200660706, 0.28564807772636414, 0.29434752464294434, 0.2810962200164795, 0.2883148789405823, 0.30365052819252014, 0.2807159721851349, 0.2795751392841339, 0.27585798501968384, 0.2804078459739685, 0.2749362885951996, 0.280900776386261, 0.27230915427207947, 0.3022323548793793, 0.28487899899482727, 0.2828400433063507, 0.2913586497306824, 0.2728140652179718, 0.27982062101364136, 0.2749784588813782, 0.28079482913017273, 0.274705171585083, 0.27669310569763184, 0.2738911509513855, 0.2631876766681671, 0.25986939668655396, 0.2612416744232178, 0.2721518874168396, 0.2691391706466675, 0.2605716288089752, 0.25868237018585205, 0.263638973236084, 0.26074814796447754, 0.26183584332466125, 0.2563507556915283, 0.27641761302948, 0.2577417492866516], 'accuracy': [0.9072351455688477, 0.9232558012008667, 0.9232558012008667, 0.9335917234420776, 0.9289405941963196, 0.935917317867279, 0.9369509220123291, 0.9328165650367737, 0.9364340901374817, 0.9328165650367737, 0.934108555316925, 0.9387596845626831, 0.9400516748428345, 0.9377260804176331, 0.9413436651229858, 0.9266149997711182, 0.933074951171875, 0.9379844665527344, 0.9444444179534912, 0.94625324010849, 0.9498708248138428, 0.933074951171875, 0.9449612498283386, 0.9449612498283386, 0.948062002658844, 0.9346253275871277, 0.9454780220985413, 0.9441860318183899, 0.9475452303886414, 0.9498708248138428, 0.94625324010849, 0.9568475484848022, 0.9444444179534912, 0.9558139443397522, 0.9488372206687927, 0.9563307762145996, 0.9558139443397522, 0.9532299637794495, 0.9457364082336426, 0.9434108734130859, 0.950904369354248, 0.9581395387649536, 0.9565891623497009, 0.9542635679244995, 0.9565891623497009, 0.9555555582046509, 0.9583979249000549, 0.9599483013153076, 0.9583979249000549, 0.9452196359634399, 0.9558139443397522, 0.9563307762145996, 0.9493539929389954, 0.961240291595459, 0.949095606803894, 0.9503875970840454, 0.9501292109489441, 0.9635658860206604, 0.9643411040306091, 0.9583979249000549, 0.9599483013153076, 0.9643411040306091, 0.9635658860206604, 0.9692506194114685, 0.9656330943107605, 0.959431529045105, 0.9677002429962158, 0.9625322818756104, 0.9540051817893982, 0.9666666388511658, 0.9633074998855591, 0.9679586291313171, 0.9661498665809631, 0.9718345999717712, 0.961240291595459, 0.9702842235565186, 0.9532299637794495, 0.9620155096054077, 0.9689922332763672, 0.9591731429100037, 0.9682170748710632, 0.9658914804458618, 0.9687338471412659, 0.961240291595459, 0.9695090651512146, 0.9645994901657104, 0.9664082527160645, 0.9731265902519226, 0.9780361652374268, 0.9705426096916199, 0.9674418568611145, 0.9666666388511658, 0.9718345999717712, 0.9746770262718201, 0.9728682041168213, 0.9710594415664673, 0.9723514318466187, 0.9741601943969727, 0.9661498665809631, 0.9741601943969727], 'val_loss': [1.0816295146942139, 1.0779188871383667, 1.0578303337097168, 1.053032398223877, 1.0842739343643188, 1.119982123374939, 1.1439954042434692, 1.2400858402252197, 1.247992753982544, 1.2846839427947998, 1.3859214782714844, 1.4835741519927979, 1.2899754047393799, 1.6461524963378906, 1.4251710176467896, 1.2406694889068604, 1.218146562576294, 1.194007396697998, 1.03377366065979, 0.7296689748764038, 0.6961890459060669, 0.6987884640693665, 0.6240060925483704, 0.6670433282852173, 0.6347737312316895, 0.6244838237762451, 0.617173433303833, 0.6612458229064941, 0.6301783323287964, 0.633449912071228, 0.6233260631561279, 0.6754037141799927, 0.6613454818725586, 0.6616191267967224, 0.6253848075866699, 0.6479431390762329, 0.689174473285675, 0.6514073610305786, 0.7309485673904419, 0.6461921334266663, 0.6811405420303345, 0.6770377159118652, 0.729163408279419, 0.6798694133758545, 0.6625458002090454, 0.6720250248908997, 0.6906630992889404, 0.6835716962814331, 0.6965152621269226, 0.7851704955101013, 0.7050989866256714, 0.678978681564331, 0.6724593639373779, 0.707610011100769, 0.7579665184020996, 0.873369574546814, 0.6582524180412292, 0.6588893532752991, 0.6971550583839417, 0.6813953518867493, 0.7225562930107117, 0.6898215413093567, 0.7135570049285889, 0.7016078233718872, 0.7696245908737183, 0.69810551404953, 0.687885582447052, 0.8661634922027588, 0.7092104554176331, 0.7163969278335571, 0.693513035774231, 0.8157690167427063, 0.8303351402282715, 0.7299063205718994, 0.7448155879974365, 0.8344444632530212, 0.7218504548072815, 0.7282105088233948, 0.7340020537376404, 0.7555782794952393, 0.7151038646697998, 0.7416737675666809, 0.7166939377784729, 0.7779691219329834, 0.7128476500511169, 0.728374183177948, 0.7586515545845032, 0.7433094382286072, 0.7493101358413696, 0.7849377989768982, 0.7996827363967896, 0.7515087127685547, 0.7862862944602966, 0.7774233222007751, 0.7986051440238953, 0.8316774368286133, 0.7429110407829285, 0.788816511631012, 0.7668739557266235, 0.750267744064331], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.4917355477809906, 0.5, 0.5020661354064941, 0.5030992031097412, 0.5268595218658447, 0.5154958963394165, 0.5330578684806824, 0.5816115736961365, 0.5960744023323059, 0.6136363744735718, 0.6508264541625977, 0.7634297609329224, 0.8016529083251953, 0.7851239442825317, 0.827479362487793, 0.80888432264328, 0.83574378490448, 0.8285123705863953, 0.8409090638160706, 0.8347107172012329, 0.8326446413993835, 0.8388429880142212, 0.8409090638160706, 0.8295454382896423, 0.8233470916748047, 0.836776852607727, 0.8398760557174683, 0.8336777091026306, 0.8305785059928894, 0.8409090638160706, 0.8037189841270447, 0.8347107172012329, 0.8243801593780518, 0.8243801593780518, 0.817148745059967, 0.827479362487793, 0.8316115736961365, 0.8316115736961365, 0.8347107172012329, 0.8264462947845459, 0.8336777091026306, 0.80888432264328, 0.8316115736961365, 0.8295454382896423, 0.8254132270812988, 0.8254132270812988, 0.807851254940033, 0.7561983466148376, 0.8336777091026306, 0.8388429880142212, 0.8316115736961365, 0.8295454382896423, 0.8212810158729553, 0.8285123705863953, 0.8316115736961365, 0.8305785059928894, 0.8212810158729553, 0.8305785059928894, 0.8264462947845459, 0.7923553586006165, 0.8254132270812988, 0.8347107172012329, 0.836776852607727, 0.8057851195335388, 0.7871900796890259, 0.8336777091026306, 0.8264462947845459, 0.7871900796890259, 0.8285123705863953, 0.8264462947845459, 0.8192148804664612, 0.8212810158729553, 0.8316115736961365, 0.8212810158729553, 0.827479362487793, 0.8130165338516235, 0.8202479481697083, 0.827479362487793, 0.8254132270812988, 0.8295454382896423, 0.8254132270812988, 0.8109503984451294, 0.8233470916748047, 0.8285123705863953, 0.8285123705863953, 0.8264462947845459, 0.8243801593780518, 0.8202479481697083, 0.8243801593780518, 0.8233470916748047, 0.8316115736961365, 0.8243801593780518]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"kleLoWSV5B7Y","executionInfo":{"status":"ok","timestamp":1717500987927,"user_tz":-360,"elapsed":5,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"d5872257-a02e-4e93-9cb3-dc2ab0762143"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.654104   0.654362  0.653266  0.653814     0.653266     0.654941   \n","1        1  0.706921   0.723664  0.669492  0.695525     0.669492     0.744350   \n","2        2  0.646586   0.638258  0.676707  0.656920     0.676707     0.616466   \n","3        0  0.692630   0.689769  0.700168  0.694929     0.700168     0.685092   \n","4        1  0.728107   0.761750  0.663842  0.709434     0.663842     0.792373   \n","5        2  0.703815   0.706721  0.696787  0.701719     0.696787     0.710843   \n","6        0  0.731156   0.726230  0.742044  0.734051     0.742044     0.720268   \n","7        1  0.761299   0.782875  0.723164  0.751836     0.723164     0.799435   \n","8        2  0.729920   0.722330  0.746988  0.734452     0.746988     0.712851   \n","9        0  0.763819   0.768313  0.755444  0.761824     0.755444     0.772194   \n","10       1  0.783898   0.768717  0.812147  0.789835     0.812147     0.755650   \n","11       2  0.789157   0.755319  0.855422  0.802260     0.855422     0.722892   \n","12       0  0.801508   0.786624  0.827471  0.806531     0.827471     0.775544   \n","13       1  0.805085   0.768657  0.872881  0.817460     0.872881     0.737288   \n","14       2  0.836345   0.807339  0.883534  0.843720     0.883534     0.789157   \n","\n","       Kappa  \n","0   0.308208  \n","1   0.413842  \n","2   0.293173  \n","3   0.385260  \n","4   0.456215  \n","5   0.407631  \n","6   0.462312  \n","7   0.522599  \n","8   0.459839  \n","9   0.527638  \n","10  0.567797  \n","11  0.578313  \n","12  0.603015  \n","13  0.610169  \n","14  0.672691  "],"text/html":["\n","  <div id=\"df-457e8f7f-5687-43c2-aae7-99e4c42fb625\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.654104</td>\n","      <td>0.654362</td>\n","      <td>0.653266</td>\n","      <td>0.653814</td>\n","      <td>0.653266</td>\n","      <td>0.654941</td>\n","      <td>0.308208</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.706921</td>\n","      <td>0.723664</td>\n","      <td>0.669492</td>\n","      <td>0.695525</td>\n","      <td>0.669492</td>\n","      <td>0.744350</td>\n","      <td>0.413842</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.646586</td>\n","      <td>0.638258</td>\n","      <td>0.676707</td>\n","      <td>0.656920</td>\n","      <td>0.676707</td>\n","      <td>0.616466</td>\n","      <td>0.293173</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.692630</td>\n","      <td>0.689769</td>\n","      <td>0.700168</td>\n","      <td>0.694929</td>\n","      <td>0.700168</td>\n","      <td>0.685092</td>\n","      <td>0.385260</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.728107</td>\n","      <td>0.761750</td>\n","      <td>0.663842</td>\n","      <td>0.709434</td>\n","      <td>0.663842</td>\n","      <td>0.792373</td>\n","      <td>0.456215</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.703815</td>\n","      <td>0.706721</td>\n","      <td>0.696787</td>\n","      <td>0.701719</td>\n","      <td>0.696787</td>\n","      <td>0.710843</td>\n","      <td>0.407631</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.731156</td>\n","      <td>0.726230</td>\n","      <td>0.742044</td>\n","      <td>0.734051</td>\n","      <td>0.742044</td>\n","      <td>0.720268</td>\n","      <td>0.462312</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.761299</td>\n","      <td>0.782875</td>\n","      <td>0.723164</td>\n","      <td>0.751836</td>\n","      <td>0.723164</td>\n","      <td>0.799435</td>\n","      <td>0.522599</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.729920</td>\n","      <td>0.722330</td>\n","      <td>0.746988</td>\n","      <td>0.734452</td>\n","      <td>0.746988</td>\n","      <td>0.712851</td>\n","      <td>0.459839</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.763819</td>\n","      <td>0.768313</td>\n","      <td>0.755444</td>\n","      <td>0.761824</td>\n","      <td>0.755444</td>\n","      <td>0.772194</td>\n","      <td>0.527638</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.783898</td>\n","      <td>0.768717</td>\n","      <td>0.812147</td>\n","      <td>0.789835</td>\n","      <td>0.812147</td>\n","      <td>0.755650</td>\n","      <td>0.567797</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.789157</td>\n","      <td>0.755319</td>\n","      <td>0.855422</td>\n","      <td>0.802260</td>\n","      <td>0.855422</td>\n","      <td>0.722892</td>\n","      <td>0.578313</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.801508</td>\n","      <td>0.786624</td>\n","      <td>0.827471</td>\n","      <td>0.806531</td>\n","      <td>0.827471</td>\n","      <td>0.775544</td>\n","      <td>0.603015</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.805085</td>\n","      <td>0.768657</td>\n","      <td>0.872881</td>\n","      <td>0.817460</td>\n","      <td>0.872881</td>\n","      <td>0.737288</td>\n","      <td>0.610169</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.836345</td>\n","      <td>0.807339</td>\n","      <td>0.883534</td>\n","      <td>0.843720</td>\n","      <td>0.883534</td>\n","      <td>0.789157</td>\n","      <td>0.672691</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-457e8f7f-5687-43c2-aae7-99e4c42fb625')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-457e8f7f-5687-43c2-aae7-99e4c42fb625 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-457e8f7f-5687-43c2-aae7-99e4c42fb625');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d8244f2a-c34e-420f-91a1-3fcfee0b5ace\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8244f2a-c34e-420f-91a1-3fcfee0b5ace')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d8244f2a-c34e-420f-91a1-3fcfee0b5ace button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05584445611271885,\n        \"min\": 0.6465863453815262,\n        \"max\": 0.8363453815261044,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7638190954773869,\n          0.7891566265060241,\n          0.6541038525963149\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04905158607064235,\n        \"min\": 0.6382575757575758,\n        \"max\": 0.8073394495412844,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.768313458262351,\n          0.7553191489361702,\n          0.6543624161073825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07956248168898655,\n        \"min\": 0.6532663316582915,\n        \"max\": 0.8835341365461847,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7554438860971524,\n          0.8554216867469879,\n          0.6532663316582915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05902147313887529,\n        \"min\": 0.6538139145012574,\n        \"max\": 0.8437200383509109,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7618243243243243,\n          0.8022598870056499,\n          0.6538139145012574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07956248168898655,\n        \"min\": 0.6532663316582915,\n        \"max\": 0.8835341365461847,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7554438860971524,\n          0.8554216867469879,\n          0.6532663316582915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05225371931826682,\n        \"min\": 0.6164658634538153,\n        \"max\": 0.7994350282485876,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7721943048576214,\n          0.7228915662650602,\n          0.6549413735343383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11168891222543768,\n        \"min\": 0.2931726907630522,\n        \"max\": 0.6726907630522088,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5276381909547738,\n          0.5783132530120482,\n          0.30820770519262985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_GRU/Beta_time_GRU.csv', index = False)"],"metadata":{"id":"QWSx6aHR5Bwr","executionInfo":{"status":"ok","timestamp":1717500987928,"user_tz":-360,"elapsed":4,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JOIXJgmr5vGB"},"execution_count":null,"outputs":[]}]}