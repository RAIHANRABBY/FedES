{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717499185018,"user_tz":-360,"elapsed":3082,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717499185792,"user_tz":-360,"elapsed":779,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717499190285,"user_tz":-360,"elapsed":4497,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717499196538,"user_tz":-360,"elapsed":6259,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19340,"status":"ok","timestamp":1717499215867,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"ceaac16d-0f3b-4f84-ca6d-a14a7a946e35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717499215868,"user_tz":-360,"elapsed":14,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time domain /RAW/Delta_time.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"DxRGNAi96nxx","executionInfo":{"status":"ok","timestamp":1717499221930,"user_tz":-360,"elapsed":6073,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"VvjC2xCQNHLP","executionInfo":{"status":"ok","timestamp":1717499496973,"user_tz":-360,"elapsed":525,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Delta/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Delta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","executionInfo":{"status":"ok","timestamp":1717500572761,"user_tz":-360,"elapsed":40846,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"09914b55-a14c-4351-9bfb-a9b731481d43"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.4064 - accuracy: 0.5026"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 9s 54ms/step - loss: 1.4043 - accuracy: 0.5048 - val_loss: 1.3741 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3476 - accuracy: 0.4822 - val_loss: 1.3191 - val_accuracy: 0.5151\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2943 - accuracy: 0.5011 - val_loss: 1.2685 - val_accuracy: 0.4741\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2452 - accuracy: 0.5054 - val_loss: 1.2216 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2002 - accuracy: 0.5119 - val_loss: 1.1783 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1577 - accuracy: 0.5186 - val_loss: 1.1381 - val_accuracy: 0.5162\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1172 - accuracy: 0.5450 - val_loss: 1.1015 - val_accuracy: 0.4989\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0798 - accuracy: 0.5517 - val_loss: 1.0669 - val_accuracy: 0.5636\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0431 - accuracy: 0.5722 - val_loss: 1.0398 - val_accuracy: 0.4806\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0076 - accuracy: 0.5830 - val_loss: 1.0089 - val_accuracy: 0.5172\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9662 - accuracy: 0.6115 - val_loss: 0.9802 - val_accuracy: 0.5862\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9268 - accuracy: 0.6325 - val_loss: 0.9582 - val_accuracy: 0.5517\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8886 - accuracy: 0.6614 - val_loss: 0.9350 - val_accuracy: 0.5938\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8451 - accuracy: 0.6783 - val_loss: 0.9219 - val_accuracy: 0.5334\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8009 - accuracy: 0.6980 - val_loss: 0.9057 - val_accuracy: 0.5312\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7460 - accuracy: 0.7284 - val_loss: 0.8913 - val_accuracy: 0.5603\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6909 - accuracy: 0.7613 - val_loss: 0.8950 - val_accuracy: 0.5226\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6661 - accuracy: 0.7635 - val_loss: 0.8765 - val_accuracy: 0.5571\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6135 - accuracy: 0.7923 - val_loss: 0.9152 - val_accuracy: 0.5291\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5860 - accuracy: 0.7971 - val_loss: 0.9061 - val_accuracy: 0.5399\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5267 - accuracy: 0.8300 - val_loss: 1.0019 - val_accuracy: 0.5323\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4807 - accuracy: 0.8491 - val_loss: 1.0605 - val_accuracy: 0.5496\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4370 - accuracy: 0.8656 - val_loss: 1.0671 - val_accuracy: 0.5625\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3889 - accuracy: 0.8866 - val_loss: 1.2886 - val_accuracy: 0.5668\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3615 - accuracy: 0.8949 - val_loss: 1.4034 - val_accuracy: 0.5496\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3536 - accuracy: 0.8976 - val_loss: 1.3386 - val_accuracy: 0.5722\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3096 - accuracy: 0.9162 - val_loss: 1.6343 - val_accuracy: 0.5603\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2890 - accuracy: 0.9195 - val_loss: 1.7414 - val_accuracy: 0.5862\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2882 - accuracy: 0.9203 - val_loss: 1.8334 - val_accuracy: 0.5700\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2525 - accuracy: 0.9351 - val_loss: 1.9927 - val_accuracy: 0.5657\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2511 - accuracy: 0.9329 - val_loss: 2.5094 - val_accuracy: 0.5259\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3376 - accuracy: 0.8963 - val_loss: 1.5892 - val_accuracy: 0.5765\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2308 - accuracy: 0.9375 - val_loss: 2.1100 - val_accuracy: 0.5754\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2226 - accuracy: 0.9402 - val_loss: 2.1609 - val_accuracy: 0.5787\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2043 - accuracy: 0.9456 - val_loss: 2.2562 - val_accuracy: 0.5700\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1732 - accuracy: 0.9642 - val_loss: 2.6795 - val_accuracy: 0.5636\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1812 - accuracy: 0.9582 - val_loss: 2.4675 - val_accuracy: 0.5711\n","Epoch 38/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1769 - accuracy: 0.9574 - val_loss: 2.4566 - val_accuracy: 0.5711\n","Epoch 39/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.1773 - accuracy: 0.9591 - val_loss: 2.3738 - val_accuracy: 0.5830\n","Epoch 40/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1785 - accuracy: 0.9558 - val_loss: 2.4657 - val_accuracy: 0.5744\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2023 - accuracy: 0.9434 - val_loss: 2.4540 - val_accuracy: 0.5690\n","Epoch 42/100\n","29/29 [==============================] - 2s 53ms/step - loss: 0.1694 - accuracy: 0.9582 - val_loss: 2.3684 - val_accuracy: 0.5970\n","Epoch 43/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1636 - accuracy: 0.9607 - val_loss: 2.5558 - val_accuracy: 0.5776\n","Epoch 44/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1553 - accuracy: 0.9634 - val_loss: 2.6141 - val_accuracy: 0.5506\n","Epoch 45/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1487 - accuracy: 0.9615 - val_loss: 2.5605 - val_accuracy: 0.5690\n","Epoch 46/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1257 - accuracy: 0.9768 - val_loss: 2.7415 - val_accuracy: 0.5797\n","Epoch 47/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1330 - accuracy: 0.9679 - val_loss: 2.7825 - val_accuracy: 0.5884\n","Epoch 48/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1170 - accuracy: 0.9787 - val_loss: 3.0335 - val_accuracy: 0.5679\n","Epoch 49/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1393 - accuracy: 0.9663 - val_loss: 2.8510 - val_accuracy: 0.5744\n","Epoch 50/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1487 - accuracy: 0.9626 - val_loss: 2.5900 - val_accuracy: 0.5733\n","Epoch 51/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1374 - accuracy: 0.9647 - val_loss: 2.6237 - val_accuracy: 0.5841\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1360 - accuracy: 0.9685 - val_loss: 2.7042 - val_accuracy: 0.5733\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1222 - accuracy: 0.9717 - val_loss: 3.0717 - val_accuracy: 0.5172\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1294 - accuracy: 0.9674 - val_loss: 2.9574 - val_accuracy: 0.5453\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1719 - accuracy: 0.9523 - val_loss: 3.0648 - val_accuracy: 0.5205\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1728 - accuracy: 0.9494 - val_loss: 2.2296 - val_accuracy: 0.5722\n","Epoch 57/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1181 - accuracy: 0.9749 - val_loss: 2.6107 - val_accuracy: 0.5528\n","Epoch 58/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1060 - accuracy: 0.9787 - val_loss: 2.8471 - val_accuracy: 0.5647\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0947 - accuracy: 0.9825 - val_loss: 2.7985 - val_accuracy: 0.5765\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0899 - accuracy: 0.9841 - val_loss: 3.0342 - val_accuracy: 0.5657\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0865 - accuracy: 0.9841 - val_loss: 3.1184 - val_accuracy: 0.5528\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0850 - accuracy: 0.9852 - val_loss: 3.1445 - val_accuracy: 0.5636\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0803 - accuracy: 0.9871 - val_loss: 3.2209 - val_accuracy: 0.5668\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0781 - accuracy: 0.9876 - val_loss: 3.2403 - val_accuracy: 0.5776\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1037 - accuracy: 0.9760 - val_loss: 3.6647 - val_accuracy: 0.5366\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1615 - accuracy: 0.9518 - val_loss: 2.2484 - val_accuracy: 0.5722\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1201 - accuracy: 0.9720 - val_loss: 2.3713 - val_accuracy: 0.5679\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0871 - accuracy: 0.9828 - val_loss: 2.7564 - val_accuracy: 0.5690\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0838 - accuracy: 0.9817 - val_loss: 2.8720 - val_accuracy: 0.5722\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0877 - accuracy: 0.9811 - val_loss: 2.7854 - val_accuracy: 0.5830\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0755 - accuracy: 0.9868 - val_loss: 3.0042 - val_accuracy: 0.5787\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0728 - accuracy: 0.9857 - val_loss: 3.0083 - val_accuracy: 0.5765\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0743 - accuracy: 0.9873 - val_loss: 2.9066 - val_accuracy: 0.5905\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0710 - accuracy: 0.9895 - val_loss: 3.3120 - val_accuracy: 0.5582\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0795 - accuracy: 0.9817 - val_loss: 2.8880 - val_accuracy: 0.5744\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0772 - accuracy: 0.9863 - val_loss: 2.9683 - val_accuracy: 0.5711\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0731 - accuracy: 0.9868 - val_loss: 3.2021 - val_accuracy: 0.5700\n","Epoch 78/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0742 - accuracy: 0.9857 - val_loss: 3.0011 - val_accuracy: 0.5808\n","Epoch 79/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1080 - accuracy: 0.9739 - val_loss: 2.7055 - val_accuracy: 0.5787\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1485 - accuracy: 0.9604 - val_loss: 2.5431 - val_accuracy: 0.5550\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1090 - accuracy: 0.9739 - val_loss: 2.2134 - val_accuracy: 0.5722\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0725 - accuracy: 0.9876 - val_loss: 2.5603 - val_accuracy: 0.5787\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.9922 - val_loss: 2.8104 - val_accuracy: 0.5765\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0641 - accuracy: 0.9879 - val_loss: 2.9998 - val_accuracy: 0.5636\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0618 - accuracy: 0.9906 - val_loss: 2.8685 - val_accuracy: 0.5819\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0657 - accuracy: 0.9879 - val_loss: 2.8345 - val_accuracy: 0.5776\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9825 - val_loss: 2.9016 - val_accuracy: 0.5700\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0704 - accuracy: 0.9844 - val_loss: 2.7769 - val_accuracy: 0.5603\n","Epoch 89/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0677 - accuracy: 0.9860 - val_loss: 2.8950 - val_accuracy: 0.5679\n","Epoch 90/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0625 - accuracy: 0.9898 - val_loss: 3.0667 - val_accuracy: 0.5657\n","Epoch 91/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0583 - accuracy: 0.9903 - val_loss: 3.1119 - val_accuracy: 0.5668\n","Epoch 92/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0661 - accuracy: 0.9871 - val_loss: 3.0128 - val_accuracy: 0.5668\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0791 - accuracy: 0.9811 - val_loss: 2.9142 - val_accuracy: 0.5603\n","Epoch 94/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1086 - accuracy: 0.9733 - val_loss: 2.5516 - val_accuracy: 0.5668\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0819 - accuracy: 0.9798 - val_loss: 2.5144 - val_accuracy: 0.5733\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0665 - accuracy: 0.9881 - val_loss: 2.7103 - val_accuracy: 0.5733\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9868 - val_loss: 2.8203 - val_accuracy: 0.5636\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0654 - accuracy: 0.9876 - val_loss: 2.8200 - val_accuracy: 0.5700\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0584 - accuracy: 0.9884 - val_loss: 2.9559 - val_accuracy: 0.5517\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 0.9908 - val_loss: 3.0309 - val_accuracy: 0.5765\n","{'loss': [1.4043174982070923, 1.3475558757781982, 1.2943472862243652, 1.2452248334884644, 1.2001811265945435, 1.1577332019805908, 1.1172473430633545, 1.07975172996521, 1.0430635213851929, 1.0076180696487427, 0.9661941528320312, 0.9268344640731812, 0.8886356949806213, 0.8451377153396606, 0.8009418249130249, 0.7459873557090759, 0.6909112334251404, 0.6660920977592468, 0.6134887933731079, 0.5859516263008118, 0.5267196297645569, 0.48069703578948975, 0.43703678250312805, 0.38893625140190125, 0.3615255653858185, 0.3535689413547516, 0.3096393644809723, 0.28901228308677673, 0.28823718428611755, 0.25254204869270325, 0.251106321811676, 0.33761948347091675, 0.2307777851819992, 0.22260412573814392, 0.2042912095785141, 0.17320512235164642, 0.18118304014205933, 0.17692126333713531, 0.17728865146636963, 0.17849785089492798, 0.2022676318883896, 0.16941963136196136, 0.163615882396698, 0.15533944964408875, 0.14873704314231873, 0.12567177414894104, 0.13304348289966583, 0.11702274531126022, 0.13928236067295074, 0.14871272444725037, 0.13737431168556213, 0.13603948056697845, 0.12219642847776413, 0.12939800322055817, 0.17190276086330414, 0.17279070615768433, 0.11808137595653534, 0.10603848844766617, 0.094664067029953, 0.08986841887235641, 0.08653886616230011, 0.08501657843589783, 0.08029597997665405, 0.0781303346157074, 0.10367850959300995, 0.16145336627960205, 0.12010692805051804, 0.08711311966180801, 0.08380169421434402, 0.08769946545362473, 0.0754786878824234, 0.07279212772846222, 0.07431533187627792, 0.0710069015622139, 0.07949448376893997, 0.0771883875131607, 0.07314623147249222, 0.07416962832212448, 0.10795743763446808, 0.14845462143421173, 0.1090129166841507, 0.07254910469055176, 0.059664200991392136, 0.06409105658531189, 0.0617704838514328, 0.06569817662239075, 0.07425003498792648, 0.0704374611377716, 0.0676850825548172, 0.06246419623494148, 0.05828428640961647, 0.06613627076148987, 0.0791396051645279, 0.10856230556964874, 0.0818517729640007, 0.0665336474776268, 0.0631851777434349, 0.06541219353675842, 0.05841119587421417, 0.05756567418575287], 'accuracy': [0.5048491358757019, 0.4822198152542114, 0.5010775923728943, 0.5053879022598267, 0.5118534564971924, 0.5185883641242981, 0.5449892282485962, 0.5517241358757019, 0.5721982717514038, 0.5829741358757019, 0.6115301847457886, 0.6325430870056152, 0.6613685488700867, 0.678340494632721, 0.6980064511299133, 0.7284482717514038, 0.7613146305084229, 0.7634698152542114, 0.7922952771186829, 0.7971444129943848, 0.8300107717514038, 0.8491379022598267, 0.865571141242981, 0.8865840435028076, 0.8949353694915771, 0.8976293206214905, 0.9162176847457886, 0.9194504022598267, 0.920258641242981, 0.9350754022598267, 0.9329202771186829, 0.8962823152542114, 0.9375, 0.9401939511299133, 0.9455819129943848, 0.9641702771186829, 0.9582435488700867, 0.9574353694915771, 0.9590517282485962, 0.9558189511299133, 0.9434267282485962, 0.9582435488700867, 0.9606680870056152, 0.9633620977401733, 0.9614762663841248, 0.9768319129943848, 0.9679418206214905, 0.9787176847457886, 0.9663254022598267, 0.962553858757019, 0.9647090435028076, 0.9684805870056152, 0.9717133641242981, 0.967402994632721, 0.9523168206214905, 0.9493534564971924, 0.974946141242981, 0.9787176847457886, 0.9824892282485962, 0.9841055870056152, 0.9841055870056152, 0.9851831793785095, 0.9870689511299133, 0.9876077771186829, 0.9760237336158752, 0.951777994632721, 0.9719827771186829, 0.982758641242981, 0.9816810488700867, 0.9811422228813171, 0.9867995977401733, 0.985722005367279, 0.9873383641242981, 0.9894935488700867, 0.9816810488700867, 0.9862607717514038, 0.9867995977401733, 0.985722005367279, 0.9738685488700867, 0.9603987336158752, 0.9738685488700867, 0.9876077771186829, 0.9921875, 0.9878771305084229, 0.990571141242981, 0.9878771305084229, 0.9824892282485962, 0.984375, 0.985991358757019, 0.9897629022598267, 0.9903017282485962, 0.9870689511299133, 0.9811422228813171, 0.9733297228813171, 0.9797952771186829, 0.9881465435028076, 0.9867995977401733, 0.9876077771186829, 0.9884159564971924, 0.990840494632721], 'val_loss': [1.3740971088409424, 1.3191161155700684, 1.2684581279754639, 1.2216392755508423, 1.1782902479171753, 1.1381077766418457, 1.1015375852584839, 1.0669348239898682, 1.0397664308547974, 1.008866310119629, 0.9802234768867493, 0.9581735134124756, 0.9350265264511108, 0.9218938946723938, 0.9056861400604248, 0.891250729560852, 0.8950117826461792, 0.8764705657958984, 0.9151889085769653, 0.9061070084571838, 1.0019112825393677, 1.0605438947677612, 1.067102074623108, 1.2885743379592896, 1.4034255743026733, 1.338636875152588, 1.6342709064483643, 1.7414085865020752, 1.8333748579025269, 1.992688775062561, 2.509434700012207, 1.5892000198364258, 2.1099627017974854, 2.160919666290283, 2.2562034130096436, 2.6795430183410645, 2.4675190448760986, 2.456566333770752, 2.373786449432373, 2.4656784534454346, 2.454009532928467, 2.368375062942505, 2.555842161178589, 2.6140944957733154, 2.5604724884033203, 2.741453170776367, 2.782494306564331, 3.033463478088379, 2.8509774208068848, 2.5900115966796875, 2.623748779296875, 2.704227924346924, 3.0716588497161865, 2.9574499130249023, 3.0647778511047363, 2.2295522689819336, 2.61065411567688, 2.8470849990844727, 2.7984838485717773, 3.0342047214508057, 3.118382453918457, 3.1445305347442627, 3.220926284790039, 3.240255117416382, 3.664702892303467, 2.24837064743042, 2.371310234069824, 2.75638747215271, 2.8719589710235596, 2.7854104042053223, 3.0042362213134766, 3.0082788467407227, 2.906641960144043, 3.3120040893554688, 2.887990713119507, 2.96832537651062, 3.2021329402923584, 3.0010855197906494, 2.705489158630371, 2.5431032180786133, 2.2134432792663574, 2.560333490371704, 2.810396909713745, 2.9998178482055664, 2.8684895038604736, 2.8345022201538086, 2.901644229888916, 2.776914596557617, 2.8949694633483887, 3.066715955734253, 3.1118531227111816, 3.012835741043091, 2.914160966873169, 2.551637887954712, 2.514369010925293, 2.7103261947631836, 2.8202993869781494, 2.8200321197509766, 2.9559481143951416, 3.0309035778045654], 'val_accuracy': [0.48491379618644714, 0.5150862336158752, 0.47413793206214905, 0.48491379618644714, 0.48491379618644714, 0.5161637663841248, 0.4989224076271057, 0.5635775923728943, 0.4806034564971924, 0.517241358757019, 0.5862069129943848, 0.5517241358757019, 0.59375, 0.5334051847457886, 0.53125, 0.5603448152542114, 0.5226293206214905, 0.5571120977401733, 0.5290948152542114, 0.5398706793785095, 0.5323275923728943, 0.5495689511299133, 0.5625, 0.5668103694915771, 0.5495689511299133, 0.5721982717514038, 0.5603448152542114, 0.5862069129943848, 0.5700430870056152, 0.5657327771186829, 0.5258620977401733, 0.576508641242981, 0.5754310488700867, 0.5786637663841248, 0.5700430870056152, 0.5635775923728943, 0.5711206793785095, 0.5711206793785095, 0.5829741358757019, 0.5743534564971924, 0.568965494632721, 0.5969827771186829, 0.5775862336158752, 0.5506465435028076, 0.568965494632721, 0.579741358757019, 0.5883620977401733, 0.5678879022598267, 0.5743534564971924, 0.5732758641242981, 0.5840517282485962, 0.5732758641242981, 0.517241358757019, 0.545258641242981, 0.5204741358757019, 0.5721982717514038, 0.5528017282485962, 0.5646551847457886, 0.576508641242981, 0.5657327771186829, 0.5528017282485962, 0.5635775923728943, 0.5668103694915771, 0.5775862336158752, 0.5366379022598267, 0.5721982717514038, 0.5678879022598267, 0.568965494632721, 0.5721982717514038, 0.5829741358757019, 0.5786637663841248, 0.576508641242981, 0.5905172228813171, 0.5581896305084229, 0.5743534564971924, 0.5711206793785095, 0.5700430870056152, 0.5808189511299133, 0.5786637663841248, 0.5549569129943848, 0.5721982717514038, 0.5786637663841248, 0.576508641242981, 0.5635775923728943, 0.5818965435028076, 0.5775862336158752, 0.5700430870056152, 0.5603448152542114, 0.5678879022598267, 0.5657327771186829, 0.5668103694915771, 0.5668103694915771, 0.5603448152542114, 0.5668103694915771, 0.5732758641242981, 0.5732758641242981, 0.5635775923728943, 0.5700430870056152, 0.5517241358757019, 0.576508641242981]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 1.4065 - accuracy: 0.4991"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 13s 60ms/step - loss: 1.4058 - accuracy: 0.4977 - val_loss: 1.3758 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3498 - accuracy: 0.5048 - val_loss: 1.3221 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2977 - accuracy: 0.5113 - val_loss: 1.2724 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2490 - accuracy: 0.5291 - val_loss: 1.2267 - val_accuracy: 0.5068\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2040 - accuracy: 0.5342 - val_loss: 1.1848 - val_accuracy: 0.5170\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1605 - accuracy: 0.5572 - val_loss: 1.1472 - val_accuracy: 0.4932\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1216 - accuracy: 0.5563 - val_loss: 1.1118 - val_accuracy: 0.5170\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0789 - accuracy: 0.5812 - val_loss: 1.0795 - val_accuracy: 0.5305\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0391 - accuracy: 0.6022 - val_loss: 1.0502 - val_accuracy: 0.5452\n","Epoch 10/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9987 - accuracy: 0.6174 - val_loss: 1.0232 - val_accuracy: 0.5543\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9627 - accuracy: 0.6435 - val_loss: 0.9999 - val_accuracy: 0.5385\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9140 - accuracy: 0.6672 - val_loss: 0.9769 - val_accuracy: 0.5475\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8739 - accuracy: 0.6800 - val_loss: 0.9587 - val_accuracy: 0.5577\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8228 - accuracy: 0.7131 - val_loss: 0.9393 - val_accuracy: 0.5396\n","Epoch 15/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.7668 - accuracy: 0.7408 - val_loss: 0.9259 - val_accuracy: 0.5600\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7165 - accuracy: 0.7657 - val_loss: 0.9174 - val_accuracy: 0.5724\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6621 - accuracy: 0.7912 - val_loss: 0.9098 - val_accuracy: 0.5679\n","Epoch 18/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6256 - accuracy: 0.8025 - val_loss: 0.9021 - val_accuracy: 0.5713\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5814 - accuracy: 0.8198 - val_loss: 0.9568 - val_accuracy: 0.5396\n","Epoch 20/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5705 - accuracy: 0.8135 - val_loss: 0.9249 - val_accuracy: 0.5645\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4991 - accuracy: 0.8611 - val_loss: 0.9915 - val_accuracy: 0.5554\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4457 - accuracy: 0.8735 - val_loss: 1.1692 - val_accuracy: 0.5520\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4240 - accuracy: 0.8795 - val_loss: 1.2357 - val_accuracy: 0.5441\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4332 - accuracy: 0.8701 - val_loss: 1.2346 - val_accuracy: 0.5611\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3683 - accuracy: 0.9038 - val_loss: 1.4549 - val_accuracy: 0.5452\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3705 - accuracy: 0.8993 - val_loss: 1.3760 - val_accuracy: 0.5543\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3460 - accuracy: 0.9058 - val_loss: 1.5958 - val_accuracy: 0.5656\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2908 - accuracy: 0.9267 - val_loss: 1.9418 - val_accuracy: 0.5407\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3328 - accuracy: 0.9089 - val_loss: 1.6917 - val_accuracy: 0.5588\n","Epoch 30/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2746 - accuracy: 0.9318 - val_loss: 2.1232 - val_accuracy: 0.5317\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3034 - accuracy: 0.9095 - val_loss: 1.8976 - val_accuracy: 0.5464\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2740 - accuracy: 0.9298 - val_loss: 2.0358 - val_accuracy: 0.5566\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2645 - accuracy: 0.9287 - val_loss: 2.0219 - val_accuracy: 0.5566\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.9392 - val_loss: 2.1677 - val_accuracy: 0.5679\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2766 - accuracy: 0.9182 - val_loss: 2.0434 - val_accuracy: 0.5362\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2716 - accuracy: 0.9205 - val_loss: 1.9831 - val_accuracy: 0.5622\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2062 - accuracy: 0.9542 - val_loss: 2.4240 - val_accuracy: 0.5498\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2004 - accuracy: 0.9513 - val_loss: 2.5096 - val_accuracy: 0.5520\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2044 - accuracy: 0.9493 - val_loss: 2.4918 - val_accuracy: 0.5305\n","Epoch 40/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1912 - accuracy: 0.9570 - val_loss: 2.6643 - val_accuracy: 0.5441\n","Epoch 41/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1836 - accuracy: 0.9570 - val_loss: 2.5970 - val_accuracy: 0.5713\n","Epoch 42/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.1935 - accuracy: 0.9547 - val_loss: 2.4889 - val_accuracy: 0.5724\n","Epoch 43/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.1831 - accuracy: 0.9570 - val_loss: 2.4510 - val_accuracy: 0.5430\n","Epoch 44/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1886 - accuracy: 0.9519 - val_loss: 2.6642 - val_accuracy: 0.5532\n","Epoch 45/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2058 - accuracy: 0.9437 - val_loss: 2.2750 - val_accuracy: 0.5633\n","Epoch 46/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1688 - accuracy: 0.9618 - val_loss: 2.6621 - val_accuracy: 0.5486\n","Epoch 47/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1491 - accuracy: 0.9629 - val_loss: 2.8356 - val_accuracy: 0.5452\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1500 - accuracy: 0.9643 - val_loss: 2.8192 - val_accuracy: 0.5633\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1711 - accuracy: 0.9536 - val_loss: 2.5547 - val_accuracy: 0.5701\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1686 - accuracy: 0.9584 - val_loss: 2.7791 - val_accuracy: 0.5498\n","Epoch 51/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1618 - accuracy: 0.9601 - val_loss: 2.5826 - val_accuracy: 0.5452\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1516 - accuracy: 0.9641 - val_loss: 2.7805 - val_accuracy: 0.5509\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1698 - accuracy: 0.9556 - val_loss: 2.8006 - val_accuracy: 0.5532\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1985 - accuracy: 0.9474 - val_loss: 2.2449 - val_accuracy: 0.5656\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1434 - accuracy: 0.9697 - val_loss: 2.5495 - val_accuracy: 0.5441\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1227 - accuracy: 0.9759 - val_loss: 2.7892 - val_accuracy: 0.5475\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1169 - accuracy: 0.9728 - val_loss: 2.9136 - val_accuracy: 0.5554\n","Epoch 58/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1131 - accuracy: 0.9762 - val_loss: 2.9510 - val_accuracy: 0.5543\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1056 - accuracy: 0.9808 - val_loss: 3.0486 - val_accuracy: 0.5520\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1091 - accuracy: 0.9796 - val_loss: 2.9900 - val_accuracy: 0.5498\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1144 - accuracy: 0.9731 - val_loss: 2.9222 - val_accuracy: 0.5498\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1127 - accuracy: 0.9759 - val_loss: 2.9862 - val_accuracy: 0.5452\n","Epoch 63/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1414 - accuracy: 0.9626 - val_loss: 2.8145 - val_accuracy: 0.5441\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1472 - accuracy: 0.9626 - val_loss: 2.4975 - val_accuracy: 0.5532\n","Epoch 65/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1184 - accuracy: 0.9737 - val_loss: 2.7492 - val_accuracy: 0.5566\n","Epoch 66/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1073 - accuracy: 0.9774 - val_loss: 2.8445 - val_accuracy: 0.5520\n","Epoch 67/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.1051 - accuracy: 0.9779 - val_loss: 2.9412 - val_accuracy: 0.5441\n","Epoch 68/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1120 - accuracy: 0.9737 - val_loss: 3.0427 - val_accuracy: 0.5600\n","Epoch 69/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1093 - accuracy: 0.9762 - val_loss: 2.9698 - val_accuracy: 0.5577\n","Epoch 70/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0991 - accuracy: 0.9810 - val_loss: 3.0346 - val_accuracy: 0.5441\n","Epoch 71/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1014 - accuracy: 0.9808 - val_loss: 3.0387 - val_accuracy: 0.5373\n","Epoch 72/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1108 - accuracy: 0.9743 - val_loss: 2.8928 - val_accuracy: 0.5351\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1060 - accuracy: 0.9765 - val_loss: 2.8281 - val_accuracy: 0.5577\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0914 - accuracy: 0.9836 - val_loss: 2.9487 - val_accuracy: 0.5701\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0862 - accuracy: 0.9833 - val_loss: 3.0727 - val_accuracy: 0.5633\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0881 - accuracy: 0.9816 - val_loss: 3.0988 - val_accuracy: 0.5543\n","Epoch 77/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0805 - accuracy: 0.9847 - val_loss: 3.0275 - val_accuracy: 0.5554\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0775 - accuracy: 0.9875 - val_loss: 3.0880 - val_accuracy: 0.5532\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0708 - accuracy: 0.9912 - val_loss: 3.2018 - val_accuracy: 0.5566\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0754 - accuracy: 0.9864 - val_loss: 3.1719 - val_accuracy: 0.5520\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9864 - val_loss: 3.2554 - val_accuracy: 0.5317\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1074 - accuracy: 0.9743 - val_loss: 3.0476 - val_accuracy: 0.5464\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1540 - accuracy: 0.9584 - val_loss: 2.2857 - val_accuracy: 0.5520\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1375 - accuracy: 0.9590 - val_loss: 2.4259 - val_accuracy: 0.5566\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0975 - accuracy: 0.9808 - val_loss: 2.5115 - val_accuracy: 0.5600\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0910 - accuracy: 0.9793 - val_loss: 2.6847 - val_accuracy: 0.5452\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0818 - accuracy: 0.9822 - val_loss: 2.7792 - val_accuracy: 0.5532\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0724 - accuracy: 0.9861 - val_loss: 2.8516 - val_accuracy: 0.5419\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0676 - accuracy: 0.9890 - val_loss: 3.0200 - val_accuracy: 0.5486\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0717 - accuracy: 0.9859 - val_loss: 3.0227 - val_accuracy: 0.5486\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0746 - accuracy: 0.9844 - val_loss: 2.8880 - val_accuracy: 0.5622\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0753 - accuracy: 0.9830 - val_loss: 2.9182 - val_accuracy: 0.5622\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0702 - accuracy: 0.9873 - val_loss: 2.9057 - val_accuracy: 0.5633\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0627 - accuracy: 0.9895 - val_loss: 3.0433 - val_accuracy: 0.5532\n","Epoch 95/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0609 - accuracy: 0.9909 - val_loss: 3.0378 - val_accuracy: 0.5645\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0613 - accuracy: 0.9904 - val_loss: 3.1426 - val_accuracy: 0.5532\n","Epoch 97/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0692 - accuracy: 0.9867 - val_loss: 3.0450 - val_accuracy: 0.5486\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0755 - accuracy: 0.9853 - val_loss: 3.1115 - val_accuracy: 0.5577\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0842 - accuracy: 0.9785 - val_loss: 2.7803 - val_accuracy: 0.5588\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0835 - accuracy: 0.9810 - val_loss: 2.9018 - val_accuracy: 0.5464\n","{'loss': [1.4058252573013306, 1.3498039245605469, 1.2977432012557983, 1.248958945274353, 1.204027533531189, 1.1604708433151245, 1.1216402053833008, 1.078948736190796, 1.0390726327896118, 0.9987333416938782, 0.9627193212509155, 0.9140269160270691, 0.873855471611023, 0.8228042125701904, 0.7668207883834839, 0.716487467288971, 0.6621407270431519, 0.6255622506141663, 0.5813788771629333, 0.5705063343048096, 0.499063640832901, 0.44574621319770813, 0.42402487993240356, 0.43320730328559875, 0.36826348304748535, 0.37049928307533264, 0.34604644775390625, 0.2907518446445465, 0.33278483152389526, 0.2745516002178192, 0.30340519547462463, 0.27404409646987915, 0.2645212709903717, 0.24552001059055328, 0.27662014961242676, 0.2716323137283325, 0.20619653165340424, 0.20038869976997375, 0.20441658794879913, 0.19120249152183533, 0.18363186717033386, 0.19347165524959564, 0.18309904634952545, 0.18863895535469055, 0.20584765076637268, 0.16878098249435425, 0.149123877286911, 0.15004733204841614, 0.17113518714904785, 0.16863469779491425, 0.1617904156446457, 0.1515718400478363, 0.16976410150527954, 0.1985301822423935, 0.1434161365032196, 0.12268202006816864, 0.11692570894956589, 0.1131414994597435, 0.10560491681098938, 0.10914434492588043, 0.1144220232963562, 0.11268350481987, 0.14141497015953064, 0.1472289264202118, 0.11841397732496262, 0.1073320135474205, 0.10506054759025574, 0.11202611029148102, 0.10933594405651093, 0.09907901287078857, 0.10144069045782089, 0.11084678769111633, 0.10600531101226807, 0.09141699969768524, 0.08616282045841217, 0.08813110738992691, 0.08053144812583923, 0.07751137763261795, 0.0708012506365776, 0.07538038492202759, 0.08062861859798431, 0.10742852091789246, 0.15398718416690826, 0.1374887228012085, 0.09747881442308426, 0.09097855538129807, 0.08176065236330032, 0.07238869369029999, 0.06758803874254227, 0.07168756425380707, 0.07455699145793915, 0.07527713477611542, 0.07023584842681885, 0.06267989426851273, 0.06093322113156319, 0.06128109619021416, 0.06918273121118546, 0.07554374635219574, 0.0842379555106163, 0.08350203186273575], 'accuracy': [0.49773627519607544, 0.5048103928565979, 0.5113186240196228, 0.5291454195976257, 0.5342388153076172, 0.5571590065956116, 0.5563101172447205, 0.5812110900878906, 0.602150559425354, 0.6174306869506836, 0.6434634923934937, 0.6672325730323792, 0.6799660325050354, 0.7130730152130127, 0.740803599357605, 0.7657045722007751, 0.7911714911460876, 0.8024901151657104, 0.819750964641571, 0.8135257363319397, 0.8610639572143555, 0.8735144138336182, 0.8794566988945007, 0.8701188564300537, 0.9037917256355286, 0.8992642760276794, 0.9057725071907043, 0.926711916923523, 0.90888512134552, 0.9318053126335144, 0.9094510674476624, 0.9298245906829834, 0.9286926984786987, 0.9391624331474304, 0.918222963809967, 0.9204866886138916, 0.9541596174240112, 0.9513299465179443, 0.9493491649627686, 0.9569892287254333, 0.9569892287254333, 0.9547255039215088, 0.9569892287254333, 0.9518958926200867, 0.9436898827552795, 0.961799681186676, 0.9629315137863159, 0.9643463492393494, 0.9535936713218689, 0.9584040641784668, 0.960101842880249, 0.9640634059906006, 0.9555743932723999, 0.9473684430122375, 0.9697226881980896, 0.975947916507721, 0.9728353023529053, 0.9762309193611145, 0.9807583689689636, 0.979626476764679, 0.9731183052062988, 0.975947916507721, 0.9626485705375671, 0.9626485705375671, 0.9736841917037964, 0.9773627519607544, 0.9779286980628967, 0.9736841917037964, 0.9762309193611145, 0.9810413122177124, 0.9807583689689636, 0.9742501378059387, 0.9765138626098633, 0.9835879802703857, 0.983305037021637, 0.9816072583198547, 0.9847198724746704, 0.9875495433807373, 0.9912280440330505, 0.9864176511764526, 0.9864176511764526, 0.9742501378059387, 0.9584040641784668, 0.9589700102806091, 0.9807583689689636, 0.9793435335159302, 0.9821732044219971, 0.9861347079277039, 0.988964319229126, 0.9858517050743103, 0.9844368696212769, 0.9830220937728882, 0.9872665405273438, 0.9895302653312683, 0.9909451007843018, 0.9903791546821594, 0.9867005944252014, 0.9852858185768127, 0.9784946441650391, 0.9810413122177124], 'val_loss': [1.3757883310317993, 1.3220776319503784, 1.2724356651306152, 1.2266801595687866, 1.1848360300064087, 1.1472238302230835, 1.111768364906311, 1.0795023441314697, 1.0502185821533203, 1.023223638534546, 0.9998668432235718, 0.9768804907798767, 0.958734929561615, 0.9393187761306763, 0.9259487986564636, 0.9174271821975708, 0.9097546935081482, 0.9020679593086243, 0.9567623734474182, 0.924917459487915, 0.9915471076965332, 1.1692310571670532, 1.2356818914413452, 1.2346407175064087, 1.4548521041870117, 1.3759759664535522, 1.595792293548584, 1.9418494701385498, 1.691660761833191, 2.1231689453125, 1.897607445716858, 2.0358173847198486, 2.021920680999756, 2.1676924228668213, 2.0434460639953613, 1.9831029176712036, 2.423966407775879, 2.5096380710601807, 2.4918370246887207, 2.6642985343933105, 2.597015619277954, 2.4888792037963867, 2.451024293899536, 2.664186716079712, 2.2749814987182617, 2.6620590686798096, 2.8355648517608643, 2.819208860397339, 2.554680585861206, 2.7790722846984863, 2.5826077461242676, 2.7804746627807617, 2.800572633743286, 2.2449374198913574, 2.5495078563690186, 2.789153575897217, 2.913562536239624, 2.9509716033935547, 3.0485711097717285, 2.989981174468994, 2.9221737384796143, 2.9861690998077393, 2.814467430114746, 2.497474193572998, 2.7492330074310303, 2.8444981575012207, 2.9412410259246826, 3.042677879333496, 2.9697721004486084, 3.0345664024353027, 3.0387144088745117, 2.892789363861084, 2.8280739784240723, 2.94868540763855, 3.0727319717407227, 3.098801612854004, 3.027453899383545, 3.08795166015625, 3.2018420696258545, 3.171926259994507, 3.2553796768188477, 3.0475616455078125, 2.2857062816619873, 2.4258854389190674, 2.5114989280700684, 2.6846580505371094, 2.7791941165924072, 2.8516204357147217, 3.0200045108795166, 3.022712230682373, 2.888010263442993, 2.918210744857788, 2.905749559402466, 3.043269157409668, 3.0377860069274902, 3.142611503601074, 3.0449602603912354, 3.1114983558654785, 2.7802786827087402, 2.9017579555511475], 'val_accuracy': [0.5045248866081238, 0.5056561231613159, 0.4954751133918762, 0.5067873597145081, 0.516968309879303, 0.49321267008781433, 0.516968309879303, 0.5305429697036743, 0.5452488660812378, 0.5542986392974854, 0.5384615659713745, 0.5475113391876221, 0.557692289352417, 0.5395927429199219, 0.5599547624588013, 0.5723981857299805, 0.5678732991218567, 0.5712669491767883, 0.5395927429199219, 0.564479649066925, 0.5554298758506775, 0.5520362257957458, 0.5441176295280457, 0.5610859990119934, 0.5452488660812378, 0.5542986392974854, 0.5656108856201172, 0.540723979473114, 0.5588235259056091, 0.5316742062568665, 0.5463801026344299, 0.5565611124038696, 0.5565611124038696, 0.5678732991218567, 0.5361990928649902, 0.5622171759605408, 0.5497737526893616, 0.5520362257957458, 0.5305429697036743, 0.5441176295280457, 0.5712669491767883, 0.5723981857299805, 0.5429864525794983, 0.5531674027442932, 0.5633484125137329, 0.5486425161361694, 0.5452488660812378, 0.5633484125137329, 0.570135772228241, 0.5497737526893616, 0.5452488660812378, 0.5509049892425537, 0.5531674027442932, 0.5656108856201172, 0.5441176295280457, 0.5475113391876221, 0.5554298758506775, 0.5542986392974854, 0.5520362257957458, 0.5497737526893616, 0.5497737526893616, 0.5452488660812378, 0.5441176295280457, 0.5531674027442932, 0.5565611124038696, 0.5520362257957458, 0.5441176295280457, 0.5599547624588013, 0.557692289352417, 0.5441176295280457, 0.5373303294181824, 0.5350678563117981, 0.557692289352417, 0.570135772228241, 0.5633484125137329, 0.5542986392974854, 0.5554298758506775, 0.5531674027442932, 0.5565611124038696, 0.5520362257957458, 0.5316742062568665, 0.5463801026344299, 0.5520362257957458, 0.5565611124038696, 0.5599547624588013, 0.5452488660812378, 0.5531674027442932, 0.5418552160263062, 0.5486425161361694, 0.5486425161361694, 0.5622171759605408, 0.5622171759605408, 0.5633484125137329, 0.5531674027442932, 0.564479649066925, 0.5531674027442932, 0.5486425161361694, 0.557692289352417, 0.5588235259056091, 0.5463801026344299]}\n","45/45 [==============================] - 2s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 1.4057 - accuracy: 0.4841"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 71ms/step - loss: 1.4034 - accuracy: 0.4868 - val_loss: 1.3701 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3421 - accuracy: 0.5062 - val_loss: 1.3116 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2857 - accuracy: 0.5044 - val_loss: 1.2578 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2341 - accuracy: 0.4953 - val_loss: 1.2083 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1861 - accuracy: 0.5158 - val_loss: 1.1630 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1422 - accuracy: 0.5189 - val_loss: 1.1214 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1005 - accuracy: 0.5434 - val_loss: 1.0838 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0610 - accuracy: 0.5496 - val_loss: 1.0485 - val_accuracy: 0.5362\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0193 - accuracy: 0.5749 - val_loss: 1.0165 - val_accuracy: 0.5475\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9802 - accuracy: 0.5933 - val_loss: 0.9884 - val_accuracy: 0.5207\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9539 - accuracy: 0.5886 - val_loss: 0.9636 - val_accuracy: 0.5610\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9063 - accuracy: 0.6382 - val_loss: 0.9414 - val_accuracy: 0.5444\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8679 - accuracy: 0.6592 - val_loss: 0.9200 - val_accuracy: 0.5713\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8262 - accuracy: 0.6705 - val_loss: 0.9059 - val_accuracy: 0.5217\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7884 - accuracy: 0.6966 - val_loss: 0.8877 - val_accuracy: 0.5413\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7410 - accuracy: 0.7194 - val_loss: 0.8789 - val_accuracy: 0.5486\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7001 - accuracy: 0.7349 - val_loss: 0.8733 - val_accuracy: 0.5506\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6502 - accuracy: 0.7672 - val_loss: 0.9059 - val_accuracy: 0.5372\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6195 - accuracy: 0.7721 - val_loss: 0.8955 - val_accuracy: 0.5351\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.7824 - val_loss: 0.9476 - val_accuracy: 0.5289\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5441 - accuracy: 0.8044 - val_loss: 1.0009 - val_accuracy: 0.5589\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5167 - accuracy: 0.8207 - val_loss: 1.0865 - val_accuracy: 0.5403\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5141 - accuracy: 0.8096 - val_loss: 1.1289 - val_accuracy: 0.5754\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4661 - accuracy: 0.8282 - val_loss: 1.4043 - val_accuracy: 0.5114\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4312 - accuracy: 0.8499 - val_loss: 1.3587 - val_accuracy: 0.5785\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4556 - accuracy: 0.8264 - val_loss: 1.2134 - val_accuracy: 0.5537\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3985 - accuracy: 0.8592 - val_loss: 1.5560 - val_accuracy: 0.5506\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3959 - accuracy: 0.8556 - val_loss: 1.3592 - val_accuracy: 0.5506\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3609 - accuracy: 0.8762 - val_loss: 1.6725 - val_accuracy: 0.5692\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.8806 - val_loss: 1.6381 - val_accuracy: 0.5548\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3238 - accuracy: 0.8886 - val_loss: 1.7585 - val_accuracy: 0.5620\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3535 - accuracy: 0.8721 - val_loss: 1.7275 - val_accuracy: 0.5630\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3065 - accuracy: 0.8974 - val_loss: 1.8686 - val_accuracy: 0.5713\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2733 - accuracy: 0.9075 - val_loss: 2.0981 - val_accuracy: 0.5548\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2685 - accuracy: 0.9093 - val_loss: 2.1564 - val_accuracy: 0.5589\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2523 - accuracy: 0.9140 - val_loss: 2.1117 - val_accuracy: 0.5661\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2318 - accuracy: 0.9292 - val_loss: 2.7126 - val_accuracy: 0.5279\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2175 - accuracy: 0.9313 - val_loss: 2.4319 - val_accuracy: 0.5465\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2407 - accuracy: 0.9191 - val_loss: 2.3288 - val_accuracy: 0.5444\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2333 - accuracy: 0.9191 - val_loss: 2.4594 - val_accuracy: 0.5496\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2100 - accuracy: 0.9372 - val_loss: 2.5466 - val_accuracy: 0.5455\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2278 - accuracy: 0.9194 - val_loss: 2.1770 - val_accuracy: 0.5527\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1887 - accuracy: 0.9432 - val_loss: 2.6520 - val_accuracy: 0.5320\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1810 - accuracy: 0.9465 - val_loss: 2.7169 - val_accuracy: 0.5444\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2379 - accuracy: 0.9140 - val_loss: 2.2555 - val_accuracy: 0.5455\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2097 - accuracy: 0.9323 - val_loss: 2.4035 - val_accuracy: 0.5671\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1883 - accuracy: 0.9364 - val_loss: 2.5596 - val_accuracy: 0.5289\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1654 - accuracy: 0.9486 - val_loss: 2.5884 - val_accuracy: 0.5517\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1515 - accuracy: 0.9517 - val_loss: 2.9137 - val_accuracy: 0.5424\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1559 - accuracy: 0.9566 - val_loss: 2.9162 - val_accuracy: 0.5599\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9556 - val_loss: 2.8156 - val_accuracy: 0.5537\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1916 - accuracy: 0.9367 - val_loss: 2.5322 - val_accuracy: 0.5558\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1830 - accuracy: 0.9390 - val_loss: 2.4796 - val_accuracy: 0.5599\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1659 - accuracy: 0.9478 - val_loss: 2.5492 - val_accuracy: 0.5475\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1265 - accuracy: 0.9638 - val_loss: 2.9369 - val_accuracy: 0.5579\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1262 - accuracy: 0.9649 - val_loss: 2.9869 - val_accuracy: 0.5475\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1697 - accuracy: 0.9432 - val_loss: 2.6173 - val_accuracy: 0.5517\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1360 - accuracy: 0.9618 - val_loss: 2.8868 - val_accuracy: 0.5455\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1193 - accuracy: 0.9651 - val_loss: 2.9417 - val_accuracy: 0.5434\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1127 - accuracy: 0.9667 - val_loss: 3.1602 - val_accuracy: 0.5455\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1115 - accuracy: 0.9680 - val_loss: 3.0971 - val_accuracy: 0.5475\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1037 - accuracy: 0.9724 - val_loss: 3.2970 - val_accuracy: 0.5434\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1034 - accuracy: 0.9718 - val_loss: 3.1998 - val_accuracy: 0.5640\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0984 - accuracy: 0.9770 - val_loss: 3.2713 - val_accuracy: 0.5527\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1214 - accuracy: 0.9672 - val_loss: 3.2474 - val_accuracy: 0.5196\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1485 - accuracy: 0.9530 - val_loss: 2.6867 - val_accuracy: 0.5568\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1254 - accuracy: 0.9623 - val_loss: 2.8014 - val_accuracy: 0.5630\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1106 - accuracy: 0.9669 - val_loss: 2.9650 - val_accuracy: 0.5517\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1215 - accuracy: 0.9654 - val_loss: 2.8899 - val_accuracy: 0.5527\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1527 - accuracy: 0.9545 - val_loss: 2.5683 - val_accuracy: 0.5403\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1191 - accuracy: 0.9633 - val_loss: 2.7382 - val_accuracy: 0.5465\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1090 - accuracy: 0.9695 - val_loss: 2.8190 - val_accuracy: 0.5475\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0872 - accuracy: 0.9801 - val_loss: 3.0207 - val_accuracy: 0.5610\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0838 - accuracy: 0.9796 - val_loss: 3.2907 - val_accuracy: 0.5372\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0871 - accuracy: 0.9762 - val_loss: 3.1758 - val_accuracy: 0.5486\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0854 - accuracy: 0.9778 - val_loss: 3.3445 - val_accuracy: 0.5424\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1060 - accuracy: 0.9708 - val_loss: 2.9465 - val_accuracy: 0.5486\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1109 - accuracy: 0.9656 - val_loss: 2.9717 - val_accuracy: 0.5589\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1166 - accuracy: 0.9651 - val_loss: 2.7504 - val_accuracy: 0.5382\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1130 - accuracy: 0.9698 - val_loss: 2.7085 - val_accuracy: 0.5537\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0999 - accuracy: 0.9705 - val_loss: 2.9626 - val_accuracy: 0.5331\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 0.9594 - val_loss: 2.5602 - val_accuracy: 0.5517\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0940 - accuracy: 0.9755 - val_loss: 2.7578 - val_accuracy: 0.5537\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1050 - accuracy: 0.9672 - val_loss: 2.6069 - val_accuracy: 0.5610\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0802 - accuracy: 0.9801 - val_loss: 2.9576 - val_accuracy: 0.5558\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0714 - accuracy: 0.9817 - val_loss: 2.9831 - val_accuracy: 0.5692\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0713 - accuracy: 0.9824 - val_loss: 3.1999 - val_accuracy: 0.5465\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0836 - accuracy: 0.9780 - val_loss: 3.0588 - val_accuracy: 0.5630\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0831 - accuracy: 0.9791 - val_loss: 3.1340 - val_accuracy: 0.5537\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0798 - accuracy: 0.9783 - val_loss: 3.0155 - val_accuracy: 0.5558\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9767 - val_loss: 3.1821 - val_accuracy: 0.5351\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0865 - accuracy: 0.9765 - val_loss: 2.9913 - val_accuracy: 0.5434\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0825 - accuracy: 0.9760 - val_loss: 3.0102 - val_accuracy: 0.5527\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0781 - accuracy: 0.9804 - val_loss: 3.0851 - val_accuracy: 0.5341\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0662 - accuracy: 0.9845 - val_loss: 3.2053 - val_accuracy: 0.5403\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0623 - accuracy: 0.9837 - val_loss: 3.2092 - val_accuracy: 0.5351\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0751 - accuracy: 0.9780 - val_loss: 3.1074 - val_accuracy: 0.5403\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0632 - accuracy: 0.9848 - val_loss: 3.1418 - val_accuracy: 0.5610\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0788 - accuracy: 0.9786 - val_loss: 3.1164 - val_accuracy: 0.5403\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0911 - accuracy: 0.9721 - val_loss: 3.0324 - val_accuracy: 0.5331\n","{'loss': [1.4034490585327148, 1.342065453529358, 1.285675048828125, 1.2340939044952393, 1.1861255168914795, 1.1421613693237305, 1.1004966497421265, 1.0609694719314575, 1.0193417072296143, 0.9802359938621521, 0.9539297819137573, 0.9063280820846558, 0.8679496645927429, 0.8262276649475098, 0.7883895039558411, 0.7409507632255554, 0.7001342177391052, 0.650225818157196, 0.6195464730262756, 0.5888967514038086, 0.544065535068512, 0.516693115234375, 0.5140567421913147, 0.46610504388809204, 0.4312365651130676, 0.45556187629699707, 0.39854082465171814, 0.3958573043346405, 0.3608570694923401, 0.3391122817993164, 0.32381007075309753, 0.3535083830356598, 0.30650565028190613, 0.27334150671958923, 0.2684798538684845, 0.25230491161346436, 0.23176178336143494, 0.21751992404460907, 0.2406710833311081, 0.23332461714744568, 0.21000035107135773, 0.2278347760438919, 0.1887063980102539, 0.18099024891853333, 0.23785331845283508, 0.20972099900245667, 0.18834592401981354, 0.16540995240211487, 0.1515105813741684, 0.15594607591629028, 0.15232889354228973, 0.19158892333507538, 0.182988241314888, 0.16589833796024323, 0.12645843625068665, 0.12621861696243286, 0.1697477102279663, 0.13595958054065704, 0.11934271454811096, 0.11270277947187424, 0.11151761561632156, 0.10371052473783493, 0.10338760912418365, 0.09840439260005951, 0.12135764211416245, 0.14845430850982666, 0.12540197372436523, 0.11056196689605713, 0.12149786949157715, 0.15269245207309723, 0.11910567432641983, 0.10896904021501541, 0.0872192308306694, 0.0838397964835167, 0.08705750107765198, 0.08544236421585083, 0.1059730052947998, 0.11088825762271881, 0.116586834192276, 0.11298952251672745, 0.09993713349103928, 0.12225565314292908, 0.09399855881929398, 0.1050097867846489, 0.08024808764457703, 0.07138918340206146, 0.07133668661117554, 0.08355548977851868, 0.08309018611907959, 0.07983904331922531, 0.08359124511480331, 0.08652260154485703, 0.08253224939107895, 0.07814917713403702, 0.06621338427066803, 0.06231498718261719, 0.07511627674102783, 0.06323616951704025, 0.07875233143568039, 0.09114734083414078], 'accuracy': [0.486821711063385, 0.5062015652656555, 0.5043927431106567, 0.49534884095191956, 0.5157622694969177, 0.5188630223274231, 0.5434108376502991, 0.5496124029159546, 0.5749353766441345, 0.593281626701355, 0.5886304974555969, 0.6382429003715515, 0.6591731309890747, 0.6705426573753357, 0.6966408491134644, 0.7193798422813416, 0.734883725643158, 0.7671834826469421, 0.7720929980278015, 0.7824289202690125, 0.8043927550315857, 0.8206718564033508, 0.8095607161521912, 0.8281653523445129, 0.8498708009719849, 0.8263565897941589, 0.8591731190681458, 0.855555534362793, 0.8762273788452148, 0.8806201815605164, 0.8886305093765259, 0.8720930218696594, 0.8974159955978394, 0.907493531703949, 0.9093023538589478, 0.9139534831047058, 0.9291989803314209, 0.9312661290168762, 0.9191214442253113, 0.9191214442253113, 0.9372093081474304, 0.9193798303604126, 0.9431524276733398, 0.9465116262435913, 0.9139534831047058, 0.9322997331619263, 0.9364340901374817, 0.9485788345336914, 0.9516795873641968, 0.9565891623497009, 0.9555555582046509, 0.9366925358772278, 0.9390180706977844, 0.9478036165237427, 0.9638242721557617, 0.9648578763008118, 0.9431524276733398, 0.9617571234703064, 0.9651162624359131, 0.9666666388511658, 0.9679586291313171, 0.9723514318466187, 0.9718345999717712, 0.9770025610923767, 0.9671834707260132, 0.9529715776443481, 0.962273895740509, 0.9669250845909119, 0.9653746485710144, 0.9545219540596008, 0.9633074998855591, 0.9695090651512146, 0.9801033735275269, 0.9795865416526794, 0.9762274026870728, 0.9777777791023254, 0.970801055431366, 0.9656330943107605, 0.9651162624359131, 0.9697674512863159, 0.9705426096916199, 0.959431529045105, 0.975452184677124, 0.9671834707260132, 0.9801033735275269, 0.9816537499427795, 0.9824289679527283, 0.9780361652374268, 0.9790697693824768, 0.9782945513725281, 0.9767441749572754, 0.9764857888221741, 0.9759690165519714, 0.9803617596626282, 0.9844961166381836, 0.9837209582328796, 0.9780361652374268, 0.9847545027732849, 0.9785529971122742, 0.9720930457115173], 'val_loss': [1.370129108428955, 1.311625599861145, 1.257785439491272, 1.2082892656326294, 1.1629765033721924, 1.1214451789855957, 1.0838418006896973, 1.0485235452651978, 1.0164861679077148, 0.9884119033813477, 0.9635673761367798, 0.9413917660713196, 0.9200480580329895, 0.9058830142021179, 0.8876886963844299, 0.8789265751838684, 0.8733007311820984, 0.9059328436851501, 0.8955240249633789, 0.9476093649864197, 1.000901460647583, 1.0865474939346313, 1.1288642883300781, 1.4042880535125732, 1.3586770296096802, 1.2133848667144775, 1.5559935569763184, 1.3591768741607666, 1.6725149154663086, 1.638108730316162, 1.7584894895553589, 1.727543592453003, 1.8685590028762817, 2.0980608463287354, 2.156393051147461, 2.1116621494293213, 2.7126286029815674, 2.43186354637146, 2.328761100769043, 2.4594240188598633, 2.546644687652588, 2.177016496658325, 2.6519775390625, 2.716900110244751, 2.255450487136841, 2.403489112854004, 2.559627056121826, 2.5884482860565186, 2.9136688709259033, 2.9162187576293945, 2.8155624866485596, 2.5321927070617676, 2.479614496231079, 2.5491514205932617, 2.936889410018921, 2.9869136810302734, 2.6172561645507812, 2.8867838382720947, 2.9416871070861816, 3.160244941711426, 3.097079038619995, 3.2969982624053955, 3.1998291015625, 3.2713429927825928, 3.2474007606506348, 2.686713695526123, 2.8014345169067383, 2.9649651050567627, 2.889935255050659, 2.568305015563965, 2.73820161819458, 2.818955898284912, 3.0207009315490723, 3.290703058242798, 3.1758339405059814, 3.3445234298706055, 2.946470260620117, 2.971672534942627, 2.7503774166107178, 2.708500862121582, 2.962566614151001, 2.56020188331604, 2.7578186988830566, 2.606898784637451, 2.9575743675231934, 2.983083724975586, 3.1999146938323975, 3.0587894916534424, 3.134033441543579, 3.0155210494995117, 3.1820971965789795, 2.991312026977539, 3.010225296020508, 3.0850727558135986, 3.2053356170654297, 3.2091519832611084, 3.1073806285858154, 3.1417794227600098, 3.1164252758026123, 3.032362699508667], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5361570119857788, 0.547520637512207, 0.5206611752510071, 0.5609503984451294, 0.5444214940071106, 0.5712810158729553, 0.5216942429542542, 0.5413222908973694, 0.5485537052154541, 0.5506198406219482, 0.5371900796890259, 0.5351239442825317, 0.5289255976676941, 0.55888432264328, 0.5402892827987671, 0.5754132270812988, 0.5113636255264282, 0.5785123705863953, 0.5537189841270447, 0.5506198406219482, 0.5506198406219482, 0.5692148804664612, 0.5547520518302917, 0.5619834661483765, 0.5630165338516235, 0.5712810158729553, 0.5547520518302917, 0.55888432264328, 0.56611567735672, 0.5278925895690918, 0.5464876294136047, 0.5444214940071106, 0.5495867729187012, 0.5454545617103577, 0.5526859760284424, 0.5320248007774353, 0.5444214940071106, 0.5454545617103577, 0.567148745059967, 0.5289255976676941, 0.5516529083251953, 0.5423553586006165, 0.5599173307418823, 0.5537189841270447, 0.5557851195335388, 0.5599173307418823, 0.547520637512207, 0.557851254940033, 0.547520637512207, 0.5516529083251953, 0.5454545617103577, 0.5433884263038635, 0.5454545617103577, 0.547520637512207, 0.5433884263038635, 0.5640496015548706, 0.5526859760284424, 0.51962810754776, 0.5568181872367859, 0.5630165338516235, 0.5516529083251953, 0.5526859760284424, 0.5402892827987671, 0.5464876294136047, 0.547520637512207, 0.5609503984451294, 0.5371900796890259, 0.5485537052154541, 0.5423553586006165, 0.5485537052154541, 0.55888432264328, 0.538223147392273, 0.5537189841270447, 0.5330578684806824, 0.5516529083251953, 0.5537189841270447, 0.5609503984451294, 0.5557851195335388, 0.5692148804664612, 0.5464876294136047, 0.5630165338516235, 0.5537189841270447, 0.5557851195335388, 0.5351239442825317, 0.5433884263038635, 0.5526859760284424, 0.5340909361839294, 0.5402892827987671, 0.5351239442825317, 0.5402892827987671, 0.5609503984451294, 0.5402892827987671, 0.5330578684806824]}\n","32/32 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.5440 - accuracy: 0.7491"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 56ms/step - loss: 0.5398 - accuracy: 0.7513 - val_loss: 0.7130 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4030 - accuracy: 0.8373 - val_loss: 0.7128 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3019 - accuracy: 0.8820 - val_loss: 0.7120 - val_accuracy: 0.5216\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2450 - accuracy: 0.9036 - val_loss: 0.7098 - val_accuracy: 0.5280\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1973 - accuracy: 0.9289 - val_loss: 0.7073 - val_accuracy: 0.5733\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1707 - accuracy: 0.9402 - val_loss: 0.7031 - val_accuracy: 0.5851\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1708 - accuracy: 0.9364 - val_loss: 0.6996 - val_accuracy: 0.6110\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1492 - accuracy: 0.9502 - val_loss: 0.6937 - val_accuracy: 0.6239\n","Epoch 9/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1230 - accuracy: 0.9626 - val_loss: 0.6872 - val_accuracy: 0.6078\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1030 - accuracy: 0.9693 - val_loss: 0.6771 - val_accuracy: 0.6250\n","Epoch 11/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1055 - accuracy: 0.9669 - val_loss: 0.6707 - val_accuracy: 0.6261\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1159 - accuracy: 0.9644 - val_loss: 0.6623 - val_accuracy: 0.6401\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1072 - accuracy: 0.9696 - val_loss: 0.6785 - val_accuracy: 0.6185\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1249 - accuracy: 0.9566 - val_loss: 0.6659 - val_accuracy: 0.6261\n","Epoch 15/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1226 - accuracy: 0.9596 - val_loss: 0.7111 - val_accuracy: 0.6444\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0969 - accuracy: 0.9674 - val_loss: 0.7307 - val_accuracy: 0.6519\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0800 - accuracy: 0.9776 - val_loss: 0.8194 - val_accuracy: 0.6390\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0756 - accuracy: 0.9820 - val_loss: 0.9267 - val_accuracy: 0.6175\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0829 - accuracy: 0.9755 - val_loss: 1.0057 - val_accuracy: 0.6562\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1007 - accuracy: 0.9701 - val_loss: 1.0919 - val_accuracy: 0.6498\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0951 - accuracy: 0.9717 - val_loss: 1.1520 - val_accuracy: 0.6552\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0834 - accuracy: 0.9744 - val_loss: 1.3142 - val_accuracy: 0.6433\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0805 - accuracy: 0.9787 - val_loss: 1.4016 - val_accuracy: 0.6455\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0684 - accuracy: 0.9814 - val_loss: 1.4276 - val_accuracy: 0.6713\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0684 - accuracy: 0.9825 - val_loss: 1.5744 - val_accuracy: 0.6444\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0606 - accuracy: 0.9844 - val_loss: 1.6074 - val_accuracy: 0.6789\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0611 - accuracy: 0.9849 - val_loss: 1.6977 - val_accuracy: 0.6659\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0647 - accuracy: 0.9828 - val_loss: 1.7224 - val_accuracy: 0.6606\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0697 - accuracy: 0.9830 - val_loss: 1.7800 - val_accuracy: 0.6616\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9749 - val_loss: 1.7845 - val_accuracy: 0.6487\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0807 - accuracy: 0.9766 - val_loss: 1.7969 - val_accuracy: 0.6466\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0898 - accuracy: 0.9720 - val_loss: 1.6031 - val_accuracy: 0.6649\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0664 - accuracy: 0.9836 - val_loss: 1.7147 - val_accuracy: 0.6627\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0609 - accuracy: 0.9849 - val_loss: 1.7726 - val_accuracy: 0.6422\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0897 - accuracy: 0.9706 - val_loss: 1.6030 - val_accuracy: 0.6756\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0643 - accuracy: 0.9830 - val_loss: 1.8422 - val_accuracy: 0.6498\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0672 - accuracy: 0.9798 - val_loss: 1.7136 - val_accuracy: 0.6638\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0523 - accuracy: 0.9876 - val_loss: 1.8944 - val_accuracy: 0.6638\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0427 - accuracy: 0.9935 - val_loss: 1.9099 - val_accuracy: 0.6606\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0526 - accuracy: 0.9868 - val_loss: 2.0687 - val_accuracy: 0.6552\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0503 - accuracy: 0.9887 - val_loss: 2.0555 - val_accuracy: 0.6519\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0458 - accuracy: 0.9895 - val_loss: 2.1358 - val_accuracy: 0.6422\n","Epoch 43/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0454 - accuracy: 0.9911 - val_loss: 1.9893 - val_accuracy: 0.6681\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0510 - accuracy: 0.9881 - val_loss: 1.9416 - val_accuracy: 0.6767\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0526 - accuracy: 0.9846 - val_loss: 1.9339 - val_accuracy: 0.6670\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0445 - accuracy: 0.9919 - val_loss: 1.9685 - val_accuracy: 0.6703\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0524 - accuracy: 0.9884 - val_loss: 2.0525 - val_accuracy: 0.6606\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0687 - accuracy: 0.9820 - val_loss: 1.8630 - val_accuracy: 0.6487\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0769 - accuracy: 0.9768 - val_loss: 1.9131 - val_accuracy: 0.6498\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0625 - accuracy: 0.9844 - val_loss: 1.7760 - val_accuracy: 0.6519\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0488 - accuracy: 0.9887 - val_loss: 1.9388 - val_accuracy: 0.6455\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0675 - accuracy: 0.9803 - val_loss: 1.9066 - val_accuracy: 0.6455\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 1.7303 - val_accuracy: 0.6272\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 1.6751 - val_accuracy: 0.6778\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0436 - accuracy: 0.9908 - val_loss: 1.8653 - val_accuracy: 0.6606\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0396 - accuracy: 0.9927 - val_loss: 1.9667 - val_accuracy: 0.6541\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 0.9938 - val_loss: 1.9909 - val_accuracy: 0.6519\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9919 - val_loss: 2.0068 - val_accuracy: 0.6595\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9941 - val_loss: 1.9732 - val_accuracy: 0.6670\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 2.0341 - val_accuracy: 0.6541\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0346 - accuracy: 0.9938 - val_loss: 2.0354 - val_accuracy: 0.6649\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9933 - val_loss: 2.1278 - val_accuracy: 0.6509\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0854 - accuracy: 0.9747 - val_loss: 1.9633 - val_accuracy: 0.6509\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0718 - accuracy: 0.9782 - val_loss: 1.6954 - val_accuracy: 0.6390\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0598 - accuracy: 0.9828 - val_loss: 1.7295 - val_accuracy: 0.6584\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0481 - accuracy: 0.9887 - val_loss: 1.8443 - val_accuracy: 0.6562\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 1.9634 - val_accuracy: 0.6573\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0333 - accuracy: 0.9935 - val_loss: 1.9742 - val_accuracy: 0.6649\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.9938 - val_loss: 1.9832 - val_accuracy: 0.6466\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0362 - accuracy: 0.9930 - val_loss: 1.9453 - val_accuracy: 0.6649\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0332 - accuracy: 0.9933 - val_loss: 1.9694 - val_accuracy: 0.6552\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0332 - accuracy: 0.9941 - val_loss: 2.0821 - val_accuracy: 0.6509\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.9930 - val_loss: 2.0610 - val_accuracy: 0.6649\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0379 - accuracy: 0.9911 - val_loss: 2.0748 - val_accuracy: 0.6476\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9949 - val_loss: 1.9798 - val_accuracy: 0.6616\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0264 - accuracy: 0.9970 - val_loss: 2.0875 - val_accuracy: 0.6584\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9954 - val_loss: 2.0568 - val_accuracy: 0.6681\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 0.9943 - val_loss: 2.1022 - val_accuracy: 0.6498\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0334 - accuracy: 0.9927 - val_loss: 1.9775 - val_accuracy: 0.6573\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 1.9580 - val_accuracy: 0.6530\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0303 - accuracy: 0.9946 - val_loss: 1.9268 - val_accuracy: 0.6606\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0259 - accuracy: 0.9978 - val_loss: 1.9778 - val_accuracy: 0.6659\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9949 - val_loss: 2.0417 - val_accuracy: 0.6595\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0264 - accuracy: 0.9960 - val_loss: 2.0290 - val_accuracy: 0.6627\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 0.9965 - val_loss: 2.1820 - val_accuracy: 0.6422\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0305 - accuracy: 0.9927 - val_loss: 1.9003 - val_accuracy: 0.6616\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0321 - accuracy: 0.9927 - val_loss: 1.8785 - val_accuracy: 0.6638\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0243 - accuracy: 0.9973 - val_loss: 1.9961 - val_accuracy: 0.6541\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0241 - accuracy: 0.9976 - val_loss: 2.0274 - val_accuracy: 0.6606\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9960 - val_loss: 2.1376 - val_accuracy: 0.6476\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0233 - accuracy: 0.9973 - val_loss: 2.0487 - val_accuracy: 0.6616\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0248 - accuracy: 0.9962 - val_loss: 2.0878 - val_accuracy: 0.6659\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9952 - val_loss: 2.0534 - val_accuracy: 0.6530\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9922 - val_loss: 1.9006 - val_accuracy: 0.6519\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0323 - accuracy: 0.9922 - val_loss: 1.9263 - val_accuracy: 0.6616\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9935 - val_loss: 2.0399 - val_accuracy: 0.6509\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0490 - accuracy: 0.9860 - val_loss: 1.8658 - val_accuracy: 0.6627\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0670 - accuracy: 0.9809 - val_loss: 1.8363 - val_accuracy: 0.6228\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0596 - accuracy: 0.9806 - val_loss: 1.5529 - val_accuracy: 0.6552\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0584 - accuracy: 0.9833 - val_loss: 1.6935 - val_accuracy: 0.6692\n","{'loss': [0.5398370027542114, 0.4029613733291626, 0.3019391894340515, 0.24498683214187622, 0.19729965925216675, 0.1706579029560089, 0.17078763246536255, 0.14921453595161438, 0.1229742169380188, 0.10304079204797745, 0.10551981627941132, 0.11590725183486938, 0.1071920245885849, 0.12486004084348679, 0.12260071188211441, 0.09693068265914917, 0.07999300956726074, 0.07556421309709549, 0.08286792784929276, 0.1007266491651535, 0.09507083892822266, 0.0833829715847969, 0.08045827597379684, 0.06842635571956635, 0.0684482529759407, 0.06064952164888382, 0.06105855852365494, 0.06473948806524277, 0.06965392827987671, 0.08522848784923553, 0.0807248130440712, 0.08976247906684875, 0.0664442703127861, 0.0609193779528141, 0.08973709493875504, 0.06429888308048248, 0.06722009927034378, 0.05233484134078026, 0.0427221916615963, 0.052639082074165344, 0.05027974396944046, 0.045829154551029205, 0.04537954181432724, 0.051017604768276215, 0.05255309119820595, 0.044508498162031174, 0.05240029841661453, 0.06866361200809479, 0.07693790644407272, 0.062497444450855255, 0.04882696270942688, 0.0674746111035347, 0.09834571182727814, 0.06858121603727341, 0.043573856353759766, 0.03955228626728058, 0.03551025316119194, 0.03628921881318092, 0.035398341715335846, 0.04005027189850807, 0.03458339348435402, 0.039199814200401306, 0.08541519939899445, 0.07181229442358017, 0.05984846502542496, 0.04805639758706093, 0.045793600380420685, 0.033258263021707535, 0.034552350640296936, 0.03616873174905777, 0.03322974964976311, 0.033190228044986725, 0.03198830783367157, 0.037942517548799515, 0.031092915683984756, 0.026379486545920372, 0.02705756388604641, 0.03048866242170334, 0.03337548300623894, 0.034035246819257736, 0.030326450243592262, 0.025885963812470436, 0.02747449465095997, 0.02644892781972885, 0.027173081412911415, 0.03046429716050625, 0.032094746828079224, 0.024331199005246162, 0.02410121075809002, 0.02622791938483715, 0.023273207247257233, 0.02475772611796856, 0.027587778866291046, 0.033000536262989044, 0.032279122620821, 0.03536461293697357, 0.048985689878463745, 0.0670398697257042, 0.05963961035013199, 0.058424241840839386], 'accuracy': [0.751347005367279, 0.837284505367279, 0.8820043206214905, 0.9035560488700867, 0.9288793206214905, 0.9401939511299133, 0.9364224076271057, 0.9501616358757019, 0.962553858757019, 0.9692887663841248, 0.9668642282485962, 0.9644396305084229, 0.9695581793785095, 0.9566271305084229, 0.959590494632721, 0.967402994632721, 0.9776400923728943, 0.9819504022598267, 0.9754849076271057, 0.970097005367279, 0.9717133641242981, 0.9744073152542114, 0.9787176847457886, 0.9814116358757019, 0.9824892282485962, 0.984375, 0.9849137663841248, 0.982758641242981, 0.983027994632721, 0.974946141242981, 0.9765625, 0.9719827771186829, 0.9835668206214905, 0.9849137663841248, 0.9706357717514038, 0.983027994632721, 0.9797952771186829, 0.9876077771186829, 0.993534505367279, 0.9867995977401733, 0.9886853694915771, 0.9894935488700867, 0.9911099076271057, 0.9881465435028076, 0.9846444129943848, 0.9919180870056152, 0.9884159564971924, 0.9819504022598267, 0.9768319129943848, 0.984375, 0.9886853694915771, 0.9803340435028076, 0.96875, 0.9822198152542114, 0.990840494632721, 0.9927262663841248, 0.993803858757019, 0.9919180870056152, 0.9940732717514038, 0.9900323152542114, 0.993803858757019, 0.9932650923728943, 0.9746767282485962, 0.978178858757019, 0.982758641242981, 0.9886853694915771, 0.9886853694915771, 0.993534505367279, 0.993803858757019, 0.9929956793785095, 0.9932650923728943, 0.9940732717514038, 0.9929956793785095, 0.9911099076271057, 0.9948814511299133, 0.9970366358757019, 0.9954202771186829, 0.9943426847457886, 0.9927262663841248, 0.9916487336158752, 0.9946120977401733, 0.9978448152542114, 0.9948814511299133, 0.9959590435028076, 0.9964978694915771, 0.9927262663841248, 0.9927262663841248, 0.9973060488700867, 0.9975754022598267, 0.9959590435028076, 0.9973060488700867, 0.9962284564971924, 0.9951508641242981, 0.9921875, 0.9921875, 0.993534505367279, 0.985991358757019, 0.9808728694915771, 0.9806034564971924, 0.9832974076271057], 'val_loss': [0.7130286693572998, 0.7127813696861267, 0.7120130658149719, 0.7098270654678345, 0.7073447108268738, 0.7031357884407043, 0.6996445059776306, 0.6937281489372253, 0.6872301697731018, 0.6771153807640076, 0.6707264184951782, 0.6622949242591858, 0.6784594058990479, 0.6658855080604553, 0.711117148399353, 0.7307307124137878, 0.8194441199302673, 0.9267138242721558, 1.0056538581848145, 1.091880440711975, 1.1520229578018188, 1.314221739768982, 1.4015617370605469, 1.4276467561721802, 1.5744173526763916, 1.6073572635650635, 1.6976646184921265, 1.7224215269088745, 1.7799519300460815, 1.7844551801681519, 1.7968677282333374, 1.6031237840652466, 1.7146693468093872, 1.772608995437622, 1.6030051708221436, 1.8422064781188965, 1.7136210203170776, 1.8944357633590698, 1.9099363088607788, 2.068718194961548, 2.0554637908935547, 2.13577938079834, 1.989314317703247, 1.941552758216858, 1.9339163303375244, 1.9684892892837524, 2.0525496006011963, 1.863031268119812, 1.9131377935409546, 1.7760038375854492, 1.9387917518615723, 1.9066377878189087, 1.730269432067871, 1.6751407384872437, 1.865328073501587, 1.9666990041732788, 1.990918755531311, 2.0068087577819824, 1.9732284545898438, 2.034142017364502, 2.0353941917419434, 2.127814531326294, 1.96329927444458, 1.6954036951065063, 1.7295467853546143, 1.8442606925964355, 1.9634313583374023, 1.9741606712341309, 1.9832446575164795, 1.9452875852584839, 1.9693816900253296, 2.082120656967163, 2.061009407043457, 2.0748400688171387, 1.9798011779785156, 2.0874743461608887, 2.0567939281463623, 2.1022467613220215, 1.9774765968322754, 1.9579795598983765, 1.926776647567749, 1.9777973890304565, 2.041696548461914, 2.028965711593628, 2.1820340156555176, 1.9002618789672852, 1.8785459995269775, 1.996096134185791, 2.027416467666626, 2.137622594833374, 2.048691749572754, 2.087815999984741, 2.0533742904663086, 1.9005569219589233, 1.9263226985931396, 2.039907693862915, 1.865813970565796, 1.836284875869751, 1.5529017448425293, 1.6935073137283325], 'val_accuracy': [0.5150862336158752, 0.517241358757019, 0.5215517282485962, 0.5280172228813171, 0.5732758641242981, 0.5851293206214905, 0.610991358757019, 0.6239224076271057, 0.607758641242981, 0.625, 0.6260775923728943, 0.6400862336158752, 0.618534505367279, 0.6260775923728943, 0.6443965435028076, 0.6519396305084229, 0.639008641242981, 0.6174569129943848, 0.65625, 0.649784505367279, 0.6551724076271057, 0.6433189511299133, 0.6454741358757019, 0.6713362336158752, 0.6443965435028076, 0.6788793206214905, 0.6659482717514038, 0.6605603694915771, 0.6616379022598267, 0.6487069129943848, 0.6465517282485962, 0.6648706793785095, 0.662715494632721, 0.642241358757019, 0.6756465435028076, 0.649784505367279, 0.6637930870056152, 0.6637930870056152, 0.6605603694915771, 0.6551724076271057, 0.6519396305084229, 0.642241358757019, 0.6681034564971924, 0.6767241358757019, 0.6670258641242981, 0.670258641242981, 0.6605603694915771, 0.6487069129943848, 0.649784505367279, 0.6519396305084229, 0.6454741358757019, 0.6454741358757019, 0.6271551847457886, 0.6778017282485962, 0.6605603694915771, 0.6540948152542114, 0.6519396305084229, 0.6594827771186829, 0.6670258641242981, 0.6540948152542114, 0.6648706793785095, 0.6508620977401733, 0.6508620977401733, 0.639008641242981, 0.6584051847457886, 0.65625, 0.6573275923728943, 0.6648706793785095, 0.6465517282485962, 0.6648706793785095, 0.6551724076271057, 0.6508620977401733, 0.6648706793785095, 0.6476293206214905, 0.6616379022598267, 0.6584051847457886, 0.6681034564971924, 0.649784505367279, 0.6573275923728943, 0.6530172228813171, 0.6605603694915771, 0.6659482717514038, 0.6594827771186829, 0.662715494632721, 0.642241358757019, 0.6616379022598267, 0.6637930870056152, 0.6540948152542114, 0.6605603694915771, 0.6476293206214905, 0.6616379022598267, 0.6659482717514038, 0.6530172228813171, 0.6519396305084229, 0.6616379022598267, 0.6508620977401733, 0.662715494632721, 0.6228448152542114, 0.6551724076271057, 0.6691810488700867]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.4874 - accuracy: 0.7804"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 55ms/step - loss: 0.4874 - accuracy: 0.7799 - val_loss: 0.7130 - val_accuracy: 0.5102\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3496 - accuracy: 0.8602 - val_loss: 0.7124 - val_accuracy: 0.5158\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2786 - accuracy: 0.8882 - val_loss: 0.7106 - val_accuracy: 0.5317\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2081 - accuracy: 0.9267 - val_loss: 0.7092 - val_accuracy: 0.5271\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1906 - accuracy: 0.9278 - val_loss: 0.7033 - val_accuracy: 0.5600\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2017 - accuracy: 0.9261 - val_loss: 0.7014 - val_accuracy: 0.5441\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1582 - accuracy: 0.9454 - val_loss: 0.6947 - val_accuracy: 0.5611\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1319 - accuracy: 0.9573 - val_loss: 0.6879 - val_accuracy: 0.5713\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1300 - accuracy: 0.9573 - val_loss: 0.6834 - val_accuracy: 0.5713\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1138 - accuracy: 0.9652 - val_loss: 0.6735 - val_accuracy: 0.5894\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0992 - accuracy: 0.9689 - val_loss: 0.6665 - val_accuracy: 0.6222\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1010 - accuracy: 0.9694 - val_loss: 0.6590 - val_accuracy: 0.6301\n","Epoch 13/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.1384 - accuracy: 0.9525 - val_loss: 0.6539 - val_accuracy: 0.6278\n","Epoch 14/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1179 - accuracy: 0.9612 - val_loss: 0.6547 - val_accuracy: 0.6471\n","Epoch 15/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0873 - accuracy: 0.9774 - val_loss: 0.6556 - val_accuracy: 0.6855\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0738 - accuracy: 0.9810 - val_loss: 0.7067 - val_accuracy: 0.6686\n","Epoch 17/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.0790 - accuracy: 0.9774 - val_loss: 0.7752 - val_accuracy: 0.6561\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1431 - accuracy: 0.9530 - val_loss: 0.7971 - val_accuracy: 0.6471\n","Epoch 19/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.1415 - accuracy: 0.9530 - val_loss: 0.7472 - val_accuracy: 0.6867\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0906 - accuracy: 0.9759 - val_loss: 0.9214 - val_accuracy: 0.6324\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9740 - val_loss: 1.0263 - val_accuracy: 0.6629\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0865 - accuracy: 0.9737 - val_loss: 1.1339 - val_accuracy: 0.6731\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0763 - accuracy: 0.9799 - val_loss: 1.3876 - val_accuracy: 0.6572\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0849 - accuracy: 0.9745 - val_loss: 1.2806 - val_accuracy: 0.6708\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0718 - accuracy: 0.9796 - val_loss: 1.3937 - val_accuracy: 0.6629\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0616 - accuracy: 0.9850 - val_loss: 1.5041 - val_accuracy: 0.6708\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0771 - accuracy: 0.9782 - val_loss: 1.4820 - val_accuracy: 0.6674\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9745 - val_loss: 1.5993 - val_accuracy: 0.6527\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0684 - accuracy: 0.9813 - val_loss: 1.5924 - val_accuracy: 0.6787\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0722 - accuracy: 0.9779 - val_loss: 1.6725 - val_accuracy: 0.6674\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0768 - accuracy: 0.9771 - val_loss: 1.7827 - val_accuracy: 0.6414\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1162 - accuracy: 0.9635 - val_loss: 1.4054 - val_accuracy: 0.6606\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0811 - accuracy: 0.9757 - val_loss: 1.5445 - val_accuracy: 0.6346\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0594 - accuracy: 0.9861 - val_loss: 1.6973 - val_accuracy: 0.6572\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0527 - accuracy: 0.9895 - val_loss: 1.8236 - val_accuracy: 0.6606\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0564 - accuracy: 0.9878 - val_loss: 1.8958 - val_accuracy: 0.6493\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0545 - accuracy: 0.9873 - val_loss: 1.8730 - val_accuracy: 0.6538\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0636 - accuracy: 0.9833 - val_loss: 1.8662 - val_accuracy: 0.6606\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0576 - accuracy: 0.9861 - val_loss: 1.8341 - val_accuracy: 0.6674\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0542 - accuracy: 0.9875 - val_loss: 1.8970 - val_accuracy: 0.6595\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0563 - accuracy: 0.9864 - val_loss: 1.9070 - val_accuracy: 0.6482\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0700 - accuracy: 0.9802 - val_loss: 1.8428 - val_accuracy: 0.6708\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0683 - accuracy: 0.9802 - val_loss: 1.9611 - val_accuracy: 0.6448\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0677 - accuracy: 0.9833 - val_loss: 1.7035 - val_accuracy: 0.6708\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0502 - accuracy: 0.9884 - val_loss: 1.8197 - val_accuracy: 0.6833\n","Epoch 46/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0434 - accuracy: 0.9918 - val_loss: 1.9157 - val_accuracy: 0.6516\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0412 - accuracy: 0.9921 - val_loss: 2.0524 - val_accuracy: 0.6459\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0408 - accuracy: 0.9924 - val_loss: 1.9161 - val_accuracy: 0.6765\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0469 - accuracy: 0.9901 - val_loss: 1.8916 - val_accuracy: 0.6765\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 2.0754 - val_accuracy: 0.6301\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0938 - accuracy: 0.9728 - val_loss: 1.6466 - val_accuracy: 0.6527\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0886 - accuracy: 0.9717 - val_loss: 1.5033 - val_accuracy: 0.6584\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0599 - accuracy: 0.9864 - val_loss: 1.6725 - val_accuracy: 0.6629\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0433 - accuracy: 0.9918 - val_loss: 1.8303 - val_accuracy: 0.6618\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0456 - accuracy: 0.9895 - val_loss: 1.7886 - val_accuracy: 0.6527\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0367 - accuracy: 0.9943 - val_loss: 1.9736 - val_accuracy: 0.6425\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0496 - accuracy: 0.9884 - val_loss: 2.1929 - val_accuracy: 0.6391\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1041 - accuracy: 0.9666 - val_loss: 1.7280 - val_accuracy: 0.6516\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9825 - val_loss: 1.6568 - val_accuracy: 0.6516\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0471 - accuracy: 0.9898 - val_loss: 1.7332 - val_accuracy: 0.6606\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0414 - accuracy: 0.9912 - val_loss: 1.8797 - val_accuracy: 0.6437\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0392 - accuracy: 0.9915 - val_loss: 1.8968 - val_accuracy: 0.6606\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0351 - accuracy: 0.9926 - val_loss: 1.9523 - val_accuracy: 0.6561\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0484 - accuracy: 0.9887 - val_loss: 1.9718 - val_accuracy: 0.6538\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 1.8615 - val_accuracy: 0.6448\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0365 - accuracy: 0.9943 - val_loss: 1.9758 - val_accuracy: 0.6629\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0440 - accuracy: 0.9904 - val_loss: 1.8597 - val_accuracy: 0.6572\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 1.9599 - val_accuracy: 0.6380\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0328 - accuracy: 0.9949 - val_loss: 1.9536 - val_accuracy: 0.6686\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0342 - accuracy: 0.9941 - val_loss: 2.0462 - val_accuracy: 0.6697\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0405 - accuracy: 0.9924 - val_loss: 2.1589 - val_accuracy: 0.6572\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0535 - accuracy: 0.9859 - val_loss: 1.9146 - val_accuracy: 0.6561\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0499 - accuracy: 0.9878 - val_loss: 2.0718 - val_accuracy: 0.6538\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0744 - accuracy: 0.9762 - val_loss: 2.0923 - val_accuracy: 0.6516\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0695 - accuracy: 0.9771 - val_loss: 1.7081 - val_accuracy: 0.6346\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0490 - accuracy: 0.9870 - val_loss: 1.8811 - val_accuracy: 0.6199\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9929 - val_loss: 1.9594 - val_accuracy: 0.6380\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0485 - accuracy: 0.9878 - val_loss: 1.8806 - val_accuracy: 0.6369\n","Epoch 79/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0405 - accuracy: 0.9907 - val_loss: 1.8532 - val_accuracy: 0.6369\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0318 - accuracy: 0.9949 - val_loss: 1.9970 - val_accuracy: 0.6516\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0304 - accuracy: 0.9958 - val_loss: 2.0395 - val_accuracy: 0.6425\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0290 - accuracy: 0.9943 - val_loss: 2.0962 - val_accuracy: 0.6403\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0278 - accuracy: 0.9960 - val_loss: 2.0976 - val_accuracy: 0.6357\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0297 - accuracy: 0.9941 - val_loss: 2.2849 - val_accuracy: 0.6290\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0354 - accuracy: 0.9935 - val_loss: 2.0828 - val_accuracy: 0.6459\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0394 - accuracy: 0.9924 - val_loss: 2.0194 - val_accuracy: 0.6335\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0423 - accuracy: 0.9907 - val_loss: 2.0692 - val_accuracy: 0.6425\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0542 - accuracy: 0.9861 - val_loss: 1.8267 - val_accuracy: 0.6482\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0633 - accuracy: 0.9813 - val_loss: 1.6837 - val_accuracy: 0.6391\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0483 - accuracy: 0.9873 - val_loss: 1.9401 - val_accuracy: 0.6391\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0579 - accuracy: 0.9822 - val_loss: 1.8626 - val_accuracy: 0.6346\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0548 - accuracy: 0.9856 - val_loss: 1.6789 - val_accuracy: 0.6618\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 1.7960 - val_accuracy: 0.6482\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0342 - accuracy: 0.9921 - val_loss: 1.9665 - val_accuracy: 0.6335\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0352 - accuracy: 0.9926 - val_loss: 2.2766 - val_accuracy: 0.6052\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0365 - accuracy: 0.9918 - val_loss: 2.0369 - val_accuracy: 0.6357\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0532 - accuracy: 0.9864 - val_loss: 1.9018 - val_accuracy: 0.6312\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0391 - accuracy: 0.9907 - val_loss: 1.9628 - val_accuracy: 0.6414\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 2.1248 - val_accuracy: 0.6471\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9958 - val_loss: 2.0600 - val_accuracy: 0.6550\n","{'loss': [0.4873943030834198, 0.3496429920196533, 0.2786441743373871, 0.20813614130020142, 0.19059206545352936, 0.20174121856689453, 0.15823161602020264, 0.13187256455421448, 0.13001014292240143, 0.11383760720491409, 0.09921062737703323, 0.10101617872714996, 0.13838303089141846, 0.11788918077945709, 0.08727678656578064, 0.07377072423696518, 0.07900264114141464, 0.14307387173175812, 0.1415279060602188, 0.09056228399276733, 0.08055990934371948, 0.08645107597112656, 0.07631586492061615, 0.08485142886638641, 0.07182455062866211, 0.06161203607916832, 0.07709560543298721, 0.08058137446641922, 0.06838953495025635, 0.07219488173723221, 0.07676613330841064, 0.11617230623960495, 0.08113664388656616, 0.059391867369413376, 0.05272867903113365, 0.05640913546085358, 0.05445149913430214, 0.06359758228063583, 0.057586755603551865, 0.05415235832333565, 0.0563216470181942, 0.0700267031788826, 0.06829333305358887, 0.06774373352527618, 0.05024562031030655, 0.043391622602939606, 0.04120253771543503, 0.0408458411693573, 0.04685413837432861, 0.05078925937414169, 0.09379337728023529, 0.08857172727584839, 0.05989840626716614, 0.04327663034200668, 0.045592933893203735, 0.036744747310876846, 0.04958556964993477, 0.10410904884338379, 0.06800061464309692, 0.04705964773893356, 0.04140268266201019, 0.039167873561382294, 0.035134561359882355, 0.04838937520980835, 0.04226964712142944, 0.0365469716489315, 0.044004425406455994, 0.03967933729290962, 0.03282258287072182, 0.03417785465717316, 0.04050241783261299, 0.05352355167269707, 0.04991860315203667, 0.07436862587928772, 0.06953591108322144, 0.049002859741449356, 0.03718582168221474, 0.048470016568899155, 0.040479227900505066, 0.0317847803235054, 0.03037312999367714, 0.028955817222595215, 0.027760308235883713, 0.029706353321671486, 0.03541431948542595, 0.039362017065286636, 0.04230407625436783, 0.054196249693632126, 0.06333377957344055, 0.048268407583236694, 0.0578794963657856, 0.05480010434985161, 0.04124349355697632, 0.03420370817184448, 0.03520573303103447, 0.036508895456790924, 0.05320773273706436, 0.03910742700099945, 0.03136736899614334, 0.028444921597838402], 'accuracy': [0.7798528671264648, 0.8602150678634644, 0.8882286548614502, 0.926711916923523, 0.9278438091278076, 0.9261460304260254, 0.9453876614570618, 0.9572722315788269, 0.9572722315788269, 0.9651952385902405, 0.9688737988471985, 0.9694397449493408, 0.9524617791175842, 0.9612337350845337, 0.9773627519607544, 0.9810413122177124, 0.9773627519607544, 0.9530277252197266, 0.9530277252197266, 0.975947916507721, 0.9739671945571899, 0.9736841917037964, 0.9799094796180725, 0.9745330810546875, 0.979626476764679, 0.9850028157234192, 0.9782116413116455, 0.9745330810546875, 0.9813242554664612, 0.9779286980628967, 0.9770798087120056, 0.9634974598884583, 0.9756649732589722, 0.9861347079277039, 0.9895302653312683, 0.9878324866294861, 0.9872665405273438, 0.983305037021637, 0.9861347079277039, 0.9875495433807373, 0.9864176511764526, 0.9801924228668213, 0.9801924228668213, 0.983305037021637, 0.9883984327316284, 0.9917939901351929, 0.9920769929885864, 0.9923599362373352, 0.9900962114334106, 0.9875495433807373, 0.9728353023529053, 0.9717034697532654, 0.9864176511764526, 0.9917939901351929, 0.9895302653312683, 0.994340717792511, 0.9883984327316284, 0.9666100740432739, 0.9824561476707458, 0.9898132681846619, 0.9912280440330505, 0.9915110468864441, 0.992642879486084, 0.9886813759803772, 0.9912280440330505, 0.994340717792511, 0.9903791546821594, 0.9912280440330505, 0.9949066042900085, 0.9940577149391174, 0.9923599362373352, 0.9858517050743103, 0.9878324866294861, 0.9762309193611145, 0.9770798087120056, 0.986983597278595, 0.9929258823394775, 0.9878324866294861, 0.990662157535553, 0.9949066042900085, 0.9957554936408997, 0.994340717792511, 0.9960384964942932, 0.9940577149391174, 0.9934917688369751, 0.9923599362373352, 0.990662157535553, 0.9861347079277039, 0.9813242554664612, 0.9872665405273438, 0.9821732044219971, 0.9855687618255615, 0.9895302653312683, 0.9920769929885864, 0.992642879486084, 0.9917939901351929, 0.9864176511764526, 0.990662157535553, 0.9940577149391174, 0.9957554936408997], 'val_loss': [0.7129576206207275, 0.7123682498931885, 0.7105652093887329, 0.7092142105102539, 0.7032715678215027, 0.7013643980026245, 0.6947069764137268, 0.6879433393478394, 0.68341463804245, 0.6735132932662964, 0.6665025353431702, 0.6590346097946167, 0.6538793444633484, 0.6547405123710632, 0.6556333899497986, 0.7067450881004333, 0.7751967906951904, 0.7971068620681763, 0.7472016215324402, 0.9213763475418091, 1.0262776613235474, 1.1338691711425781, 1.3876349925994873, 1.2805722951889038, 1.3936572074890137, 1.5040524005889893, 1.4819730520248413, 1.5993216037750244, 1.5923537015914917, 1.6724728345870972, 1.7826582193374634, 1.4053775072097778, 1.5445270538330078, 1.697261929512024, 1.8235656023025513, 1.8958097696304321, 1.8729708194732666, 1.8661543130874634, 1.8341474533081055, 1.8969776630401611, 1.907010555267334, 1.8427846431732178, 1.9610806703567505, 1.7034779787063599, 1.819650650024414, 1.915723443031311, 2.0523624420166016, 1.9161405563354492, 1.8915612697601318, 2.075352668762207, 1.6466305255889893, 1.5033211708068848, 1.672488808631897, 1.8303252458572388, 1.7885576486587524, 1.9735941886901855, 2.1929306983947754, 1.7280099391937256, 1.6567540168762207, 1.733191967010498, 1.8797293901443481, 1.8968137502670288, 1.9522888660430908, 1.9718210697174072, 1.8615070581436157, 1.975817084312439, 1.85965895652771, 1.9599443674087524, 1.9536257982254028, 2.046194553375244, 2.1589179039001465, 1.9146292209625244, 2.071829080581665, 2.0922536849975586, 1.708080768585205, 1.881052017211914, 1.959387183189392, 1.8805804252624512, 1.8531543016433716, 1.997019648551941, 2.0395278930664062, 2.0962064266204834, 2.097628593444824, 2.2849104404449463, 2.082815647125244, 2.0194263458251953, 2.0692224502563477, 1.8267171382904053, 1.6837440729141235, 1.940056562423706, 1.8625870943069458, 1.6789288520812988, 1.795980453491211, 1.9665460586547852, 2.2765955924987793, 2.0369315147399902, 1.9018008708953857, 1.9627631902694702, 2.1248321533203125, 2.0599544048309326], 'val_accuracy': [0.5101810097694397, 0.5158371329307556, 0.5316742062568665, 0.5271493196487427, 0.5599547624588013, 0.5441176295280457, 0.5610859990119934, 0.5712669491767883, 0.5712669491767883, 0.5893664956092834, 0.622171938419342, 0.6300904750823975, 0.627828061580658, 0.6470588445663452, 0.685520350933075, 0.668552041053772, 0.6561086177825928, 0.6470588445663452, 0.6866515874862671, 0.6323529481887817, 0.662895917892456, 0.6730769276618958, 0.6572397947311401, 0.6708144545555115, 0.662895917892456, 0.6708144545555115, 0.6674208045005798, 0.6527149081230164, 0.6787330508232117, 0.6674208045005798, 0.6414027214050293, 0.6606335043907166, 0.6346153616905212, 0.6572397947311401, 0.6606335043907166, 0.6493212580680847, 0.6538461446762085, 0.6606335043907166, 0.6674208045005798, 0.6595022678375244, 0.6481900215148926, 0.6708144545555115, 0.6447963714599609, 0.6708144545555115, 0.6832579374313354, 0.651583731174469, 0.6459276080131531, 0.6764705777168274, 0.6764705777168274, 0.6300904750823975, 0.6527149081230164, 0.6583710312843323, 0.662895917892456, 0.6617646813392639, 0.6527149081230164, 0.6425339579582214, 0.639140248298645, 0.651583731174469, 0.651583731174469, 0.6606335043907166, 0.6436651349067688, 0.6606335043907166, 0.6561086177825928, 0.6538461446762085, 0.6447963714599609, 0.662895917892456, 0.6572397947311401, 0.6380090713500977, 0.668552041053772, 0.6696832776069641, 0.6572397947311401, 0.6561086177825928, 0.6538461446762085, 0.651583731174469, 0.6346153616905212, 0.6199095249176025, 0.6380090713500977, 0.6368778347969055, 0.6368778347969055, 0.651583731174469, 0.6425339579582214, 0.6402714848518372, 0.6357465982437134, 0.6289592981338501, 0.6459276080131531, 0.6334841847419739, 0.6425339579582214, 0.6481900215148926, 0.639140248298645, 0.639140248298645, 0.6346153616905212, 0.6617646813392639, 0.6481900215148926, 0.6334841847419739, 0.6052036285400391, 0.6357465982437134, 0.6312217116355896, 0.6414027214050293, 0.6470588445663452, 0.6549773812294006]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5175 - accuracy: 0.7645"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 54ms/step - loss: 0.5150 - accuracy: 0.7636 - val_loss: 0.7131 - val_accuracy: 0.5165\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3759 - accuracy: 0.8403 - val_loss: 0.7127 - val_accuracy: 0.5238\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2970 - accuracy: 0.8762 - val_loss: 0.7120 - val_accuracy: 0.5310\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2362 - accuracy: 0.9026 - val_loss: 0.7109 - val_accuracy: 0.5300\n","Epoch 5/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.2028 - accuracy: 0.9204 - val_loss: 0.7075 - val_accuracy: 0.5465\n","Epoch 6/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2124 - accuracy: 0.9142 - val_loss: 0.7030 - val_accuracy: 0.5847\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2046 - accuracy: 0.9209 - val_loss: 0.7025 - val_accuracy: 0.5496\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1487 - accuracy: 0.9460 - val_loss: 0.6930 - val_accuracy: 0.5785\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1395 - accuracy: 0.9460 - val_loss: 0.6882 - val_accuracy: 0.5671\n","Epoch 10/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1439 - accuracy: 0.9478 - val_loss: 0.6763 - val_accuracy: 0.6116\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1727 - accuracy: 0.9328 - val_loss: 0.6885 - val_accuracy: 0.5857\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1518 - accuracy: 0.9452 - val_loss: 0.6912 - val_accuracy: 0.5847\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1347 - accuracy: 0.9506 - val_loss: 0.6938 - val_accuracy: 0.6302\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1070 - accuracy: 0.9656 - val_loss: 0.7375 - val_accuracy: 0.6116\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0909 - accuracy: 0.9713 - val_loss: 0.8312 - val_accuracy: 0.6219\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1099 - accuracy: 0.9633 - val_loss: 0.9165 - val_accuracy: 0.5930\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1106 - accuracy: 0.9636 - val_loss: 0.9511 - val_accuracy: 0.6260\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1113 - accuracy: 0.9641 - val_loss: 1.0526 - val_accuracy: 0.6229\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1214 - accuracy: 0.9561 - val_loss: 1.1177 - val_accuracy: 0.6271\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1011 - accuracy: 0.9682 - val_loss: 1.2990 - val_accuracy: 0.6302\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0963 - accuracy: 0.9698 - val_loss: 1.4399 - val_accuracy: 0.6281\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1196 - accuracy: 0.9605 - val_loss: 1.4472 - val_accuracy: 0.6302\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1082 - accuracy: 0.9641 - val_loss: 1.5292 - val_accuracy: 0.6167\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1035 - accuracy: 0.9641 - val_loss: 1.6491 - val_accuracy: 0.6312\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1148 - accuracy: 0.9568 - val_loss: 1.7467 - val_accuracy: 0.6136\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1068 - accuracy: 0.9633 - val_loss: 1.6797 - val_accuracy: 0.6312\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0800 - accuracy: 0.9788 - val_loss: 1.8026 - val_accuracy: 0.6405\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0722 - accuracy: 0.9773 - val_loss: 1.9280 - val_accuracy: 0.6219\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1082 - accuracy: 0.9620 - val_loss: 1.7269 - val_accuracy: 0.6384\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0891 - accuracy: 0.9729 - val_loss: 1.8554 - val_accuracy: 0.6333\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0763 - accuracy: 0.9767 - val_loss: 2.0453 - val_accuracy: 0.6302\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0822 - accuracy: 0.9755 - val_loss: 2.0011 - val_accuracy: 0.6198\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9747 - val_loss: 1.9168 - val_accuracy: 0.6312\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0756 - accuracy: 0.9765 - val_loss: 1.9398 - val_accuracy: 0.6405\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 1.9908 - val_accuracy: 0.6405\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0606 - accuracy: 0.9832 - val_loss: 2.1202 - val_accuracy: 0.6302\n","Epoch 37/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0688 - accuracy: 0.9796 - val_loss: 2.1974 - val_accuracy: 0.6426\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0866 - accuracy: 0.9716 - val_loss: 2.0972 - val_accuracy: 0.6250\n","Epoch 39/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0719 - accuracy: 0.9796 - val_loss: 2.0612 - val_accuracy: 0.6488\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0592 - accuracy: 0.9858 - val_loss: 2.0735 - val_accuracy: 0.6333\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0578 - accuracy: 0.9848 - val_loss: 2.3105 - val_accuracy: 0.6250\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1056 - accuracy: 0.9649 - val_loss: 1.9785 - val_accuracy: 0.6229\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0844 - accuracy: 0.9721 - val_loss: 1.9028 - val_accuracy: 0.6302\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0786 - accuracy: 0.9744 - val_loss: 1.9273 - val_accuracy: 0.6436\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0718 - accuracy: 0.9767 - val_loss: 2.0472 - val_accuracy: 0.6343\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0684 - accuracy: 0.9786 - val_loss: 2.0648 - val_accuracy: 0.6353\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0656 - accuracy: 0.9814 - val_loss: 1.9939 - val_accuracy: 0.6374\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 2.1821 - val_accuracy: 0.6198\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0648 - accuracy: 0.9814 - val_loss: 2.1893 - val_accuracy: 0.6312\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0590 - accuracy: 0.9832 - val_loss: 2.2085 - val_accuracy: 0.6250\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0667 - accuracy: 0.9796 - val_loss: 2.0649 - val_accuracy: 0.6446\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 2.1335 - val_accuracy: 0.6364\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0534 - accuracy: 0.9871 - val_loss: 2.3357 - val_accuracy: 0.6291\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0591 - accuracy: 0.9819 - val_loss: 2.1994 - val_accuracy: 0.6343\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0474 - accuracy: 0.9884 - val_loss: 2.2012 - val_accuracy: 0.6374\n","Epoch 56/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0499 - accuracy: 0.9871 - val_loss: 2.1992 - val_accuracy: 0.6508\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 2.3805 - val_accuracy: 0.6405\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0619 - accuracy: 0.9827 - val_loss: 2.2142 - val_accuracy: 0.6426\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0693 - accuracy: 0.9786 - val_loss: 2.2580 - val_accuracy: 0.6033\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1363 - accuracy: 0.9525 - val_loss: 1.6621 - val_accuracy: 0.6064\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0788 - accuracy: 0.9755 - val_loss: 1.8307 - val_accuracy: 0.6126\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0875 - accuracy: 0.9700 - val_loss: 2.1247 - val_accuracy: 0.6188\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0700 - accuracy: 0.9786 - val_loss: 1.9160 - val_accuracy: 0.6426\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 2.0436 - val_accuracy: 0.6178\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 2.0507 - val_accuracy: 0.6312\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 2.0487 - val_accuracy: 0.6436\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0518 - accuracy: 0.9853 - val_loss: 2.1049 - val_accuracy: 0.6457\n","Epoch 68/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0437 - accuracy: 0.9879 - val_loss: 2.1669 - val_accuracy: 0.6529\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0920 - accuracy: 0.9705 - val_loss: 1.8785 - val_accuracy: 0.6374\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0984 - accuracy: 0.9680 - val_loss: 1.6961 - val_accuracy: 0.6415\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0562 - accuracy: 0.9860 - val_loss: 1.9249 - val_accuracy: 0.6405\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0440 - accuracy: 0.9884 - val_loss: 2.1415 - val_accuracy: 0.6384\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0399 - accuracy: 0.9917 - val_loss: 2.1568 - val_accuracy: 0.6384\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0359 - accuracy: 0.9928 - val_loss: 2.2871 - val_accuracy: 0.6333\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0441 - accuracy: 0.9868 - val_loss: 2.0560 - val_accuracy: 0.6581\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0432 - accuracy: 0.9884 - val_loss: 2.1366 - val_accuracy: 0.6364\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0403 - accuracy: 0.9894 - val_loss: 2.1275 - val_accuracy: 0.6322\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0430 - accuracy: 0.9886 - val_loss: 2.1012 - val_accuracy: 0.6333\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0393 - accuracy: 0.9899 - val_loss: 2.0884 - val_accuracy: 0.6519\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0341 - accuracy: 0.9938 - val_loss: 2.1631 - val_accuracy: 0.6446\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0406 - accuracy: 0.9886 - val_loss: 2.2618 - val_accuracy: 0.6508\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0386 - accuracy: 0.9917 - val_loss: 2.3298 - val_accuracy: 0.6374\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0370 - accuracy: 0.9915 - val_loss: 2.1944 - val_accuracy: 0.6209\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 2.1620 - val_accuracy: 0.6364\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 2.2500 - val_accuracy: 0.6343\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0425 - accuracy: 0.9876 - val_loss: 2.1096 - val_accuracy: 0.6395\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0392 - accuracy: 0.9897 - val_loss: 2.1653 - val_accuracy: 0.6353\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0337 - accuracy: 0.9935 - val_loss: 2.1985 - val_accuracy: 0.6436\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9938 - val_loss: 2.2631 - val_accuracy: 0.6405\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0377 - accuracy: 0.9917 - val_loss: 2.6256 - val_accuracy: 0.6281\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0572 - accuracy: 0.9817 - val_loss: 2.1465 - val_accuracy: 0.6250\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0709 - accuracy: 0.9765 - val_loss: 1.9434 - val_accuracy: 0.6271\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0858 - accuracy: 0.9685 - val_loss: 1.7913 - val_accuracy: 0.6436\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0712 - accuracy: 0.9765 - val_loss: 1.7762 - val_accuracy: 0.6364\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 2.1448 - val_accuracy: 0.6353\n","Epoch 96/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0540 - accuracy: 0.9860 - val_loss: 1.9949 - val_accuracy: 0.6405\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0450 - accuracy: 0.9876 - val_loss: 2.1970 - val_accuracy: 0.6250\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0480 - accuracy: 0.9871 - val_loss: 2.1442 - val_accuracy: 0.6209\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0419 - accuracy: 0.9904 - val_loss: 2.0813 - val_accuracy: 0.6147\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0306 - accuracy: 0.9959 - val_loss: 2.1978 - val_accuracy: 0.6198\n","{'loss': [0.5149954557418823, 0.37586724758148193, 0.29697176814079285, 0.23618845641613007, 0.20275220274925232, 0.2124001681804657, 0.2045585811138153, 0.14869077503681183, 0.13952340185642242, 0.14394859969615936, 0.1727375090122223, 0.15183456242084503, 0.13474880158901215, 0.10704316943883896, 0.09086646139621735, 0.10994262248277664, 0.11058275401592255, 0.11127357929944992, 0.12137002497911453, 0.10105324536561966, 0.09627338498830795, 0.11958456039428711, 0.10822641104459763, 0.10354070365428925, 0.1147841140627861, 0.10676445811986923, 0.07996512204408646, 0.07220247387886047, 0.10818040370941162, 0.08913608640432358, 0.07631959766149521, 0.08224456757307053, 0.08058687299489975, 0.07560689747333527, 0.07249120622873306, 0.0606473833322525, 0.06879320740699768, 0.08656903356313705, 0.07185447961091995, 0.05924795940518379, 0.05781847983598709, 0.10557985305786133, 0.08437275141477585, 0.07858054339885712, 0.07180694490671158, 0.06836550682783127, 0.06558068841695786, 0.06577983498573303, 0.06475233286619186, 0.059029579162597656, 0.06668480485677719, 0.05756599083542824, 0.053359001874923706, 0.05907054618000984, 0.047360096126794815, 0.04992733523249626, 0.043038882315158844, 0.06187189370393753, 0.06932494044303894, 0.13629691302776337, 0.07879740744829178, 0.08745454996824265, 0.06998401135206223, 0.056009188294410706, 0.060997169464826584, 0.053660038858652115, 0.05175526440143585, 0.04365124925971031, 0.09196246415376663, 0.09835539758205414, 0.05617528036236763, 0.04400945454835892, 0.0398864708840847, 0.035864073783159256, 0.04406626150012016, 0.043204788118600845, 0.04028145968914032, 0.04302707314491272, 0.03926282376050949, 0.03411136195063591, 0.04055449366569519, 0.038576651364564896, 0.03699486330151558, 0.03666171804070473, 0.03771556168794632, 0.04251234978437424, 0.03921328857541084, 0.033740367740392685, 0.03233208507299423, 0.037675559520721436, 0.057239461690187454, 0.07085970044136047, 0.08581830561161041, 0.07120012491941452, 0.046020302921533585, 0.05399046465754509, 0.04499228298664093, 0.048025015741586685, 0.04187341406941414, 0.030603615567088127], 'accuracy': [0.7635658979415894, 0.8403100967407227, 0.8762273788452148, 0.9025839567184448, 0.9204134345054626, 0.9142118692398071, 0.9209302067756653, 0.9459948539733887, 0.9459948539733887, 0.9478036165237427, 0.9328165650367737, 0.9452196359634399, 0.9506459832191467, 0.9656330943107605, 0.9713178277015686, 0.9633074998855591, 0.9635658860206604, 0.964082658290863, 0.9560723304748535, 0.9682170748710632, 0.9697674512863159, 0.960465133190155, 0.964082658290863, 0.964082658290863, 0.9568475484848022, 0.9633074998855591, 0.9788113832473755, 0.9772610068321228, 0.9620155096054077, 0.9728682041168213, 0.9767441749572754, 0.975452184677124, 0.9746770262718201, 0.9764857888221741, 0.9775193929672241, 0.9832041263580322, 0.9795865416526794, 0.9715762138366699, 0.9795865416526794, 0.985788106918335, 0.9847545027732849, 0.9648578763008118, 0.9720930457115173, 0.974418580532074, 0.9767441749572754, 0.9785529971122742, 0.9813953638076782, 0.9821705222129822, 0.9813953638076782, 0.9832041263580322, 0.9795865416526794, 0.9824289679527283, 0.9870800971984863, 0.9819121360778809, 0.9883720874786377, 0.9870800971984863, 0.9912144541740417, 0.9826873540878296, 0.9785529971122742, 0.9524548053741455, 0.975452184677124, 0.9700258374214172, 0.9785529971122742, 0.9821705222129822, 0.9806201457977295, 0.985788106918335, 0.9852713346481323, 0.9878553152084351, 0.9705426096916199, 0.9679586291313171, 0.9860464930534363, 0.9883720874786377, 0.9917312860488892, 0.9927648305892944, 0.986821711063385, 0.9883720874786377, 0.9894056916236877, 0.988630473613739, 0.9899224638938904, 0.9937984347343445, 0.988630473613739, 0.9917312860488892, 0.9914728403091431, 0.9909560680389404, 0.9904392957687378, 0.987596869468689, 0.9896640777587891, 0.9935400485992432, 0.9937984347343445, 0.9917312860488892, 0.9816537499427795, 0.9764857888221741, 0.9684754610061646, 0.9764857888221741, 0.985788106918335, 0.9860464930534363, 0.987596869468689, 0.9870800971984863, 0.9904392957687378, 0.9958656430244446], 'val_loss': [0.7130943536758423, 0.7127231359481812, 0.7120180130004883, 0.7109056711196899, 0.7074826955795288, 0.7030203938484192, 0.7025205492973328, 0.6929661631584167, 0.6882472038269043, 0.6763024926185608, 0.6885145902633667, 0.6911872029304504, 0.6938212513923645, 0.7374536991119385, 0.8311790823936462, 0.9165025949478149, 0.9510754942893982, 1.0526211261749268, 1.117719054222107, 1.299001693725586, 1.4398647546768188, 1.447169542312622, 1.5291744470596313, 1.6490561962127686, 1.7467243671417236, 1.67966890335083, 1.8026412725448608, 1.927971601486206, 1.7268688678741455, 1.8554047346115112, 2.045285701751709, 2.0010907649993896, 1.9167845249176025, 1.9398484230041504, 1.9908162355422974, 2.120185375213623, 2.197408676147461, 2.097172975540161, 2.061192035675049, 2.073509931564331, 2.3105366230010986, 1.9784847497940063, 1.9027936458587646, 1.927329659461975, 2.047152280807495, 2.0648353099823, 1.993930697441101, 2.1820623874664307, 2.1893136501312256, 2.208462715148926, 2.0649049282073975, 2.133517265319824, 2.335653781890869, 2.199355125427246, 2.2011754512786865, 2.199249744415283, 2.3804595470428467, 2.2141590118408203, 2.2579751014709473, 1.6620924472808838, 1.830654263496399, 2.12465238571167, 1.9160326719284058, 2.0436489582061768, 2.050712823867798, 2.0486679077148438, 2.104937791824341, 2.1669023036956787, 1.878494381904602, 1.6960692405700684, 1.9249225854873657, 2.1415083408355713, 2.1568403244018555, 2.2871406078338623, 2.0560033321380615, 2.136573076248169, 2.127532482147217, 2.1012203693389893, 2.088418960571289, 2.1630520820617676, 2.261777400970459, 2.3298466205596924, 2.1943671703338623, 2.1619932651519775, 2.250037908554077, 2.109649181365967, 2.165264844894409, 2.198471784591675, 2.2631428241729736, 2.6256392002105713, 2.146481990814209, 1.9434441328048706, 1.791314721107483, 1.77615487575531, 2.144801616668701, 1.994938850402832, 2.196988105773926, 2.144155979156494, 2.0812978744506836, 2.197845697402954], 'val_accuracy': [0.5165289044380188, 0.5237603187561035, 0.5309917330741882, 0.5299586653709412, 0.5464876294136047, 0.5847107172012329, 0.5495867729187012, 0.5785123705863953, 0.567148745059967, 0.6115702390670776, 0.58574378490448, 0.5847107172012329, 0.6301652789115906, 0.6115702390670776, 0.6219007968902588, 0.5929751992225647, 0.6260330677032471, 0.6229338645935059, 0.6270661354064941, 0.6301652789115906, 0.6280992031097412, 0.6301652789115906, 0.6167355179786682, 0.6311983466148376, 0.6136363744735718, 0.6311983466148376, 0.6404958963394165, 0.6219007968902588, 0.6384297609329224, 0.6332644820213318, 0.6301652789115906, 0.6198347210884094, 0.6311983466148376, 0.6404958963394165, 0.6404958963394165, 0.6301652789115906, 0.6425619721412659, 0.625, 0.6487603187561035, 0.6332644820213318, 0.625, 0.6229338645935059, 0.6301652789115906, 0.6435950398445129, 0.6342975497245789, 0.6353305578231812, 0.6373966932296753, 0.6198347210884094, 0.6311983466148376, 0.625, 0.64462810754776, 0.6363636255264282, 0.6291322112083435, 0.6342975497245789, 0.6373966932296753, 0.6508264541625977, 0.6404958963394165, 0.6425619721412659, 0.6033057570457458, 0.6064049601554871, 0.6126033067703247, 0.6188016533851624, 0.6425619721412659, 0.6177685856819153, 0.6311983466148376, 0.6435950398445129, 0.6456611752510071, 0.6528925895690918, 0.6373966932296753, 0.6415289044380188, 0.6404958963394165, 0.6384297609329224, 0.6384297609329224, 0.6332644820213318, 0.6580578684806824, 0.6363636255264282, 0.6322314143180847, 0.6332644820213318, 0.6518595218658447, 0.64462810754776, 0.6508264541625977, 0.6373966932296753, 0.6208677887916565, 0.6363636255264282, 0.6342975497245789, 0.6394628286361694, 0.6353305578231812, 0.6435950398445129, 0.6404958963394165, 0.6280992031097412, 0.625, 0.6270661354064941, 0.6435950398445129, 0.6363636255264282, 0.6353305578231812, 0.6404958963394165, 0.625, 0.6208677887916565, 0.6146694421768188, 0.6198347210884094]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.1444 - accuracy: 0.9585"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 61ms/step - loss: 0.1419 - accuracy: 0.9588 - val_loss: 0.6987 - val_accuracy: 0.5172\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0727 - accuracy: 0.9803 - val_loss: 0.6953 - val_accuracy: 0.5194\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0478 - accuracy: 0.9871 - val_loss: 0.6868 - val_accuracy: 0.5409\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0442 - accuracy: 0.9890 - val_loss: 0.6783 - val_accuracy: 0.5420\n","Epoch 5/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0438 - accuracy: 0.9890 - val_loss: 0.6562 - val_accuracy: 0.6250\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0444 - accuracy: 0.9873 - val_loss: 0.6434 - val_accuracy: 0.6390\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0725 - accuracy: 0.9766 - val_loss: 0.6444 - val_accuracy: 0.6013\n","Epoch 8/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0750 - accuracy: 0.9744 - val_loss: 0.6246 - val_accuracy: 0.6649\n","Epoch 9/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0750 - accuracy: 0.9752 - val_loss: 0.6075 - val_accuracy: 0.7134\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0440 - accuracy: 0.9906 - val_loss: 0.5986 - val_accuracy: 0.6735\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0346 - accuracy: 0.9914 - val_loss: 0.5559 - val_accuracy: 0.7371\n","Epoch 12/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 0.5211 - val_accuracy: 0.7748\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0323 - accuracy: 0.9935 - val_loss: 0.5314 - val_accuracy: 0.7737\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0289 - accuracy: 0.9941 - val_loss: 0.5392 - val_accuracy: 0.7737\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0307 - accuracy: 0.9938 - val_loss: 0.5790 - val_accuracy: 0.7791\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0316 - accuracy: 0.9933 - val_loss: 0.5640 - val_accuracy: 0.7920\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0375 - accuracy: 0.9898 - val_loss: 0.6298 - val_accuracy: 0.7845\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0677 - accuracy: 0.9795 - val_loss: 0.6103 - val_accuracy: 0.7834\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.6854 - val_accuracy: 0.7629\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0634 - accuracy: 0.9793 - val_loss: 0.6889 - val_accuracy: 0.7705\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0500 - accuracy: 0.9849 - val_loss: 0.7164 - val_accuracy: 0.7920\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0347 - accuracy: 0.9938 - val_loss: 0.7858 - val_accuracy: 0.7856\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0285 - accuracy: 0.9941 - val_loss: 0.8442 - val_accuracy: 0.7920\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0274 - accuracy: 0.9946 - val_loss: 0.9505 - val_accuracy: 0.7877\n","Epoch 25/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0256 - accuracy: 0.9952 - val_loss: 0.9897 - val_accuracy: 0.7963\n","Epoch 26/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 1.0024 - val_accuracy: 0.8028\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0344 - accuracy: 0.9916 - val_loss: 1.0415 - val_accuracy: 0.7931\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0373 - accuracy: 0.9906 - val_loss: 1.0657 - val_accuracy: 0.7823\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0332 - accuracy: 0.9938 - val_loss: 1.0391 - val_accuracy: 0.8028\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0373 - accuracy: 0.9919 - val_loss: 1.0911 - val_accuracy: 0.7769\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0498 - accuracy: 0.9857 - val_loss: 1.0291 - val_accuracy: 0.7780\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0704 - accuracy: 0.9768 - val_loss: 1.0582 - val_accuracy: 0.7532\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0551 - accuracy: 0.9841 - val_loss: 0.8457 - val_accuracy: 0.7888\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0496 - accuracy: 0.9865 - val_loss: 0.9279 - val_accuracy: 0.7909\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0386 - accuracy: 0.9927 - val_loss: 0.9352 - val_accuracy: 0.7845\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 1.1324 - val_accuracy: 0.7672\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0418 - accuracy: 0.9876 - val_loss: 1.0532 - val_accuracy: 0.7716\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0297 - accuracy: 0.9941 - val_loss: 1.0135 - val_accuracy: 0.7920\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0337 - accuracy: 0.9919 - val_loss: 1.1509 - val_accuracy: 0.7640\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 1.2094 - val_accuracy: 0.7640\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9943 - val_loss: 1.1981 - val_accuracy: 0.7683\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 0.9960 - val_loss: 1.2737 - val_accuracy: 0.7575\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0271 - accuracy: 0.9941 - val_loss: 1.1389 - val_accuracy: 0.7748\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 0.9930 - val_loss: 1.2738 - val_accuracy: 0.7554\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9930 - val_loss: 1.3517 - val_accuracy: 0.7489\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.9952 - val_loss: 1.2114 - val_accuracy: 0.7737\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0324 - accuracy: 0.9919 - val_loss: 1.1072 - val_accuracy: 0.7705\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 1.2212 - val_accuracy: 0.7597\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9970 - val_loss: 1.1888 - val_accuracy: 0.7759\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0265 - accuracy: 0.9946 - val_loss: 1.3890 - val_accuracy: 0.7435\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0530 - accuracy: 0.9860 - val_loss: 1.1547 - val_accuracy: 0.7629\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 1.0301 - val_accuracy: 0.7748\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 0.9844 - val_loss: 1.0809 - val_accuracy: 0.7672\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0487 - accuracy: 0.9857 - val_loss: 1.3331 - val_accuracy: 0.7349\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0607 - accuracy: 0.9798 - val_loss: 1.0885 - val_accuracy: 0.7478\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0374 - accuracy: 0.9903 - val_loss: 1.0779 - val_accuracy: 0.7608\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 1.1491 - val_accuracy: 0.7597\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0205 - accuracy: 0.9973 - val_loss: 1.2886 - val_accuracy: 0.7651\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0205 - accuracy: 0.9968 - val_loss: 1.2821 - val_accuracy: 0.7726\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0182 - accuracy: 0.9981 - val_loss: 1.2403 - val_accuracy: 0.7683\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0191 - accuracy: 0.9968 - val_loss: 1.2528 - val_accuracy: 0.7759\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 1.2379 - val_accuracy: 0.7597\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 1.2799 - val_accuracy: 0.7748\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9978 - val_loss: 1.2482 - val_accuracy: 0.7769\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 0.9976 - val_loss: 1.2277 - val_accuracy: 0.7759\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 0.9978 - val_loss: 1.2698 - val_accuracy: 0.7651\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9976 - val_loss: 1.2326 - val_accuracy: 0.7812\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9970 - val_loss: 1.1882 - val_accuracy: 0.7823\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9981 - val_loss: 1.1538 - val_accuracy: 0.7877\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 1.1751 - val_accuracy: 0.7780\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9919 - val_loss: 1.1231 - val_accuracy: 0.7694\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 1.0910 - val_accuracy: 0.7597\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 1.2119 - val_accuracy: 0.7586\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9978 - val_loss: 1.2564 - val_accuracy: 0.7651\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 0.9978 - val_loss: 1.2163 - val_accuracy: 0.7759\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 0.9984 - val_loss: 1.2359 - val_accuracy: 0.7759\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9965 - val_loss: 1.2035 - val_accuracy: 0.7769\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0456 - accuracy: 0.9871 - val_loss: 1.1428 - val_accuracy: 0.7651\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0353 - accuracy: 0.9898 - val_loss: 1.1111 - val_accuracy: 0.7672\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0468 - accuracy: 0.9892 - val_loss: 1.1760 - val_accuracy: 0.7360\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 1.1782 - val_accuracy: 0.7371\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 1.4050 - val_accuracy: 0.7328\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9943 - val_loss: 1.3337 - val_accuracy: 0.7468\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0546 - accuracy: 0.9830 - val_loss: 1.1865 - val_accuracy: 0.7425\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0563 - accuracy: 0.9822 - val_loss: 1.1863 - val_accuracy: 0.7241\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0507 - accuracy: 0.9857 - val_loss: 1.0789 - val_accuracy: 0.7349\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 1.2216 - val_accuracy: 0.7274\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0200 - accuracy: 0.9965 - val_loss: 1.3144 - val_accuracy: 0.7328\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9984 - val_loss: 1.3261 - val_accuracy: 0.7457\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.9984 - val_loss: 1.4342 - val_accuracy: 0.7371\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0154 - accuracy: 0.9981 - val_loss: 1.4777 - val_accuracy: 0.7403\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 0.9973 - val_loss: 1.2493 - val_accuracy: 0.7511\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0179 - accuracy: 0.9970 - val_loss: 1.3857 - val_accuracy: 0.7317\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0224 - accuracy: 0.9954 - val_loss: 1.3094 - val_accuracy: 0.7532\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0220 - accuracy: 0.9957 - val_loss: 1.3113 - val_accuracy: 0.7392\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 1.1747 - val_accuracy: 0.7435\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 1.3248 - val_accuracy: 0.7446\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9989 - val_loss: 1.3081 - val_accuracy: 0.7478\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 1.8852 - val_accuracy: 0.6950\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 1.1830 - val_accuracy: 0.7306\n","{'loss': [0.1418597251176834, 0.0727466568350792, 0.04783725365996361, 0.04419143497943878, 0.04378432780504227, 0.04440243914723396, 0.07249274849891663, 0.07501456886529922, 0.07498715072870255, 0.044043783098459244, 0.03461397439241409, 0.03886749967932701, 0.03227340430021286, 0.028879720717668533, 0.030655808746814728, 0.031575825065374374, 0.037480246275663376, 0.0677044689655304, 0.053151581436395645, 0.06341725587844849, 0.04997731372714043, 0.034661222249269485, 0.028541380539536476, 0.027443131431937218, 0.02563396841287613, 0.03289263695478439, 0.034420162439346313, 0.03733515366911888, 0.03321593627333641, 0.037301596254110336, 0.04975196346640587, 0.0703982338309288, 0.05505185201764107, 0.04964391142129898, 0.038614124059677124, 0.038914259523153305, 0.04177726432681084, 0.02972514182329178, 0.03366685286164284, 0.03227321803569794, 0.03118949383497238, 0.026708479970693588, 0.027137653902173042, 0.02880742959678173, 0.026500046253204346, 0.02416948415338993, 0.032372601330280304, 0.026838237419724464, 0.022170405834913254, 0.026512842625379562, 0.05302170291543007, 0.0370996929705143, 0.04817758873105049, 0.048733148723840714, 0.060709912329912186, 0.037395089864730835, 0.027642209082841873, 0.020459214225411415, 0.020492883399128914, 0.018247956410050392, 0.01913389191031456, 0.020119106397032738, 0.020737754181027412, 0.016802938655018806, 0.017104195430874825, 0.016212686896324158, 0.017578033730387688, 0.019830558449029922, 0.01779928058385849, 0.017968354746699333, 0.02924819476902485, 0.0300938468426466, 0.023597853258252144, 0.01745288446545601, 0.018825577571988106, 0.01590617001056671, 0.020720357075333595, 0.04558601975440979, 0.03525744751095772, 0.046784210950136185, 0.03382495418190956, 0.031765587627887726, 0.027625447139143944, 0.054578930139541626, 0.056338220834732056, 0.05071699619293213, 0.030218685045838356, 0.01999790221452713, 0.016128089278936386, 0.015635646879673004, 0.015415304340422153, 0.019107574597001076, 0.017920471727848053, 0.02243896946310997, 0.022049108520150185, 0.02222677692770958, 0.019015485420823097, 0.015872154384851456, 0.018584825098514557, 0.045779913663864136], 'accuracy': [0.9587823152542114, 0.9803340435028076, 0.9870689511299133, 0.9889547228813171, 0.9889547228813171, 0.9873383641242981, 0.9765625, 0.9744073152542114, 0.975215494632721, 0.990571141242981, 0.9913793206214905, 0.9900323152542114, 0.993534505367279, 0.9940732717514038, 0.993803858757019, 0.9932650923728943, 0.9897629022598267, 0.9795258641242981, 0.984375, 0.9792564511299133, 0.9849137663841248, 0.993803858757019, 0.9940732717514038, 0.9946120977401733, 0.9951508641242981, 0.9911099076271057, 0.9916487336158752, 0.990571141242981, 0.993803858757019, 0.9919180870056152, 0.985722005367279, 0.9768319129943848, 0.9841055870056152, 0.9865301847457886, 0.9927262663841248, 0.9900323152542114, 0.9876077771186829, 0.9940732717514038, 0.9919180870056152, 0.9911099076271057, 0.9943426847457886, 0.9959590435028076, 0.9940732717514038, 0.9929956793785095, 0.9929956793785095, 0.9951508641242981, 0.9919180870056152, 0.993803858757019, 0.9970366358757019, 0.9946120977401733, 0.985991358757019, 0.9897629022598267, 0.984375, 0.985722005367279, 0.9797952771186829, 0.9903017282485962, 0.993534505367279, 0.9973060488700867, 0.9967672228813171, 0.9981142282485962, 0.9967672228813171, 0.9954202771186829, 0.9956896305084229, 0.9978448152542114, 0.9975754022598267, 0.9978448152542114, 0.9975754022598267, 0.9970366358757019, 0.9981142282485962, 0.9975754022598267, 0.9919180870056152, 0.9929956793785095, 0.9956896305084229, 0.9978448152542114, 0.9978448152542114, 0.998383641242981, 0.9964978694915771, 0.9870689511299133, 0.9897629022598267, 0.9892241358757019, 0.9897629022598267, 0.9911099076271057, 0.9943426847457886, 0.983027994632721, 0.9822198152542114, 0.985722005367279, 0.9927262663841248, 0.9964978694915771, 0.998383641242981, 0.998383641242981, 0.9981142282485962, 0.9973060488700867, 0.9970366358757019, 0.9954202771186829, 0.9956896305084229, 0.993803858757019, 0.9970366358757019, 0.9989224076271057, 0.9962284564971924, 0.9862607717514038], 'val_loss': [0.6986911296844482, 0.6952528357505798, 0.686779797077179, 0.6783261895179749, 0.6562496423721313, 0.6434258818626404, 0.6443607807159424, 0.6246157884597778, 0.6074602007865906, 0.5986226201057434, 0.5558758974075317, 0.521070659160614, 0.5314170122146606, 0.5391956567764282, 0.5790401697158813, 0.5639716386795044, 0.6297613382339478, 0.610342264175415, 0.685408353805542, 0.6888823509216309, 0.7163742780685425, 0.7857985496520996, 0.8441550731658936, 0.9504883885383606, 0.9896888732910156, 1.0024397373199463, 1.0415208339691162, 1.0657004117965698, 1.0390803813934326, 1.091090202331543, 1.0291317701339722, 1.058163046836853, 0.8457095623016357, 0.9279191493988037, 0.9351971745491028, 1.1323697566986084, 1.0531588792800903, 1.0134727954864502, 1.1509324312210083, 1.2093948125839233, 1.198065161705017, 1.2737294435501099, 1.1388816833496094, 1.2738178968429565, 1.351706624031067, 1.2113677263259888, 1.107163429260254, 1.2212461233139038, 1.1888442039489746, 1.3890172243118286, 1.1547185182571411, 1.030097246170044, 1.0808970928192139, 1.3331475257873535, 1.088454246520996, 1.0778597593307495, 1.1490626335144043, 1.2885522842407227, 1.2821295261383057, 1.2403054237365723, 1.2527525424957275, 1.2379062175750732, 1.2798584699630737, 1.248167872428894, 1.2276513576507568, 1.269766092300415, 1.2326316833496094, 1.1881673336029053, 1.1537785530090332, 1.1750738620758057, 1.123067021369934, 1.0909630060195923, 1.2118531465530396, 1.2564257383346558, 1.2163444757461548, 1.235862374305725, 1.203495740890503, 1.1428414583206177, 1.1110514402389526, 1.1760083436965942, 1.1781631708145142, 1.40498948097229, 1.3336979150772095, 1.1865437030792236, 1.186298131942749, 1.0788966417312622, 1.221558690071106, 1.3144073486328125, 1.3260551691055298, 1.434220552444458, 1.4777216911315918, 1.2493144273757935, 1.3856598138809204, 1.3094086647033691, 1.311264991760254, 1.1746535301208496, 1.324803113937378, 1.3080625534057617, 1.8852301836013794, 1.1830096244812012], 'val_accuracy': [0.517241358757019, 0.5193965435028076, 0.5409482717514038, 0.5420258641242981, 0.625, 0.639008641242981, 0.6012930870056152, 0.6648706793785095, 0.7133620977401733, 0.673491358757019, 0.7370689511299133, 0.774784505367279, 0.7737069129943848, 0.7737069129943848, 0.7790948152542114, 0.7920258641242981, 0.7844827771186829, 0.7834051847457886, 0.7629310488700867, 0.7704741358757019, 0.7920258641242981, 0.7855603694915771, 0.7920258641242981, 0.787715494632721, 0.7963362336158752, 0.8028017282485962, 0.7931034564971924, 0.7823275923728943, 0.8028017282485962, 0.7769396305084229, 0.7780172228813171, 0.7532327771186829, 0.7887930870056152, 0.7909482717514038, 0.7844827771186829, 0.767241358757019, 0.7715517282485962, 0.7920258641242981, 0.764008641242981, 0.764008641242981, 0.7683189511299133, 0.7575430870056152, 0.774784505367279, 0.7553879022598267, 0.7489224076271057, 0.7737069129943848, 0.7704741358757019, 0.7596982717514038, 0.7758620977401733, 0.743534505367279, 0.7629310488700867, 0.774784505367279, 0.767241358757019, 0.7349137663841248, 0.7478448152542114, 0.7607758641242981, 0.7596982717514038, 0.7650862336158752, 0.7726293206214905, 0.7683189511299133, 0.7758620977401733, 0.7596982717514038, 0.774784505367279, 0.7769396305084229, 0.7758620977401733, 0.7650862336158752, 0.78125, 0.7823275923728943, 0.787715494632721, 0.7780172228813171, 0.7693965435028076, 0.7596982717514038, 0.7586206793785095, 0.7650862336158752, 0.7758620977401733, 0.7758620977401733, 0.7769396305084229, 0.7650862336158752, 0.767241358757019, 0.735991358757019, 0.7370689511299133, 0.732758641242981, 0.7467672228813171, 0.7424569129943848, 0.7241379022598267, 0.7349137663841248, 0.7273706793785095, 0.732758641242981, 0.7456896305084229, 0.7370689511299133, 0.7403017282485962, 0.7510775923728943, 0.7316810488700867, 0.7532327771186829, 0.7392241358757019, 0.743534505367279, 0.7446120977401733, 0.7478448152542114, 0.6950430870056152, 0.7306034564971924]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.1293 - accuracy: 0.9579"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 59ms/step - loss: 0.1292 - accuracy: 0.9570 - val_loss: 0.6974 - val_accuracy: 0.5238\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0831 - accuracy: 0.9717 - val_loss: 0.6955 - val_accuracy: 0.5102\n","Epoch 3/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0519 - accuracy: 0.9875 - val_loss: 0.6847 - val_accuracy: 0.5396\n","Epoch 4/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0327 - accuracy: 0.9946 - val_loss: 0.6723 - val_accuracy: 0.5543\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0368 - accuracy: 0.9918 - val_loss: 0.6541 - val_accuracy: 0.6018\n","Epoch 6/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.6343 - val_accuracy: 0.6697\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0546 - accuracy: 0.9856 - val_loss: 0.6520 - val_accuracy: 0.5701\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0709 - accuracy: 0.9748 - val_loss: 0.6382 - val_accuracy: 0.6063\n","Epoch 9/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0579 - accuracy: 0.9839 - val_loss: 0.6004 - val_accuracy: 0.7172\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 0.5785 - val_accuracy: 0.7149\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 0.5458 - val_accuracy: 0.7726\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.5786 - val_accuracy: 0.7093\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0563 - accuracy: 0.9847 - val_loss: 0.5419 - val_accuracy: 0.7557\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0570 - accuracy: 0.9836 - val_loss: 0.5709 - val_accuracy: 0.7353\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0482 - accuracy: 0.9867 - val_loss: 0.5589 - val_accuracy: 0.7489\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0431 - accuracy: 0.9887 - val_loss: 0.5898 - val_accuracy: 0.7432\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9932 - val_loss: 0.5783 - val_accuracy: 0.7670\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0268 - accuracy: 0.9955 - val_loss: 0.6125 - val_accuracy: 0.7851\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9955 - val_loss: 0.6475 - val_accuracy: 0.7715\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0299 - accuracy: 0.9935 - val_loss: 0.7014 - val_accuracy: 0.7885\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.6841 - val_accuracy: 0.7817\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0322 - accuracy: 0.9926 - val_loss: 0.7183 - val_accuracy: 0.7907\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0320 - accuracy: 0.9926 - val_loss: 0.8507 - val_accuracy: 0.7794\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0462 - accuracy: 0.9875 - val_loss: 0.9514 - val_accuracy: 0.7692\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0390 - accuracy: 0.9907 - val_loss: 0.7655 - val_accuracy: 0.7998\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0347 - accuracy: 0.9926 - val_loss: 0.9475 - val_accuracy: 0.7738\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 0.9929 - val_loss: 1.0034 - val_accuracy: 0.7760\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0422 - accuracy: 0.9901 - val_loss: 1.0582 - val_accuracy: 0.7726\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 1.0294 - val_accuracy: 0.7500\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0863 - accuracy: 0.9714 - val_loss: 0.8684 - val_accuracy: 0.7647\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 0.9864 - val_loss: 0.8818 - val_accuracy: 0.7794\n","Epoch 32/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0355 - accuracy: 0.9907 - val_loss: 0.9385 - val_accuracy: 0.7738\n","Epoch 33/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0317 - accuracy: 0.9924 - val_loss: 1.0544 - val_accuracy: 0.7738\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0408 - accuracy: 0.9892 - val_loss: 1.0374 - val_accuracy: 0.7783\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9921 - val_loss: 1.0101 - val_accuracy: 0.7828\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 0.9946 - val_loss: 1.0981 - val_accuracy: 0.7692\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0350 - accuracy: 0.9904 - val_loss: 1.1306 - val_accuracy: 0.7738\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 1.0923 - val_accuracy: 0.7726\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0399 - accuracy: 0.9898 - val_loss: 1.1739 - val_accuracy: 0.7590\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0376 - accuracy: 0.9898 - val_loss: 1.0598 - val_accuracy: 0.7771\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 0.9929 - val_loss: 1.1940 - val_accuracy: 0.7534\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 0.9980 - val_loss: 1.2900 - val_accuracy: 0.7489\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 1.2649 - val_accuracy: 0.7590\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.9960 - val_loss: 1.2084 - val_accuracy: 0.7726\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9963 - val_loss: 1.1840 - val_accuracy: 0.7624\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 1.1883 - val_accuracy: 0.7658\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9992 - val_loss: 1.2256 - val_accuracy: 0.7613\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 0.9986 - val_loss: 1.2513 - val_accuracy: 0.7704\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 0.9989 - val_loss: 1.1977 - val_accuracy: 0.7681\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9935 - val_loss: 1.1549 - val_accuracy: 0.7647\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9932 - val_loss: 1.0714 - val_accuracy: 0.7885\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 0.9963 - val_loss: 1.1561 - val_accuracy: 0.7771\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9955 - val_loss: 1.0774 - val_accuracy: 0.7738\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9975 - val_loss: 1.1122 - val_accuracy: 0.7715\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 1.0947 - val_accuracy: 0.7794\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0263 - accuracy: 0.9946 - val_loss: 1.1273 - val_accuracy: 0.7715\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 1.1914 - val_accuracy: 0.7670\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9952 - val_loss: 1.1473 - val_accuracy: 0.7715\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 1.2063 - val_accuracy: 0.7647\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0504 - accuracy: 0.9859 - val_loss: 1.2712 - val_accuracy: 0.7296\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0462 - accuracy: 0.9875 - val_loss: 1.1884 - val_accuracy: 0.7443\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 1.1016 - val_accuracy: 0.7613\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0487 - accuracy: 0.9873 - val_loss: 1.1629 - val_accuracy: 0.7432\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9887 - val_loss: 1.1704 - val_accuracy: 0.7477\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0459 - accuracy: 0.9870 - val_loss: 1.0045 - val_accuracy: 0.7681\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 1.1684 - val_accuracy: 0.7545\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0243 - accuracy: 0.9943 - val_loss: 1.2490 - val_accuracy: 0.7636\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0307 - accuracy: 0.9943 - val_loss: 1.1764 - val_accuracy: 0.7647\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0350 - accuracy: 0.9892 - val_loss: 1.3436 - val_accuracy: 0.7251\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 1.0894 - val_accuracy: 0.7376\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0422 - accuracy: 0.9887 - val_loss: 1.0190 - val_accuracy: 0.7590\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 1.1455 - val_accuracy: 0.7489\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 1.2414 - val_accuracy: 0.7376\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9955 - val_loss: 1.3799 - val_accuracy: 0.7229\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9975 - val_loss: 1.3627 - val_accuracy: 0.7387\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9943 - val_loss: 1.2562 - val_accuracy: 0.7590\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9972 - val_loss: 1.2179 - val_accuracy: 0.7681\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 0.9972 - val_loss: 1.2492 - val_accuracy: 0.7579\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9955 - val_loss: 1.1829 - val_accuracy: 0.7624\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9972 - val_loss: 1.1942 - val_accuracy: 0.7557\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 1.1651 - val_accuracy: 0.7636\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 1.2587 - val_accuracy: 0.7557\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9977 - val_loss: 1.2310 - val_accuracy: 0.7602\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9980 - val_loss: 1.2094 - val_accuracy: 0.7602\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0146 - accuracy: 0.9983 - val_loss: 1.2728 - val_accuracy: 0.7557\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9977 - val_loss: 1.2624 - val_accuracy: 0.7624\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9972 - val_loss: 1.2155 - val_accuracy: 0.7624\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 0.9997 - val_loss: 1.2572 - val_accuracy: 0.7670\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9997 - val_loss: 1.2689 - val_accuracy: 0.7647\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9986 - val_loss: 1.2608 - val_accuracy: 0.7692\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9977 - val_loss: 1.3105 - val_accuracy: 0.7557\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 1.1939 - val_accuracy: 0.7636\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 1.0853 - val_accuracy: 0.7670\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 1.1692 - val_accuracy: 0.7636\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0157 - accuracy: 0.9983 - val_loss: 1.2377 - val_accuracy: 0.7636\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9986 - val_loss: 1.3120 - val_accuracy: 0.7613\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.9986 - val_loss: 1.2788 - val_accuracy: 0.7568\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0133 - accuracy: 0.9989 - val_loss: 1.3748 - val_accuracy: 0.7579\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 1.3239 - val_accuracy: 0.7534\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9986 - val_loss: 1.2315 - val_accuracy: 0.7602\n","{'loss': [0.12918026745319366, 0.0831385925412178, 0.05185860022902489, 0.03269372135400772, 0.03676031529903412, 0.039141811430454254, 0.05460201948881149, 0.07091749459505081, 0.0578700453042984, 0.046217020601034164, 0.04601304605603218, 0.06466835737228394, 0.05631795525550842, 0.05695164576172829, 0.048178646713495255, 0.04308337718248367, 0.032273292541503906, 0.02676369808614254, 0.026626218110322952, 0.029860809445381165, 0.04752882570028305, 0.0321744829416275, 0.03202051669359207, 0.046200405806303024, 0.03900626674294472, 0.034682005643844604, 0.03152475878596306, 0.04215340316295624, 0.07192506641149521, 0.0863485038280487, 0.049979597330093384, 0.03549272567033768, 0.03174954652786255, 0.0408325269818306, 0.03667695075273514, 0.028593413531780243, 0.0349578820168972, 0.04232984036207199, 0.03987044841051102, 0.03762597590684891, 0.02945816144347191, 0.022935612127184868, 0.022806350141763687, 0.023415498435497284, 0.025205494835972786, 0.02028687484562397, 0.016588889062404633, 0.016642292961478233, 0.01695137284696102, 0.028558123856782913, 0.028559133410453796, 0.02021782472729683, 0.027464596554636955, 0.01988726295530796, 0.01989927887916565, 0.0263168066740036, 0.023809323087334633, 0.02380889467895031, 0.024339234456419945, 0.050373516976833344, 0.046242013573646545, 0.04746625944972038, 0.04866749420762062, 0.04637622833251953, 0.04586061090230942, 0.027323247864842415, 0.024310318753123283, 0.03066943772137165, 0.03498109430074692, 0.051418837159872055, 0.0422331877052784, 0.035455990582704544, 0.02771523967385292, 0.024317599833011627, 0.018905041739344597, 0.026502519845962524, 0.021007996052503586, 0.020965272560715675, 0.023481173440814018, 0.017402373254299164, 0.0240391306579113, 0.01688637211918831, 0.016734939068555832, 0.018755260854959488, 0.014592881314456463, 0.015839623287320137, 0.01758025772869587, 0.01291336677968502, 0.012743817642331123, 0.01476369984447956, 0.016657629981637, 0.021178564056754112, 0.027026930823922157, 0.01724976673722267, 0.015747562050819397, 0.014194400981068611, 0.014440744183957577, 0.013341202400624752, 0.016511911526322365, 0.014044494368135929], 'accuracy': [0.9569892287254333, 0.9717034697532654, 0.9875495433807373, 0.9946236610412598, 0.9917939901351929, 0.9892473220825195, 0.9855687618255615, 0.974816083908081, 0.9838709831237793, 0.9864176511764526, 0.9861347079277039, 0.9824561476707458, 0.9847198724746704, 0.9835879802703857, 0.9867005944252014, 0.9886813759803772, 0.9932088255882263, 0.9954725503921509, 0.9954725503921509, 0.9934917688369751, 0.9858517050743103, 0.992642879486084, 0.992642879486084, 0.9875495433807373, 0.990662157535553, 0.992642879486084, 0.9929258823394775, 0.9900962114334106, 0.9799094796180725, 0.9714204668998718, 0.9864176511764526, 0.990662157535553, 0.9923599362373352, 0.9892473220825195, 0.9920769929885864, 0.9946236610412598, 0.9903791546821594, 0.9878324866294861, 0.9898132681846619, 0.9898132681846619, 0.9929258823394775, 0.9980192184448242, 0.9968873858451843, 0.9960384964942932, 0.996321439743042, 0.9968873858451843, 0.9991511106491089, 0.9985851645469666, 0.9988681674003601, 0.9934917688369751, 0.9932088255882263, 0.996321439743042, 0.9954725503921509, 0.9974533319473267, 0.9960384964942932, 0.9946236610412598, 0.9949066042900085, 0.9951896071434021, 0.9949066042900085, 0.9858517050743103, 0.9875495433807373, 0.9852858185768127, 0.9872665405273438, 0.9886813759803772, 0.986983597278595, 0.9937747716903687, 0.994340717792511, 0.994340717792511, 0.9892473220825195, 0.9841539263725281, 0.9886813759803772, 0.9900962114334106, 0.9929258823394775, 0.9954725503921509, 0.9974533319473267, 0.994340717792511, 0.9971703290939331, 0.9971703290939331, 0.9954725503921509, 0.9971703290939331, 0.9929258823394775, 0.9974533319473267, 0.9977362751960754, 0.9980192184448242, 0.9983022212982178, 0.9977362751960754, 0.9971703290939331, 0.9997170567512512, 0.9997170567512512, 0.9985851645469666, 0.9977362751960754, 0.9949066042900085, 0.9934917688369751, 0.996321439743042, 0.9983022212982178, 0.9985851645469666, 0.9985851645469666, 0.9988681674003601, 0.9968873858451843, 0.9985851645469666], 'val_loss': [0.6974139213562012, 0.6954684853553772, 0.6847214698791504, 0.6722932457923889, 0.6541041731834412, 0.6342507004737854, 0.6519743800163269, 0.6382238864898682, 0.6004425287246704, 0.5784547328948975, 0.5458412170410156, 0.5785842537879944, 0.5419444441795349, 0.5708946585655212, 0.5588694214820862, 0.5898063778877258, 0.5782637000083923, 0.612522304058075, 0.6474674940109253, 0.7014090418815613, 0.6841221451759338, 0.718302845954895, 0.8506545424461365, 0.951411247253418, 0.7654910683631897, 0.9474774599075317, 1.0033506155014038, 1.0582373142242432, 1.0293570756912231, 0.8683688044548035, 0.8817963600158691, 0.9385296702384949, 1.0544158220291138, 1.0374081134796143, 1.0101158618927002, 1.098092794418335, 1.1306124925613403, 1.0923079252243042, 1.1739065647125244, 1.0598071813583374, 1.1940304040908813, 1.289965033531189, 1.2648957967758179, 1.20835280418396, 1.1839808225631714, 1.1882951259613037, 1.2256115674972534, 1.2512801885604858, 1.1977006196975708, 1.1548715829849243, 1.0713969469070435, 1.156112790107727, 1.0773975849151611, 1.1121546030044556, 1.0947271585464478, 1.1273192167282104, 1.1914280652999878, 1.1473199129104614, 1.2063018083572388, 1.2712489366531372, 1.1884117126464844, 1.1015524864196777, 1.162862777709961, 1.1704469919204712, 1.00450599193573, 1.1683621406555176, 1.2490425109863281, 1.1763988733291626, 1.3436346054077148, 1.0894272327423096, 1.0189838409423828, 1.1455442905426025, 1.2414379119873047, 1.3799375295639038, 1.3627381324768066, 1.2562479972839355, 1.2179272174835205, 1.2492469549179077, 1.1829147338867188, 1.194231629371643, 1.1651256084442139, 1.258681058883667, 1.230979084968567, 1.2094157934188843, 1.2727563381195068, 1.2624064683914185, 1.2155101299285889, 1.2572017908096313, 1.2688548564910889, 1.260772466659546, 1.3105120658874512, 1.1939228773117065, 1.0853415727615356, 1.16920006275177, 1.2376500368118286, 1.3119709491729736, 1.2788441181182861, 1.3747695684432983, 1.3239113092422485, 1.231526255607605], 'val_accuracy': [0.523755669593811, 0.5101810097694397, 0.5395927429199219, 0.5542986392974854, 0.6018099784851074, 0.6696832776069641, 0.570135772228241, 0.6063348650932312, 0.7171945571899414, 0.7149321436882019, 0.7726244330406189, 0.709276020526886, 0.7556561231613159, 0.7352941036224365, 0.7488687634468079, 0.7432126402854919, 0.766968309879303, 0.7850678563117981, 0.7714931964874268, 0.7884615659713745, 0.7816742062568665, 0.790723979473114, 0.779411792755127, 0.7692307829856873, 0.7997737526893616, 0.773755669593811, 0.7760180830955505, 0.7726244330406189, 0.75, 0.7647058963775635, 0.779411792755127, 0.773755669593811, 0.773755669593811, 0.7782805562019348, 0.7828054428100586, 0.7692307829856873, 0.773755669593811, 0.7726244330406189, 0.7590497732162476, 0.7771493196487427, 0.7533936500549316, 0.7488687634468079, 0.7590497732162476, 0.7726244330406189, 0.7624434232711792, 0.7658371329307556, 0.7613122463226318, 0.7703620195388794, 0.7680995464324951, 0.7647058963775635, 0.7884615659713745, 0.7771493196487427, 0.773755669593811, 0.7714931964874268, 0.779411792755127, 0.7714931964874268, 0.766968309879303, 0.7714931964874268, 0.7647058963775635, 0.7296379804611206, 0.7443438768386841, 0.7613122463226318, 0.7432126402854919, 0.7477375268936157, 0.7680995464324951, 0.7545248866081238, 0.7635746598243713, 0.7647058963775635, 0.7251130938529968, 0.7375565767288208, 0.7590497732162476, 0.7488687634468079, 0.7375565767288208, 0.7228506803512573, 0.7386877536773682, 0.7590497732162476, 0.7680995464324951, 0.7579185366630554, 0.7624434232711792, 0.7556561231613159, 0.7635746598243713, 0.7556561231613159, 0.7601810097694397, 0.7601810097694397, 0.7556561231613159, 0.7624434232711792, 0.7624434232711792, 0.766968309879303, 0.7647058963775635, 0.7692307829856873, 0.7556561231613159, 0.7635746598243713, 0.766968309879303, 0.7635746598243713, 0.7635746598243713, 0.7613122463226318, 0.7567873597145081, 0.7579185366630554, 0.7533936500549316, 0.7601810097694397]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.9429"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 59ms/step - loss: 0.1804 - accuracy: 0.9429 - val_loss: 0.6980 - val_accuracy: 0.5176\n","Epoch 2/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0914 - accuracy: 0.9664 - val_loss: 0.6939 - val_accuracy: 0.5279\n","Epoch 3/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 0.6873 - val_accuracy: 0.5320\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0558 - accuracy: 0.9850 - val_loss: 0.6732 - val_accuracy: 0.5733\n","Epoch 5/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0519 - accuracy: 0.9845 - val_loss: 0.6556 - val_accuracy: 0.6436\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0478 - accuracy: 0.9873 - val_loss: 0.6417 - val_accuracy: 0.6415\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0522 - accuracy: 0.9863 - val_loss: 0.6216 - val_accuracy: 0.6550\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0667 - accuracy: 0.9791 - val_loss: 0.6383 - val_accuracy: 0.6147\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.5961 - val_accuracy: 0.6890\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0646 - accuracy: 0.9793 - val_loss: 0.5744 - val_accuracy: 0.7149\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0675 - accuracy: 0.9783 - val_loss: 0.5474 - val_accuracy: 0.7366\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.5768 - val_accuracy: 0.7293\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0647 - accuracy: 0.9767 - val_loss: 0.5394 - val_accuracy: 0.7593\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0683 - accuracy: 0.9775 - val_loss: 0.5962 - val_accuracy: 0.7438\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.6217 - val_accuracy: 0.7469\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0419 - accuracy: 0.9889 - val_loss: 0.6979 - val_accuracy: 0.7510\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.7339 - val_accuracy: 0.7593\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0486 - accuracy: 0.9860 - val_loss: 0.7929 - val_accuracy: 0.7521\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0497 - accuracy: 0.9848 - val_loss: 0.7441 - val_accuracy: 0.7769\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0435 - accuracy: 0.9876 - val_loss: 0.8442 - val_accuracy: 0.7676\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0380 - accuracy: 0.9902 - val_loss: 0.8893 - val_accuracy: 0.7707\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0393 - accuracy: 0.9915 - val_loss: 0.9832 - val_accuracy: 0.7707\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0603 - accuracy: 0.9827 - val_loss: 1.1530 - val_accuracy: 0.7345\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0715 - accuracy: 0.9757 - val_loss: 0.9104 - val_accuracy: 0.7696\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0524 - accuracy: 0.9845 - val_loss: 1.0251 - val_accuracy: 0.7696\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0464 - accuracy: 0.9873 - val_loss: 1.0549 - val_accuracy: 0.7696\n","Epoch 27/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0435 - accuracy: 0.9879 - val_loss: 1.0866 - val_accuracy: 0.7789\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 1.1776 - val_accuracy: 0.7614\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0479 - accuracy: 0.9840 - val_loss: 1.1589 - val_accuracy: 0.7500\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 1.1174 - val_accuracy: 0.7645\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0520 - accuracy: 0.9827 - val_loss: 1.1756 - val_accuracy: 0.7552\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0427 - accuracy: 0.9891 - val_loss: 1.1355 - val_accuracy: 0.7707\n","Epoch 33/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0343 - accuracy: 0.9925 - val_loss: 1.1621 - val_accuracy: 0.7831\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0388 - accuracy: 0.9907 - val_loss: 1.3191 - val_accuracy: 0.7448\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 1.1976 - val_accuracy: 0.7541\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 1.2440 - val_accuracy: 0.7324\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0638 - accuracy: 0.9788 - val_loss: 1.1255 - val_accuracy: 0.7469\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0436 - accuracy: 0.9891 - val_loss: 1.1950 - val_accuracy: 0.7500\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 1.1900 - val_accuracy: 0.7521\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9933 - val_loss: 1.2081 - val_accuracy: 0.7614\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0261 - accuracy: 0.9953 - val_loss: 1.2508 - val_accuracy: 0.7572\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0262 - accuracy: 0.9951 - val_loss: 1.2495 - val_accuracy: 0.7490\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9953 - val_loss: 1.2124 - val_accuracy: 0.7645\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0408 - accuracy: 0.9902 - val_loss: 1.2703 - val_accuracy: 0.7541\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0398 - accuracy: 0.9889 - val_loss: 1.2040 - val_accuracy: 0.7634\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0305 - accuracy: 0.9933 - val_loss: 1.1479 - val_accuracy: 0.7779\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0316 - accuracy: 0.9925 - val_loss: 1.1972 - val_accuracy: 0.7603\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 0.9959 - val_loss: 1.2150 - val_accuracy: 0.7696\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0252 - accuracy: 0.9959 - val_loss: 1.2271 - val_accuracy: 0.7645\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0433 - accuracy: 0.9871 - val_loss: 1.2231 - val_accuracy: 0.7686\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0466 - accuracy: 0.9871 - val_loss: 1.2091 - val_accuracy: 0.7376\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 1.3617 - val_accuracy: 0.7438\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0518 - accuracy: 0.9858 - val_loss: 1.3359 - val_accuracy: 0.7386\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0700 - accuracy: 0.9786 - val_loss: 1.1339 - val_accuracy: 0.7345\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 1.1867 - val_accuracy: 0.7479\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 1.3233 - val_accuracy: 0.7273\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0437 - accuracy: 0.9884 - val_loss: 1.3966 - val_accuracy: 0.7366\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0462 - accuracy: 0.9837 - val_loss: 1.3103 - val_accuracy: 0.7366\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 1.3368 - val_accuracy: 0.7283\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0375 - accuracy: 0.9910 - val_loss: 1.3825 - val_accuracy: 0.7283\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0410 - accuracy: 0.9881 - val_loss: 1.3516 - val_accuracy: 0.7376\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0547 - accuracy: 0.9806 - val_loss: 1.2614 - val_accuracy: 0.7169\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0344 - accuracy: 0.9915 - val_loss: 1.3473 - val_accuracy: 0.7221\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0363 - accuracy: 0.9894 - val_loss: 1.3558 - val_accuracy: 0.7252\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0335 - accuracy: 0.9897 - val_loss: 1.3000 - val_accuracy: 0.7324\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0353 - accuracy: 0.9910 - val_loss: 1.4100 - val_accuracy: 0.7262\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0333 - accuracy: 0.9935 - val_loss: 1.3882 - val_accuracy: 0.7345\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0304 - accuracy: 0.9946 - val_loss: 1.3572 - val_accuracy: 0.7448\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9953 - val_loss: 1.4114 - val_accuracy: 0.7448\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0269 - accuracy: 0.9953 - val_loss: 1.4946 - val_accuracy: 0.7314\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0283 - accuracy: 0.9953 - val_loss: 1.6657 - val_accuracy: 0.6973\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0410 - accuracy: 0.9879 - val_loss: 1.4206 - val_accuracy: 0.7128\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0251 - accuracy: 0.9951 - val_loss: 1.4820 - val_accuracy: 0.7283\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9964 - val_loss: 1.4160 - val_accuracy: 0.7397\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 1.6202 - val_accuracy: 0.7169\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0384 - accuracy: 0.9891 - val_loss: 1.4269 - val_accuracy: 0.7221\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 1.4070 - val_accuracy: 0.7283\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0339 - accuracy: 0.9907 - val_loss: 1.3395 - val_accuracy: 0.7428\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0490 - accuracy: 0.9832 - val_loss: 1.1646 - val_accuracy: 0.7304\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0272 - accuracy: 0.9946 - val_loss: 1.3116 - val_accuracy: 0.7355\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9972 - val_loss: 1.4185 - val_accuracy: 0.7355\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9972 - val_loss: 1.4043 - val_accuracy: 0.7459\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9977 - val_loss: 1.4820 - val_accuracy: 0.7304\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 1.5650 - val_accuracy: 0.7262\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0414 - accuracy: 0.9886 - val_loss: 1.2158 - val_accuracy: 0.7355\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 1.2396 - val_accuracy: 0.7531\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 1.2351 - val_accuracy: 0.7510\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 1.2802 - val_accuracy: 0.7541\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0202 - accuracy: 0.9974 - val_loss: 1.3318 - val_accuracy: 0.7521\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0189 - accuracy: 0.9966 - val_loss: 1.4645 - val_accuracy: 0.7355\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0312 - accuracy: 0.9907 - val_loss: 1.3346 - val_accuracy: 0.7355\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0225 - accuracy: 0.9959 - val_loss: 1.3554 - val_accuracy: 0.7469\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 1.6512 - val_accuracy: 0.7066\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0381 - accuracy: 0.9894 - val_loss: 1.4074 - val_accuracy: 0.7087\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 1.3914 - val_accuracy: 0.7304\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0219 - accuracy: 0.9961 - val_loss: 1.5266 - val_accuracy: 0.7180\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9959 - val_loss: 1.5184 - val_accuracy: 0.7190\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9943 - val_loss: 1.4603 - val_accuracy: 0.7262\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 1.4720 - val_accuracy: 0.7314\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9946 - val_loss: 1.8849 - val_accuracy: 0.6880\n","{'loss': [0.18040885031223297, 0.09141408652067184, 0.06386514753103256, 0.05576452985405922, 0.051908332854509354, 0.04775841906666756, 0.05223876237869263, 0.06667929887771606, 0.05837397277355194, 0.06464363634586334, 0.06751270592212677, 0.06368578225374222, 0.06469792872667313, 0.06826543807983398, 0.05075172707438469, 0.04185192659497261, 0.05835093930363655, 0.048608556389808655, 0.049677036702632904, 0.04352200776338577, 0.037954822182655334, 0.03934698551893234, 0.06029864028096199, 0.07149660587310791, 0.05244705453515053, 0.046426981687545776, 0.043461065739393234, 0.047279633581638336, 0.0479031577706337, 0.050821512937545776, 0.05201655998826027, 0.04265270382165909, 0.03434787690639496, 0.03881196677684784, 0.04463599622249603, 0.058468885719776154, 0.06379974633455276, 0.04358832538127899, 0.04340263828635216, 0.03179536759853363, 0.026130521669983864, 0.026225265115499496, 0.026453720405697823, 0.04081154242157936, 0.03976030647754669, 0.030523493885993958, 0.03156401216983795, 0.024025529623031616, 0.025224342942237854, 0.04325234889984131, 0.04661013185977936, 0.04052995145320892, 0.05179480463266373, 0.07003126293420792, 0.05995557829737663, 0.04200106859207153, 0.04371792823076248, 0.046166591346263885, 0.04324531555175781, 0.03749777004122734, 0.04095582664012909, 0.05474254861474037, 0.03435369208455086, 0.036295872181653976, 0.03351273387670517, 0.035271789878606796, 0.03334084898233414, 0.030359480530023575, 0.02471405453979969, 0.026892894878983498, 0.028349721804261208, 0.04097369685769081, 0.025071967393159866, 0.023128068074584007, 0.03361867740750313, 0.038447216153144836, 0.030216142535209656, 0.033870287239551544, 0.04898686707019806, 0.027201132848858833, 0.020279446616768837, 0.019473567605018616, 0.017643921077251434, 0.017957212403416634, 0.04142031446099281, 0.037595294415950775, 0.028090162202715874, 0.02836468070745468, 0.02022646740078926, 0.01892695389688015, 0.031186530366539955, 0.022490141913294792, 0.024338841438293457, 0.03811940923333168, 0.03024962730705738, 0.021943559870123863, 0.022101353853940964, 0.02488820068538189, 0.028316808864474297, 0.026904720813035965], 'accuracy': [0.9428940415382385, 0.9664082527160645, 0.9821705222129822, 0.985012948513031, 0.9844961166381836, 0.9873384833335876, 0.9863049387931824, 0.9790697693824768, 0.9803617596626282, 0.9793281555175781, 0.9782945513725281, 0.9826873540878296, 0.9767441749572754, 0.9775193929672241, 0.9855297207832336, 0.9888888597488403, 0.9808785319328308, 0.9860464930534363, 0.9847545027732849, 0.987596869468689, 0.9901808500289917, 0.9914728403091431, 0.9826873540878296, 0.9757105708122253, 0.9844961166381836, 0.9873384833335876, 0.9878553152084351, 0.9860464930534363, 0.983979344367981, 0.9834625124931335, 0.9826873540878296, 0.9891473054885864, 0.9925064444541931, 0.9906976819038391, 0.9878553152084351, 0.9821705222129822, 0.9788113832473755, 0.9891473054885864, 0.9865633249282837, 0.9932816624641418, 0.9953488111495972, 0.9950904250144958, 0.9953488111495972, 0.9901808500289917, 0.9888888597488403, 0.9932816624641418, 0.9925064444541931, 0.9958656430244446, 0.9958656430244446, 0.9870800971984863, 0.9870800971984863, 0.9878553152084351, 0.985788106918335, 0.9785529971122742, 0.9801033735275269, 0.9873384833335876, 0.9883720874786377, 0.9837209582328796, 0.9852713346481323, 0.9909560680389404, 0.9881137013435364, 0.9806201457977295, 0.9914728403091431, 0.9894056916236877, 0.9896640777587891, 0.9909560680389404, 0.9935400485992432, 0.9945736527442932, 0.9953488111495972, 0.9953488111495972, 0.9953488111495972, 0.9878553152084351, 0.9950904250144958, 0.9963824152946472, 0.9912144541740417, 0.9891473054885864, 0.9917312860488892, 0.9906976819038391, 0.9832041263580322, 0.9945736527442932, 0.997157633304596, 0.997157633304596, 0.9976744055747986, 0.9968992471694946, 0.988630473613739, 0.9883720874786377, 0.9930232763290405, 0.9927648305892944, 0.9974160194396973, 0.9966408014297485, 0.9906976819038391, 0.9958656430244446, 0.9935400485992432, 0.9894056916236877, 0.9925064444541931, 0.9961240291595459, 0.9958656430244446, 0.9943152666091919, 0.9912144541740417, 0.9945736527442932], 'val_loss': [0.6980385780334473, 0.6939471364021301, 0.6873442530632019, 0.6731775403022766, 0.6556131839752197, 0.6417462229728699, 0.6215842962265015, 0.6383365392684937, 0.596142590045929, 0.574422299861908, 0.547435462474823, 0.576772928237915, 0.5393949151039124, 0.5961994528770447, 0.6217485666275024, 0.6978940963745117, 0.7339274883270264, 0.7929419279098511, 0.7441341280937195, 0.8442099690437317, 0.8892877101898193, 0.9832010865211487, 1.1530413627624512, 0.910412609577179, 1.0250505208969116, 1.0549286603927612, 1.0866403579711914, 1.1775596141815186, 1.1588820219039917, 1.117423176765442, 1.1755787134170532, 1.135513186454773, 1.1620919704437256, 1.3190889358520508, 1.1976261138916016, 1.2439799308776855, 1.1254643201828003, 1.195042610168457, 1.1900476217269897, 1.2081397771835327, 1.2508124113082886, 1.249544382095337, 1.2123680114746094, 1.2702937126159668, 1.2040077447891235, 1.147865653038025, 1.1972053050994873, 1.215015172958374, 1.2271292209625244, 1.22305428981781, 1.2091044187545776, 1.3617010116577148, 1.3358957767486572, 1.1339114904403687, 1.186728835105896, 1.3233487606048584, 1.3965978622436523, 1.3102502822875977, 1.3368014097213745, 1.3824995756149292, 1.3515678644180298, 1.2613632678985596, 1.3472628593444824, 1.3557798862457275, 1.2999794483184814, 1.4099847078323364, 1.3882323503494263, 1.357177495956421, 1.4114490747451782, 1.494604468345642, 1.6657413244247437, 1.4206007719039917, 1.4820008277893066, 1.4159573316574097, 1.6201813220977783, 1.426938533782959, 1.4069583415985107, 1.339463233947754, 1.164615511894226, 1.3115978240966797, 1.4184949398040771, 1.4043015241622925, 1.4819669723510742, 1.5650267601013184, 1.215835690498352, 1.2395951747894287, 1.2350778579711914, 1.2802189588546753, 1.3317532539367676, 1.4645437002182007, 1.3345990180969238, 1.3554266691207886, 1.6511876583099365, 1.4074385166168213, 1.3914060592651367, 1.5265589952468872, 1.5183794498443604, 1.460339069366455, 1.4719537496566772, 1.8849469423294067], 'val_accuracy': [0.5175619721412659, 0.5278925895690918, 0.5320248007774353, 0.5733470916748047, 0.6435950398445129, 0.6415289044380188, 0.6549586653709412, 0.6146694421768188, 0.6890496015548706, 0.7148760557174683, 0.7365702390670776, 0.7293388247489929, 0.7592975497245789, 0.7438016533851624, 0.7469007968902588, 0.7510330677032471, 0.7592975497245789, 0.7520661354064941, 0.7768595218658447, 0.7675619721412659, 0.7706611752510071, 0.7706611752510071, 0.7345041036605835, 0.76962810754776, 0.76962810754776, 0.76962810754776, 0.7789255976676941, 0.7613636255264282, 0.75, 0.7644628286361694, 0.7551652789115906, 0.7706611752510071, 0.7830578684806824, 0.7448347210884094, 0.7541322112083435, 0.7324380278587341, 0.7469007968902588, 0.75, 0.7520661354064941, 0.7613636255264282, 0.7572314143180847, 0.7489669322967529, 0.7644628286361694, 0.7541322112083435, 0.7634297609329224, 0.7778925895690918, 0.7603305578231812, 0.76962810754776, 0.7644628286361694, 0.7685950398445129, 0.7376033067703247, 0.7438016533851624, 0.7386363744735718, 0.7345041036605835, 0.7479338645935059, 0.7272727489471436, 0.7365702390670776, 0.7365702390670776, 0.7283057570457458, 0.7283057570457458, 0.7376033067703247, 0.7169421315193176, 0.7221074104309082, 0.7252066135406494, 0.7324380278587341, 0.7262396812438965, 0.7345041036605835, 0.7448347210884094, 0.7448347210884094, 0.7314049601554871, 0.6973140239715576, 0.7128099203109741, 0.7283057570457458, 0.7396694421768188, 0.7169421315193176, 0.7221074104309082, 0.7283057570457458, 0.7427685856819153, 0.73037189245224, 0.7355371713638306, 0.7355371713638306, 0.7458677887916565, 0.73037189245224, 0.7262396812438965, 0.7355371713638306, 0.7530992031097412, 0.7510330677032471, 0.7541322112083435, 0.7520661354064941, 0.7355371713638306, 0.7355371713638306, 0.7469007968902588, 0.7066115736961365, 0.7086777091026306, 0.73037189245224, 0.7179751992225647, 0.7190082669258118, 0.7262396812438965, 0.7314049601554871, 0.6880165338516235]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9828"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 53ms/step - loss: 0.0609 - accuracy: 0.9828 - val_loss: 0.6907 - val_accuracy: 0.5302\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.6810 - val_accuracy: 0.6034\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 0.6649 - val_accuracy: 0.6541\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0233 - accuracy: 0.9952 - val_loss: 0.6465 - val_accuracy: 0.7026\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0269 - accuracy: 0.9930 - val_loss: 0.6223 - val_accuracy: 0.7252\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.5905 - val_accuracy: 0.7791\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.5702 - val_accuracy: 0.7586\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.5505 - val_accuracy: 0.8114\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0394 - accuracy: 0.9876 - val_loss: 0.5421 - val_accuracy: 0.7877\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 0.5015 - val_accuracy: 0.7856\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.5208 - val_accuracy: 0.7457\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.4775 - val_accuracy: 0.7974\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.4713 - val_accuracy: 0.7845\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0272 - accuracy: 0.9946 - val_loss: 0.4788 - val_accuracy: 0.8103\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0349 - accuracy: 0.9903 - val_loss: 0.4704 - val_accuracy: 0.8114\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0426 - accuracy: 0.9881 - val_loss: 0.4825 - val_accuracy: 0.8028\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 0.5382 - val_accuracy: 0.8157\n","Epoch 18/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0348 - accuracy: 0.9925 - val_loss: 0.5081 - val_accuracy: 0.8276\n","Epoch 19/100\n","29/29 [==============================] - 1s 16ms/step - loss: 0.0362 - accuracy: 0.9916 - val_loss: 0.5427 - val_accuracy: 0.8276\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0224 - accuracy: 0.9962 - val_loss: 0.5639 - val_accuracy: 0.8330\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9941 - val_loss: 0.6397 - val_accuracy: 0.8254\n","Epoch 22/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0326 - accuracy: 0.9919 - val_loss: 0.5857 - val_accuracy: 0.8394\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.9954 - val_loss: 0.6599 - val_accuracy: 0.8200\n","Epoch 24/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.6537 - val_accuracy: 0.8438\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.6728 - val_accuracy: 0.8341\n","Epoch 26/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0167 - accuracy: 0.9970 - val_loss: 0.6484 - val_accuracy: 0.8631\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.7307 - val_accuracy: 0.8491\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9962 - val_loss: 0.7293 - val_accuracy: 0.8427\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.7489 - val_accuracy: 0.8481\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 0.7625 - val_accuracy: 0.8556\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 0.7498 - val_accuracy: 0.8534\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9981 - val_loss: 0.9190 - val_accuracy: 0.8222\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9954 - val_loss: 0.6929 - val_accuracy: 0.8481\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.6937 - val_accuracy: 0.8481\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9987 - val_loss: 0.8539 - val_accuracy: 0.8287\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 0.7879 - val_accuracy: 0.8405\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0150 - accuracy: 0.9981 - val_loss: 0.7690 - val_accuracy: 0.8470\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 0.9978 - val_loss: 0.8263 - val_accuracy: 0.8405\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0243 - accuracy: 0.9943 - val_loss: 0.8887 - val_accuracy: 0.8265\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0505 - accuracy: 0.9863 - val_loss: 0.7769 - val_accuracy: 0.8082\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.7751 - val_accuracy: 0.8050\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 0.7434 - val_accuracy: 0.8222\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.8121 - val_accuracy: 0.8319\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0319 - accuracy: 0.9927 - val_loss: 0.8761 - val_accuracy: 0.8168\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0213 - accuracy: 0.9957 - val_loss: 0.8320 - val_accuracy: 0.8308\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.9543 - val_accuracy: 0.8125\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9930 - val_loss: 0.8056 - val_accuracy: 0.8244\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.8081 - val_accuracy: 0.8200\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.9308 - val_accuracy: 0.8179\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.9033 - val_accuracy: 0.8082\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.9092 - val_accuracy: 0.8254\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.8617 - val_accuracy: 0.8125\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0259 - accuracy: 0.9941 - val_loss: 0.9331 - val_accuracy: 0.8082\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0244 - accuracy: 0.9946 - val_loss: 0.9420 - val_accuracy: 0.8082\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.9244 - val_accuracy: 0.8168\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.9728 - val_accuracy: 0.7888\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.8615 - val_accuracy: 0.8136\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.8987 - val_accuracy: 0.8114\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.9006 - val_accuracy: 0.8114\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9989 - val_loss: 0.9544 - val_accuracy: 0.8179\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9989 - val_loss: 1.0082 - val_accuracy: 0.8136\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 1.1219 - val_accuracy: 0.7953\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 1.0390 - val_accuracy: 0.8060\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9992 - val_loss: 0.9977 - val_accuracy: 0.8050\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 1.0058 - val_accuracy: 0.8136\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 1.0437 - val_accuracy: 0.7953\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 0.8836 - val_accuracy: 0.8006\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.9856 - val_accuracy: 0.7920\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.8661 - val_accuracy: 0.8082\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.9204 - val_accuracy: 0.8017\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.9110 - val_accuracy: 0.8136\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9954 - val_loss: 0.9215 - val_accuracy: 0.8017\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9984 - val_loss: 0.9414 - val_accuracy: 0.8190\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 1.0126 - val_accuracy: 0.8125\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9989 - val_loss: 0.9629 - val_accuracy: 0.8211\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9976 - val_loss: 1.0062 - val_accuracy: 0.8060\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9949 - val_loss: 0.9977 - val_accuracy: 0.7985\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.8614 - val_accuracy: 0.8039\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.9996 - val_accuracy: 0.7845\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0295 - accuracy: 0.9919 - val_loss: 0.9308 - val_accuracy: 0.7974\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 1.0005 - val_accuracy: 0.7909\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.9971 - val_accuracy: 0.7963\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.9241 - val_accuracy: 0.7942\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9970 - val_loss: 0.9403 - val_accuracy: 0.8028\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9984 - val_loss: 1.0824 - val_accuracy: 0.7845\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 0.9409 - val_accuracy: 0.7877\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 0.9981 - val_loss: 0.9681 - val_accuracy: 0.8050\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 0.9997 - val_loss: 1.0737 - val_accuracy: 0.7974\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9997 - val_loss: 1.1801 - val_accuracy: 0.7909\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 1.1236 - val_accuracy: 0.8050\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 1.1546 - val_accuracy: 0.7899\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0505 - accuracy: 0.9846 - val_loss: 1.0000 - val_accuracy: 0.7780\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.8326 - val_accuracy: 0.7953\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 0.9913 - val_accuracy: 0.7888\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.9696 - val_accuracy: 0.8114\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0221 - accuracy: 0.9952 - val_loss: 0.9006 - val_accuracy: 0.8060\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.9787 - val_accuracy: 0.8060\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 0.9984 - val_loss: 1.0416 - val_accuracy: 0.7996\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9987 - val_loss: 0.9847 - val_accuracy: 0.8136\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.9560 - val_accuracy: 0.8125\n","{'loss': [0.06091151386499405, 0.03896697610616684, 0.021235918626189232, 0.023287197574973106, 0.026883769780397415, 0.026605401188135147, 0.02609541080892086, 0.035577837377786636, 0.03944968432188034, 0.03353247791528702, 0.023257864639163017, 0.029379243031144142, 0.02796296216547489, 0.02720663882791996, 0.03489625081419945, 0.042596131563186646, 0.03599318489432335, 0.034771714359521866, 0.03621187433600426, 0.022390048950910568, 0.02791854552924633, 0.032572563737630844, 0.02394883707165718, 0.02425624057650566, 0.020846262574195862, 0.016726339235901833, 0.016110625118017197, 0.018420103937387466, 0.014834127388894558, 0.012983230873942375, 0.01244895439594984, 0.014196646399796009, 0.02299833670258522, 0.021483683958649635, 0.01698746718466282, 0.01209841575473547, 0.015029672533273697, 0.01566651277244091, 0.024304427206516266, 0.050480324774980545, 0.05976906046271324, 0.04385554417967796, 0.024490462616086006, 0.03185221552848816, 0.021328961476683617, 0.018499938771128654, 0.02840311825275421, 0.0262755136936903, 0.02086016908288002, 0.01935640349984169, 0.016147250309586525, 0.02149856835603714, 0.025872869417071342, 0.02436460554599762, 0.032990384846925735, 0.03336912766098976, 0.03196602687239647, 0.02256864868104458, 0.01968122087419033, 0.01333690620958805, 0.0127515634521842, 0.013277275487780571, 0.013245837762951851, 0.011410849168896675, 0.01169296819716692, 0.019038204103708267, 0.02779386192560196, 0.023144247010350227, 0.02172558754682541, 0.022714177146553993, 0.021948980167508125, 0.020300857722759247, 0.013137721456587315, 0.011717112734913826, 0.012759054079651833, 0.01670890301465988, 0.026592493057250977, 0.0356454998254776, 0.025805549696087837, 0.029493805021047592, 0.018622392788529396, 0.021512635052204132, 0.022418007254600525, 0.01628090627491474, 0.014227189123630524, 0.027342142537236214, 0.013759275898337364, 0.01072405930608511, 0.00974688958376646, 0.01036122441291809, 0.014962827786803246, 0.05054287612438202, 0.04860764369368553, 0.024204762652516365, 0.02252773754298687, 0.02210378646850586, 0.013445417396724224, 0.015903297811746597, 0.013255751691758633, 0.013053136877715588], 'accuracy': [0.982758641242981, 0.9884159564971924, 0.9956896305084229, 0.9951508641242981, 0.9929956793785095, 0.993803858757019, 0.9927262663841248, 0.9897629022598267, 0.9876077771186829, 0.9903017282485962, 0.9940732717514038, 0.9916487336158752, 0.9916487336158752, 0.9946120977401733, 0.9903017282485962, 0.9881465435028076, 0.9889547228813171, 0.9924569129943848, 0.9916487336158752, 0.9962284564971924, 0.9940732717514038, 0.9919180870056152, 0.9954202771186829, 0.993803858757019, 0.9943426847457886, 0.9970366358757019, 0.9962284564971924, 0.9962284564971924, 0.9970366358757019, 0.998652994632721, 0.9991918206214905, 0.9981142282485962, 0.9954202771186829, 0.9956896305084229, 0.998652994632721, 0.9994612336158752, 0.9981142282485962, 0.9978448152542114, 0.9943426847457886, 0.9862607717514038, 0.9822198152542114, 0.9865301847457886, 0.9946120977401733, 0.9927262663841248, 0.9956896305084229, 0.9956896305084229, 0.9929956793785095, 0.9932650923728943, 0.9956896305084229, 0.9959590435028076, 0.9975754022598267, 0.9951508641242981, 0.9940732717514038, 0.9946120977401733, 0.9884159564971924, 0.9894935488700867, 0.9903017282485962, 0.9940732717514038, 0.9954202771186829, 0.9989224076271057, 0.9989224076271057, 0.9981142282485962, 0.9981142282485962, 0.9991918206214905, 0.9989224076271057, 0.9954202771186829, 0.9919180870056152, 0.993803858757019, 0.9951508641242981, 0.9943426847457886, 0.9940732717514038, 0.9954202771186829, 0.998383641242981, 0.9989224076271057, 0.9989224076271057, 0.9975754022598267, 0.9948814511299133, 0.9897629022598267, 0.9946120977401733, 0.9919180870056152, 0.9962284564971924, 0.9954202771186829, 0.9948814511299133, 0.9970366358757019, 0.998383641242981, 0.993803858757019, 0.9981142282485962, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9975754022598267, 0.9846444129943848, 0.9846444129943848, 0.9946120977401733, 0.9943426847457886, 0.9951508641242981, 0.998652994632721, 0.998383641242981, 0.998652994632721, 0.9975754022598267], 'val_loss': [0.6907355785369873, 0.6810106635093689, 0.6649070382118225, 0.6464771032333374, 0.6222923994064331, 0.5904715061187744, 0.5701760649681091, 0.5505026578903198, 0.5421346426010132, 0.5015409588813782, 0.5208319425582886, 0.47754502296447754, 0.47127488255500793, 0.4787742793560028, 0.4704485535621643, 0.4824978709220886, 0.538184642791748, 0.5080845952033997, 0.5426780581474304, 0.563947856426239, 0.6397283673286438, 0.5856673121452332, 0.6599282622337341, 0.6536718010902405, 0.6727738380432129, 0.6484120488166809, 0.7307231426239014, 0.729335606098175, 0.7488505244255066, 0.7625234723091125, 0.7497786283493042, 0.9190100431442261, 0.6928649544715881, 0.6936599016189575, 0.8539108633995056, 0.7879327535629272, 0.769019365310669, 0.8262808322906494, 0.8886528611183167, 0.7768757343292236, 0.775117814540863, 0.743369996547699, 0.8121004700660706, 0.8760695457458496, 0.832000732421875, 0.954311192035675, 0.8055835366249084, 0.8081313967704773, 0.9308326244354248, 0.9032695889472961, 0.9092377424240112, 0.8617044687271118, 0.9330629110336304, 0.9420245885848999, 0.9243597984313965, 0.9727994203567505, 0.8615151047706604, 0.8986599445343018, 0.900621771812439, 0.9544162154197693, 1.008246660232544, 1.1218998432159424, 1.0390286445617676, 0.9976589679718018, 1.0057786703109741, 1.0437254905700684, 0.8835648894309998, 0.9856241345405579, 0.8660562634468079, 0.9203720688819885, 0.9110227823257446, 0.9214958548545837, 0.9414057731628418, 1.012597918510437, 0.9628629088401794, 1.006168007850647, 0.997704803943634, 0.8614023327827454, 0.99964839220047, 0.9308366179466248, 1.0004769563674927, 0.9970898628234863, 0.9241476655006409, 0.9403111934661865, 1.0824016332626343, 0.940941333770752, 0.9681442379951477, 1.0736855268478394, 1.180052638053894, 1.123602271080017, 1.1546436548233032, 1.000040888786316, 0.8326152563095093, 0.9913158416748047, 0.9696415662765503, 0.9006125926971436, 0.9786939024925232, 1.0415928363800049, 0.9847134351730347, 0.955962061882019], 'val_accuracy': [0.5301724076271057, 0.6034482717514038, 0.6540948152542114, 0.7025862336158752, 0.725215494632721, 0.7790948152542114, 0.7586206793785095, 0.8114224076271057, 0.787715494632721, 0.7855603694915771, 0.7456896305084229, 0.7974137663841248, 0.7844827771186829, 0.8103448152542114, 0.8114224076271057, 0.8028017282485962, 0.8157327771186829, 0.8275862336158752, 0.8275862336158752, 0.8329741358757019, 0.8254310488700867, 0.8394396305084229, 0.8200430870056152, 0.84375, 0.8340517282485962, 0.8631465435028076, 0.8491379022598267, 0.8426724076271057, 0.8480603694915771, 0.8556034564971924, 0.8534482717514038, 0.8221982717514038, 0.8480603694915771, 0.8480603694915771, 0.8286637663841248, 0.8405172228813171, 0.8469827771186829, 0.8405172228813171, 0.826508641242981, 0.8081896305084229, 0.8049569129943848, 0.8221982717514038, 0.8318965435028076, 0.8168103694915771, 0.8308189511299133, 0.8125, 0.8243534564971924, 0.8200430870056152, 0.8178879022598267, 0.8081896305084229, 0.8254310488700867, 0.8125, 0.8081896305084229, 0.8081896305084229, 0.8168103694915771, 0.7887930870056152, 0.8135775923728943, 0.8114224076271057, 0.8114224076271057, 0.8178879022598267, 0.8135775923728943, 0.795258641242981, 0.806034505367279, 0.8049569129943848, 0.8135775923728943, 0.795258641242981, 0.8006465435028076, 0.7920258641242981, 0.8081896305084229, 0.8017241358757019, 0.8135775923728943, 0.8017241358757019, 0.818965494632721, 0.8125, 0.8211206793785095, 0.806034505367279, 0.798491358757019, 0.8038793206214905, 0.7844827771186829, 0.7974137663841248, 0.7909482717514038, 0.7963362336158752, 0.7941810488700867, 0.8028017282485962, 0.7844827771186829, 0.787715494632721, 0.8049569129943848, 0.7974137663841248, 0.7909482717514038, 0.8049569129943848, 0.7898706793785095, 0.7780172228813171, 0.795258641242981, 0.7887930870056152, 0.8114224076271057, 0.806034505367279, 0.806034505367279, 0.7995689511299133, 0.8135775923728943, 0.8125]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.0567 - accuracy: 0.9834"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 59ms/step - loss: 0.0578 - accuracy: 0.9833 - val_loss: 0.6864 - val_accuracy: 0.5814\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 0.6775 - val_accuracy: 0.6324\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0247 - accuracy: 0.9952 - val_loss: 0.6591 - val_accuracy: 0.6686\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.6407 - val_accuracy: 0.7048\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0253 - accuracy: 0.9941 - val_loss: 0.6144 - val_accuracy: 0.7421\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0259 - accuracy: 0.9941 - val_loss: 0.5978 - val_accuracy: 0.7262\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0168 - accuracy: 0.9983 - val_loss: 0.5443 - val_accuracy: 0.7952\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9983 - val_loss: 0.5046 - val_accuracy: 0.7952\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0158 - accuracy: 0.9975 - val_loss: 0.4603 - val_accuracy: 0.8156\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.4395 - val_accuracy: 0.8360\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.4247 - val_accuracy: 0.8326\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9949 - val_loss: 0.4024 - val_accuracy: 0.8314\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0453 - accuracy: 0.9873 - val_loss: 0.4314 - val_accuracy: 0.8077\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.4281 - val_accuracy: 0.8190\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9907 - val_loss: 0.4222 - val_accuracy: 0.8122\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0338 - accuracy: 0.9932 - val_loss: 0.4352 - val_accuracy: 0.8371\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0338 - accuracy: 0.9921 - val_loss: 0.4237 - val_accuracy: 0.8348\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0247 - accuracy: 0.9952 - val_loss: 0.4672 - val_accuracy: 0.8416\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.4824 - val_accuracy: 0.8326\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0419 - accuracy: 0.9884 - val_loss: 0.4736 - val_accuracy: 0.8247\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0262 - accuracy: 0.9946 - val_loss: 0.5718 - val_accuracy: 0.8179\n","Epoch 22/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.5375 - val_accuracy: 0.8473\n","Epoch 23/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0246 - accuracy: 0.9943 - val_loss: 0.5465 - val_accuracy: 0.8541\n","Epoch 24/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0196 - accuracy: 0.9972 - val_loss: 0.5270 - val_accuracy: 0.8609\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0142 - accuracy: 0.9989 - val_loss: 0.5684 - val_accuracy: 0.8654\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.6003 - val_accuracy: 0.8507\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 0.5916 - val_accuracy: 0.8575\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.6075 - val_accuracy: 0.8609\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 0.9992 - val_loss: 0.6591 - val_accuracy: 0.8495\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.6209 - val_accuracy: 0.8609\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.5901 - val_accuracy: 0.8609\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 0.8889 - val_accuracy: 0.8179\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.7384 - val_accuracy: 0.8450\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 0.9952 - val_loss: 0.6960 - val_accuracy: 0.8394\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0262 - accuracy: 0.9943 - val_loss: 0.6718 - val_accuracy: 0.8529\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.7212 - val_accuracy: 0.8337\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.6527 - val_accuracy: 0.8405\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0515 - accuracy: 0.9867 - val_loss: 0.6452 - val_accuracy: 0.8258\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.7114 - val_accuracy: 0.8122\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0201 - accuracy: 0.9952 - val_loss: 0.8710 - val_accuracy: 0.8111\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9949 - val_loss: 0.7979 - val_accuracy: 0.8258\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0344 - accuracy: 0.9907 - val_loss: 0.7846 - val_accuracy: 0.8179\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.7938 - val_accuracy: 0.8224\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.7394 - val_accuracy: 0.8043\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0352 - accuracy: 0.9887 - val_loss: 0.7992 - val_accuracy: 0.8066\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0230 - accuracy: 0.9963 - val_loss: 0.8223 - val_accuracy: 0.8224\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9963 - val_loss: 0.8193 - val_accuracy: 0.8292\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9986 - val_loss: 0.8307 - val_accuracy: 0.8201\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.8662 - val_accuracy: 0.8156\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.9992 - val_loss: 0.8708 - val_accuracy: 0.8190\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9994 - val_loss: 0.8890 - val_accuracy: 0.8247\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.8226 - val_accuracy: 0.8326\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0141 - accuracy: 0.9980 - val_loss: 0.7888 - val_accuracy: 0.8371\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.9992 - val_loss: 0.8219 - val_accuracy: 0.8281\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0103 - accuracy: 0.9997 - val_loss: 0.8481 - val_accuracy: 0.8326\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.8495 - val_accuracy: 0.8348\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.7985 - val_accuracy: 0.8439\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 0.7977 - val_accuracy: 0.8450\n","Epoch 59/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 0.8891 - val_accuracy: 0.8167\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9941 - val_loss: 0.7871 - val_accuracy: 0.8167\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.7948 - val_accuracy: 0.8235\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 0.9992 - val_loss: 0.8878 - val_accuracy: 0.8269\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 0.9986 - val_loss: 0.8550 - val_accuracy: 0.8235\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.8744 - val_accuracy: 0.8314\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.8273 - val_accuracy: 0.8156\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.8722 - val_accuracy: 0.8043\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.8850 - val_accuracy: 0.8066\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.8697 - val_accuracy: 0.8167\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0466 - accuracy: 0.9861 - val_loss: 0.8333 - val_accuracy: 0.7941\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.8261 - val_accuracy: 0.7885\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0322 - accuracy: 0.9929 - val_loss: 1.0002 - val_accuracy: 0.7817\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 1.0568 - val_accuracy: 0.7647\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.9781 - val_accuracy: 0.7794\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0325 - accuracy: 0.9918 - val_loss: 1.0010 - val_accuracy: 0.7704\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0332 - accuracy: 0.9909 - val_loss: 0.9576 - val_accuracy: 0.7805\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0292 - accuracy: 0.9929 - val_loss: 0.8767 - val_accuracy: 0.8054\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9943 - val_loss: 0.9230 - val_accuracy: 0.8009\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.8082 - val_accuracy: 0.8043\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.7823 - val_accuracy: 0.8009\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 1.0131 - val_accuracy: 0.8020\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0178 - accuracy: 0.9966 - val_loss: 0.9286 - val_accuracy: 0.8032\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.8153 - val_accuracy: 0.8190\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9955 - val_loss: 1.1428 - val_accuracy: 0.7749\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.9317 - val_accuracy: 0.7760\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.9875 - val_accuracy: 0.7704\n","Epoch 86/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.8011 - val_accuracy: 0.8145\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.8275 - val_accuracy: 0.8247\n","Epoch 88/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0109 - accuracy: 0.9997 - val_loss: 0.8611 - val_accuracy: 0.8145\n","Epoch 89/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: 0.8627 - val_accuracy: 0.8213\n","Epoch 90/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 0.8555 - val_accuracy: 0.8100\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.9365 - val_accuracy: 0.8077\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.9179 - val_accuracy: 0.8077\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.9255 - val_accuracy: 0.8100\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 0.9994 - val_loss: 0.8742 - val_accuracy: 0.8122\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.9997 - val_loss: 0.8906 - val_accuracy: 0.8156\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.8840 - val_accuracy: 0.8201\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.9997 - val_loss: 0.9055 - val_accuracy: 0.8224\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.9997 - val_loss: 0.9058 - val_accuracy: 0.8100\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.8167\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.8133\n","{'loss': [0.05780176818370819, 0.038752481341362, 0.02465052716434002, 0.03015751764178276, 0.02529773861169815, 0.02590997703373432, 0.016756782308220863, 0.014562265947461128, 0.015787744894623756, 0.024449743330478668, 0.024419408291578293, 0.023395037278532982, 0.04530378803610802, 0.04256945103406906, 0.03448321670293808, 0.033767301589250565, 0.03377571329474449, 0.024727938696742058, 0.03261975944042206, 0.04185936972498894, 0.026232650503516197, 0.024978095665574074, 0.024573909118771553, 0.019599810242652893, 0.014230417087674141, 0.01488696038722992, 0.024346526712179184, 0.019444141536951065, 0.013458376750349998, 0.01408328115940094, 0.013998867943882942, 0.01545210275799036, 0.017719564959406853, 0.028118133544921875, 0.02618643268942833, 0.0317053459584713, 0.04121803119778633, 0.0515204519033432, 0.03938182070851326, 0.02012927643954754, 0.022649522870779037, 0.03444560244679451, 0.03174862638115883, 0.043468374758958817, 0.03516339510679245, 0.02301083318889141, 0.020794378593564034, 0.014450251124799252, 0.013409096747636795, 0.01318240538239479, 0.01085581909865141, 0.013794898055493832, 0.014090764336287975, 0.011545997112989426, 0.010319859720766544, 0.009796618483960629, 0.01049331296235323, 0.010135604999959469, 0.013186256401240826, 0.025335021317005157, 0.014911273494362831, 0.011494957841932774, 0.01091583538800478, 0.012750753201544285, 0.01827288791537285, 0.026675110682845116, 0.025957046076655388, 0.024562738835811615, 0.04655813053250313, 0.045534707605838776, 0.03222117945551872, 0.028963055461645126, 0.02775331772863865, 0.032494060695171356, 0.033185772597789764, 0.02921762689948082, 0.02532460354268551, 0.040439192205667496, 0.024355757981538773, 0.019763173535466194, 0.01783871464431286, 0.020263347774744034, 0.022327223792672157, 0.03187408670783043, 0.02430434338748455, 0.02233573980629444, 0.014446127228438854, 0.010917180217802525, 0.013347139582037926, 0.016558140516281128, 0.012341421097517014, 0.012802686542272568, 0.010508308187127113, 0.009927649050951004, 0.008945890702307224, 0.008949067443609238, 0.008570929057896137, 0.00906086154282093, 0.008312800899147987, 0.008284336887300014], 'accuracy': [0.983305037021637, 0.9895302653312683, 0.9951896071434021, 0.992642879486084, 0.9940577149391174, 0.9940577149391174, 0.9983022212982178, 0.9983022212982178, 0.9974533319473267, 0.9932088255882263, 0.994340717792511, 0.9949066042900085, 0.9872665405273438, 0.986983597278595, 0.990662157535553, 0.9932088255882263, 0.9920769929885864, 0.9951896071434021, 0.9898132681846619, 0.9883984327316284, 0.9946236610412598, 0.9937747716903687, 0.994340717792511, 0.9971703290939331, 0.9988681674003601, 0.9980192184448242, 0.9949066042900085, 0.996321439743042, 0.9991511106491089, 0.9977362751960754, 0.9977362751960754, 0.9971703290939331, 0.9968873858451843, 0.9951896071434021, 0.994340717792511, 0.9900962114334106, 0.988964319229126, 0.9867005944252014, 0.9895302653312683, 0.9951896071434021, 0.9949066042900085, 0.990662157535553, 0.9900962114334106, 0.9867005944252014, 0.9886813759803772, 0.996321439743042, 0.996321439743042, 0.9985851645469666, 0.9980192184448242, 0.9991511106491089, 0.9994340538978577, 0.9983022212982178, 0.9980192184448242, 0.9991511106491089, 0.9997170567512512, 1.0, 0.9994340538978577, 0.9997170567512512, 0.9983022212982178, 0.9940577149391174, 0.9980192184448242, 0.9991511106491089, 0.9985851645469666, 0.9983022212982178, 0.9951896071434021, 0.9912280440330505, 0.9929258823394775, 0.9929258823394775, 0.9861347079277039, 0.9858517050743103, 0.9929258823394775, 0.9923599362373352, 0.992642879486084, 0.9917939901351929, 0.9909451007843018, 0.9929258823394775, 0.994340717792511, 0.9878324866294861, 0.994340717792511, 0.9957554936408997, 0.9966044425964355, 0.9960384964942932, 0.9954725503921509, 0.9909451007843018, 0.9923599362373352, 0.9946236610412598, 0.9980192184448242, 0.9997170567512512, 0.9980192184448242, 0.9960384964942932, 0.9983022212982178, 0.9980192184448242, 0.9994340538978577, 0.9994340538978577, 0.9997170567512512, 1.0, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0], 'val_loss': [0.686391294002533, 0.6775389909744263, 0.6590564250946045, 0.6406947374343872, 0.614351212978363, 0.5977779030799866, 0.5442882180213928, 0.504593014717102, 0.4603182375431061, 0.4395378530025482, 0.42466554045677185, 0.4024384915828705, 0.43138161301612854, 0.42812609672546387, 0.4221762716770172, 0.4352472126483917, 0.4236651659011841, 0.4671536386013031, 0.4824230372905731, 0.4735962450504303, 0.571776807308197, 0.537470281124115, 0.5464782118797302, 0.5269865393638611, 0.568406343460083, 0.6002647280693054, 0.5915631055831909, 0.6074731945991516, 0.6591095328330994, 0.62086021900177, 0.5901362895965576, 0.8889142870903015, 0.7383650541305542, 0.6959969401359558, 0.6718318462371826, 0.7212281823158264, 0.6526594758033752, 0.6451791524887085, 0.7113731503486633, 0.8709517121315002, 0.7978739738464355, 0.7846367359161377, 0.793775737285614, 0.7393829226493835, 0.7992090582847595, 0.8222530484199524, 0.8193373084068298, 0.8307252526283264, 0.8661645650863647, 0.8707560300827026, 0.8889553546905518, 0.8225544095039368, 0.7888093590736389, 0.8218967914581299, 0.8481012582778931, 0.8494845628738403, 0.7985468506813049, 0.7976645827293396, 0.8890708684921265, 0.7871115803718567, 0.7948194742202759, 0.8878284692764282, 0.8550337553024292, 0.8743830323219299, 0.8273248672485352, 0.8722208142280579, 0.885012686252594, 0.8696932792663574, 0.8333061933517456, 0.8261248469352722, 1.0001921653747559, 1.0567692518234253, 0.9781498312950134, 1.0009602308273315, 0.9576385617256165, 0.8766652941703796, 0.9230157732963562, 0.8081861734390259, 0.7823297381401062, 1.013117790222168, 0.9286062121391296, 0.8152660131454468, 1.1428056955337524, 0.9316839575767517, 0.9874534010887146, 0.8011437058448792, 0.8274549245834351, 0.8610934019088745, 0.8627384305000305, 0.8555019497871399, 0.9365314245223999, 0.9178536534309387, 0.9254730939865112, 0.8741732835769653, 0.8905950784683228, 0.88399738073349, 0.9054547548294067, 0.9057949781417847, 0.8950521945953369, 0.8902100920677185], 'val_accuracy': [0.581447958946228, 0.6323529481887817, 0.668552041053772, 0.7047511339187622, 0.7420814633369446, 0.726244330406189, 0.7952488660812378, 0.7952488660812378, 0.8156108856201172, 0.8359728455543518, 0.8325791954994202, 0.831447958946228, 0.807692289352417, 0.8190045356750488, 0.8122171759605408, 0.837104082107544, 0.8348416090011597, 0.8416289687156677, 0.8325791954994202, 0.8246606588363647, 0.8178732991218567, 0.8472850918769836, 0.8540723919868469, 0.860859751701355, 0.8653846383094788, 0.8506787419319153, 0.8574660420417786, 0.860859751701355, 0.8495475053787231, 0.860859751701355, 0.860859751701355, 0.8178732991218567, 0.8450226187705994, 0.8393664956092834, 0.8529411554336548, 0.8337104320526123, 0.8404977321624756, 0.8257918357849121, 0.8122171759605408, 0.8110859990119934, 0.8257918357849121, 0.8178732991218567, 0.8223981857299805, 0.8042986392974854, 0.8065611124038696, 0.8223981857299805, 0.8291855454444885, 0.820135772228241, 0.8156108856201172, 0.8190045356750488, 0.8246606588363647, 0.8325791954994202, 0.837104082107544, 0.8280543088912964, 0.8325791954994202, 0.8348416090011597, 0.8438913822174072, 0.8450226187705994, 0.8167420625686646, 0.8167420625686646, 0.8235294222831726, 0.8269230723381042, 0.8235294222831726, 0.831447958946228, 0.8156108856201172, 0.8042986392974854, 0.8065611124038696, 0.8167420625686646, 0.7941176295280457, 0.7884615659713745, 0.7816742062568665, 0.7647058963775635, 0.779411792755127, 0.7703620195388794, 0.7805429697036743, 0.8054298758506775, 0.8009049892425537, 0.8042986392974854, 0.8009049892425537, 0.8020362257957458, 0.8031674027442932, 0.8190045356750488, 0.7748869061470032, 0.7760180830955505, 0.7703620195388794, 0.814479649066925, 0.8246606588363647, 0.814479649066925, 0.8212669491767883, 0.8099547624588013, 0.807692289352417, 0.807692289352417, 0.8099547624588013, 0.8122171759605408, 0.8156108856201172, 0.820135772228241, 0.8223981857299805, 0.8099547624588013, 0.8167420625686646, 0.8133484125137329]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.0771 - accuracy: 0.9744"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 51ms/step - loss: 0.0774 - accuracy: 0.9739 - val_loss: 0.6890 - val_accuracy: 0.5548\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.6777 - val_accuracy: 0.5971\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0321 - accuracy: 0.9925 - val_loss: 0.6608 - val_accuracy: 0.6353\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0317 - accuracy: 0.9928 - val_loss: 0.6478 - val_accuracy: 0.6374\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.6205 - val_accuracy: 0.6952\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.6035 - val_accuracy: 0.6839\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0272 - accuracy: 0.9946 - val_loss: 0.5691 - val_accuracy: 0.7324\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.5668 - val_accuracy: 0.7355\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0441 - accuracy: 0.9855 - val_loss: 0.5244 - val_accuracy: 0.7872\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.5331 - val_accuracy: 0.7562\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.4850 - val_accuracy: 0.7913\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0222 - accuracy: 0.9966 - val_loss: 0.4940 - val_accuracy: 0.7975\n","Epoch 13/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 0.5173 - val_accuracy: 0.8037\n","Epoch 14/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.5080 - val_accuracy: 0.8326\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.5705 - val_accuracy: 0.7934\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.5671 - val_accuracy: 0.8089\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0444 - accuracy: 0.9868 - val_loss: 0.5019 - val_accuracy: 0.8316\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0567 - accuracy: 0.9809 - val_loss: 0.6611 - val_accuracy: 0.7924\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0435 - accuracy: 0.9891 - val_loss: 0.6457 - val_accuracy: 0.8099\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 0.6967 - val_accuracy: 0.8213\n","Epoch 21/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0292 - accuracy: 0.9925 - val_loss: 0.6748 - val_accuracy: 0.8399\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 0.7755 - val_accuracy: 0.8285\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 0.9941 - val_loss: 0.8581 - val_accuracy: 0.8110\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9943 - val_loss: 0.8394 - val_accuracy: 0.8202\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.8174 - val_accuracy: 0.8264\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9917 - val_loss: 0.8839 - val_accuracy: 0.8110\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.7629 - val_accuracy: 0.8202\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.7484 - val_accuracy: 0.8378\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 0.7799 - val_accuracy: 0.8233\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9977 - val_loss: 0.8110 - val_accuracy: 0.8368\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 0.9984 - val_loss: 0.9010 - val_accuracy: 0.8285\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.8053 - val_accuracy: 0.8306\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9956 - val_loss: 0.8705 - val_accuracy: 0.8192\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9984 - val_loss: 0.8654 - val_accuracy: 0.8337\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.8957 - val_accuracy: 0.8223\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 0.8065 - val_accuracy: 0.8492\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0175 - accuracy: 0.9964 - val_loss: 0.8511 - val_accuracy: 0.8326\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.9052 - val_accuracy: 0.8233\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0459 - accuracy: 0.9840 - val_loss: 0.8513 - val_accuracy: 0.8140\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.8359 - val_accuracy: 0.8326\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.9964 - val_loss: 0.8779 - val_accuracy: 0.8337\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.8398 - val_accuracy: 0.8378\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0574 - accuracy: 0.9809 - val_loss: 0.7893 - val_accuracy: 0.7986\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0434 - accuracy: 0.9871 - val_loss: 0.8980 - val_accuracy: 0.7996\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0586 - accuracy: 0.9806 - val_loss: 0.8273 - val_accuracy: 0.7934\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0521 - accuracy: 0.9809 - val_loss: 0.8026 - val_accuracy: 0.8079\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0248 - accuracy: 0.9951 - val_loss: 0.9587 - val_accuracy: 0.8079\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.9643 - val_accuracy: 0.7986\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0351 - accuracy: 0.9907 - val_loss: 1.0358 - val_accuracy: 0.7882\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0334 - accuracy: 0.9899 - val_loss: 1.0964 - val_accuracy: 0.7676\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.8399 - val_accuracy: 0.8140\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.8877 - val_accuracy: 0.8058\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0274 - accuracy: 0.9930 - val_loss: 1.0125 - val_accuracy: 0.7893\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.9100 - val_accuracy: 0.8295\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9979 - val_loss: 0.9676 - val_accuracy: 0.8202\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 0.9961 - val_loss: 1.2202 - val_accuracy: 0.7779\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.8781 - val_accuracy: 0.8171\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.9516 - val_accuracy: 0.8006\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 0.9217 - val_accuracy: 0.8264\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.9977 - val_loss: 0.9603 - val_accuracy: 0.8254\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 0.9478 - val_accuracy: 0.8182\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9990 - val_loss: 0.9774 - val_accuracy: 0.8192\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9990 - val_loss: 0.9806 - val_accuracy: 0.8295\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.9722 - val_accuracy: 0.8244\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 0.9997 - val_loss: 0.9934 - val_accuracy: 0.8244\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.9997 - val_loss: 0.9842 - val_accuracy: 0.8316\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 0.9232 - val_accuracy: 0.8223\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.9979 - val_accuracy: 0.8079\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.9684 - val_accuracy: 0.8192\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.9297 - val_accuracy: 0.8192\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.9104 - val_accuracy: 0.8171\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.9187 - val_accuracy: 0.8254\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9979 - val_loss: 0.9611 - val_accuracy: 0.8182\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 1.0022 - val_accuracy: 0.8089\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0403 - accuracy: 0.9884 - val_loss: 0.8401 - val_accuracy: 0.8110\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0248 - accuracy: 0.9953 - val_loss: 0.9961 - val_accuracy: 0.7975\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0204 - accuracy: 0.9948 - val_loss: 0.9683 - val_accuracy: 0.8058\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0386 - accuracy: 0.9879 - val_loss: 1.0514 - val_accuracy: 0.7831\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0647 - accuracy: 0.9788 - val_loss: 0.7718 - val_accuracy: 0.8006\n","Epoch 80/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0394 - accuracy: 0.9899 - val_loss: 1.2513 - val_accuracy: 0.7376\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0269 - accuracy: 0.9930 - val_loss: 1.0494 - val_accuracy: 0.7758\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.9825 - val_accuracy: 0.7727\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0636 - accuracy: 0.9798 - val_loss: 0.9024 - val_accuracy: 0.7903\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 0.9943 - val_loss: 1.0663 - val_accuracy: 0.7634\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0203 - accuracy: 0.9966 - val_loss: 1.0956 - val_accuracy: 0.7820\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 1.0848 - val_accuracy: 0.7779\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9966 - val_loss: 1.1112 - val_accuracy: 0.7831\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 0.9959 - val_loss: 1.1277 - val_accuracy: 0.7758\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 1.2109 - val_accuracy: 0.7583\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0307 - accuracy: 0.9910 - val_loss: 1.1571 - val_accuracy: 0.7758\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0665 - accuracy: 0.9783 - val_loss: 0.8508 - val_accuracy: 0.7593\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9941 - val_loss: 1.1295 - val_accuracy: 0.7738\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 1.2058 - val_accuracy: 0.7738\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9982 - val_loss: 1.1727 - val_accuracy: 0.7738\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9984 - val_loss: 1.1425 - val_accuracy: 0.7862\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 1.1544 - val_accuracy: 0.7913\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0141 - accuracy: 0.9982 - val_loss: 1.0955 - val_accuracy: 0.8017\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 1.2480 - val_accuracy: 0.7769\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0358 - accuracy: 0.9899 - val_loss: 1.0806 - val_accuracy: 0.7779\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 1.2195 - val_accuracy: 0.7665\n","{'loss': [0.07741526514291763, 0.044815897941589355, 0.0320962630212307, 0.0316820852458477, 0.033925727009773254, 0.032766975462436676, 0.0272107794880867, 0.0629759356379509, 0.04411694034934044, 0.039289288222789764, 0.028395362198352814, 0.02221052162349224, 0.020421020686626434, 0.021648792549967766, 0.026391226798295975, 0.03546133637428284, 0.044376444071531296, 0.0566728450357914, 0.04347282648086548, 0.024826601147651672, 0.029225438833236694, 0.0242515467107296, 0.02458004467189312, 0.02565145306289196, 0.029015708714723587, 0.03140717372298241, 0.04843885451555252, 0.02920185960829258, 0.028357960283756256, 0.016404710710048676, 0.016178032383322716, 0.027149243280291557, 0.020991161465644836, 0.01632462814450264, 0.01553158275783062, 0.01931803673505783, 0.017476918175816536, 0.02335907146334648, 0.0458693653345108, 0.026101505383849144, 0.01781880296766758, 0.03199370577931404, 0.05742279440164566, 0.04340776056051254, 0.058556634932756424, 0.052068233489990234, 0.02483932301402092, 0.036290619522333145, 0.03508516773581505, 0.03340838477015495, 0.03811890631914139, 0.03302478417754173, 0.02739218808710575, 0.01966742053627968, 0.015689082443714142, 0.019734038040041924, 0.031090280041098595, 0.023737896233797073, 0.017066888511180878, 0.015627194195985794, 0.01300053484737873, 0.012583243660628796, 0.011911679059267044, 0.0120405787602067, 0.01079624891281128, 0.01030921470373869, 0.017282603308558464, 0.013205062597990036, 0.013206527568399906, 0.015510303899645805, 0.015642179176211357, 0.013787390664219856, 0.015173571184277534, 0.016673129051923752, 0.040338270366191864, 0.024799853563308716, 0.0204100850969553, 0.03861292451620102, 0.06467771530151367, 0.03944828733801842, 0.026909084990620613, 0.047924626618623734, 0.06360479444265366, 0.02884053625166416, 0.020335771143436432, 0.02759028598666191, 0.017498653382062912, 0.022981733083724976, 0.016452345997095108, 0.0307052880525589, 0.06646101176738739, 0.027529580518603325, 0.017328308895230293, 0.01378877554088831, 0.01358581893146038, 0.012385863810777664, 0.014110610820353031, 0.019473956897854805, 0.0358123779296875, 0.021445348858833313], 'accuracy': [0.9739018082618713, 0.9865633249282837, 0.9925064444541931, 0.9927648305892944, 0.9914728403091431, 0.9909560680389404, 0.9945736527442932, 0.9798449873924255, 0.9855297207832336, 0.9870800971984863, 0.9927648305892944, 0.9966408014297485, 0.9961240291595459, 0.9950904250144958, 0.9925064444541931, 0.9894056916236877, 0.986821711063385, 0.9808785319328308, 0.9891473054885864, 0.9956072568893433, 0.9925064444541931, 0.9945736527442932, 0.9940568208694458, 0.9943152666091919, 0.9932816624641418, 0.9917312860488892, 0.9852713346481323, 0.9919896721839905, 0.9925064444541931, 0.9976744055747986, 0.9984496235847473, 0.9914728403091431, 0.9956072568893433, 0.9984496235847473, 0.9976744055747986, 0.9958656430244446, 0.9963824152946472, 0.9940568208694458, 0.983979344367981, 0.9932816624641418, 0.9963824152946472, 0.9899224638938904, 0.9808785319328308, 0.9870800971984863, 0.9806201457977295, 0.9808785319328308, 0.9950904250144958, 0.9901808500289917, 0.9906976819038391, 0.9899224638938904, 0.987596869468689, 0.9912144541740417, 0.9930232763290405, 0.9963824152946472, 0.9979327917098999, 0.9961240291595459, 0.9917312860488892, 0.9927648305892944, 0.997157633304596, 0.9976744055747986, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.99896639585495, 0.9997416138648987, 0.9997416138648987, 0.9966408014297485, 0.9987080097198486, 0.9976744055747986, 0.9974160194396973, 0.9966408014297485, 0.997157633304596, 0.9979327917098999, 0.9966408014297485, 0.9883720874786377, 0.9953488111495972, 0.9948320388793945, 0.9878553152084351, 0.9788113832473755, 0.9899224638938904, 0.9930232763290405, 0.9852713346481323, 0.9798449873924255, 0.9943152666091919, 0.9966408014297485, 0.9917312860488892, 0.9966408014297485, 0.9958656430244446, 0.9968992471694946, 0.9909560680389404, 0.9782945513725281, 0.9940568208694458, 0.9966408014297485, 0.998191237449646, 0.9984496235847473, 0.9992247819900513, 0.998191237449646, 0.9953488111495972, 0.9899224638938904, 0.9958656430244446], 'val_loss': [0.6889914870262146, 0.6776868104934692, 0.6608421206474304, 0.6477621793746948, 0.6204876899719238, 0.6035202741622925, 0.5691071152687073, 0.5668028593063354, 0.5244491696357727, 0.5331356525421143, 0.4849894642829895, 0.49397116899490356, 0.5172981023788452, 0.5080074071884155, 0.5704800486564636, 0.5670660138130188, 0.5019016265869141, 0.661134660243988, 0.6456693410873413, 0.6967002153396606, 0.6747608184814453, 0.7755146026611328, 0.8581085205078125, 0.839381992816925, 0.8174189329147339, 0.8839253783226013, 0.7629317045211792, 0.7483550906181335, 0.7799266576766968, 0.8109760880470276, 0.9009526968002319, 0.8052625060081482, 0.8705423474311829, 0.8654318451881409, 0.8956610560417175, 0.8065387606620789, 0.8511359095573425, 0.905226469039917, 0.8513017892837524, 0.8359434604644775, 0.8778759241104126, 0.8398200869560242, 0.7893244028091431, 0.8980405330657959, 0.8273316621780396, 0.8025563359260559, 0.958737313747406, 0.9643111824989319, 1.0357792377471924, 1.096401572227478, 0.8398674130439758, 0.887715756893158, 1.0125008821487427, 0.9099730253219604, 0.967595100402832, 1.2201896905899048, 0.8780511617660522, 0.9516159296035767, 0.9216796159744263, 0.9603101015090942, 0.9477928876876831, 0.9774479866027832, 0.980636715888977, 0.9722293019294739, 0.993369460105896, 0.9842125177383423, 0.9232113361358643, 0.997931718826294, 0.9684250950813293, 0.9297256469726562, 0.9103959798812866, 0.918708324432373, 0.9610653519630432, 1.002160906791687, 0.8400766849517822, 0.9961355328559875, 0.9682597517967224, 1.051374912261963, 0.7718050479888916, 1.2513371706008911, 1.0494309663772583, 0.9825182557106018, 0.9023604393005371, 1.0662890672683716, 1.0955623388290405, 1.0848015546798706, 1.1111855506896973, 1.1276509761810303, 1.2108737230300903, 1.1570855379104614, 0.8508333563804626, 1.1295477151870728, 1.2058087587356567, 1.1726993322372437, 1.1424624919891357, 1.1544194221496582, 1.0955127477645874, 1.248030662536621, 1.080574631690979, 1.2194536924362183], 'val_accuracy': [0.5547520518302917, 0.5971074104309082, 0.6353305578231812, 0.6373966932296753, 0.6952479481697083, 0.68388432264328, 0.7324380278587341, 0.7355371713638306, 0.7871900796890259, 0.7561983466148376, 0.7913222908973694, 0.797520637512207, 0.8037189841270447, 0.8326446413993835, 0.7933884263038635, 0.80888432264328, 0.8316115736961365, 0.7923553586006165, 0.8099173307418823, 0.8212810158729553, 0.8398760557174683, 0.8285123705863953, 0.8109503984451294, 0.8202479481697083, 0.8264462947845459, 0.8109503984451294, 0.8202479481697083, 0.8378099203109741, 0.8233470916748047, 0.836776852607727, 0.8285123705863953, 0.8305785059928894, 0.8192148804664612, 0.8336777091026306, 0.8223140239715576, 0.8491735458374023, 0.8326446413993835, 0.8233470916748047, 0.8140496015548706, 0.8326446413993835, 0.8336777091026306, 0.8378099203109741, 0.7985537052154541, 0.7995867729187012, 0.7933884263038635, 0.807851254940033, 0.807851254940033, 0.7985537052154541, 0.788223147392273, 0.7675619721412659, 0.8140496015548706, 0.8057851195335388, 0.78925621509552, 0.8295454382896423, 0.8202479481697083, 0.7778925895690918, 0.817148745059967, 0.8006198406219482, 0.8264462947845459, 0.8254132270812988, 0.8181818127632141, 0.8192148804664612, 0.8295454382896423, 0.8243801593780518, 0.8243801593780518, 0.8316115736961365, 0.8223140239715576, 0.807851254940033, 0.8192148804664612, 0.8192148804664612, 0.817148745059967, 0.8254132270812988, 0.8181818127632141, 0.80888432264328, 0.8109503984451294, 0.797520637512207, 0.8057851195335388, 0.7830578684806824, 0.8006198406219482, 0.7376033067703247, 0.7758264541625977, 0.7727272510528564, 0.7902892827987671, 0.7634297609329224, 0.7820248007774353, 0.7778925895690918, 0.7830578684806824, 0.7758264541625977, 0.7582644820213318, 0.7758264541625977, 0.7592975497245789, 0.7737603187561035, 0.7737603187561035, 0.7737603187561035, 0.7861570119857788, 0.7913222908973694, 0.8016529083251953, 0.7768595218658447, 0.7778925895690918, 0.7665289044380188]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 6s 51ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.6894 - val_accuracy: 0.5269\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.6786 - val_accuracy: 0.6002\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.6645 - val_accuracy: 0.6002\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0118 - accuracy: 0.9989 - val_loss: 0.6319 - val_accuracy: 0.6961\n","Epoch 5/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.5973 - val_accuracy: 0.7468\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.9981 - val_loss: 0.5700 - val_accuracy: 0.7371\n","Epoch 7/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.5376 - val_accuracy: 0.8082\n","Epoch 8/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.5131 - val_accuracy: 0.8211\n","Epoch 9/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 0.4689 - val_accuracy: 0.8373\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.4360 - val_accuracy: 0.8491\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.4474 - val_accuracy: 0.8200\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9960 - val_loss: 0.4228 - val_accuracy: 0.8384\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9935 - val_loss: 0.4665 - val_accuracy: 0.8265\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0323 - accuracy: 0.9914 - val_loss: 0.4335 - val_accuracy: 0.8319\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.4371 - val_accuracy: 0.8481\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 0.4490 - val_accuracy: 0.8319\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.4431 - val_accuracy: 0.8610\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9949 - val_loss: 0.4870 - val_accuracy: 0.8567\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 0.9941 - val_loss: 0.4635 - val_accuracy: 0.8567\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 0.9968 - val_loss: 0.4941 - val_accuracy: 0.8599\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.5878 - val_accuracy: 0.8599\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.5835 - val_accuracy: 0.8685\n","Epoch 23/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.5891 - val_accuracy: 0.8739\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0098 - accuracy: 0.9995 - val_loss: 0.5664 - val_accuracy: 0.8804\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0093 - accuracy: 0.9997 - val_loss: 0.5583 - val_accuracy: 0.8858\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.5951 - val_accuracy: 0.8825\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.5717 - val_accuracy: 0.8836\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.5868 - val_accuracy: 0.8750\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.6074 - val_accuracy: 0.8664\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 0.5722 - val_accuracy: 0.8825\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.6240 - val_accuracy: 0.8782\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.5774 - val_accuracy: 0.8696\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 0.5861 - val_accuracy: 0.8804\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.6277 - val_accuracy: 0.8772\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.6135 - val_accuracy: 0.8815\n","Epoch 36/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6140 - val_accuracy: 0.8890\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 0.9997 - val_loss: 0.6345 - val_accuracy: 0.8825\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.5892 - val_accuracy: 0.8879\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.9962 - val_loss: 0.5878 - val_accuracy: 0.8685\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.6768 - val_accuracy: 0.8470\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.5520 - val_accuracy: 0.8448\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.6256 - val_accuracy: 0.8599\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0275 - accuracy: 0.9927 - val_loss: 0.7318 - val_accuracy: 0.8384\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0295 - accuracy: 0.9930 - val_loss: 0.6888 - val_accuracy: 0.8459\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.7268 - val_accuracy: 0.8481\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9965 - val_loss: 0.7133 - val_accuracy: 0.8459\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.7020 - val_accuracy: 0.8416\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9930 - val_loss: 0.6318 - val_accuracy: 0.8502\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 0.7124 - val_accuracy: 0.8578\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9995 - val_loss: 0.8018 - val_accuracy: 0.8459\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9984 - val_loss: 0.7852 - val_accuracy: 0.8545\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.7684 - val_accuracy: 0.8513\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 0.9995 - val_loss: 0.8207 - val_accuracy: 0.8470\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.7387 - val_accuracy: 0.8653\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.7345 - val_accuracy: 0.8578\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.7288 - val_accuracy: 0.8567\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.9997 - val_loss: 0.7387 - val_accuracy: 0.8675\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.8631\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 0.7676 - val_accuracy: 0.8545\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.7907 - val_accuracy: 0.8545\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.7769 - val_accuracy: 0.8556\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.8567\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9997 - val_loss: 0.7542 - val_accuracy: 0.8610\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9997 - val_loss: 0.7874 - val_accuracy: 0.8578\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.8375 - val_accuracy: 0.8351\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 0.6950 - val_accuracy: 0.8513\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0322 - accuracy: 0.9906 - val_loss: 0.6687 - val_accuracy: 0.8362\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0350 - accuracy: 0.9892 - val_loss: 0.6669 - val_accuracy: 0.8384\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.8455 - val_accuracy: 0.8125\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.5769 - val_accuracy: 0.8394\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.7845 - val_accuracy: 0.8190\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.7796 - val_accuracy: 0.8244\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.7165 - val_accuracy: 0.8276\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0233 - accuracy: 0.9949 - val_loss: 0.8003 - val_accuracy: 0.8287\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.8042 - val_accuracy: 0.8244\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 0.9941 - val_loss: 0.7090 - val_accuracy: 0.8319\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 0.6825 - val_accuracy: 0.8319\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.9978 - val_loss: 0.6276 - val_accuracy: 0.8631\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.7449 - val_accuracy: 0.8394\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 0.8225 - val_accuracy: 0.8265\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.7584 - val_accuracy: 0.8394\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.7824 - val_accuracy: 0.8362\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9927 - val_loss: 0.7162 - val_accuracy: 0.8276\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.6693 - val_accuracy: 0.8438\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 0.7468 - val_accuracy: 0.8438\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.7859 - val_accuracy: 0.8373\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9970 - val_loss: 0.7199 - val_accuracy: 0.8524\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.7263 - val_accuracy: 0.8438\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.7386 - val_accuracy: 0.8448\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.8204 - val_accuracy: 0.8319\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.7891 - val_accuracy: 0.8491\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.7541 - val_accuracy: 0.8524\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.7246 - val_accuracy: 0.8459\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9981 - val_loss: 0.7215 - val_accuracy: 0.8416\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.8282 - val_accuracy: 0.8351\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.8078 - val_accuracy: 0.8459\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.7586 - val_accuracy: 0.8448\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 1.0135 - val_accuracy: 0.8136\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9970 - val_loss: 0.8720 - val_accuracy: 0.8244\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 0.8570 - val_accuracy: 0.8341\n","{'loss': [0.039323728531599045, 0.030877964571118355, 0.019918665289878845, 0.011844079941511154, 0.011441600508987904, 0.014208084903657436, 0.022091198712587357, 0.02195165306329727, 0.017468774691224098, 0.028738584369421005, 0.03755061700940132, 0.021048637107014656, 0.03041752800345421, 0.03234386816620827, 0.02170330099761486, 0.03328757733106613, 0.024036768823862076, 0.023973198607563972, 0.024610791355371475, 0.015672264620661736, 0.013505762442946434, 0.012363581918179989, 0.010061108507215977, 0.009755001403391361, 0.009291858412325382, 0.011133275926113129, 0.013859771192073822, 0.019538842141628265, 0.01975749246776104, 0.011825280264019966, 0.010086886584758759, 0.016176722943782806, 0.011787265539169312, 0.01073803286999464, 0.010743164457380772, 0.00889364443719387, 0.008744647726416588, 0.012917948886752129, 0.018431125208735466, 0.027180593460798264, 0.05133037269115448, 0.03101319819688797, 0.027451302856206894, 0.02954505756497383, 0.02115052565932274, 0.025754310190677643, 0.022352056577801704, 0.027565859258174896, 0.013021772727370262, 0.011124465614557266, 0.01277675200253725, 0.013335959054529667, 0.010197693482041359, 0.012394316494464874, 0.012618672102689743, 0.010409035719931126, 0.008424856700003147, 0.008055055513978004, 0.00898399855941534, 0.009274426847696304, 0.00870424136519432, 0.007845529355108738, 0.007925569079816341, 0.00791163183748722, 0.01613915152847767, 0.018276272341609, 0.03223047032952309, 0.03503686934709549, 0.027800869196653366, 0.04069315269589424, 0.026858506724238396, 0.023533327504992485, 0.028069637715816498, 0.02329305000603199, 0.025486014783382416, 0.026101313531398773, 0.029563186690211296, 0.01563853770494461, 0.018462222069501877, 0.017945704981684685, 0.016013022512197495, 0.017741920426487923, 0.0299483984708786, 0.0252798143774271, 0.013875158503651619, 0.014651486650109291, 0.017206819728016853, 0.016174839809536934, 0.013487442396581173, 0.010701218619942665, 0.011509500443935394, 0.01530146598815918, 0.011734366416931152, 0.013958948664367199, 0.009512591175734997, 0.013855120167136192, 0.014329819008708, 0.013497300446033478, 0.01739705167710781, 0.013330084271728992], 'accuracy': [0.9876077771186829, 0.9900323152542114, 0.9959590435028076, 0.9989224076271057, 0.998652994632721, 0.9981142282485962, 0.9940732717514038, 0.9940732717514038, 0.9964978694915771, 0.9916487336158752, 0.9884159564971924, 0.9959590435028076, 0.993534505367279, 0.9913793206214905, 0.9943426847457886, 0.9903017282485962, 0.993534505367279, 0.9948814511299133, 0.9940732717514038, 0.9967672228813171, 0.9978448152542114, 0.998383641242981, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 0.998652994632721, 0.9975754022598267, 0.9946120977401733, 0.9954202771186829, 0.998652994632721, 0.9991918206214905, 0.9967672228813171, 0.998652994632721, 0.998652994632721, 0.9991918206214905, 1.0, 0.9997305870056152, 0.9970366358757019, 0.9962284564971924, 0.9913793206214905, 0.9841055870056152, 0.9911099076271057, 0.9927262663841248, 0.9929956793785095, 0.9948814511299133, 0.9964978694915771, 0.9948814511299133, 0.9929956793785095, 0.998652994632721, 0.9994612336158752, 0.998383641242981, 0.9978448152542114, 0.9994612336158752, 0.998383641242981, 0.9978448152542114, 0.998652994632721, 0.9997305870056152, 1.0, 0.9994612336158752, 0.9991918206214905, 0.9991918206214905, 1.0, 0.9997305870056152, 0.9997305870056152, 0.9964978694915771, 0.9959590435028076, 0.990571141242981, 0.9892241358757019, 0.9913793206214905, 0.9873383641242981, 0.993803858757019, 0.993803858757019, 0.9916487336158752, 0.9948814511299133, 0.9927262663841248, 0.9940732717514038, 0.9932650923728943, 0.9978448152542114, 0.9962284564971924, 0.9962284564971924, 0.9970366358757019, 0.9962284564971924, 0.9927262663841248, 0.9927262663841248, 0.9981142282485962, 0.998383641242981, 0.9970366358757019, 0.9975754022598267, 0.9973060488700867, 0.998652994632721, 0.9989224076271057, 0.9973060488700867, 0.9981142282485962, 0.9981142282485962, 0.9991918206214905, 0.9970366358757019, 0.9970366358757019, 0.9978448152542114, 0.9970366358757019, 0.9981142282485962], 'val_loss': [0.6894460916519165, 0.6786384582519531, 0.6645178198814392, 0.6318951845169067, 0.5972751975059509, 0.5699863433837891, 0.5375828742980957, 0.5130562782287598, 0.4689275622367859, 0.43597444891929626, 0.44741442799568176, 0.42282480001449585, 0.4664701521396637, 0.43345901370048523, 0.4370577931404114, 0.44896748661994934, 0.44308972358703613, 0.48700523376464844, 0.46351882815361023, 0.4941110610961914, 0.5878041386604309, 0.5835459232330322, 0.5890941023826599, 0.5663604736328125, 0.5583187341690063, 0.595132052898407, 0.571668803691864, 0.5867564082145691, 0.607387900352478, 0.5721532702445984, 0.6240206956863403, 0.5773810744285583, 0.586092472076416, 0.6276749968528748, 0.6134833693504333, 0.6139636635780334, 0.6345449090003967, 0.5891579985618591, 0.5877546668052673, 0.6768443584442139, 0.5519594550132751, 0.625591516494751, 0.7318317294120789, 0.688805103302002, 0.7267871499061584, 0.7132774591445923, 0.7020488977432251, 0.6317969560623169, 0.7124380469322205, 0.801767885684967, 0.785224974155426, 0.7684330940246582, 0.8206857442855835, 0.7386851906776428, 0.7344641089439392, 0.7287567257881165, 0.7387195229530334, 0.75087970495224, 0.7675572037696838, 0.790716290473938, 0.7768527269363403, 0.7689677476882935, 0.7541593313217163, 0.7873507142066956, 0.8374606370925903, 0.6950364708900452, 0.6686593890190125, 0.6668567657470703, 0.845504105091095, 0.576939046382904, 0.7845098972320557, 0.7796361446380615, 0.7165214419364929, 0.8003172874450684, 0.8041936755180359, 0.7090290188789368, 0.682496964931488, 0.6275575160980225, 0.7448769211769104, 0.8225061893463135, 0.7584046721458435, 0.7823618054389954, 0.7161913514137268, 0.669327437877655, 0.7468361854553223, 0.7859370708465576, 0.719912588596344, 0.7262531518936157, 0.7385868430137634, 0.820418655872345, 0.7891496419906616, 0.7540793418884277, 0.72456955909729, 0.7214677929878235, 0.8282023668289185, 0.807831883430481, 0.758648157119751, 1.0135343074798584, 0.8720349073410034, 0.8570278286933899], 'val_accuracy': [0.5269396305084229, 0.600215494632721, 0.600215494632721, 0.6961206793785095, 0.7467672228813171, 0.7370689511299133, 0.8081896305084229, 0.8211206793785095, 0.837284505367279, 0.8491379022598267, 0.8200430870056152, 0.8383620977401733, 0.826508641242981, 0.8318965435028076, 0.8480603694915771, 0.8318965435028076, 0.860991358757019, 0.8566810488700867, 0.8566810488700867, 0.8599137663841248, 0.8599137663841248, 0.868534505367279, 0.8739224076271057, 0.8803879022598267, 0.8857758641242981, 0.8825430870056152, 0.8836206793785095, 0.875, 0.8663793206214905, 0.8825430870056152, 0.8782327771186829, 0.8696120977401733, 0.8803879022598267, 0.8771551847457886, 0.881465494632721, 0.889008641242981, 0.8825430870056152, 0.8879310488700867, 0.868534505367279, 0.8469827771186829, 0.8448275923728943, 0.8599137663841248, 0.8383620977401733, 0.8459051847457886, 0.8480603694915771, 0.8459051847457886, 0.8415948152542114, 0.850215494632721, 0.857758641242981, 0.8459051847457886, 0.8545258641242981, 0.8512930870056152, 0.8469827771186829, 0.8653017282485962, 0.857758641242981, 0.8566810488700867, 0.8674569129943848, 0.8631465435028076, 0.8545258641242981, 0.8545258641242981, 0.8556034564971924, 0.8566810488700867, 0.860991358757019, 0.857758641242981, 0.8351293206214905, 0.8512930870056152, 0.8362069129943848, 0.8383620977401733, 0.8125, 0.8394396305084229, 0.818965494632721, 0.8243534564971924, 0.8275862336158752, 0.8286637663841248, 0.8243534564971924, 0.8318965435028076, 0.8318965435028076, 0.8631465435028076, 0.8394396305084229, 0.826508641242981, 0.8394396305084229, 0.8362069129943848, 0.8275862336158752, 0.84375, 0.84375, 0.837284505367279, 0.8523706793785095, 0.84375, 0.8448275923728943, 0.8318965435028076, 0.8491379022598267, 0.8523706793785095, 0.8459051847457886, 0.8415948152542114, 0.8351293206214905, 0.8459051847457886, 0.8448275923728943, 0.8135775923728943, 0.8243534564971924, 0.8340517282485962]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.0376 - accuracy: 0.9876"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 56ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.6835 - val_accuracy: 0.5792\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.6733 - val_accuracy: 0.5962\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.6522 - val_accuracy: 0.6731\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 0.6328 - val_accuracy: 0.7308\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.6098 - val_accuracy: 0.7115\n","Epoch 6/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.5654 - val_accuracy: 0.7624\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 0.5187 - val_accuracy: 0.8201\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 0.4736 - val_accuracy: 0.8428\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0232 - accuracy: 0.9952 - val_loss: 0.4487 - val_accuracy: 0.8337\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0395 - accuracy: 0.9904 - val_loss: 0.4496 - val_accuracy: 0.8190\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.4421 - val_accuracy: 0.7986\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.4173 - val_accuracy: 0.8156\n","Epoch 13/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.3833 - val_accuracy: 0.8360\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.3457 - val_accuracy: 0.8597\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0113 - accuracy: 0.9994 - val_loss: 0.3514 - val_accuracy: 0.8722\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.3814 - val_accuracy: 0.8631\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.3756 - val_accuracy: 0.8643\n","Epoch 18/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.3583 - val_accuracy: 0.8756\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.9986 - val_loss: 0.4486 - val_accuracy: 0.8744\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.4297 - val_accuracy: 0.8767\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0427 - accuracy: 0.9890 - val_loss: 0.4231 - val_accuracy: 0.8563\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 0.3693 - val_accuracy: 0.8778\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.4524 - val_accuracy: 0.8665\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0139 - accuracy: 0.9980 - val_loss: 0.4671 - val_accuracy: 0.8790\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0149 - accuracy: 0.9977 - val_loss: 0.4755 - val_accuracy: 0.8903\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 0.5212 - val_accuracy: 0.8801\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 0.5425 - val_accuracy: 0.8790\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.5343 - val_accuracy: 0.8801\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 0.9989 - val_loss: 0.5281 - val_accuracy: 0.8801\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.5281 - val_accuracy: 0.8710\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.4753 - val_accuracy: 0.8869\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.5204 - val_accuracy: 0.8857\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.6591 - val_accuracy: 0.8722\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.9955 - val_loss: 0.6115 - val_accuracy: 0.8563\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: 0.5853 - val_accuracy: 0.8631\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.6167 - val_accuracy: 0.8722\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9946 - val_loss: 0.5539 - val_accuracy: 0.8609\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.9932 - val_loss: 0.5974 - val_accuracy: 0.8529\n","Epoch 39/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.5471 - val_accuracy: 0.8631\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0320 - accuracy: 0.9924 - val_loss: 0.5360 - val_accuracy: 0.8597\n","Epoch 41/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0335 - accuracy: 0.9924 - val_loss: 0.6451 - val_accuracy: 0.8360\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.5980 - val_accuracy: 0.8360\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.6294 - val_accuracy: 0.8552\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.7445 - val_accuracy: 0.8416\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.5706 - val_accuracy: 0.8631\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.6225 - val_accuracy: 0.8609\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0135 - accuracy: 0.9983 - val_loss: 0.6689 - val_accuracy: 0.8586\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 0.9986 - val_loss: 0.7156 - val_accuracy: 0.8541\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.6180 - val_accuracy: 0.8778\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.6391 - val_accuracy: 0.8801\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.9997 - val_loss: 0.7174 - val_accuracy: 0.8609\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.9997 - val_loss: 0.7021 - val_accuracy: 0.8597\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.8676\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8643\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 0.8722\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.8722\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.8699\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.8688\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.8722\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.8665\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.8710\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.8654\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.8631\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.8676\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.8688\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.8665\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.8665\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.8665\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8699\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.8710\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.8688\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.8699\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.8699\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.8722\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.8688\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.8688\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.8699\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.8699\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.8710\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.8733\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8744\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.8733\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.8699\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8733\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8722\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.8710\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8722\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8710\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.8722\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8722\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.8778\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.8710\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.8767\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8756\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.8722\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.8733\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.8722\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.8733\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.8744\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.8722\n","{'loss': [0.03724626079201698, 0.02579050324857235, 0.020799467340111732, 0.0255710668861866, 0.02111155539751053, 0.014858453534543514, 0.015949830412864685, 0.017720000818371773, 0.02317485772073269, 0.03945336863398552, 0.02063841000199318, 0.01978159323334694, 0.01748453825712204, 0.015342812053859234, 0.011348403058946133, 0.016208723187446594, 0.014892037957906723, 0.0150041114538908, 0.012810545042157173, 0.013709469698369503, 0.04271964728832245, 0.037105824798345566, 0.02219344489276409, 0.013920177705585957, 0.014925368130207062, 0.01253491174429655, 0.013756009750068188, 0.01213329192250967, 0.010344073176383972, 0.016681991517543793, 0.01363341510295868, 0.010787129402160645, 0.019324196502566338, 0.01984340138733387, 0.014642544090747833, 0.018107762560248375, 0.023924605920910835, 0.02963026985526085, 0.028276780620217323, 0.0320139080286026, 0.033487718552351, 0.03628970682621002, 0.03479751572012901, 0.020366868004202843, 0.03135672211647034, 0.016662873327732086, 0.013522223569452763, 0.011027897708117962, 0.013839313760399818, 0.010097239166498184, 0.009186658076941967, 0.009311915375292301, 0.008056387305259705, 0.00801830179989338, 0.00783152412623167, 0.007757025305181742, 0.007707518059760332, 0.007689987774938345, 0.00763716222718358, 0.007571382448077202, 0.007551939692348242, 0.007544944994151592, 0.0075139570981264114, 0.007477808743715286, 0.007447276264429092, 0.007431156001985073, 0.007457523141056299, 0.007412588223814964, 0.00739589286968112, 0.0073735276237130165, 0.007370811887085438, 0.007341948337852955, 0.007335998583585024, 0.007320570293813944, 0.007299880962818861, 0.007292133290320635, 0.007269012276083231, 0.007262169383466244, 0.007264778949320316, 0.007288168650120497, 0.007263933774083853, 0.00723964674398303, 0.007214050740003586, 0.00720649678260088, 0.007202124688774347, 0.007186471484601498, 0.007186413276940584, 0.007157393731176853, 0.007162067573517561, 0.007159248925745487, 0.007136383559554815, 0.0071311634965240955, 0.007101844996213913, 0.007096806075423956, 0.00708971731364727, 0.007071035914123058, 0.007063671946525574, 0.00705994525924325, 0.007042612414807081, 0.007031355984508991], 'accuracy': [0.9875495433807373, 0.9932088255882263, 0.9960384964942932, 0.9934917688369751, 0.9946236610412598, 0.9980192184448242, 0.9971703290939331, 0.9974533319473267, 0.9951896071434021, 0.9903791546821594, 0.9949066042900085, 0.9951896071434021, 0.996321439743042, 0.9966044425964355, 0.9994340538978577, 0.9966044425964355, 0.9968873858451843, 0.9968873858451843, 0.9985851645469666, 0.9977362751960754, 0.988964319229126, 0.9895302653312683, 0.9946236610412598, 0.9980192184448242, 0.9977362751960754, 0.9985851645469666, 0.9977362751960754, 0.9983022212982178, 0.9988681674003601, 0.996321439743042, 0.9983022212982178, 0.9991511106491089, 0.9957554936408997, 0.9954725503921509, 0.9980192184448242, 0.9968873858451843, 0.9946236610412598, 0.9932088255882263, 0.9915110468864441, 0.9923599362373352, 0.9923599362373352, 0.9898132681846619, 0.9895302653312683, 0.9951896071434021, 0.9912280440330505, 0.9968873858451843, 0.9983022212982178, 0.9985851645469666, 0.9974533319473267, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.683493971824646, 0.6732832789421082, 0.6522190570831299, 0.6328485012054443, 0.6097944378852844, 0.5654152035713196, 0.5186973810195923, 0.4735749661922455, 0.448742151260376, 0.4495908319950104, 0.44206494092941284, 0.4173261821269989, 0.38332614302635193, 0.34565573930740356, 0.3514067232608795, 0.3813628852367401, 0.3756263256072998, 0.35831350088119507, 0.4485524296760559, 0.4296647608280182, 0.42308324575424194, 0.36927530169487, 0.4524468183517456, 0.46706631779670715, 0.47550252079963684, 0.5212323069572449, 0.54251629114151, 0.5343111753463745, 0.5280570983886719, 0.5281178951263428, 0.4752807021141052, 0.5203830003738403, 0.6590523719787598, 0.6114850044250488, 0.5853123068809509, 0.6166692972183228, 0.5539479851722717, 0.59739089012146, 0.5471181273460388, 0.5360314249992371, 0.6450958847999573, 0.5980264544487, 0.6293854117393494, 0.7445189952850342, 0.5705944299697876, 0.6225128769874573, 0.6689165234565735, 0.7155793309211731, 0.6179774403572083, 0.6390949487686157, 0.7174338102340698, 0.7021234631538391, 0.6444755792617798, 0.6850658655166626, 0.6399328112602234, 0.6347805261611938, 0.6327134966850281, 0.6473947763442993, 0.6248599886894226, 0.6284424662590027, 0.6242507100105286, 0.6329126358032227, 0.6308473348617554, 0.6223047971725464, 0.6201355457305908, 0.6215026378631592, 0.6146227717399597, 0.6170215606689453, 0.6148847341537476, 0.6145673990249634, 0.6159656047821045, 0.6173785924911499, 0.6127318739891052, 0.6103271842002869, 0.6114379167556763, 0.6130179762840271, 0.6086507439613342, 0.609145998954773, 0.6132523417472839, 0.6248327493667603, 0.6062887907028198, 0.6102654933929443, 0.6127738952636719, 0.6102403998374939, 0.6078523397445679, 0.6117174029350281, 0.6102150678634644, 0.6131480932235718, 0.6159494519233704, 0.6130532026290894, 0.6085035800933838, 0.6116347312927246, 0.6040617823600769, 0.6060625314712524, 0.6088205575942993, 0.6068496108055115, 0.6084144115447998, 0.6114886403083801, 0.6097845435142517, 0.6123318076133728], 'val_accuracy': [0.5791855454444885, 0.5961538553237915, 0.6730769276618958, 0.7307692170143127, 0.7115384340286255, 0.7624434232711792, 0.820135772228241, 0.8427602052688599, 0.8337104320526123, 0.8190045356750488, 0.7986425161361694, 0.8156108856201172, 0.8359728455543518, 0.8597285151481628, 0.872171938419342, 0.8631221652030945, 0.8642534017562866, 0.8755655884742737, 0.8744344115257263, 0.8766968250274658, 0.8563348650932312, 0.877828061580658, 0.8665158152580261, 0.8789592981338501, 0.8902714848518372, 0.8800904750823975, 0.8789592981338501, 0.8800904750823975, 0.8800904750823975, 0.8710407018661499, 0.8868778347969055, 0.8857465982437134, 0.872171938419342, 0.8563348650932312, 0.8631221652030945, 0.872171938419342, 0.860859751701355, 0.8529411554336548, 0.8631221652030945, 0.8597285151481628, 0.8359728455543518, 0.8359728455543518, 0.8552036285400391, 0.8416289687156677, 0.8631221652030945, 0.860859751701355, 0.8585972785949707, 0.8540723919868469, 0.877828061580658, 0.8800904750823975, 0.860859751701355, 0.8597285151481628, 0.8676470518112183, 0.8642534017562866, 0.872171938419342, 0.872171938419342, 0.8699095249176025, 0.8687782883644104, 0.872171938419342, 0.8665158152580261, 0.8710407018661499, 0.8653846383094788, 0.8631221652030945, 0.8676470518112183, 0.8687782883644104, 0.8665158152580261, 0.8665158152580261, 0.8665158152580261, 0.8699095249176025, 0.8710407018661499, 0.8687782883644104, 0.8699095249176025, 0.8699095249176025, 0.872171938419342, 0.8687782883644104, 0.8687782883644104, 0.8699095249176025, 0.8699095249176025, 0.8710407018661499, 0.8733031749725342, 0.8744344115257263, 0.8733031749725342, 0.8699095249176025, 0.8733031749725342, 0.872171938419342, 0.8710407018661499, 0.872171938419342, 0.8710407018661499, 0.872171938419342, 0.872171938419342, 0.877828061580658, 0.8710407018661499, 0.8766968250274658, 0.8755655884742737, 0.872171938419342, 0.8733031749725342, 0.872171938419342, 0.8733031749725342, 0.8744344115257263, 0.872171938419342]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.0539 - accuracy: 0.9860"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 7s 56ms/step - loss: 0.0530 - accuracy: 0.9858 - val_loss: 0.6860 - val_accuracy: 0.5837\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0280 - accuracy: 0.9930 - val_loss: 0.6709 - val_accuracy: 0.6374\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.6504 - val_accuracy: 0.6725\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0229 - accuracy: 0.9948 - val_loss: 0.6183 - val_accuracy: 0.7252\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 0.5951 - val_accuracy: 0.7624\n","Epoch 6/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0185 - accuracy: 0.9959 - val_loss: 0.5548 - val_accuracy: 0.7758\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.5036 - val_accuracy: 0.8037\n","Epoch 8/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0142 - accuracy: 0.9982 - val_loss: 0.4736 - val_accuracy: 0.8089\n","Epoch 9/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 0.4592 - val_accuracy: 0.8182\n","Epoch 10/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0544 - accuracy: 0.9819 - val_loss: 0.4649 - val_accuracy: 0.8316\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0325 - accuracy: 0.9920 - val_loss: 0.4418 - val_accuracy: 0.8430\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9961 - val_loss: 0.4360 - val_accuracy: 0.8378\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9972 - val_loss: 0.4968 - val_accuracy: 0.8192\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.4812 - val_accuracy: 0.8399\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.6684 - val_accuracy: 0.7862\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.4769 - val_accuracy: 0.8450\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.5590 - val_accuracy: 0.8440\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.4920 - val_accuracy: 0.8554\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.5498 - val_accuracy: 0.8688\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 0.6031 - val_accuracy: 0.8564\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.6198 - val_accuracy: 0.8636\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.6123 - val_accuracy: 0.8647\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.7077 - val_accuracy: 0.8533\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.5844 - val_accuracy: 0.8750\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0177 - accuracy: 0.9966 - val_loss: 0.6616 - val_accuracy: 0.8729\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9959 - val_loss: 0.7204 - val_accuracy: 0.8616\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0177 - accuracy: 0.9972 - val_loss: 0.6871 - val_accuracy: 0.8678\n","Epoch 28/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.6474 - val_accuracy: 0.8802\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.6921 - val_accuracy: 0.8688\n","Epoch 30/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0113 - accuracy: 0.9992 - val_loss: 0.7011 - val_accuracy: 0.8812\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.7012 - val_accuracy: 0.8688\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.7548 - val_accuracy: 0.8399\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.6783 - val_accuracy: 0.8523\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.7010 - val_accuracy: 0.8492\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.8257 - val_accuracy: 0.8264\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0335 - accuracy: 0.9910 - val_loss: 0.7222 - val_accuracy: 0.8378\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0462 - accuracy: 0.9873 - val_loss: 0.6030 - val_accuracy: 0.8471\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0378 - accuracy: 0.9910 - val_loss: 0.6429 - val_accuracy: 0.8554\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0180 - accuracy: 0.9966 - val_loss: 0.7269 - val_accuracy: 0.8605\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 0.7727 - val_accuracy: 0.8430\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0254 - accuracy: 0.9935 - val_loss: 0.8954 - val_accuracy: 0.8223\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.6998 - val_accuracy: 0.8523\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9961 - val_loss: 0.7551 - val_accuracy: 0.8523\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.8171 - val_accuracy: 0.8512\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.8004 - val_accuracy: 0.8595\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0095 - accuracy: 0.9997 - val_loss: 0.7953 - val_accuracy: 0.8554\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7603 - val_accuracy: 0.8688\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 0.8069 - val_accuracy: 0.8678\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.7584 - val_accuracy: 0.8647\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 0.7249 - val_accuracy: 0.8729\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.7483 - val_accuracy: 0.8554\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.8222 - val_accuracy: 0.8357\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 0.6748 - val_accuracy: 0.8430\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0489 - accuracy: 0.9855 - val_loss: 0.6280 - val_accuracy: 0.8440\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.7503 - val_accuracy: 0.8430\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9943 - val_loss: 0.9134 - val_accuracy: 0.8233\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0463 - accuracy: 0.9873 - val_loss: 0.5953 - val_accuracy: 0.8554\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0300 - accuracy: 0.9922 - val_loss: 0.6485 - val_accuracy: 0.8502\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.7285 - val_accuracy: 0.8264\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 0.6855 - val_accuracy: 0.8409\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.6650 - val_accuracy: 0.8378\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 0.6741 - val_accuracy: 0.8533\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 0.7682 - val_accuracy: 0.8502\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.8157 - val_accuracy: 0.8471\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.7102 - val_accuracy: 0.8512\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.7302 - val_accuracy: 0.8512\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: 0.7472 - val_accuracy: 0.8512\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 0.7472 - val_accuracy: 0.8533\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0085 - accuracy: 0.9997 - val_loss: 0.7659 - val_accuracy: 0.8461\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.8512\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.7636 - val_accuracy: 0.8523\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8585\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8554\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 0.9997 - val_loss: 0.7548 - val_accuracy: 0.8564\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8492\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7802 - val_accuracy: 0.8461\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.7626 - val_accuracy: 0.8512\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.7325 - val_accuracy: 0.8450\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.9543 - val_accuracy: 0.7882\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.8073 - val_accuracy: 0.8161\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0346 - accuracy: 0.9899 - val_loss: 0.7300 - val_accuracy: 0.8357\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.7816 - val_accuracy: 0.8326\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.7351 - val_accuracy: 0.8275\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.8292 - val_accuracy: 0.8202\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 0.9136 - val_accuracy: 0.8295\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9961 - val_loss: 0.9313 - val_accuracy: 0.8140\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9972 - val_loss: 0.8585 - val_accuracy: 0.8110\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.8926 - val_accuracy: 0.8295\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.8553 - val_accuracy: 0.8182\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 0.8707 - val_accuracy: 0.8068\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 0.9388 - val_accuracy: 0.8192\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0127 - accuracy: 0.9984 - val_loss: 0.9896 - val_accuracy: 0.8110\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.9004 - val_accuracy: 0.8130\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 0.8604 - val_accuracy: 0.8264\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.9147 - val_accuracy: 0.8233\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 1.0221 - val_accuracy: 0.8171\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.9781 - val_accuracy: 0.8192\n","Epoch 98/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0281 - accuracy: 0.9941 - val_loss: 0.9118 - val_accuracy: 0.7903\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.8610 - val_accuracy: 0.8089\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0401 - accuracy: 0.9853 - val_loss: 0.8476 - val_accuracy: 0.8058\n","{'loss': [0.053037844598293304, 0.027990270406007767, 0.030109427869319916, 0.02292872592806816, 0.03128630667924881, 0.018541228026151657, 0.013813218101859093, 0.014176581054925919, 0.026742978021502495, 0.054401595145463943, 0.03252122923731804, 0.018716959282755852, 0.016290443018078804, 0.018965594470500946, 0.030053313821554184, 0.040885359048843384, 0.024507544934749603, 0.037103649228811264, 0.02048950269818306, 0.017024116590619087, 0.01921943947672844, 0.020450333133339882, 0.020163536071777344, 0.023785877972841263, 0.017668120563030243, 0.018465213477611542, 0.017694251611828804, 0.015594910830259323, 0.012556320056319237, 0.011269669979810715, 0.014237294904887676, 0.023447958752512932, 0.02682756632566452, 0.03141142800450325, 0.024763265624642372, 0.03351945802569389, 0.046246569603681564, 0.03779911249876022, 0.01801280677318573, 0.018936844542622566, 0.025406548753380775, 0.025860311463475227, 0.018454425036907196, 0.013731476850807667, 0.01113524753600359, 0.009539119899272919, 0.009284659288823605, 0.008971843868494034, 0.009730502031743526, 0.011886697262525558, 0.01468496210873127, 0.019622700288891792, 0.03467646613717079, 0.04891470819711685, 0.02246173843741417, 0.023808905854821205, 0.046339068561792374, 0.030033666640520096, 0.03270545229315758, 0.03252073749899864, 0.034641094505786896, 0.02059589885175228, 0.011760499328374863, 0.010696020908653736, 0.019603857770562172, 0.020244721323251724, 0.012493852525949478, 0.010136410593986511, 0.00847570225596428, 0.008218072354793549, 0.009586774744093418, 0.008291985839605331, 0.007955602370202541, 0.007954047992825508, 0.007882198318839073, 0.007811690215021372, 0.010593601502478123, 0.021429991349577904, 0.03163261339068413, 0.03084295243024826, 0.03462602198123932, 0.023105189204216003, 0.029055455699563026, 0.02673378773033619, 0.017257170751690865, 0.021017087623476982, 0.01764548011124134, 0.012020801194012165, 0.019538743421435356, 0.026867985725402832, 0.01708853803575039, 0.012689491733908653, 0.020963430404663086, 0.016680747270584106, 0.011184784583747387, 0.013876223936676979, 0.01306864619255066, 0.028116030618548393, 0.03327010199427605, 0.04009006917476654], 'accuracy': [0.985788106918335, 0.9930232763290405, 0.9914728403091431, 0.9948320388793945, 0.9906976819038391, 0.9958656430244446, 0.9979327917098999, 0.998191237449646, 0.9932816624641418, 0.9819121360778809, 0.9919896721839905, 0.9961240291595459, 0.997157633304596, 0.9956072568893433, 0.9901808500289917, 0.9873384833335876, 0.9932816624641418, 0.9881137013435364, 0.9956072568893433, 0.9961240291595459, 0.9956072568893433, 0.9950904250144958, 0.9953488111495972, 0.9940568208694458, 0.9966408014297485, 0.9958656430244446, 0.997157633304596, 0.9966408014297485, 0.998191237449646, 0.9992247819900513, 0.9976744055747986, 0.9932816624641418, 0.9914728403091431, 0.9899224638938904, 0.9922480583190918, 0.9909560680389404, 0.9873384833335876, 0.9909560680389404, 0.9966408014297485, 0.9961240291595459, 0.9935400485992432, 0.9937984347343445, 0.9961240291595459, 0.9976744055747986, 0.9987080097198486, 0.9997416138648987, 1.0, 0.9994832277297974, 0.9994832277297974, 0.9984496235847473, 0.9974160194396973, 0.9953488111495972, 0.988630473613739, 0.9855297207832336, 0.9945736527442932, 0.9943152666091919, 0.9873384833335876, 0.9922480583190918, 0.9881137013435364, 0.9899224638938904, 0.9891473054885864, 0.9956072568893433, 0.9984496235847473, 0.9987080097198486, 0.9948320388793945, 0.9948320388793945, 0.9987080097198486, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9992247819900513, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 0.998191237449646, 0.9940568208694458, 0.9899224638938904, 0.9901808500289917, 0.9899224638938904, 0.9945736527442932, 0.9917312860488892, 0.9922480583190918, 0.9966408014297485, 0.9961240291595459, 0.997157633304596, 0.9984496235847473, 0.9945736527442932, 0.9922480583190918, 0.9961240291595459, 0.9984496235847473, 0.9943152666091919, 0.9966408014297485, 0.998191237449646, 0.9979327917098999, 0.9979327917098999, 0.9940568208694458, 0.9896640777587891, 0.9852713346481323], 'val_loss': [0.6859908103942871, 0.6708827614784241, 0.6503637433052063, 0.6182830333709717, 0.595058798789978, 0.5547847151756287, 0.5036373734474182, 0.47359782457351685, 0.45922112464904785, 0.46488139033317566, 0.44180211424827576, 0.4359889626502991, 0.4968326985836029, 0.4812456965446472, 0.6684219241142273, 0.4769306480884552, 0.5589900016784668, 0.4919843375682831, 0.549811065196991, 0.6030686497688293, 0.6197958588600159, 0.6122536659240723, 0.7076511383056641, 0.5843821167945862, 0.6615985631942749, 0.7203802466392517, 0.6871244311332703, 0.6474118828773499, 0.6920997500419617, 0.7010539174079895, 0.7012074589729309, 0.7548174262046814, 0.6783219575881958, 0.7010077834129333, 0.8257437944412231, 0.7222041487693787, 0.6030471324920654, 0.6428965926170349, 0.7268542051315308, 0.772746205329895, 0.895419180393219, 0.6997765898704529, 0.7551136612892151, 0.8170562982559204, 0.800387442111969, 0.795305609703064, 0.7602872252464294, 0.8069217205047607, 0.758443295955658, 0.7248834371566772, 0.7482645511627197, 0.8222124576568604, 0.6747927665710449, 0.6280269622802734, 0.7502771019935608, 0.9133552312850952, 0.5953347086906433, 0.6485460996627808, 0.7285391688346863, 0.6855131387710571, 0.665041446685791, 0.6740795969963074, 0.7682182788848877, 0.8156924843788147, 0.7102062702178955, 0.7301747798919678, 0.7472019791603088, 0.7471672892570496, 0.7658648490905762, 0.7587049007415771, 0.7636018395423889, 0.7599656581878662, 0.7632973790168762, 0.7547751069068909, 0.7577407360076904, 0.7802318334579468, 0.7625942826271057, 0.732517659664154, 0.9543254375457764, 0.8072763085365295, 0.7300048470497131, 0.7815565466880798, 0.7350980043411255, 0.8292264938354492, 0.9136319756507874, 0.9312600493431091, 0.8584612607955933, 0.8925575613975525, 0.8552642464637756, 0.8706997036933899, 0.9388046860694885, 0.9895782470703125, 0.9004207849502563, 0.8604424595832825, 0.9147211313247681, 1.0220874547958374, 0.9781486392021179, 0.9118333458900452, 0.8609868884086609, 0.8476343750953674], 'val_accuracy': [0.5836777091026306, 0.6373966932296753, 0.672520637512207, 0.7252066135406494, 0.7623966932296753, 0.7758264541625977, 0.8037189841270447, 0.80888432264328, 0.8181818127632141, 0.8316115736961365, 0.8429751992225647, 0.8378099203109741, 0.8192148804664612, 0.8398760557174683, 0.7861570119857788, 0.8450413346290588, 0.8440082669258118, 0.85537189245224, 0.8688016533851624, 0.8564049601554871, 0.8636363744735718, 0.8646694421768188, 0.8533057570457458, 0.875, 0.8729338645935059, 0.8615702390670776, 0.8677685856819153, 0.8801652789115906, 0.8688016533851624, 0.8811983466148376, 0.8688016533851624, 0.8398760557174683, 0.8522727489471436, 0.8491735458374023, 0.8264462947845459, 0.8378099203109741, 0.8471074104309082, 0.85537189245224, 0.8605371713638306, 0.8429751992225647, 0.8223140239715576, 0.8522727489471436, 0.8522727489471436, 0.8512396812438965, 0.8595041036605835, 0.85537189245224, 0.8688016533851624, 0.8677685856819153, 0.8646694421768188, 0.8729338645935059, 0.85537189245224, 0.83574378490448, 0.8429751992225647, 0.8440082669258118, 0.8429751992225647, 0.8233470916748047, 0.85537189245224, 0.8502066135406494, 0.8264462947845459, 0.8409090638160706, 0.8378099203109741, 0.8533057570457458, 0.8502066135406494, 0.8471074104309082, 0.8512396812438965, 0.8512396812438965, 0.8512396812438965, 0.8533057570457458, 0.8460744023323059, 0.8512396812438965, 0.8522727489471436, 0.8584710955619812, 0.85537189245224, 0.8564049601554871, 0.8491735458374023, 0.8460744023323059, 0.8512396812438965, 0.8450413346290588, 0.788223147392273, 0.81611567735672, 0.83574378490448, 0.8326446413993835, 0.827479362487793, 0.8202479481697083, 0.8295454382896423, 0.8140496015548706, 0.8109503984451294, 0.8295454382896423, 0.8181818127632141, 0.8068181872367859, 0.8192148804664612, 0.8109503984451294, 0.8130165338516235, 0.8264462947845459, 0.8233470916748047, 0.817148745059967, 0.8192148804664612, 0.7902892827987671, 0.80888432264328, 0.8057851195335388]}\n","32/32 [==============================] - 1s 3ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"Ik5JoVP2NPvY","executionInfo":{"status":"ok","timestamp":1717500572784,"user_tz":-360,"elapsed":20,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"3b3c7dff-6f34-4f57-9b70-d0d50760ea51"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.536      0.544   0.442  0.488        0.442        0.630   \n","1        1     0.561      0.602   0.359  0.450        0.359        0.763   \n","2        2     0.572      0.585   0.496  0.537        0.496        0.649   \n","3        0     0.642      0.647   0.626  0.637        0.626        0.658   \n","4        1     0.643      0.655   0.603  0.628        0.603        0.682   \n","5        2     0.632      0.655   0.556  0.602        0.556        0.707   \n","6        0     0.744      0.745   0.740  0.743        0.740        0.747   \n","7        1     0.764      0.748   0.797  0.772        0.797        0.732   \n","8        2     0.765      0.777   0.743  0.760        0.743        0.787   \n","9        0     0.816      0.815   0.817  0.816        0.817        0.814   \n","10       1     0.823      0.837   0.802  0.819        0.802        0.843   \n","11       2     0.832      0.847   0.811  0.829        0.811        0.853   \n","12       0     0.837      0.862   0.802  0.831        0.802        0.871   \n","13       1     0.850      0.869   0.823  0.846        0.823        0.876   \n","14       2     0.866      0.856   0.882  0.868        0.882        0.851   \n","\n","    Kappa  \n","0   0.072  \n","1   0.121  \n","2   0.145  \n","3   0.285  \n","4   0.285  \n","5   0.263  \n","6   0.487  \n","7   0.528  \n","8   0.530  \n","9   0.631  \n","10  0.645  \n","11  0.665  \n","12  0.673  \n","13  0.699  \n","14  0.733  "],"text/html":["\n","  <div id=\"df-2455baba-af9e-4aa2-8ac8-2350cd88aabe\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.536</td>\n","      <td>0.544</td>\n","      <td>0.442</td>\n","      <td>0.488</td>\n","      <td>0.442</td>\n","      <td>0.630</td>\n","      <td>0.072</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.561</td>\n","      <td>0.602</td>\n","      <td>0.359</td>\n","      <td>0.450</td>\n","      <td>0.359</td>\n","      <td>0.763</td>\n","      <td>0.121</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.572</td>\n","      <td>0.585</td>\n","      <td>0.496</td>\n","      <td>0.537</td>\n","      <td>0.496</td>\n","      <td>0.649</td>\n","      <td>0.145</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.642</td>\n","      <td>0.647</td>\n","      <td>0.626</td>\n","      <td>0.637</td>\n","      <td>0.626</td>\n","      <td>0.658</td>\n","      <td>0.285</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.643</td>\n","      <td>0.655</td>\n","      <td>0.603</td>\n","      <td>0.628</td>\n","      <td>0.603</td>\n","      <td>0.682</td>\n","      <td>0.285</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.632</td>\n","      <td>0.655</td>\n","      <td>0.556</td>\n","      <td>0.602</td>\n","      <td>0.556</td>\n","      <td>0.707</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.744</td>\n","      <td>0.745</td>\n","      <td>0.740</td>\n","      <td>0.743</td>\n","      <td>0.740</td>\n","      <td>0.747</td>\n","      <td>0.487</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.764</td>\n","      <td>0.748</td>\n","      <td>0.797</td>\n","      <td>0.772</td>\n","      <td>0.797</td>\n","      <td>0.732</td>\n","      <td>0.528</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.765</td>\n","      <td>0.777</td>\n","      <td>0.743</td>\n","      <td>0.760</td>\n","      <td>0.743</td>\n","      <td>0.787</td>\n","      <td>0.530</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.816</td>\n","      <td>0.815</td>\n","      <td>0.817</td>\n","      <td>0.816</td>\n","      <td>0.817</td>\n","      <td>0.814</td>\n","      <td>0.631</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.823</td>\n","      <td>0.837</td>\n","      <td>0.802</td>\n","      <td>0.819</td>\n","      <td>0.802</td>\n","      <td>0.843</td>\n","      <td>0.645</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.832</td>\n","      <td>0.847</td>\n","      <td>0.811</td>\n","      <td>0.829</td>\n","      <td>0.811</td>\n","      <td>0.853</td>\n","      <td>0.665</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.837</td>\n","      <td>0.862</td>\n","      <td>0.802</td>\n","      <td>0.831</td>\n","      <td>0.802</td>\n","      <td>0.871</td>\n","      <td>0.673</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.850</td>\n","      <td>0.869</td>\n","      <td>0.823</td>\n","      <td>0.846</td>\n","      <td>0.823</td>\n","      <td>0.876</td>\n","      <td>0.699</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.866</td>\n","      <td>0.856</td>\n","      <td>0.882</td>\n","      <td>0.868</td>\n","      <td>0.882</td>\n","      <td>0.851</td>\n","      <td>0.733</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2455baba-af9e-4aa2-8ac8-2350cd88aabe')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2455baba-af9e-4aa2-8ac8-2350cd88aabe button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2455baba-af9e-4aa2-8ac8-2350cd88aabe');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0863826c-e809-4026-b6c6-07fc1a17f766\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0863826c-e809-4026-b6c6-07fc1a17f766')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0863826c-e809-4026-b6c6-07fc1a17f766 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11623551625082254,\n        \"min\": 0.536,\n        \"max\": 0.866,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.816,\n          0.832,\n          0.536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11253473537831182,\n        \"min\": 0.544,\n        \"max\": 0.869,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.837,\n          0.862,\n          0.544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16153672735856167,\n        \"min\": 0.359,\n        \"max\": 0.882,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.817,\n          0.811,\n          0.442\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1397200261747961,\n        \"min\": 0.45,\n        \"max\": 0.868,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.816,\n          0.829,\n          0.488\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16153672735856167,\n        \"min\": 0.359,\n        \"max\": 0.882,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.817,\n          0.811,\n          0.442\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08554714656675746,\n        \"min\": 0.63,\n        \"max\": 0.876,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.814,\n          0.853,\n          0.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2324162521978923,\n        \"min\": 0.072,\n        \"max\": 0.733,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.645,\n          0.673,\n          0.072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717500572785,"user_tz":-360,"elapsed":18,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_LSTM/Delta_Time_CNN_LSTM.csv', index = False)"]},{"cell_type":"markdown","metadata":{"id":"QUuWzfMHSNmi"},"source":["# CNN"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717500572787,"user_tz":-360,"elapsed":20,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Delta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Delta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"H1TaNdIbSfkq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717501312819,"user_tz":-360,"elapsed":355748,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"49fe3f13-7585-4bb0-f973-1edf56511fe0"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 1.7713 - accuracy: 0.4938 - val_loss: 1.7646 - val_accuracy: 0.4989\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.7604 - accuracy: 0.5469"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 1s 18ms/step - loss: 1.7578 - accuracy: 0.5391 - val_loss: 1.7559 - val_accuracy: 0.5065\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7471 - accuracy: 0.5579 - val_loss: 1.7473 - val_accuracy: 0.5194\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7364 - accuracy: 0.5595 - val_loss: 1.7387 - val_accuracy: 0.5463\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7253 - accuracy: 0.5692 - val_loss: 1.7307 - val_accuracy: 0.4774\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.7160 - accuracy: 0.5749 - val_loss: 1.7223 - val_accuracy: 0.5022\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.7043 - accuracy: 0.5924 - val_loss: 1.7138 - val_accuracy: 0.5269\n","Epoch 8/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6945 - accuracy: 0.6018 - val_loss: 1.7057 - val_accuracy: 0.5216\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6834 - accuracy: 0.6094 - val_loss: 1.6971 - val_accuracy: 0.5614\n","Epoch 10/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6749 - accuracy: 0.6113 - val_loss: 1.6894 - val_accuracy: 0.5496\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6632 - accuracy: 0.6242 - val_loss: 1.6810 - val_accuracy: 0.5657\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6527 - accuracy: 0.6202 - val_loss: 1.6732 - val_accuracy: 0.5625\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6433 - accuracy: 0.6202 - val_loss: 1.6644 - val_accuracy: 0.5528\n","Epoch 14/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6314 - accuracy: 0.6331 - val_loss: 1.6566 - val_accuracy: 0.5625\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6201 - accuracy: 0.6463 - val_loss: 1.6500 - val_accuracy: 0.5485\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6107 - accuracy: 0.6420 - val_loss: 1.6409 - val_accuracy: 0.5797\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.6001 - accuracy: 0.6495 - val_loss: 1.6335 - val_accuracy: 0.5808\n","Epoch 18/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5900 - accuracy: 0.6600 - val_loss: 1.6251 - val_accuracy: 0.5787\n","Epoch 19/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5791 - accuracy: 0.6700 - val_loss: 1.6186 - val_accuracy: 0.5668\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5719 - accuracy: 0.6552 - val_loss: 1.6075 - val_accuracy: 0.5851\n","Epoch 21/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5615 - accuracy: 0.6611 - val_loss: 1.6003 - val_accuracy: 0.5851\n","Epoch 22/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.5534 - accuracy: 0.6616 - val_loss: 1.5979 - val_accuracy: 0.5647\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5410 - accuracy: 0.6770 - val_loss: 1.5860 - val_accuracy: 0.5873\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5318 - accuracy: 0.6797 - val_loss: 1.5794 - val_accuracy: 0.5938\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5205 - accuracy: 0.6875 - val_loss: 1.5728 - val_accuracy: 0.5959\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5106 - accuracy: 0.6913 - val_loss: 1.5670 - val_accuracy: 0.5916\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5019 - accuracy: 0.6956 - val_loss: 1.5614 - val_accuracy: 0.5873\n","Epoch 28/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4916 - accuracy: 0.6956 - val_loss: 1.5563 - val_accuracy: 0.5819\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4855 - accuracy: 0.6829 - val_loss: 1.5503 - val_accuracy: 0.5873\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4794 - accuracy: 0.6773 - val_loss: 1.5532 - val_accuracy: 0.5625\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4657 - accuracy: 0.6940 - val_loss: 1.5486 - val_accuracy: 0.5582\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4539 - accuracy: 0.7072 - val_loss: 1.5369 - val_accuracy: 0.5862\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4430 - accuracy: 0.7109 - val_loss: 1.5384 - val_accuracy: 0.5625\n","Epoch 34/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4347 - accuracy: 0.7150 - val_loss: 1.5392 - val_accuracy: 0.5550\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4246 - accuracy: 0.7152 - val_loss: 1.5245 - val_accuracy: 0.5797\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4135 - accuracy: 0.7220 - val_loss: 1.5201 - val_accuracy: 0.5797\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4048 - accuracy: 0.7220 - val_loss: 1.5178 - val_accuracy: 0.5862\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.3938 - accuracy: 0.7314 - val_loss: 1.5230 - val_accuracy: 0.5560\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3858 - accuracy: 0.7223 - val_loss: 1.5099 - val_accuracy: 0.5787\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3723 - accuracy: 0.7411 - val_loss: 1.5047 - val_accuracy: 0.5765\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3622 - accuracy: 0.7408 - val_loss: 1.5038 - val_accuracy: 0.5765\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3523 - accuracy: 0.7408 - val_loss: 1.5073 - val_accuracy: 0.5754\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3404 - accuracy: 0.7513 - val_loss: 1.4965 - val_accuracy: 0.5754\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3290 - accuracy: 0.7519 - val_loss: 1.4939 - val_accuracy: 0.5733\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3187 - accuracy: 0.7602 - val_loss: 1.4917 - val_accuracy: 0.5722\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3082 - accuracy: 0.7637 - val_loss: 1.4942 - val_accuracy: 0.5722\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3002 - accuracy: 0.7586 - val_loss: 1.5114 - val_accuracy: 0.5603\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2898 - accuracy: 0.7759 - val_loss: 1.4866 - val_accuracy: 0.5765\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2758 - accuracy: 0.7767 - val_loss: 1.4840 - val_accuracy: 0.5722\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2693 - accuracy: 0.7777 - val_loss: 1.4846 - val_accuracy: 0.5700\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2558 - accuracy: 0.7799 - val_loss: 1.4874 - val_accuracy: 0.5700\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2421 - accuracy: 0.7891 - val_loss: 1.4837 - val_accuracy: 0.5668\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2324 - accuracy: 0.7990 - val_loss: 1.4836 - val_accuracy: 0.5754\n","Epoch 54/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.2296 - accuracy: 0.7834 - val_loss: 1.5096 - val_accuracy: 0.5614\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2250 - accuracy: 0.7880 - val_loss: 1.4912 - val_accuracy: 0.5722\n","Epoch 56/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2108 - accuracy: 0.7985 - val_loss: 1.4940 - val_accuracy: 0.5722\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1990 - accuracy: 0.7953 - val_loss: 1.4793 - val_accuracy: 0.5700\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1853 - accuracy: 0.8028 - val_loss: 1.4854 - val_accuracy: 0.5722\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1737 - accuracy: 0.8209 - val_loss: 1.4743 - val_accuracy: 0.5722\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1726 - accuracy: 0.8095 - val_loss: 1.4783 - val_accuracy: 0.5819\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1529 - accuracy: 0.8268 - val_loss: 1.4824 - val_accuracy: 0.5711\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1382 - accuracy: 0.8357 - val_loss: 1.4797 - val_accuracy: 0.5733\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1311 - accuracy: 0.8335 - val_loss: 1.4797 - val_accuracy: 0.5722\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1194 - accuracy: 0.8384 - val_loss: 1.5065 - val_accuracy: 0.5582\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1210 - accuracy: 0.8254 - val_loss: 1.4790 - val_accuracy: 0.5711\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1024 - accuracy: 0.8416 - val_loss: 1.4831 - val_accuracy: 0.5776\n","Epoch 67/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0923 - accuracy: 0.8513 - val_loss: 1.4951 - val_accuracy: 0.5603\n","Epoch 68/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0838 - accuracy: 0.8521 - val_loss: 1.4839 - val_accuracy: 0.5808\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0689 - accuracy: 0.8623 - val_loss: 1.4849 - val_accuracy: 0.5711\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0613 - accuracy: 0.8596 - val_loss: 1.4917 - val_accuracy: 0.5679\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0556 - accuracy: 0.8605 - val_loss: 1.5347 - val_accuracy: 0.5485\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0422 - accuracy: 0.8661 - val_loss: 1.5081 - val_accuracy: 0.5647\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0374 - accuracy: 0.8626 - val_loss: 1.5117 - val_accuracy: 0.5894\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0465 - accuracy: 0.8494 - val_loss: 1.4982 - val_accuracy: 0.5819\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0176 - accuracy: 0.8742 - val_loss: 1.5004 - val_accuracy: 0.5754\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0051 - accuracy: 0.8823 - val_loss: 1.5099 - val_accuracy: 0.5668\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9981 - accuracy: 0.8798 - val_loss: 1.5144 - val_accuracy: 0.5862\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9946 - accuracy: 0.8747 - val_loss: 1.5053 - val_accuracy: 0.5830\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9859 - accuracy: 0.8807 - val_loss: 1.5102 - val_accuracy: 0.5722\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9662 - accuracy: 0.8933 - val_loss: 1.5179 - val_accuracy: 0.5733\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9624 - accuracy: 0.8906 - val_loss: 1.5395 - val_accuracy: 0.5711\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9605 - accuracy: 0.8885 - val_loss: 1.5157 - val_accuracy: 0.5733\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9450 - accuracy: 0.8922 - val_loss: 1.5227 - val_accuracy: 0.5765\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9373 - accuracy: 0.9003 - val_loss: 1.5359 - val_accuracy: 0.5657\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9332 - accuracy: 0.8966 - val_loss: 1.5283 - val_accuracy: 0.5851\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9235 - accuracy: 0.9022 - val_loss: 1.5388 - val_accuracy: 0.5733\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9122 - accuracy: 0.9065 - val_loss: 1.5491 - val_accuracy: 0.5744\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9114 - accuracy: 0.9038 - val_loss: 1.5397 - val_accuracy: 0.5733\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8954 - accuracy: 0.9138 - val_loss: 1.5489 - val_accuracy: 0.5776\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8897 - accuracy: 0.9124 - val_loss: 1.5605 - val_accuracy: 0.5830\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8804 - accuracy: 0.9170 - val_loss: 1.5505 - val_accuracy: 0.5787\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8751 - accuracy: 0.9197 - val_loss: 1.5569 - val_accuracy: 0.5700\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8704 - accuracy: 0.9178 - val_loss: 1.5631 - val_accuracy: 0.5700\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8594 - accuracy: 0.9211 - val_loss: 1.5749 - val_accuracy: 0.5808\n","Epoch 95/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8556 - accuracy: 0.9254 - val_loss: 1.5704 - val_accuracy: 0.5765\n","Epoch 96/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8481 - accuracy: 0.9262 - val_loss: 1.5863 - val_accuracy: 0.5841\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8514 - accuracy: 0.9186 - val_loss: 1.5910 - val_accuracy: 0.5700\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8271 - accuracy: 0.9345 - val_loss: 1.5951 - val_accuracy: 0.5744\n","Epoch 99/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8268 - accuracy: 0.9289 - val_loss: 1.5978 - val_accuracy: 0.5808\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8242 - accuracy: 0.9275 - val_loss: 1.5964 - val_accuracy: 0.5765\n","{'loss': [1.7713403701782227, 1.757755994796753, 1.74705171585083, 1.736425518989563, 1.725295901298523, 1.7160203456878662, 1.7043497562408447, 1.6944910287857056, 1.68341863155365, 1.6749459505081177, 1.6632295846939087, 1.652732014656067, 1.6432796716690063, 1.631394624710083, 1.6200803518295288, 1.6107407808303833, 1.6001150608062744, 1.5899674892425537, 1.5791194438934326, 1.571850299835205, 1.561492919921875, 1.5533926486968994, 1.5409842729568481, 1.5317926406860352, 1.5204638242721558, 1.5106446743011475, 1.5019444227218628, 1.4915590286254883, 1.4855223894119263, 1.4793570041656494, 1.4657286405563354, 1.4539300203323364, 1.4430392980575562, 1.4347282648086548, 1.4246399402618408, 1.4134936332702637, 1.4048047065734863, 1.3937695026397705, 1.385801076889038, 1.3723061084747314, 1.3621879816055298, 1.3522922992706299, 1.3404252529144287, 1.3289695978164673, 1.318682074546814, 1.3081642389297485, 1.300184726715088, 1.2898155450820923, 1.2757768630981445, 1.269268274307251, 1.2558221817016602, 1.242051362991333, 1.2324401140213013, 1.2295961380004883, 1.225027322769165, 1.2108384370803833, 1.1990249156951904, 1.185300350189209, 1.1737159490585327, 1.1726090908050537, 1.1528764963150024, 1.138169288635254, 1.1310957670211792, 1.1194343566894531, 1.1209527254104614, 1.102368950843811, 1.092289686203003, 1.083767056465149, 1.0689325332641602, 1.0613375902175903, 1.0556477308273315, 1.0422050952911377, 1.0374350547790527, 1.0465130805969238, 1.0175817012786865, 1.005070447921753, 0.9981486797332764, 0.9946221113204956, 0.9858733415603638, 0.966231107711792, 0.9623647928237915, 0.96054607629776, 0.944969117641449, 0.937250554561615, 0.9332008957862854, 0.9234723448753357, 0.9121926426887512, 0.9113661050796509, 0.8954353928565979, 0.8896770477294922, 0.8803879022598267, 0.8750903606414795, 0.8703928589820862, 0.8593788743019104, 0.855570375919342, 0.848136842250824, 0.8513584136962891, 0.8271141648292542, 0.8268195986747742, 0.8242411017417908], 'accuracy': [0.49380388855934143, 0.5390625, 0.5579202771186829, 0.5595366358757019, 0.5692349076271057, 0.5748922228813171, 0.592402994632721, 0.6018319129943848, 0.609375, 0.6112607717514038, 0.6241918206214905, 0.6201508641242981, 0.6201508641242981, 0.6330819129943848, 0.6462823152542114, 0.641972005367279, 0.6495150923728943, 0.6600215435028076, 0.6699892282485962, 0.6551724076271057, 0.6610991358757019, 0.6616379022598267, 0.6769935488700867, 0.6796875, 0.6875, 0.6912715435028076, 0.6955819129943848, 0.6955819129943848, 0.6829202771186829, 0.6772629022598267, 0.693965494632721, 0.7071659564971924, 0.7109375, 0.7149784564971924, 0.7152478694915771, 0.7219827771186829, 0.7219827771186829, 0.7314116358757019, 0.7222521305084229, 0.7411099076271057, 0.740840494632721, 0.740840494632721, 0.751347005367279, 0.7518857717514038, 0.7602370977401733, 0.7637392282485962, 0.7586206793785095, 0.7758620977401733, 0.7766702771186829, 0.7777478694915771, 0.779902994632721, 0.7890625, 0.7990301847457886, 0.7834051847457886, 0.7879849076271057, 0.798491358757019, 0.795258641242981, 0.8028017282485962, 0.8208512663841248, 0.8095366358757019, 0.826777994632721, 0.8356680870056152, 0.8335129022598267, 0.8383620977401733, 0.8254310488700867, 0.8415948152542114, 0.8512930870056152, 0.8521012663841248, 0.8623383641242981, 0.8596444129943848, 0.8604525923728943, 0.8661099076271057, 0.8626077771186829, 0.8494073152542114, 0.8741918206214905, 0.8822737336158752, 0.8798491358757019, 0.8747305870056152, 0.8806573152542114, 0.8933189511299133, 0.890625, 0.8884698152542114, 0.892241358757019, 0.9003232717514038, 0.8965517282485962, 0.9022090435028076, 0.9065194129943848, 0.9038254022598267, 0.9137930870056152, 0.912446141242981, 0.9170258641242981, 0.9197198152542114, 0.9178340435028076, 0.9210668206214905, 0.9253771305084229, 0.9261853694915771, 0.9186422228813171, 0.9345366358757019, 0.9288793206214905, 0.9275323152542114], 'val_loss': [1.7645822763442993, 1.7559038400650024, 1.7473044395446777, 1.7386754751205444, 1.7306628227233887, 1.7222799062728882, 1.7138166427612305, 1.7056920528411865, 1.69709312915802, 1.689378023147583, 1.6809604167938232, 1.6732399463653564, 1.664376974105835, 1.656630277633667, 1.6499844789505005, 1.640925645828247, 1.6335031986236572, 1.6250855922698975, 1.6185554265975952, 1.6074546575546265, 1.6003341674804688, 1.597867488861084, 1.5859946012496948, 1.579365849494934, 1.5728367567062378, 1.566996693611145, 1.5614489316940308, 1.5562748908996582, 1.5502878427505493, 1.553160548210144, 1.5486096143722534, 1.5369211435317993, 1.5384496450424194, 1.539156198501587, 1.5244799852371216, 1.5201152563095093, 1.5177806615829468, 1.5230493545532227, 1.5098804235458374, 1.5046783685684204, 1.5038208961486816, 1.5072964429855347, 1.496471643447876, 1.4938772916793823, 1.4917436838150024, 1.494184970855713, 1.5114169120788574, 1.4866422414779663, 1.4839664697647095, 1.4845645427703857, 1.4873868227005005, 1.4836513996124268, 1.483593463897705, 1.5096449851989746, 1.4912376403808594, 1.4940180778503418, 1.4792909622192383, 1.4853832721710205, 1.4742752313613892, 1.4783298969268799, 1.4823991060256958, 1.4796510934829712, 1.479669213294983, 1.506533145904541, 1.4789685010910034, 1.483060598373413, 1.4950753450393677, 1.483863353729248, 1.4849462509155273, 1.4916598796844482, 1.5346695184707642, 1.5080746412277222, 1.5116682052612305, 1.4982001781463623, 1.5004429817199707, 1.5098557472229004, 1.5143636465072632, 1.5052653551101685, 1.5102298259735107, 1.517884373664856, 1.5394580364227295, 1.5156890153884888, 1.522722601890564, 1.5358853340148926, 1.5283465385437012, 1.538824439048767, 1.5490658283233643, 1.5396736860275269, 1.5489002466201782, 1.5605206489562988, 1.5505218505859375, 1.5569264888763428, 1.563059687614441, 1.5748823881149292, 1.5703537464141846, 1.5863064527511597, 1.591038465499878, 1.595099925994873, 1.5978258848190308, 1.596404790878296], 'val_accuracy': [0.4989224076271057, 0.506465494632721, 0.5193965435028076, 0.5463362336158752, 0.4773706793785095, 0.5021551847457886, 0.5269396305084229, 0.5215517282485962, 0.5614224076271057, 0.5495689511299133, 0.5657327771186829, 0.5625, 0.5528017282485962, 0.5625, 0.548491358757019, 0.579741358757019, 0.5808189511299133, 0.5786637663841248, 0.5668103694915771, 0.5851293206214905, 0.5851293206214905, 0.5646551847457886, 0.587284505367279, 0.59375, 0.5959051847457886, 0.5915948152542114, 0.587284505367279, 0.5818965435028076, 0.587284505367279, 0.5625, 0.5581896305084229, 0.5862069129943848, 0.5625, 0.5549569129943848, 0.579741358757019, 0.579741358757019, 0.5862069129943848, 0.556034505367279, 0.5786637663841248, 0.576508641242981, 0.576508641242981, 0.5754310488700867, 0.5754310488700867, 0.5732758641242981, 0.5721982717514038, 0.5721982717514038, 0.5603448152542114, 0.576508641242981, 0.5721982717514038, 0.5700430870056152, 0.5700430870056152, 0.5668103694915771, 0.5754310488700867, 0.5614224076271057, 0.5721982717514038, 0.5721982717514038, 0.5700430870056152, 0.5721982717514038, 0.5721982717514038, 0.5818965435028076, 0.5711206793785095, 0.5732758641242981, 0.5721982717514038, 0.5581896305084229, 0.5711206793785095, 0.5775862336158752, 0.5603448152542114, 0.5808189511299133, 0.5711206793785095, 0.5678879022598267, 0.548491358757019, 0.5646551847457886, 0.5894396305084229, 0.5818965435028076, 0.5754310488700867, 0.5668103694915771, 0.5862069129943848, 0.5829741358757019, 0.5721982717514038, 0.5732758641242981, 0.5711206793785095, 0.5732758641242981, 0.576508641242981, 0.5657327771186829, 0.5851293206214905, 0.5732758641242981, 0.5743534564971924, 0.5732758641242981, 0.5775862336158752, 0.5829741358757019, 0.5786637663841248, 0.5700430870056152, 0.5700430870056152, 0.5808189511299133, 0.576508641242981, 0.5840517282485962, 0.5700430870056152, 0.5743534564971924, 0.5808189511299133, 0.576508641242981]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 31ms/step - loss: 1.7716 - accuracy: 0.5014 - val_loss: 1.7648 - val_accuracy: 0.5057\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.7624 - accuracy: 0.5469"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 0s 18ms/step - loss: 1.7582 - accuracy: 0.5410 - val_loss: 1.7565 - val_accuracy: 0.5294\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7465 - accuracy: 0.5727 - val_loss: 1.7481 - val_accuracy: 0.5475\n","Epoch 4/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.7360 - accuracy: 0.5747 - val_loss: 1.7399 - val_accuracy: 0.5238\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.7250 - accuracy: 0.5840 - val_loss: 1.7318 - val_accuracy: 0.5192\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.7143 - accuracy: 0.5948 - val_loss: 1.7238 - val_accuracy: 0.5238\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.7039 - accuracy: 0.5951 - val_loss: 1.7158 - val_accuracy: 0.5475\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6950 - accuracy: 0.5976 - val_loss: 1.7080 - val_accuracy: 0.5226\n","Epoch 9/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.6846 - accuracy: 0.6098 - val_loss: 1.7002 - val_accuracy: 0.5373\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6749 - accuracy: 0.6061 - val_loss: 1.6926 - val_accuracy: 0.5351\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6636 - accuracy: 0.6135 - val_loss: 1.6851 - val_accuracy: 0.5260\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6522 - accuracy: 0.6171 - val_loss: 1.6775 - val_accuracy: 0.5339\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6430 - accuracy: 0.6220 - val_loss: 1.6700 - val_accuracy: 0.5362\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.6317 - accuracy: 0.6310 - val_loss: 1.6625 - val_accuracy: 0.5509\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6213 - accuracy: 0.6361 - val_loss: 1.6551 - val_accuracy: 0.5498\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.6127 - accuracy: 0.6392 - val_loss: 1.6478 - val_accuracy: 0.5622\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6020 - accuracy: 0.6437 - val_loss: 1.6405 - val_accuracy: 0.5509\n","Epoch 18/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5927 - accuracy: 0.6463 - val_loss: 1.6333 - val_accuracy: 0.5509\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5829 - accuracy: 0.6474 - val_loss: 1.6266 - val_accuracy: 0.5486\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5731 - accuracy: 0.6565 - val_loss: 1.6203 - val_accuracy: 0.5656\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5638 - accuracy: 0.6590 - val_loss: 1.6146 - val_accuracy: 0.5373\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5575 - accuracy: 0.6675 - val_loss: 1.6072 - val_accuracy: 0.5679\n","Epoch 23/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5448 - accuracy: 0.6678 - val_loss: 1.6017 - val_accuracy: 0.5656\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5353 - accuracy: 0.6752 - val_loss: 1.5964 - val_accuracy: 0.5747\n","Epoch 25/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5264 - accuracy: 0.6726 - val_loss: 1.5916 - val_accuracy: 0.5656\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5155 - accuracy: 0.6819 - val_loss: 1.5876 - val_accuracy: 0.5633\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5059 - accuracy: 0.6868 - val_loss: 1.5859 - val_accuracy: 0.5667\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4983 - accuracy: 0.6819 - val_loss: 1.5793 - val_accuracy: 0.5781\n","Epoch 29/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4891 - accuracy: 0.6777 - val_loss: 1.5757 - val_accuracy: 0.5645\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4806 - accuracy: 0.6930 - val_loss: 1.5774 - val_accuracy: 0.5543\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4684 - accuracy: 0.7023 - val_loss: 1.5676 - val_accuracy: 0.5645\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4575 - accuracy: 0.7066 - val_loss: 1.5665 - val_accuracy: 0.5600\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4508 - accuracy: 0.7015 - val_loss: 1.5747 - val_accuracy: 0.5452\n","Epoch 34/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4405 - accuracy: 0.7071 - val_loss: 1.5564 - val_accuracy: 0.5758\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4286 - accuracy: 0.7184 - val_loss: 1.5511 - val_accuracy: 0.5792\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4197 - accuracy: 0.7190 - val_loss: 1.5496 - val_accuracy: 0.5679\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4091 - accuracy: 0.7295 - val_loss: 1.5467 - val_accuracy: 0.5826\n","Epoch 38/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4009 - accuracy: 0.7301 - val_loss: 1.5424 - val_accuracy: 0.5679\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3954 - accuracy: 0.7213 - val_loss: 1.5434 - val_accuracy: 0.5769\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3835 - accuracy: 0.7323 - val_loss: 1.5366 - val_accuracy: 0.5724\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3697 - accuracy: 0.7456 - val_loss: 1.5359 - val_accuracy: 0.5622\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3590 - accuracy: 0.7490 - val_loss: 1.5342 - val_accuracy: 0.5814\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3484 - accuracy: 0.7513 - val_loss: 1.5321 - val_accuracy: 0.5690\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3369 - accuracy: 0.7558 - val_loss: 1.5295 - val_accuracy: 0.5747\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3268 - accuracy: 0.7632 - val_loss: 1.5279 - val_accuracy: 0.5690\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3244 - accuracy: 0.7552 - val_loss: 1.5281 - val_accuracy: 0.5554\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3070 - accuracy: 0.7750 - val_loss: 1.5272 - val_accuracy: 0.5645\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2968 - accuracy: 0.7742 - val_loss: 1.5270 - val_accuracy: 0.5758\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2902 - accuracy: 0.7799 - val_loss: 1.5267 - val_accuracy: 0.5498\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2790 - accuracy: 0.7787 - val_loss: 1.5302 - val_accuracy: 0.5317\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2654 - accuracy: 0.7878 - val_loss: 1.5242 - val_accuracy: 0.5633\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2646 - accuracy: 0.7742 - val_loss: 1.5266 - val_accuracy: 0.5724\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2480 - accuracy: 0.7920 - val_loss: 1.5251 - val_accuracy: 0.5475\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2361 - accuracy: 0.7971 - val_loss: 1.5231 - val_accuracy: 0.5679\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2253 - accuracy: 0.7957 - val_loss: 1.5336 - val_accuracy: 0.5419\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2151 - accuracy: 0.8022 - val_loss: 1.5598 - val_accuracy: 0.5339\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2091 - accuracy: 0.8048 - val_loss: 1.5299 - val_accuracy: 0.5611\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1946 - accuracy: 0.8172 - val_loss: 1.5507 - val_accuracy: 0.5339\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1852 - accuracy: 0.8192 - val_loss: 1.5278 - val_accuracy: 0.5656\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1786 - accuracy: 0.8212 - val_loss: 1.5317 - val_accuracy: 0.5588\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1672 - accuracy: 0.8240 - val_loss: 1.5648 - val_accuracy: 0.5362\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1585 - accuracy: 0.8251 - val_loss: 1.5345 - val_accuracy: 0.5577\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1444 - accuracy: 0.8370 - val_loss: 1.5374 - val_accuracy: 0.5441\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1390 - accuracy: 0.8291 - val_loss: 1.5426 - val_accuracy: 0.5419\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1333 - accuracy: 0.8316 - val_loss: 1.5475 - val_accuracy: 0.5566\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1158 - accuracy: 0.8520 - val_loss: 1.5408 - val_accuracy: 0.5509\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1054 - accuracy: 0.8506 - val_loss: 1.5432 - val_accuracy: 0.5600\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0984 - accuracy: 0.8478 - val_loss: 1.5542 - val_accuracy: 0.5509\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0915 - accuracy: 0.8461 - val_loss: 1.5521 - val_accuracy: 0.5475\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0791 - accuracy: 0.8546 - val_loss: 1.5638 - val_accuracy: 0.5475\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0654 - accuracy: 0.8628 - val_loss: 1.5631 - val_accuracy: 0.5486\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0553 - accuracy: 0.8625 - val_loss: 1.5674 - val_accuracy: 0.5452\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0484 - accuracy: 0.8701 - val_loss: 1.5667 - val_accuracy: 0.5566\n","Epoch 74/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0367 - accuracy: 0.8735 - val_loss: 1.5702 - val_accuracy: 0.5509\n","Epoch 75/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0259 - accuracy: 0.8769 - val_loss: 1.5727 - val_accuracy: 0.5532\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0203 - accuracy: 0.8772 - val_loss: 1.5793 - val_accuracy: 0.5475\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0151 - accuracy: 0.8778 - val_loss: 1.5869 - val_accuracy: 0.5430\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0171 - accuracy: 0.8628 - val_loss: 1.5842 - val_accuracy: 0.5532\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9903 - accuracy: 0.8908 - val_loss: 1.5891 - val_accuracy: 0.5532\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9841 - accuracy: 0.8891 - val_loss: 1.5959 - val_accuracy: 0.5509\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9752 - accuracy: 0.8945 - val_loss: 1.5994 - val_accuracy: 0.5486\n","Epoch 82/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9663 - accuracy: 0.8990 - val_loss: 1.6023 - val_accuracy: 0.5486\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9620 - accuracy: 0.8930 - val_loss: 1.6146 - val_accuracy: 0.5486\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9687 - accuracy: 0.8780 - val_loss: 1.6111 - val_accuracy: 0.5554\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9528 - accuracy: 0.8925 - val_loss: 1.6135 - val_accuracy: 0.5498\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9375 - accuracy: 0.9024 - val_loss: 1.6178 - val_accuracy: 0.5498\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9299 - accuracy: 0.9007 - val_loss: 1.6174 - val_accuracy: 0.5543\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9214 - accuracy: 0.9103 - val_loss: 1.6266 - val_accuracy: 0.5588\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9121 - accuracy: 0.9140 - val_loss: 1.6317 - val_accuracy: 0.5464\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9059 - accuracy: 0.9134 - val_loss: 1.6372 - val_accuracy: 0.5543\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9013 - accuracy: 0.9151 - val_loss: 1.6535 - val_accuracy: 0.5509\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8921 - accuracy: 0.9157 - val_loss: 1.6529 - val_accuracy: 0.5430\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8866 - accuracy: 0.9160 - val_loss: 1.7259 - val_accuracy: 0.5271\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8883 - accuracy: 0.9069 - val_loss: 1.6564 - val_accuracy: 0.5464\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8697 - accuracy: 0.9261 - val_loss: 1.6618 - val_accuracy: 0.5475\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8650 - accuracy: 0.9276 - val_loss: 1.6666 - val_accuracy: 0.5588\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8559 - accuracy: 0.9281 - val_loss: 1.6852 - val_accuracy: 0.5452\n","Epoch 98/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8572 - accuracy: 0.9219 - val_loss: 1.6992 - val_accuracy: 0.5441\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8470 - accuracy: 0.9284 - val_loss: 1.6811 - val_accuracy: 0.5498\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8394 - accuracy: 0.9315 - val_loss: 1.7013 - val_accuracy: 0.5520\n","{'loss': [1.7716106176376343, 1.7582457065582275, 1.746514081954956, 1.7360087633132935, 1.7250351905822754, 1.7142947912216187, 1.7039375305175781, 1.695038914680481, 1.6846026182174683, 1.6749401092529297, 1.6635892391204834, 1.6522080898284912, 1.642999291419983, 1.6317368745803833, 1.6212955713272095, 1.6127326488494873, 1.6019792556762695, 1.5926719903945923, 1.5828862190246582, 1.5730856657028198, 1.5637612342834473, 1.557539701461792, 1.5447767972946167, 1.5352784395217896, 1.5264036655426025, 1.5154757499694824, 1.5058948993682861, 1.4983075857162476, 1.48910391330719, 1.4806370735168457, 1.4683626890182495, 1.4575457572937012, 1.4508036375045776, 1.440487265586853, 1.4286469221115112, 1.419687032699585, 1.4091335535049438, 1.4009391069412231, 1.395416498184204, 1.3834636211395264, 1.3696715831756592, 1.3589578866958618, 1.3483808040618896, 1.3368724584579468, 1.3267849683761597, 1.3244330883026123, 1.3069791793823242, 1.2967532873153687, 1.290172815322876, 1.278964638710022, 1.2654144763946533, 1.2645517587661743, 1.2479538917541504, 1.2361066341400146, 1.225319743156433, 1.2151097059249878, 1.2090976238250732, 1.1946368217468262, 1.1851999759674072, 1.1785649061203003, 1.1671513319015503, 1.1584552526474, 1.1444098949432373, 1.1390442848205566, 1.1333128213882446, 1.1157559156417847, 1.1053698062896729, 1.0983805656433105, 1.0915117263793945, 1.0790917873382568, 1.0653542280197144, 1.0553085803985596, 1.0484206676483154, 1.0366605520248413, 1.0258921384811401, 1.020316481590271, 1.0151314735412598, 1.0171247720718384, 0.990347683429718, 0.9841395616531372, 0.9752315282821655, 0.9663015007972717, 0.9620161652565002, 0.9686696529388428, 0.9527790546417236, 0.9375212788581848, 0.9298695921897888, 0.9213584065437317, 0.9120532870292664, 0.9058693647384644, 0.9013141393661499, 0.892129123210907, 0.886630117893219, 0.8883373141288757, 0.8697165846824646, 0.8650419116020203, 0.8558722138404846, 0.8572292923927307, 0.8469663858413696, 0.8393540382385254], 'accuracy': [0.5014148354530334, 0.5410299897193909, 0.5727221369743347, 0.5747028589248657, 0.5840407609939575, 0.594793438911438, 0.5950763821601868, 0.5976231098175049, 0.6097906231880188, 0.6061120629310608, 0.6134691834449768, 0.61714768409729, 0.6219581365585327, 0.631013035774231, 0.6361063718795776, 0.6392189860343933, 0.6437464356422424, 0.6462931632995605, 0.6474249958992004, 0.6564798951148987, 0.6590266227722168, 0.6675155758857727, 0.6677985191345215, 0.6751556396484375, 0.6726089119911194, 0.6819468140602112, 0.6867572069168091, 0.6819468140602112, 0.6777023077011108, 0.6929824352264404, 0.7023203372955322, 0.7065647840499878, 0.7014714479446411, 0.7071307301521301, 0.7184493541717529, 0.7190153002738953, 0.7294849753379822, 0.7300509214401245, 0.7212790250778198, 0.7323146462440491, 0.7456140518188477, 0.7490096092224121, 0.7512733340263367, 0.7558007836341858, 0.7631579041481018, 0.7552348375320435, 0.7750424742698669, 0.774193525314331, 0.7798528671264648, 0.7787209749221802, 0.7877758741378784, 0.774193525314331, 0.7920203804969788, 0.7971137762069702, 0.7956989407539368, 0.8022071123123169, 0.804753839969635, 0.8172042965888977, 0.8191850781440735, 0.8211658000946045, 0.8239954710006714, 0.825127363204956, 0.8370118737220764, 0.8290888667106628, 0.8316355347633362, 0.8520090579986572, 0.8505942225456238, 0.8477645516395569, 0.8460667729377747, 0.8545557260513306, 0.8627617359161377, 0.8624787926673889, 0.8701188564300537, 0.8735144138336182, 0.8769100308418274, 0.8771929740905762, 0.8777589201927185, 0.8627617359161377, 0.8907753229141235, 0.8890775442123413, 0.8944538831710815, 0.8989813327789307, 0.8930390477180481, 0.8780418634414673, 0.8924731016159058, 0.9023768901824951, 0.9006791114807129, 0.9102999567985535, 0.9139785170555115, 0.9134125709533691, 0.9151103496551514, 0.9156762957572937, 0.9159592390060425, 0.9069043397903442, 0.9261460304260254, 0.9275608658790588, 0.9281267523765564, 0.921901524066925, 0.92840975522995, 0.9315223693847656], 'val_loss': [1.7648069858551025, 1.7564524412155151, 1.7481427192687988, 1.7399381399154663, 1.7318040132522583, 1.7237600088119507, 1.7158225774765015, 1.7080413103103638, 1.7002102136611938, 1.6926045417785645, 1.6850941181182861, 1.6774604320526123, 1.669985294342041, 1.6624996662139893, 1.6551464796066284, 1.6477856636047363, 1.6405266523361206, 1.633289098739624, 1.6265588998794556, 1.6203110218048096, 1.6146211624145508, 1.6072397232055664, 1.6017428636550903, 1.5964384078979492, 1.5915589332580566, 1.5876322984695435, 1.5858728885650635, 1.5792670249938965, 1.5757091045379639, 1.5773506164550781, 1.5675699710845947, 1.5664819478988647, 1.5746779441833496, 1.5563510656356812, 1.5510873794555664, 1.5495846271514893, 1.5467479228973389, 1.5424208641052246, 1.5434311628341675, 1.5366487503051758, 1.5358906984329224, 1.5342200994491577, 1.5321391820907593, 1.5295398235321045, 1.5278728008270264, 1.5280629396438599, 1.5272237062454224, 1.527024745941162, 1.5266863107681274, 1.5301616191864014, 1.5242162942886353, 1.5266385078430176, 1.525067925453186, 1.523132085800171, 1.5336178541183472, 1.5598156452178955, 1.5299499034881592, 1.5506516695022583, 1.527760624885559, 1.5317176580429077, 1.5648317337036133, 1.5344624519348145, 1.5374048948287964, 1.5426490306854248, 1.5474649667739868, 1.54081392288208, 1.5432422161102295, 1.5541731119155884, 1.55210280418396, 1.5637843608856201, 1.563149333000183, 1.5673530101776123, 1.5666825771331787, 1.570191502571106, 1.572709321975708, 1.5792717933654785, 1.5868889093399048, 1.584188461303711, 1.5890897512435913, 1.595924735069275, 1.599412441253662, 1.6022666692733765, 1.6145806312561035, 1.6110620498657227, 1.6135425567626953, 1.617767333984375, 1.6174328327178955, 1.6265687942504883, 1.6317293643951416, 1.6372498273849487, 1.6534695625305176, 1.6528657674789429, 1.7258877754211426, 1.6563999652862549, 1.6618496179580688, 1.6665512323379517, 1.6851531267166138, 1.6991926431655884, 1.6811273097991943, 1.7013399600982666], 'val_accuracy': [0.5056561231613159, 0.529411792755127, 0.5475113391876221, 0.523755669593811, 0.5192307829856873, 0.523755669593811, 0.5475113391876221, 0.5226244330406189, 0.5373303294181824, 0.5350678563117981, 0.5260180830955505, 0.5339366793632507, 0.5361990928649902, 0.5509049892425537, 0.5497737526893616, 0.5622171759605408, 0.5509049892425537, 0.5509049892425537, 0.5486425161361694, 0.5656108856201172, 0.5373303294181824, 0.5678732991218567, 0.5656108856201172, 0.5746606588363647, 0.5656108856201172, 0.5633484125137329, 0.5667420625686646, 0.5780543088912964, 0.564479649066925, 0.5542986392974854, 0.564479649066925, 0.5599547624588013, 0.5452488660812378, 0.5757918357849121, 0.5791855454444885, 0.5678732991218567, 0.5825791954994202, 0.5678732991218567, 0.5769230723381042, 0.5723981857299805, 0.5622171759605408, 0.581447958946228, 0.5690045356750488, 0.5746606588363647, 0.5690045356750488, 0.5554298758506775, 0.564479649066925, 0.5757918357849121, 0.5497737526893616, 0.5316742062568665, 0.5633484125137329, 0.5723981857299805, 0.5475113391876221, 0.5678732991218567, 0.5418552160263062, 0.5339366793632507, 0.5610859990119934, 0.5339366793632507, 0.5656108856201172, 0.5588235259056091, 0.5361990928649902, 0.557692289352417, 0.5441176295280457, 0.5418552160263062, 0.5565611124038696, 0.5509049892425537, 0.5599547624588013, 0.5509049892425537, 0.5475113391876221, 0.5475113391876221, 0.5486425161361694, 0.5452488660812378, 0.5565611124038696, 0.5509049892425537, 0.5531674027442932, 0.5475113391876221, 0.5429864525794983, 0.5531674027442932, 0.5531674027442932, 0.5509049892425537, 0.5486425161361694, 0.5486425161361694, 0.5486425161361694, 0.5554298758506775, 0.5497737526893616, 0.5497737526893616, 0.5542986392974854, 0.5588235259056091, 0.5463801026344299, 0.5542986392974854, 0.5509049892425537, 0.5429864525794983, 0.5271493196487427, 0.5463801026344299, 0.5475113391876221, 0.5588235259056091, 0.5452488660812378, 0.5441176295280457, 0.5497737526893616, 0.5520362257957458]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 1.7709 - accuracy: 0.4980"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 4s 36ms/step - loss: 1.7706 - accuracy: 0.4943 - val_loss: 1.7639 - val_accuracy: 0.5114\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.7576 - accuracy: 0.5351 - val_loss: 1.7548 - val_accuracy: 0.5124\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.7467 - accuracy: 0.5439 - val_loss: 1.7458 - val_accuracy: 0.5599\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.7344 - accuracy: 0.5894 - val_loss: 1.7369 - val_accuracy: 0.5455\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.7231 - accuracy: 0.6013 - val_loss: 1.7281 - val_accuracy: 0.5403\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7122 - accuracy: 0.6052 - val_loss: 1.7194 - val_accuracy: 0.5579\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7010 - accuracy: 0.6106 - val_loss: 1.7111 - val_accuracy: 0.5196\n","Epoch 8/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6906 - accuracy: 0.5995 - val_loss: 1.7022 - val_accuracy: 0.5558\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6789 - accuracy: 0.6085 - val_loss: 1.6937 - val_accuracy: 0.5537\n","Epoch 10/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6689 - accuracy: 0.6072 - val_loss: 1.6860 - val_accuracy: 0.5351\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6572 - accuracy: 0.6284 - val_loss: 1.6770 - val_accuracy: 0.5651\n","Epoch 12/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6474 - accuracy: 0.6256 - val_loss: 1.6692 - val_accuracy: 0.5620\n","Epoch 13/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6368 - accuracy: 0.6209 - val_loss: 1.6612 - val_accuracy: 0.5651\n","Epoch 14/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6262 - accuracy: 0.6341 - val_loss: 1.6526 - val_accuracy: 0.5651\n","Epoch 15/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6167 - accuracy: 0.6401 - val_loss: 1.6447 - val_accuracy: 0.5620\n","Epoch 16/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6060 - accuracy: 0.6475 - val_loss: 1.6362 - val_accuracy: 0.5640\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5961 - accuracy: 0.6535 - val_loss: 1.6280 - val_accuracy: 0.5713\n","Epoch 18/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5858 - accuracy: 0.6530 - val_loss: 1.6201 - val_accuracy: 0.5671\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5762 - accuracy: 0.6594 - val_loss: 1.6123 - val_accuracy: 0.5733\n","Epoch 20/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5678 - accuracy: 0.6558 - val_loss: 1.6064 - val_accuracy: 0.5506\n","Epoch 21/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5561 - accuracy: 0.6633 - val_loss: 1.5973 - val_accuracy: 0.5795\n","Epoch 22/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5472 - accuracy: 0.6680 - val_loss: 1.5920 - val_accuracy: 0.5579\n","Epoch 23/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5369 - accuracy: 0.6729 - val_loss: 1.5862 - val_accuracy: 0.5475\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5277 - accuracy: 0.6749 - val_loss: 1.5796 - val_accuracy: 0.5744\n","Epoch 25/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5181 - accuracy: 0.6778 - val_loss: 1.5747 - val_accuracy: 0.5713\n","Epoch 26/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5124 - accuracy: 0.6568 - val_loss: 1.5733 - val_accuracy: 0.5517\n","Epoch 27/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5013 - accuracy: 0.6829 - val_loss: 1.5636 - val_accuracy: 0.5558\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4897 - accuracy: 0.6845 - val_loss: 1.5571 - val_accuracy: 0.5806\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4807 - accuracy: 0.6899 - val_loss: 1.5533 - val_accuracy: 0.5682\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4705 - accuracy: 0.6915 - val_loss: 1.5476 - val_accuracy: 0.5733\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4616 - accuracy: 0.6922 - val_loss: 1.5476 - val_accuracy: 0.5465\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4518 - accuracy: 0.7036 - val_loss: 1.5422 - val_accuracy: 0.5527\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4408 - accuracy: 0.7132 - val_loss: 1.5337 - val_accuracy: 0.5723\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4328 - accuracy: 0.7119 - val_loss: 1.5343 - val_accuracy: 0.5475\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4237 - accuracy: 0.7103 - val_loss: 1.5265 - val_accuracy: 0.5579\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4119 - accuracy: 0.7196 - val_loss: 1.5234 - val_accuracy: 0.5496\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4025 - accuracy: 0.7258 - val_loss: 1.5175 - val_accuracy: 0.5610\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3907 - accuracy: 0.7279 - val_loss: 1.5189 - val_accuracy: 0.5723\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3821 - accuracy: 0.7266 - val_loss: 1.5117 - val_accuracy: 0.5610\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3712 - accuracy: 0.7302 - val_loss: 1.5129 - val_accuracy: 0.5568\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3605 - accuracy: 0.7408 - val_loss: 1.5069 - val_accuracy: 0.5579\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3490 - accuracy: 0.7424 - val_loss: 1.5049 - val_accuracy: 0.5568\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3395 - accuracy: 0.7434 - val_loss: 1.5072 - val_accuracy: 0.5661\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3360 - accuracy: 0.7377 - val_loss: 1.5031 - val_accuracy: 0.5589\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3166 - accuracy: 0.7543 - val_loss: 1.5056 - val_accuracy: 0.5455\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3106 - accuracy: 0.7561 - val_loss: 1.4959 - val_accuracy: 0.5610\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2984 - accuracy: 0.7568 - val_loss: 1.4947 - val_accuracy: 0.5568\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2862 - accuracy: 0.7682 - val_loss: 1.4990 - val_accuracy: 0.5517\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2763 - accuracy: 0.7711 - val_loss: 1.4984 - val_accuracy: 0.5527\n","Epoch 50/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2726 - accuracy: 0.7584 - val_loss: 1.5076 - val_accuracy: 0.5475\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2586 - accuracy: 0.7724 - val_loss: 1.4925 - val_accuracy: 0.5310\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2506 - accuracy: 0.7747 - val_loss: 1.4896 - val_accuracy: 0.5548\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2357 - accuracy: 0.7806 - val_loss: 1.4935 - val_accuracy: 0.5599\n","Epoch 54/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2265 - accuracy: 0.7953 - val_loss: 1.4867 - val_accuracy: 0.5548\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2177 - accuracy: 0.7948 - val_loss: 1.4842 - val_accuracy: 0.5434\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2066 - accuracy: 0.7979 - val_loss: 1.4912 - val_accuracy: 0.5599\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1994 - accuracy: 0.8003 - val_loss: 1.4869 - val_accuracy: 0.5589\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1860 - accuracy: 0.8023 - val_loss: 1.4888 - val_accuracy: 0.5465\n","Epoch 59/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1745 - accuracy: 0.8065 - val_loss: 1.4910 - val_accuracy: 0.5486\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1722 - accuracy: 0.8080 - val_loss: 1.4826 - val_accuracy: 0.5393\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1582 - accuracy: 0.8072 - val_loss: 1.5030 - val_accuracy: 0.5362\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1535 - accuracy: 0.8098 - val_loss: 1.5244 - val_accuracy: 0.5434\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1524 - accuracy: 0.7995 - val_loss: 1.4953 - val_accuracy: 0.5475\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1297 - accuracy: 0.8251 - val_loss: 1.4882 - val_accuracy: 0.5444\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1191 - accuracy: 0.8313 - val_loss: 1.4997 - val_accuracy: 0.5465\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1107 - accuracy: 0.8305 - val_loss: 1.4956 - val_accuracy: 0.5455\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1060 - accuracy: 0.8256 - val_loss: 1.5072 - val_accuracy: 0.5537\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0904 - accuracy: 0.8444 - val_loss: 1.4917 - val_accuracy: 0.5486\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0813 - accuracy: 0.8437 - val_loss: 1.4951 - val_accuracy: 0.5444\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0709 - accuracy: 0.8468 - val_loss: 1.4998 - val_accuracy: 0.5506\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0637 - accuracy: 0.8483 - val_loss: 1.4955 - val_accuracy: 0.5465\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0554 - accuracy: 0.8509 - val_loss: 1.5257 - val_accuracy: 0.5341\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0477 - accuracy: 0.8504 - val_loss: 1.5139 - val_accuracy: 0.5403\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0435 - accuracy: 0.8504 - val_loss: 1.5039 - val_accuracy: 0.5475\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0268 - accuracy: 0.8643 - val_loss: 1.5070 - val_accuracy: 0.5558\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0180 - accuracy: 0.8649 - val_loss: 1.5185 - val_accuracy: 0.5465\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0177 - accuracy: 0.8592 - val_loss: 1.5234 - val_accuracy: 0.5393\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0011 - accuracy: 0.8762 - val_loss: 1.5235 - val_accuracy: 0.5465\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9973 - accuracy: 0.8680 - val_loss: 1.5208 - val_accuracy: 0.5465\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9846 - accuracy: 0.8747 - val_loss: 1.5310 - val_accuracy: 0.5465\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9752 - accuracy: 0.8788 - val_loss: 1.5344 - val_accuracy: 0.5496\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9693 - accuracy: 0.8749 - val_loss: 1.5406 - val_accuracy: 0.5424\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9623 - accuracy: 0.8775 - val_loss: 1.5388 - val_accuracy: 0.5424\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9617 - accuracy: 0.8747 - val_loss: 1.5525 - val_accuracy: 0.5403\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9508 - accuracy: 0.8788 - val_loss: 1.5336 - val_accuracy: 0.5589\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9371 - accuracy: 0.8902 - val_loss: 1.5569 - val_accuracy: 0.5413\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9334 - accuracy: 0.8829 - val_loss: 1.5891 - val_accuracy: 0.5362\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9278 - accuracy: 0.8907 - val_loss: 1.5557 - val_accuracy: 0.5496\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9177 - accuracy: 0.8902 - val_loss: 1.5585 - val_accuracy: 0.5455\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9082 - accuracy: 0.8961 - val_loss: 1.5666 - val_accuracy: 0.5362\n","Epoch 91/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9033 - accuracy: 0.8974 - val_loss: 1.5779 - val_accuracy: 0.5320\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9023 - accuracy: 0.8902 - val_loss: 1.5720 - val_accuracy: 0.5403\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8848 - accuracy: 0.9013 - val_loss: 1.5757 - val_accuracy: 0.5465\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8803 - accuracy: 0.9023 - val_loss: 1.6253 - val_accuracy: 0.5424\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8793 - accuracy: 0.8992 - val_loss: 1.6134 - val_accuracy: 0.5320\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8687 - accuracy: 0.9036 - val_loss: 1.6010 - val_accuracy: 0.5403\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8611 - accuracy: 0.9078 - val_loss: 1.5897 - val_accuracy: 0.5486\n","Epoch 98/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8629 - accuracy: 0.9036 - val_loss: 1.6346 - val_accuracy: 0.5372\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8491 - accuracy: 0.9111 - val_loss: 1.6047 - val_accuracy: 0.5465\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8369 - accuracy: 0.9181 - val_loss: 1.6047 - val_accuracy: 0.5351\n","{'loss': [1.7705659866333008, 1.7576026916503906, 1.7466983795166016, 1.7343518733978271, 1.7231392860412598, 1.7121869325637817, 1.7010107040405273, 1.6906198263168335, 1.678913950920105, 1.6688646078109741, 1.6571685075759888, 1.6473997831344604, 1.6368045806884766, 1.626229166984558, 1.6167324781417847, 1.6060236692428589, 1.5961467027664185, 1.5857656002044678, 1.5762193202972412, 1.5678406953811646, 1.556063175201416, 1.5471588373184204, 1.5369359254837036, 1.5277432203292847, 1.5181118249893188, 1.5124359130859375, 1.5012940168380737, 1.4897459745407104, 1.4807268381118774, 1.470466136932373, 1.461628794670105, 1.451804757118225, 1.4408488273620605, 1.4328196048736572, 1.4236778020858765, 1.4119211435317993, 1.4025393724441528, 1.3907309770584106, 1.3820656538009644, 1.3711752891540527, 1.3604737520217896, 1.3489524126052856, 1.3395274877548218, 1.3359928131103516, 1.3165687322616577, 1.310601830482483, 1.2984414100646973, 1.2862263917922974, 1.2763112783432007, 1.2725520133972168, 1.2585994005203247, 1.2506197690963745, 1.2356890439987183, 1.226486086845398, 1.2176780700683594, 1.2066048383712769, 1.1994332075119019, 1.1860350370407104, 1.1745238304138184, 1.1722259521484375, 1.1581897735595703, 1.1535142660140991, 1.1524113416671753, 1.129704475402832, 1.11910879611969, 1.110650658607483, 1.1059731245040894, 1.0904171466827393, 1.0813133716583252, 1.0708879232406616, 1.0636757612228394, 1.055426836013794, 1.0477436780929565, 1.0435490608215332, 1.026785135269165, 1.0179611444473267, 1.01766836643219, 1.0010838508605957, 0.997309148311615, 0.9845921397209167, 0.9751731157302856, 0.9693415760993958, 0.9623379707336426, 0.96172034740448, 0.9507513046264648, 0.9370747208595276, 0.9333861470222473, 0.9278380274772644, 0.9176778793334961, 0.9081931710243225, 0.903285801410675, 0.9022616147994995, 0.8847880959510803, 0.880269467830658, 0.879298746585846, 0.8686703443527222, 0.8611136078834534, 0.8628640174865723, 0.8491143584251404, 0.8368518352508545], 'accuracy': [0.4943152368068695, 0.5351421236991882, 0.5439276695251465, 0.5894056558609009, 0.6012920141220093, 0.6051679849624634, 0.6105943322181702, 0.5994831919670105, 0.6085271239280701, 0.6072351336479187, 0.6284237504005432, 0.6255813837051392, 0.6209302544593811, 0.6341085433959961, 0.6400516629219055, 0.6475452184677124, 0.6534883975982666, 0.6529715657234192, 0.659431517124176, 0.6558139324188232, 0.6633074879646301, 0.667958676815033, 0.6728681921958923, 0.6749354004859924, 0.6777777671813965, 0.6568475365638733, 0.682945728302002, 0.6844961047172546, 0.6899224519729614, 0.6914728879928589, 0.6922480463981628, 0.7036175727844238, 0.713178277015686, 0.7118862867355347, 0.710335910320282, 0.7196382284164429, 0.7258397936820984, 0.7279070019721985, 0.7266150116920471, 0.7302325367927551, 0.7408268451690674, 0.7423772811889648, 0.7434108257293701, 0.737726092338562, 0.7542635798454285, 0.7560723423957825, 0.7568475604057312, 0.7682170271873474, 0.7710594534873962, 0.7583979368209839, 0.7723514437675476, 0.7746769785881042, 0.7806201577186584, 0.7953488230705261, 0.7948320508003235, 0.7979328036308289, 0.8002583980560303, 0.8023256063461304, 0.8064599633216858, 0.8080103397369385, 0.8072351217269897, 0.8098191022872925, 0.7994831800460815, 0.8250645995140076, 0.8312661647796631, 0.8304909467697144, 0.8255813717842102, 0.8444444537162781, 0.8436692357063293, 0.8467700481414795, 0.8483204245567322, 0.8509044051170349, 0.8503875732421875, 0.8503875732421875, 0.8643410801887512, 0.8648578524589539, 0.8591731190681458, 0.8762273788452148, 0.867958664894104, 0.8746770024299622, 0.8788113594055176, 0.8749353885650635, 0.8775193691253662, 0.8746770024299622, 0.8788113594055176, 0.8901808857917786, 0.882945716381073, 0.8906976580619812, 0.8901808857917786, 0.896124005317688, 0.8974159955978394, 0.8901808857917786, 0.9012919664382935, 0.9023255705833435, 0.8992248177528381, 0.9036175608634949, 0.9077519178390503, 0.9036175608634949, 0.9111111164093018, 0.9180878400802612], 'val_loss': [1.7639278173446655, 1.7547898292541504, 1.7457771301269531, 1.7368980646133423, 1.7281140089035034, 1.719437837600708, 1.711057424545288, 1.7022346258163452, 1.6937204599380493, 1.6859501600265503, 1.6770073175430298, 1.6691654920578003, 1.6611524820327759, 1.652620553970337, 1.644726037979126, 1.6362215280532837, 1.6279700994491577, 1.6200839281082153, 1.6123055219650269, 1.6063525676727295, 1.5973422527313232, 1.5919842720031738, 1.586218237876892, 1.5796042680740356, 1.5746616125106812, 1.5732754468917847, 1.5635936260223389, 1.5570716857910156, 1.5533452033996582, 1.5475822687149048, 1.5475552082061768, 1.5422343015670776, 1.5336564779281616, 1.534321904182434, 1.5264534950256348, 1.5233827829360962, 1.517533779144287, 1.5189322233200073, 1.5117342472076416, 1.5128508806228638, 1.506851077079773, 1.5048578977584839, 1.5071622133255005, 1.5031040906906128, 1.5055694580078125, 1.495872139930725, 1.494746208190918, 1.4989588260650635, 1.4984307289123535, 1.5075992345809937, 1.4924899339675903, 1.4896265268325806, 1.4934707880020142, 1.4866554737091064, 1.4841963052749634, 1.4912339448928833, 1.4869424104690552, 1.4888356924057007, 1.4910098314285278, 1.4826222658157349, 1.5029819011688232, 1.5243717432022095, 1.495282769203186, 1.4882004261016846, 1.4996803998947144, 1.4955507516860962, 1.507237434387207, 1.491716742515564, 1.4951350688934326, 1.499845027923584, 1.4955430030822754, 1.5256789922714233, 1.5138574838638306, 1.5039130449295044, 1.506982684135437, 1.5185291767120361, 1.5233683586120605, 1.5235443115234375, 1.5207949876785278, 1.5309844017028809, 1.5344282388687134, 1.5406138896942139, 1.5388439893722534, 1.5524725914001465, 1.5335627794265747, 1.5568976402282715, 1.5891284942626953, 1.555696725845337, 1.5585498809814453, 1.566616177558899, 1.5778765678405762, 1.5719525814056396, 1.5757206678390503, 1.625347375869751, 1.6133774518966675, 1.6010297536849976, 1.5896533727645874, 1.6346285343170166, 1.6047080755233765, 1.6047420501708984], 'val_accuracy': [0.5113636255264282, 0.5123966932296753, 0.5599173307418823, 0.5454545617103577, 0.5402892827987671, 0.557851254940033, 0.51962810754776, 0.5557851195335388, 0.5537189841270447, 0.5351239442825317, 0.5650826692581177, 0.5619834661483765, 0.5650826692581177, 0.5650826692581177, 0.5619834661483765, 0.5640496015548706, 0.5712810158729553, 0.567148745059967, 0.5733470916748047, 0.5506198406219482, 0.5795454382896423, 0.557851254940033, 0.547520637512207, 0.5743801593780518, 0.5712810158729553, 0.5516529083251953, 0.5557851195335388, 0.5805785059928894, 0.5681818127632141, 0.5733470916748047, 0.5464876294136047, 0.5526859760284424, 0.5723140239715576, 0.547520637512207, 0.557851254940033, 0.5495867729187012, 0.5609503984451294, 0.5723140239715576, 0.5609503984451294, 0.5568181872367859, 0.557851254940033, 0.5568181872367859, 0.56611567735672, 0.55888432264328, 0.5454545617103577, 0.5609503984451294, 0.5568181872367859, 0.5516529083251953, 0.5526859760284424, 0.547520637512207, 0.5309917330741882, 0.5547520518302917, 0.5599173307418823, 0.5547520518302917, 0.5433884263038635, 0.5599173307418823, 0.55888432264328, 0.5464876294136047, 0.5485537052154541, 0.53925621509552, 0.5361570119857788, 0.5433884263038635, 0.547520637512207, 0.5444214940071106, 0.5464876294136047, 0.5454545617103577, 0.5537189841270447, 0.5485537052154541, 0.5444214940071106, 0.5506198406219482, 0.5464876294136047, 0.5340909361839294, 0.5402892827987671, 0.547520637512207, 0.5557851195335388, 0.5464876294136047, 0.53925621509552, 0.5464876294136047, 0.5464876294136047, 0.5464876294136047, 0.5495867729187012, 0.5423553586006165, 0.5423553586006165, 0.5402892827987671, 0.55888432264328, 0.5413222908973694, 0.5361570119857788, 0.5495867729187012, 0.5454545617103577, 0.5361570119857788, 0.5320248007774353, 0.5402892827987671, 0.5464876294136047, 0.5423553586006165, 0.5320248007774353, 0.5402892827987671, 0.5485537052154541, 0.5371900796890259, 0.5464876294136047, 0.5351239442825317]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 27ms/step - loss: 1.0708 - accuracy: 0.7834 - val_loss: 1.2873 - val_accuracy: 0.5830\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.0414 - accuracy: 0.7578"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 0s 12ms/step - loss: 1.0375 - accuracy: 0.8074 - val_loss: 1.2848 - val_accuracy: 0.5474\n","Epoch 3/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0216 - accuracy: 0.8133 - val_loss: 1.2779 - val_accuracy: 0.6239\n","Epoch 4/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0122 - accuracy: 0.8230 - val_loss: 1.2731 - val_accuracy: 0.6304\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0050 - accuracy: 0.8225 - val_loss: 1.2713 - val_accuracy: 0.5722\n","Epoch 6/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9916 - accuracy: 0.8297 - val_loss: 1.2635 - val_accuracy: 0.6196\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9759 - accuracy: 0.8451 - val_loss: 1.2570 - val_accuracy: 0.6422\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9711 - accuracy: 0.8467 - val_loss: 1.2521 - val_accuracy: 0.6412\n","Epoch 9/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9514 - accuracy: 0.8640 - val_loss: 1.2466 - val_accuracy: 0.6207\n","Epoch 10/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9482 - accuracy: 0.8607 - val_loss: 1.2410 - val_accuracy: 0.6218\n","Epoch 11/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9389 - accuracy: 0.8621 - val_loss: 1.2328 - val_accuracy: 0.6422\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9337 - accuracy: 0.8677 - val_loss: 1.2269 - val_accuracy: 0.6401\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9198 - accuracy: 0.8801 - val_loss: 1.2182 - val_accuracy: 0.6455\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9099 - accuracy: 0.8796 - val_loss: 1.2143 - val_accuracy: 0.6325\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9060 - accuracy: 0.8809 - val_loss: 1.2127 - val_accuracy: 0.6347\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9082 - accuracy: 0.8737 - val_loss: 1.2001 - val_accuracy: 0.6498\n","Epoch 17/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8970 - accuracy: 0.8798 - val_loss: 1.1941 - val_accuracy: 0.6455\n","Epoch 18/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8930 - accuracy: 0.8739 - val_loss: 1.1929 - val_accuracy: 0.6476\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8855 - accuracy: 0.8815 - val_loss: 1.1833 - val_accuracy: 0.6595\n","Epoch 20/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8634 - accuracy: 0.9011 - val_loss: 1.1835 - val_accuracy: 0.6606\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8589 - accuracy: 0.9017 - val_loss: 1.1799 - val_accuracy: 0.6638\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8578 - accuracy: 0.8930 - val_loss: 1.1883 - val_accuracy: 0.6476\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8519 - accuracy: 0.8976 - val_loss: 1.1912 - val_accuracy: 0.6509\n","Epoch 24/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8416 - accuracy: 0.9057 - val_loss: 1.1875 - val_accuracy: 0.6778\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8278 - accuracy: 0.9135 - val_loss: 1.1850 - val_accuracy: 0.6638\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8325 - accuracy: 0.9049 - val_loss: 1.2056 - val_accuracy: 0.6681\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8253 - accuracy: 0.9103 - val_loss: 1.1903 - val_accuracy: 0.6713\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8165 - accuracy: 0.9141 - val_loss: 1.2022 - val_accuracy: 0.6875\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8163 - accuracy: 0.9081 - val_loss: 1.2026 - val_accuracy: 0.6756\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8039 - accuracy: 0.9162 - val_loss: 1.2118 - val_accuracy: 0.6627\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8060 - accuracy: 0.9060 - val_loss: 1.2076 - val_accuracy: 0.6810\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7876 - accuracy: 0.9221 - val_loss: 1.2098 - val_accuracy: 0.6713\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7803 - accuracy: 0.9267 - val_loss: 1.2160 - val_accuracy: 0.6638\n","Epoch 34/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7765 - accuracy: 0.9289 - val_loss: 1.2275 - val_accuracy: 0.6789\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7863 - accuracy: 0.9103 - val_loss: 1.2327 - val_accuracy: 0.6595\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7693 - accuracy: 0.9278 - val_loss: 1.2240 - val_accuracy: 0.6789\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7668 - accuracy: 0.9289 - val_loss: 1.2248 - val_accuracy: 0.6724\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7526 - accuracy: 0.9351 - val_loss: 1.2381 - val_accuracy: 0.6735\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7540 - accuracy: 0.9318 - val_loss: 1.2552 - val_accuracy: 0.6530\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7527 - accuracy: 0.9281 - val_loss: 1.2363 - val_accuracy: 0.6724\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7379 - accuracy: 0.9380 - val_loss: 1.2512 - val_accuracy: 0.6832\n","Epoch 42/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7363 - accuracy: 0.9340 - val_loss: 1.2594 - val_accuracy: 0.6724\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7367 - accuracy: 0.9302 - val_loss: 1.2719 - val_accuracy: 0.6422\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7374 - accuracy: 0.9281 - val_loss: 1.2526 - val_accuracy: 0.6616\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7193 - accuracy: 0.9391 - val_loss: 1.2703 - val_accuracy: 0.6562\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7227 - accuracy: 0.9340 - val_loss: 1.2905 - val_accuracy: 0.6724\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7137 - accuracy: 0.9418 - val_loss: 1.2712 - val_accuracy: 0.6552\n","Epoch 48/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7135 - accuracy: 0.9399 - val_loss: 1.2652 - val_accuracy: 0.6724\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7083 - accuracy: 0.9407 - val_loss: 1.3019 - val_accuracy: 0.6412\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7091 - accuracy: 0.9335 - val_loss: 1.2882 - val_accuracy: 0.6487\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6953 - accuracy: 0.9445 - val_loss: 1.2761 - val_accuracy: 0.6703\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6843 - accuracy: 0.9488 - val_loss: 1.2851 - val_accuracy: 0.6530\n","Epoch 53/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6818 - accuracy: 0.9529 - val_loss: 1.2778 - val_accuracy: 0.6606\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.9512 - val_loss: 1.2832 - val_accuracy: 0.6584\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6760 - accuracy: 0.9531 - val_loss: 1.2983 - val_accuracy: 0.6552\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6711 - accuracy: 0.9555 - val_loss: 1.3025 - val_accuracy: 0.6649\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6692 - accuracy: 0.9529 - val_loss: 1.2975 - val_accuracy: 0.6692\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6650 - accuracy: 0.9539 - val_loss: 1.3178 - val_accuracy: 0.6476\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6678 - accuracy: 0.9485 - val_loss: 1.3003 - val_accuracy: 0.6487\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6581 - accuracy: 0.9531 - val_loss: 1.3340 - val_accuracy: 0.6466\n","Epoch 61/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6525 - accuracy: 0.9588 - val_loss: 1.3187 - val_accuracy: 0.6541\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6474 - accuracy: 0.9582 - val_loss: 1.3161 - val_accuracy: 0.6681\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6425 - accuracy: 0.9593 - val_loss: 1.3275 - val_accuracy: 0.6433\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6396 - accuracy: 0.9615 - val_loss: 1.3325 - val_accuracy: 0.6455\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6361 - accuracy: 0.9580 - val_loss: 1.3348 - val_accuracy: 0.6530\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6326 - accuracy: 0.9626 - val_loss: 1.3368 - val_accuracy: 0.6476\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6373 - accuracy: 0.9518 - val_loss: 1.3420 - val_accuracy: 0.6616\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6299 - accuracy: 0.9604 - val_loss: 1.3449 - val_accuracy: 0.6487\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6304 - accuracy: 0.9577 - val_loss: 1.3502 - val_accuracy: 0.6401\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6237 - accuracy: 0.9588 - val_loss: 1.3706 - val_accuracy: 0.6433\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6246 - accuracy: 0.9574 - val_loss: 1.3509 - val_accuracy: 0.6573\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6130 - accuracy: 0.9655 - val_loss: 1.3613 - val_accuracy: 0.6466\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6121 - accuracy: 0.9644 - val_loss: 1.3944 - val_accuracy: 0.6616\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6101 - accuracy: 0.9604 - val_loss: 1.3795 - val_accuracy: 0.6466\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6040 - accuracy: 0.9688 - val_loss: 1.3740 - val_accuracy: 0.6466\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5985 - accuracy: 0.9706 - val_loss: 1.3748 - val_accuracy: 0.6552\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5976 - accuracy: 0.9712 - val_loss: 1.3762 - val_accuracy: 0.6562\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5999 - accuracy: 0.9647 - val_loss: 1.3875 - val_accuracy: 0.6573\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6004 - accuracy: 0.9652 - val_loss: 1.4366 - val_accuracy: 0.6444\n","Epoch 80/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5988 - accuracy: 0.9655 - val_loss: 1.3908 - val_accuracy: 0.6552\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.9677 - val_loss: 1.4096 - val_accuracy: 0.6401\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5893 - accuracy: 0.9679 - val_loss: 1.4462 - val_accuracy: 0.6606\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5897 - accuracy: 0.9666 - val_loss: 1.4115 - val_accuracy: 0.6401\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5836 - accuracy: 0.9690 - val_loss: 1.4660 - val_accuracy: 0.6390\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5793 - accuracy: 0.9701 - val_loss: 1.4121 - val_accuracy: 0.6466\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5792 - accuracy: 0.9688 - val_loss: 1.4610 - val_accuracy: 0.6422\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5732 - accuracy: 0.9698 - val_loss: 1.4363 - val_accuracy: 0.6487\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5710 - accuracy: 0.9736 - val_loss: 1.4263 - val_accuracy: 0.6390\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.9744 - val_loss: 1.4420 - val_accuracy: 0.6422\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5646 - accuracy: 0.9736 - val_loss: 1.4485 - val_accuracy: 0.6433\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5608 - accuracy: 0.9752 - val_loss: 1.4492 - val_accuracy: 0.6509\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5581 - accuracy: 0.9776 - val_loss: 1.5054 - val_accuracy: 0.6261\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5557 - accuracy: 0.9760 - val_loss: 1.4940 - val_accuracy: 0.6325\n","Epoch 94/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5588 - accuracy: 0.9714 - val_loss: 1.4708 - val_accuracy: 0.6379\n","Epoch 95/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5560 - accuracy: 0.9720 - val_loss: 1.4610 - val_accuracy: 0.6487\n","Epoch 96/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5493 - accuracy: 0.9766 - val_loss: 1.4711 - val_accuracy: 0.6552\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5472 - accuracy: 0.9782 - val_loss: 1.4763 - val_accuracy: 0.6466\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5477 - accuracy: 0.9741 - val_loss: 1.4831 - val_accuracy: 0.6444\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.9739 - val_loss: 1.4800 - val_accuracy: 0.6444\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5420 - accuracy: 0.9784 - val_loss: 1.4873 - val_accuracy: 0.6369\n","{'loss': [1.0707612037658691, 1.0374503135681152, 1.0216084718704224, 1.0122475624084473, 1.0049930810928345, 0.9916443824768066, 0.9758549928665161, 0.971081554889679, 0.9513709545135498, 0.9482412934303284, 0.9389364123344421, 0.9336541295051575, 0.919833779335022, 0.9099043011665344, 0.906033992767334, 0.9081904888153076, 0.8969569802284241, 0.8929787874221802, 0.8854851722717285, 0.8633698225021362, 0.8589365482330322, 0.8577908277511597, 0.8519145846366882, 0.841558575630188, 0.8278009295463562, 0.8325495719909668, 0.8253085613250732, 0.8165433406829834, 0.8162747621536255, 0.8038793206214905, 0.8059898018836975, 0.7875669598579407, 0.7802627086639404, 0.7765190005302429, 0.7863103747367859, 0.7693320512771606, 0.7667980790138245, 0.7525826096534729, 0.754047155380249, 0.7526910901069641, 0.7378656268119812, 0.7363262176513672, 0.7367250323295593, 0.7373977303504944, 0.7192618250846863, 0.7226724028587341, 0.7137255668640137, 0.713456928730011, 0.708333432674408, 0.7090577483177185, 0.695267379283905, 0.6843217015266418, 0.681774377822876, 0.677772581577301, 0.6759527325630188, 0.6710840463638306, 0.6692423820495605, 0.6649618744850159, 0.6678446531295776, 0.6581130027770996, 0.6524713039398193, 0.6473731398582458, 0.6425241231918335, 0.6396101117134094, 0.6360880732536316, 0.6326444149017334, 0.6373148560523987, 0.6299108266830444, 0.6303797364234924, 0.623691976070404, 0.6245518326759338, 0.6129670143127441, 0.6120578050613403, 0.6101334691047668, 0.6039562821388245, 0.5985227823257446, 0.5976341962814331, 0.5998762249946594, 0.600372850894928, 0.5988193154335022, 0.5883775949478149, 0.5893344879150391, 0.5897057056427002, 0.5835656523704529, 0.5793050527572632, 0.579205334186554, 0.5731500387191772, 0.5709526538848877, 0.5653528571128845, 0.5646199584007263, 0.5607578158378601, 0.5581331849098206, 0.5557253360748291, 0.5588416457176208, 0.5559820532798767, 0.5493394732475281, 0.5471640229225159, 0.5476946830749512, 0.550011396408081, 0.5420079231262207], 'accuracy': [0.7834051847457886, 0.8073814511299133, 0.8133081793785095, 0.8230064511299133, 0.8224676847457886, 0.829741358757019, 0.845097005367279, 0.8467133641242981, 0.8639547228813171, 0.860722005367279, 0.8620689511299133, 0.8677262663841248, 0.8801185488700867, 0.8795797228813171, 0.8809267282485962, 0.873652994632721, 0.8798491358757019, 0.8739224076271057, 0.881465494632721, 0.9011314511299133, 0.9016702771186829, 0.8930495977401733, 0.8976293206214905, 0.9057112336158752, 0.9135237336158752, 0.904902994632721, 0.9102909564971924, 0.9140625, 0.9081357717514038, 0.9162176847457886, 0.9059805870056152, 0.9221444129943848, 0.9267241358757019, 0.9288793206214905, 0.9102909564971924, 0.9278017282485962, 0.9288793206214905, 0.9350754022598267, 0.9318426847457886, 0.928071141242981, 0.9380387663841248, 0.9339978694915771, 0.9302262663841248, 0.928071141242981, 0.939116358757019, 0.9339978694915771, 0.9418103694915771, 0.9399245977401733, 0.9407327771186829, 0.9334590435028076, 0.9445043206214905, 0.9488146305084229, 0.9528555870056152, 0.9512392282485962, 0.953125, 0.9555495977401733, 0.9528555870056152, 0.9539331793785095, 0.9485452771186829, 0.953125, 0.9587823152542114, 0.9582435488700867, 0.959321141242981, 0.9614762663841248, 0.9579741358757019, 0.962553858757019, 0.951777994632721, 0.9603987336158752, 0.9577047228813171, 0.9587823152542114, 0.9574353694915771, 0.9655172228813171, 0.9644396305084229, 0.9603987336158752, 0.96875, 0.9706357717514038, 0.9711745977401733, 0.9647090435028076, 0.9652478694915771, 0.9655172228813171, 0.9676724076271057, 0.9679418206214905, 0.9665948152542114, 0.9690194129943848, 0.970097005367279, 0.96875, 0.9698275923728943, 0.9735991358757019, 0.9744073152542114, 0.9735991358757019, 0.975215494632721, 0.9776400923728943, 0.9760237336158752, 0.9714439511299133, 0.9719827771186829, 0.9765625, 0.978178858757019, 0.9741379022598267, 0.9738685488700867, 0.9784482717514038], 'val_loss': [1.2872552871704102, 1.2847968339920044, 1.2779357433319092, 1.2731132507324219, 1.2713240385055542, 1.2635401487350464, 1.2569516897201538, 1.2521086931228638, 1.2466306686401367, 1.2410054206848145, 1.2328424453735352, 1.2268685102462769, 1.2182384729385376, 1.214250087738037, 1.21271550655365, 1.2001194953918457, 1.1940767765045166, 1.1928775310516357, 1.1833117008209229, 1.183478593826294, 1.1798982620239258, 1.1882671117782593, 1.1911967992782593, 1.1875109672546387, 1.1850199699401855, 1.2056199312210083, 1.1902813911437988, 1.2022356986999512, 1.202584147453308, 1.211814522743225, 1.2076196670532227, 1.2097578048706055, 1.2160321474075317, 1.2274739742279053, 1.2327295541763306, 1.2239505052566528, 1.2247793674468994, 1.238069772720337, 1.2552070617675781, 1.2363479137420654, 1.2512012720108032, 1.2593989372253418, 1.271892786026001, 1.2525814771652222, 1.2703334093093872, 1.2904586791992188, 1.2712072134017944, 1.2652324438095093, 1.3019304275512695, 1.288233995437622, 1.2761203050613403, 1.2851202487945557, 1.2778494358062744, 1.283165454864502, 1.2982673645019531, 1.3024532794952393, 1.2974573373794556, 1.3177834749221802, 1.3002797365188599, 1.3339660167694092, 1.3186540603637695, 1.316132664680481, 1.3275476694107056, 1.332456350326538, 1.3347561359405518, 1.3367928266525269, 1.3419874906539917, 1.344875454902649, 1.350224494934082, 1.370591402053833, 1.3509355783462524, 1.361272931098938, 1.3943870067596436, 1.3795087337493896, 1.374024748802185, 1.37477707862854, 1.3762481212615967, 1.3875113725662231, 1.4366036653518677, 1.3908063173294067, 1.4095697402954102, 1.4461822509765625, 1.4115045070648193, 1.466025948524475, 1.4120936393737793, 1.4609992504119873, 1.436270833015442, 1.4263161420822144, 1.4419937133789062, 1.4484739303588867, 1.4492108821868896, 1.5053901672363281, 1.4940155744552612, 1.4708248376846313, 1.460993766784668, 1.47114098072052, 1.476338505744934, 1.4831156730651855, 1.4799662828445435, 1.4872949123382568], 'val_accuracy': [0.5829741358757019, 0.5474137663841248, 0.6239224076271057, 0.6303879022598267, 0.5721982717514038, 0.6196120977401733, 0.642241358757019, 0.6411637663841248, 0.6206896305084229, 0.6217672228813171, 0.642241358757019, 0.6400862336158752, 0.6454741358757019, 0.6325430870056152, 0.6346982717514038, 0.649784505367279, 0.6454741358757019, 0.6476293206214905, 0.6594827771186829, 0.6605603694915771, 0.6637930870056152, 0.6476293206214905, 0.6508620977401733, 0.6778017282485962, 0.6637930870056152, 0.6681034564971924, 0.6713362336158752, 0.6875, 0.6756465435028076, 0.662715494632721, 0.681034505367279, 0.6713362336158752, 0.6637930870056152, 0.6788793206214905, 0.6594827771186829, 0.6788793206214905, 0.6724137663841248, 0.673491358757019, 0.6530172228813171, 0.6724137663841248, 0.6831896305084229, 0.6724137663841248, 0.642241358757019, 0.6616379022598267, 0.65625, 0.6724137663841248, 0.6551724076271057, 0.6724137663841248, 0.6411637663841248, 0.6487069129943848, 0.670258641242981, 0.6530172228813171, 0.6605603694915771, 0.6584051847457886, 0.6551724076271057, 0.6648706793785095, 0.6691810488700867, 0.6476293206214905, 0.6487069129943848, 0.6465517282485962, 0.6540948152542114, 0.6681034564971924, 0.6433189511299133, 0.6454741358757019, 0.6530172228813171, 0.6476293206214905, 0.6616379022598267, 0.6487069129943848, 0.6400862336158752, 0.6433189511299133, 0.6573275923728943, 0.6465517282485962, 0.6616379022598267, 0.6465517282485962, 0.6465517282485962, 0.6551724076271057, 0.65625, 0.6573275923728943, 0.6443965435028076, 0.6551724076271057, 0.6400862336158752, 0.6605603694915771, 0.6400862336158752, 0.639008641242981, 0.6465517282485962, 0.642241358757019, 0.6487069129943848, 0.639008641242981, 0.642241358757019, 0.6433189511299133, 0.6508620977401733, 0.6260775923728943, 0.6325430870056152, 0.6379310488700867, 0.6487069129943848, 0.6551724076271057, 0.6465517282485962, 0.6443965435028076, 0.6443965435028076, 0.6368534564971924]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 29ms/step - loss: 1.0641 - accuracy: 0.7844 - val_loss: 1.2871 - val_accuracy: 0.6041\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.0474 - accuracy: 0.7969"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 0s 11ms/step - loss: 1.0267 - accuracy: 0.8141 - val_loss: 1.2828 - val_accuracy: 0.6018\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0108 - accuracy: 0.8271 - val_loss: 1.2783 - val_accuracy: 0.6120\n","Epoch 4/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9970 - accuracy: 0.8322 - val_loss: 1.2751 - val_accuracy: 0.5781\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9892 - accuracy: 0.8415 - val_loss: 1.2687 - val_accuracy: 0.6199\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9769 - accuracy: 0.8458 - val_loss: 1.2662 - val_accuracy: 0.5962\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9688 - accuracy: 0.8492 - val_loss: 1.2592 - val_accuracy: 0.6109\n","Epoch 8/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9603 - accuracy: 0.8551 - val_loss: 1.2536 - val_accuracy: 0.6143\n","Epoch 9/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9443 - accuracy: 0.8639 - val_loss: 1.2516 - val_accuracy: 0.6176\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9404 - accuracy: 0.8636 - val_loss: 1.2429 - val_accuracy: 0.6278\n","Epoch 11/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9287 - accuracy: 0.8650 - val_loss: 1.2381 - val_accuracy: 0.6131\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9176 - accuracy: 0.8755 - val_loss: 1.2308 - val_accuracy: 0.6222\n","Epoch 13/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9126 - accuracy: 0.8783 - val_loss: 1.2251 - val_accuracy: 0.6165\n","Epoch 14/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8991 - accuracy: 0.8871 - val_loss: 1.2302 - val_accuracy: 0.6210\n","Epoch 15/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8936 - accuracy: 0.8851 - val_loss: 1.2258 - val_accuracy: 0.6176\n","Epoch 16/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8998 - accuracy: 0.8795 - val_loss: 1.2278 - val_accuracy: 0.6154\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8796 - accuracy: 0.8939 - val_loss: 1.2069 - val_accuracy: 0.6290\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8740 - accuracy: 0.8922 - val_loss: 1.2027 - val_accuracy: 0.6437\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8645 - accuracy: 0.8953 - val_loss: 1.2040 - val_accuracy: 0.6403\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8693 - accuracy: 0.8882 - val_loss: 1.2004 - val_accuracy: 0.6459\n","Epoch 21/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8494 - accuracy: 0.9024 - val_loss: 1.2035 - val_accuracy: 0.6516\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8479 - accuracy: 0.9038 - val_loss: 1.2070 - val_accuracy: 0.6561\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8396 - accuracy: 0.9072 - val_loss: 1.2141 - val_accuracy: 0.6437\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8300 - accuracy: 0.9128 - val_loss: 1.2255 - val_accuracy: 0.6312\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8221 - accuracy: 0.9174 - val_loss: 1.2211 - val_accuracy: 0.6561\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8164 - accuracy: 0.9196 - val_loss: 1.2275 - val_accuracy: 0.6550\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8089 - accuracy: 0.9205 - val_loss: 1.2849 - val_accuracy: 0.6063\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8139 - accuracy: 0.9103 - val_loss: 1.2414 - val_accuracy: 0.6505\n","Epoch 29/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7947 - accuracy: 0.9290 - val_loss: 1.2435 - val_accuracy: 0.6516\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7896 - accuracy: 0.9284 - val_loss: 1.2488 - val_accuracy: 0.6550\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7876 - accuracy: 0.9213 - val_loss: 1.2707 - val_accuracy: 0.6414\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7767 - accuracy: 0.9324 - val_loss: 1.2727 - val_accuracy: 0.6369\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7791 - accuracy: 0.9261 - val_loss: 1.2664 - val_accuracy: 0.6391\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7657 - accuracy: 0.9366 - val_loss: 1.2738 - val_accuracy: 0.6448\n","Epoch 35/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7597 - accuracy: 0.9349 - val_loss: 1.2774 - val_accuracy: 0.6459\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7558 - accuracy: 0.9338 - val_loss: 1.2769 - val_accuracy: 0.6425\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7527 - accuracy: 0.9355 - val_loss: 1.2808 - val_accuracy: 0.6414\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7441 - accuracy: 0.9428 - val_loss: 1.2899 - val_accuracy: 0.6527\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7445 - accuracy: 0.9355 - val_loss: 1.2892 - val_accuracy: 0.6482\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7442 - accuracy: 0.9304 - val_loss: 1.2930 - val_accuracy: 0.6471\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7294 - accuracy: 0.9457 - val_loss: 1.3336 - val_accuracy: 0.6380\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7397 - accuracy: 0.9304 - val_loss: 1.3096 - val_accuracy: 0.6516\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7296 - accuracy: 0.9341 - val_loss: 1.3296 - val_accuracy: 0.6459\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7150 - accuracy: 0.9468 - val_loss: 1.3072 - val_accuracy: 0.6459\n","Epoch 45/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7163 - accuracy: 0.9372 - val_loss: 1.3341 - val_accuracy: 0.6312\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7191 - accuracy: 0.9372 - val_loss: 1.3094 - val_accuracy: 0.6459\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7024 - accuracy: 0.9485 - val_loss: 1.3155 - val_accuracy: 0.6391\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6953 - accuracy: 0.9513 - val_loss: 1.3257 - val_accuracy: 0.6357\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6918 - accuracy: 0.9510 - val_loss: 1.3330 - val_accuracy: 0.6493\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6859 - accuracy: 0.9516 - val_loss: 1.3443 - val_accuracy: 0.6357\n","Epoch 51/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6836 - accuracy: 0.9508 - val_loss: 1.3638 - val_accuracy: 0.6335\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.9510 - val_loss: 1.3423 - val_accuracy: 0.6448\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6779 - accuracy: 0.9508 - val_loss: 1.3409 - val_accuracy: 0.6471\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6692 - accuracy: 0.9553 - val_loss: 1.3490 - val_accuracy: 0.6459\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6671 - accuracy: 0.9564 - val_loss: 1.3860 - val_accuracy: 0.6131\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6671 - accuracy: 0.9488 - val_loss: 1.3653 - val_accuracy: 0.6346\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6629 - accuracy: 0.9559 - val_loss: 1.3680 - val_accuracy: 0.6324\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6530 - accuracy: 0.9604 - val_loss: 1.3637 - val_accuracy: 0.6267\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6537 - accuracy: 0.9573 - val_loss: 1.3810 - val_accuracy: 0.6448\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.9544 - val_loss: 1.3786 - val_accuracy: 0.6324\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6447 - accuracy: 0.9598 - val_loss: 1.4153 - val_accuracy: 0.6380\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6516 - accuracy: 0.9519 - val_loss: 1.3738 - val_accuracy: 0.6391\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6438 - accuracy: 0.9547 - val_loss: 1.3925 - val_accuracy: 0.6437\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6333 - accuracy: 0.9626 - val_loss: 1.3863 - val_accuracy: 0.6471\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6311 - accuracy: 0.9610 - val_loss: 1.3856 - val_accuracy: 0.6459\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6381 - accuracy: 0.9547 - val_loss: 1.3856 - val_accuracy: 0.6471\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6242 - accuracy: 0.9615 - val_loss: 1.3953 - val_accuracy: 0.6414\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6228 - accuracy: 0.9635 - val_loss: 1.4026 - val_accuracy: 0.6448\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6225 - accuracy: 0.9601 - val_loss: 1.4153 - val_accuracy: 0.6222\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6117 - accuracy: 0.9658 - val_loss: 1.4095 - val_accuracy: 0.6437\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6136 - accuracy: 0.9624 - val_loss: 1.4097 - val_accuracy: 0.6403\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6099 - accuracy: 0.9660 - val_loss: 1.4340 - val_accuracy: 0.6346\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6218 - accuracy: 0.9573 - val_loss: 1.4358 - val_accuracy: 0.6482\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6019 - accuracy: 0.9675 - val_loss: 1.4482 - val_accuracy: 0.6425\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6014 - accuracy: 0.9677 - val_loss: 1.4410 - val_accuracy: 0.6380\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6029 - accuracy: 0.9615 - val_loss: 1.4270 - val_accuracy: 0.6346\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5932 - accuracy: 0.9703 - val_loss: 1.4705 - val_accuracy: 0.6369\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5984 - accuracy: 0.9612 - val_loss: 1.4810 - val_accuracy: 0.6075\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5915 - accuracy: 0.9658 - val_loss: 1.4515 - val_accuracy: 0.6437\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5837 - accuracy: 0.9726 - val_loss: 1.4604 - val_accuracy: 0.6414\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5838 - accuracy: 0.9677 - val_loss: 1.4517 - val_accuracy: 0.6414\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5790 - accuracy: 0.9740 - val_loss: 1.4675 - val_accuracy: 0.6403\n","Epoch 83/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5794 - accuracy: 0.9700 - val_loss: 1.4656 - val_accuracy: 0.6380\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5764 - accuracy: 0.9714 - val_loss: 1.4728 - val_accuracy: 0.6403\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5760 - accuracy: 0.9692 - val_loss: 1.5052 - val_accuracy: 0.6109\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5700 - accuracy: 0.9762 - val_loss: 1.4863 - val_accuracy: 0.6380\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5690 - accuracy: 0.9737 - val_loss: 1.5203 - val_accuracy: 0.6278\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5773 - accuracy: 0.9680 - val_loss: 1.4909 - val_accuracy: 0.6301\n","Epoch 89/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5636 - accuracy: 0.9748 - val_loss: 1.4901 - val_accuracy: 0.6301\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5611 - accuracy: 0.9765 - val_loss: 1.4865 - val_accuracy: 0.6391\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5567 - accuracy: 0.9765 - val_loss: 1.5033 - val_accuracy: 0.6278\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5586 - accuracy: 0.9728 - val_loss: 1.5034 - val_accuracy: 0.6459\n","Epoch 93/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5555 - accuracy: 0.9759 - val_loss: 1.5362 - val_accuracy: 0.6380\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.9751 - val_loss: 1.5373 - val_accuracy: 0.6075\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5490 - accuracy: 0.9762 - val_loss: 1.5145 - val_accuracy: 0.6380\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5576 - accuracy: 0.9692 - val_loss: 1.5987 - val_accuracy: 0.6278\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5508 - accuracy: 0.9700 - val_loss: 1.5309 - val_accuracy: 0.6425\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5465 - accuracy: 0.9740 - val_loss: 1.5884 - val_accuracy: 0.6267\n","Epoch 99/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5570 - accuracy: 0.9663 - val_loss: 1.5756 - val_accuracy: 0.6063\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5435 - accuracy: 0.9779 - val_loss: 1.5326 - val_accuracy: 0.6561\n","{'loss': [1.0641385316848755, 1.0267105102539062, 1.0108106136322021, 0.9969672560691833, 0.989159107208252, 0.9768512845039368, 0.9688037037849426, 0.9603213667869568, 0.9443176984786987, 0.9404422640800476, 0.9286860823631287, 0.9175847172737122, 0.9125936031341553, 0.8990933299064636, 0.8936015367507935, 0.899848222732544, 0.8795770406723022, 0.8739694356918335, 0.8644940257072449, 0.8693040609359741, 0.8494062423706055, 0.8478798866271973, 0.8395500183105469, 0.8300323486328125, 0.8220889568328857, 0.8163752555847168, 0.8088757395744324, 0.8138962984085083, 0.7946563363075256, 0.7895561456680298, 0.78762286901474, 0.7767072319984436, 0.7790586948394775, 0.7656654119491577, 0.7597137689590454, 0.755778968334198, 0.752655029296875, 0.7440590858459473, 0.7444968819618225, 0.7442378997802734, 0.7293524146080017, 0.7396516799926758, 0.7295804619789124, 0.715008556842804, 0.7163341045379639, 0.7191159129142761, 0.7023566365242004, 0.6952524185180664, 0.6918383240699768, 0.685911238193512, 0.6835660338401794, 0.6814997792243958, 0.6778994798660278, 0.6692368388175964, 0.667071521282196, 0.6670928597450256, 0.6629300117492676, 0.6529658436775208, 0.6537476181983948, 0.6519993543624878, 0.6447166800498962, 0.6516339778900146, 0.6437859535217285, 0.6333404779434204, 0.6310791373252869, 0.6380857229232788, 0.624167263507843, 0.6227633357048035, 0.6225026845932007, 0.6117064952850342, 0.6136149764060974, 0.6099146008491516, 0.6218122243881226, 0.6019412279129028, 0.6013527512550354, 0.6029148697853088, 0.5932211875915527, 0.5983503460884094, 0.5915390849113464, 0.5837305784225464, 0.58379727602005, 0.5789709687232971, 0.5794392824172974, 0.5763627886772156, 0.5759780406951904, 0.5700422525405884, 0.5689641833305359, 0.5772988796234131, 0.5635845065116882, 0.5611465573310852, 0.5567169189453125, 0.5586130023002625, 0.555511474609375, 0.5548696517944336, 0.5489758849143982, 0.5576353073120117, 0.5508244037628174, 0.5464989542961121, 0.5569581985473633, 0.543463408946991], 'accuracy': [0.784380316734314, 0.814091682434082, 0.8271080851554871, 0.8322014808654785, 0.8415393233299255, 0.8457838296890259, 0.8491793870925903, 0.8551216721534729, 0.8638936281204224, 0.8636106252670288, 0.8650254607200623, 0.875495195388794, 0.8783248662948608, 0.8870967626571655, 0.8851160407066345, 0.8794566988945007, 0.8938879370689392, 0.892190158367157, 0.8953027725219727, 0.8882286548614502, 0.9023768901824951, 0.9037917256355286, 0.9071873426437378, 0.9128466248512268, 0.9173740744590759, 0.9196377992630005, 0.9204866886138916, 0.9102999567985535, 0.9289756417274475, 0.92840975522995, 0.9213355779647827, 0.9323712587356567, 0.9261460304260254, 0.9366157054901123, 0.9349179267883301, 0.9337860941886902, 0.9354838728904724, 0.9428409934043884, 0.9354838728904724, 0.930390477180481, 0.9456706047058105, 0.930390477180481, 0.934069037437439, 0.9468024969100952, 0.9371816515922546, 0.9371816515922546, 0.9485002756118774, 0.9513299465179443, 0.9510469436645508, 0.9516128897666931, 0.950764000415802, 0.9510469436645508, 0.950764000415802, 0.9552914500236511, 0.9564233422279358, 0.9487832188606262, 0.9558573961257935, 0.9603848457336426, 0.9572722315788269, 0.95444256067276, 0.9598188996315002, 0.9518958926200867, 0.9547255039215088, 0.9626485705375671, 0.9609507918357849, 0.9547255039215088, 0.9615166783332825, 0.9634974598884583, 0.960101842880249, 0.9657611846923828, 0.9623655676841736, 0.9660441279411316, 0.9572722315788269, 0.967458963394165, 0.9677419066429138, 0.9615166783332825, 0.9702886343002319, 0.9612337350845337, 0.9657611846923828, 0.9725523591041565, 0.9677419066429138, 0.9739671945571899, 0.9700056314468384, 0.9714204668998718, 0.9691567420959473, 0.9762309193611145, 0.9736841917037964, 0.9680249094963074, 0.974816083908081, 0.9765138626098633, 0.9765138626098633, 0.9728353023529053, 0.975947916507721, 0.9750990271568298, 0.9762309193611145, 0.9691567420959473, 0.9700056314468384, 0.9739671945571899, 0.9663271307945251, 0.9779286980628967], 'val_loss': [1.2870928049087524, 1.2828178405761719, 1.278304100036621, 1.2751061916351318, 1.2687040567398071, 1.2661547660827637, 1.259171962738037, 1.2535679340362549, 1.2515512704849243, 1.2428998947143555, 1.2380850315093994, 1.2308454513549805, 1.2251070737838745, 1.2302287817001343, 1.2258062362670898, 1.227764368057251, 1.2069164514541626, 1.202720284461975, 1.2039549350738525, 1.200435996055603, 1.2034987211227417, 1.2069673538208008, 1.2141224145889282, 1.2254507541656494, 1.2210708856582642, 1.227474570274353, 1.2848880290985107, 1.2414467334747314, 1.2434754371643066, 1.2487717866897583, 1.2707231044769287, 1.2727198600769043, 1.2664220333099365, 1.2737948894500732, 1.2773523330688477, 1.2768580913543701, 1.2807986736297607, 1.2898682355880737, 1.2892342805862427, 1.2930150032043457, 1.3335670232772827, 1.3096058368682861, 1.3296418190002441, 1.307155728340149, 1.3340586423873901, 1.3093855381011963, 1.3155215978622437, 1.3256860971450806, 1.3329851627349854, 1.3443323373794556, 1.3638408184051514, 1.3422971963882446, 1.3408784866333008, 1.3489813804626465, 1.3859875202178955, 1.3653101921081543, 1.3680452108383179, 1.363735318183899, 1.3810205459594727, 1.3786451816558838, 1.4152824878692627, 1.3737623691558838, 1.3925293684005737, 1.3863357305526733, 1.3856412172317505, 1.3856115341186523, 1.3953057527542114, 1.4025899171829224, 1.4153285026550293, 1.4094932079315186, 1.4096803665161133, 1.4339957237243652, 1.435796856880188, 1.4481743574142456, 1.4410024881362915, 1.4269819259643555, 1.4705092906951904, 1.4810235500335693, 1.45146644115448, 1.460445761680603, 1.4516971111297607, 1.4675264358520508, 1.4655781984329224, 1.4728150367736816, 1.5051580667495728, 1.4862886667251587, 1.520342469215393, 1.4909015893936157, 1.4900524616241455, 1.4865473508834839, 1.5032734870910645, 1.5034091472625732, 1.5361671447753906, 1.5372579097747803, 1.5145014524459839, 1.5987130403518677, 1.5309436321258545, 1.5884493589401245, 1.575610637664795, 1.532577395439148], 'val_accuracy': [0.6040723919868469, 0.6018099784851074, 0.6119909286499023, 0.5780543088912964, 0.6199095249176025, 0.5961538553237915, 0.610859751701355, 0.6142534017562866, 0.6176470518112183, 0.627828061580658, 0.6131221652030945, 0.622171938419342, 0.6165158152580261, 0.6210407018661499, 0.6176470518112183, 0.6153846383094788, 0.6289592981338501, 0.6436651349067688, 0.6402714848518372, 0.6459276080131531, 0.651583731174469, 0.6561086177825928, 0.6436651349067688, 0.6312217116355896, 0.6561086177825928, 0.6549773812294006, 0.6063348650932312, 0.6504524946212769, 0.651583731174469, 0.6549773812294006, 0.6414027214050293, 0.6368778347969055, 0.639140248298645, 0.6447963714599609, 0.6459276080131531, 0.6425339579582214, 0.6414027214050293, 0.6527149081230164, 0.6481900215148926, 0.6470588445663452, 0.6380090713500977, 0.651583731174469, 0.6459276080131531, 0.6459276080131531, 0.6312217116355896, 0.6459276080131531, 0.639140248298645, 0.6357465982437134, 0.6493212580680847, 0.6357465982437134, 0.6334841847419739, 0.6447963714599609, 0.6470588445663452, 0.6459276080131531, 0.6131221652030945, 0.6346153616905212, 0.6323529481887817, 0.6266968250274658, 0.6447963714599609, 0.6323529481887817, 0.6380090713500977, 0.639140248298645, 0.6436651349067688, 0.6470588445663452, 0.6459276080131531, 0.6470588445663452, 0.6414027214050293, 0.6447963714599609, 0.622171938419342, 0.6436651349067688, 0.6402714848518372, 0.6346153616905212, 0.6481900215148926, 0.6425339579582214, 0.6380090713500977, 0.6346153616905212, 0.6368778347969055, 0.6074660420417786, 0.6436651349067688, 0.6414027214050293, 0.6414027214050293, 0.6402714848518372, 0.6380090713500977, 0.6402714848518372, 0.610859751701355, 0.6380090713500977, 0.627828061580658, 0.6300904750823975, 0.6300904750823975, 0.639140248298645, 0.627828061580658, 0.6459276080131531, 0.6380090713500977, 0.6074660420417786, 0.6380090713500977, 0.627828061580658, 0.6425339579582214, 0.6266968250274658, 0.6063348650932312, 0.6561086177825928]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 27ms/step - loss: 1.0820 - accuracy: 0.7674 - val_loss: 1.2856 - val_accuracy: 0.6116\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.0480 - accuracy: 0.7891"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 12ms/step - loss: 1.0500 - accuracy: 0.7925 - val_loss: 1.2815 - val_accuracy: 0.6033\n","Epoch 3/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0296 - accuracy: 0.8078 - val_loss: 1.2781 - val_accuracy: 0.5620\n","Epoch 4/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0211 - accuracy: 0.8121 - val_loss: 1.2734 - val_accuracy: 0.5733\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0046 - accuracy: 0.8256 - val_loss: 1.2659 - val_accuracy: 0.6426\n","Epoch 6/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9969 - accuracy: 0.8256 - val_loss: 1.2617 - val_accuracy: 0.6116\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9912 - accuracy: 0.8302 - val_loss: 1.2572 - val_accuracy: 0.6074\n","Epoch 8/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9795 - accuracy: 0.8395 - val_loss: 1.2574 - val_accuracy: 0.5661\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9724 - accuracy: 0.8382 - val_loss: 1.2449 - val_accuracy: 0.6167\n","Epoch 10/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9537 - accuracy: 0.8563 - val_loss: 1.2365 - val_accuracy: 0.6322\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9575 - accuracy: 0.8395 - val_loss: 1.2311 - val_accuracy: 0.6240\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9418 - accuracy: 0.8522 - val_loss: 1.2257 - val_accuracy: 0.6343\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9287 - accuracy: 0.8646 - val_loss: 1.2283 - val_accuracy: 0.5971\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9246 - accuracy: 0.8638 - val_loss: 1.2103 - val_accuracy: 0.6457\n","Epoch 15/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9191 - accuracy: 0.8594 - val_loss: 1.2092 - val_accuracy: 0.6384\n","Epoch 16/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9038 - accuracy: 0.8778 - val_loss: 1.2091 - val_accuracy: 0.6312\n","Epoch 17/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8983 - accuracy: 0.8734 - val_loss: 1.2056 - val_accuracy: 0.6353\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8940 - accuracy: 0.8786 - val_loss: 1.2046 - val_accuracy: 0.6446\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8877 - accuracy: 0.8786 - val_loss: 1.2115 - val_accuracy: 0.6322\n","Epoch 20/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8864 - accuracy: 0.8721 - val_loss: 1.2174 - val_accuracy: 0.6343\n","Epoch 21/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8792 - accuracy: 0.8711 - val_loss: 1.2207 - val_accuracy: 0.6405\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8642 - accuracy: 0.8855 - val_loss: 1.2160 - val_accuracy: 0.6488\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8558 - accuracy: 0.8938 - val_loss: 1.2024 - val_accuracy: 0.6529\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8470 - accuracy: 0.8984 - val_loss: 1.2116 - val_accuracy: 0.6498\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8408 - accuracy: 0.8984 - val_loss: 1.2418 - val_accuracy: 0.6333\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8424 - accuracy: 0.8966 - val_loss: 1.2165 - val_accuracy: 0.6560\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8244 - accuracy: 0.9101 - val_loss: 1.2301 - val_accuracy: 0.6560\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8271 - accuracy: 0.8992 - val_loss: 1.3054 - val_accuracy: 0.6322\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8286 - accuracy: 0.8899 - val_loss: 1.2331 - val_accuracy: 0.6550\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8136 - accuracy: 0.9034 - val_loss: 1.2377 - val_accuracy: 0.6519\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8102 - accuracy: 0.9031 - val_loss: 1.2358 - val_accuracy: 0.6581\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7957 - accuracy: 0.9158 - val_loss: 1.2512 - val_accuracy: 0.6550\n","Epoch 33/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7930 - accuracy: 0.9116 - val_loss: 1.2457 - val_accuracy: 0.6508\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7861 - accuracy: 0.9152 - val_loss: 1.2547 - val_accuracy: 0.6591\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7791 - accuracy: 0.9189 - val_loss: 1.2548 - val_accuracy: 0.6436\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7748 - accuracy: 0.9199 - val_loss: 1.2520 - val_accuracy: 0.6570\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7690 - accuracy: 0.9225 - val_loss: 1.3261 - val_accuracy: 0.6353\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7650 - accuracy: 0.9186 - val_loss: 1.2709 - val_accuracy: 0.6426\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7571 - accuracy: 0.9251 - val_loss: 1.2694 - val_accuracy: 0.6436\n","Epoch 40/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7529 - accuracy: 0.9240 - val_loss: 1.2775 - val_accuracy: 0.6395\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7449 - accuracy: 0.9276 - val_loss: 1.2941 - val_accuracy: 0.6384\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7508 - accuracy: 0.9173 - val_loss: 1.2810 - val_accuracy: 0.6405\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7338 - accuracy: 0.9331 - val_loss: 1.2809 - val_accuracy: 0.6436\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7349 - accuracy: 0.9339 - val_loss: 1.2827 - val_accuracy: 0.6539\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7281 - accuracy: 0.9328 - val_loss: 1.3322 - val_accuracy: 0.6260\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7424 - accuracy: 0.9152 - val_loss: 1.2907 - val_accuracy: 0.6508\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7202 - accuracy: 0.9326 - val_loss: 1.2915 - val_accuracy: 0.6519\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7120 - accuracy: 0.9403 - val_loss: 1.2907 - val_accuracy: 0.6529\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7143 - accuracy: 0.9320 - val_loss: 1.3014 - val_accuracy: 0.6519\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7097 - accuracy: 0.9320 - val_loss: 1.3188 - val_accuracy: 0.6343\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7108 - accuracy: 0.9326 - val_loss: 1.3452 - val_accuracy: 0.6219\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7005 - accuracy: 0.9364 - val_loss: 1.3118 - val_accuracy: 0.6477\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.9406 - val_loss: 1.3090 - val_accuracy: 0.6550\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6946 - accuracy: 0.9362 - val_loss: 1.3173 - val_accuracy: 0.6343\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6829 - accuracy: 0.9437 - val_loss: 1.3179 - val_accuracy: 0.6508\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.9455 - val_loss: 1.3286 - val_accuracy: 0.6374\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6707 - accuracy: 0.9463 - val_loss: 1.3422 - val_accuracy: 0.6395\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6674 - accuracy: 0.9488 - val_loss: 1.3488 - val_accuracy: 0.6405\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6636 - accuracy: 0.9475 - val_loss: 1.3366 - val_accuracy: 0.6508\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6702 - accuracy: 0.9416 - val_loss: 1.3426 - val_accuracy: 0.6291\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6599 - accuracy: 0.9468 - val_loss: 1.3682 - val_accuracy: 0.6364\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6541 - accuracy: 0.9519 - val_loss: 1.3527 - val_accuracy: 0.6457\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6498 - accuracy: 0.9499 - val_loss: 1.3533 - val_accuracy: 0.6343\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6450 - accuracy: 0.9548 - val_loss: 1.3524 - val_accuracy: 0.6477\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6422 - accuracy: 0.9537 - val_loss: 1.3609 - val_accuracy: 0.6446\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6402 - accuracy: 0.9506 - val_loss: 1.3724 - val_accuracy: 0.6405\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6420 - accuracy: 0.9475 - val_loss: 1.3809 - val_accuracy: 0.6446\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6371 - accuracy: 0.9512 - val_loss: 1.3742 - val_accuracy: 0.6333\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6333 - accuracy: 0.9535 - val_loss: 1.3747 - val_accuracy: 0.6364\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6237 - accuracy: 0.9607 - val_loss: 1.3976 - val_accuracy: 0.6302\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6239 - accuracy: 0.9599 - val_loss: 1.3931 - val_accuracy: 0.6384\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6178 - accuracy: 0.9576 - val_loss: 1.3892 - val_accuracy: 0.6374\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6145 - accuracy: 0.9638 - val_loss: 1.4011 - val_accuracy: 0.6291\n","Epoch 74/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6152 - accuracy: 0.9550 - val_loss: 1.4015 - val_accuracy: 0.6343\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6092 - accuracy: 0.9618 - val_loss: 1.4044 - val_accuracy: 0.6374\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6119 - accuracy: 0.9599 - val_loss: 1.4051 - val_accuracy: 0.6415\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6108 - accuracy: 0.9574 - val_loss: 1.4086 - val_accuracy: 0.6467\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6017 - accuracy: 0.9615 - val_loss: 1.4145 - val_accuracy: 0.6457\n","Epoch 79/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5970 - accuracy: 0.9669 - val_loss: 1.4190 - val_accuracy: 0.6426\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6058 - accuracy: 0.9540 - val_loss: 1.4277 - val_accuracy: 0.6322\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5933 - accuracy: 0.9633 - val_loss: 1.4634 - val_accuracy: 0.6384\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6024 - accuracy: 0.9548 - val_loss: 1.4337 - val_accuracy: 0.6271\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.9646 - val_loss: 1.4677 - val_accuracy: 0.6333\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5876 - accuracy: 0.9638 - val_loss: 1.5127 - val_accuracy: 0.6240\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5836 - accuracy: 0.9659 - val_loss: 1.4758 - val_accuracy: 0.6353\n","Epoch 86/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5825 - accuracy: 0.9659 - val_loss: 1.4511 - val_accuracy: 0.6343\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5778 - accuracy: 0.9643 - val_loss: 1.4561 - val_accuracy: 0.6333\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5831 - accuracy: 0.9612 - val_loss: 1.4617 - val_accuracy: 0.6353\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5716 - accuracy: 0.9690 - val_loss: 1.4726 - val_accuracy: 0.6302\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5691 - accuracy: 0.9698 - val_loss: 1.4809 - val_accuracy: 0.6436\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5671 - accuracy: 0.9680 - val_loss: 1.4896 - val_accuracy: 0.6250\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5679 - accuracy: 0.9659 - val_loss: 1.5895 - val_accuracy: 0.6167\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5703 - accuracy: 0.9654 - val_loss: 1.4961 - val_accuracy: 0.6312\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5610 - accuracy: 0.9669 - val_loss: 1.5204 - val_accuracy: 0.6271\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5613 - accuracy: 0.9695 - val_loss: 1.4914 - val_accuracy: 0.6384\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5547 - accuracy: 0.9687 - val_loss: 1.4974 - val_accuracy: 0.6302\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5548 - accuracy: 0.9682 - val_loss: 1.5055 - val_accuracy: 0.6343\n","Epoch 98/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5525 - accuracy: 0.9708 - val_loss: 1.5516 - val_accuracy: 0.6374\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5508 - accuracy: 0.9721 - val_loss: 1.5549 - val_accuracy: 0.6209\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5573 - accuracy: 0.9638 - val_loss: 1.5234 - val_accuracy: 0.6260\n","{'loss': [1.0819504261016846, 1.049991250038147, 1.0295816659927368, 1.0210537910461426, 1.0046088695526123, 0.9968995451927185, 0.9911545515060425, 0.979512095451355, 0.9723919034004211, 0.953678548336029, 0.9574637413024902, 0.9418037533760071, 0.9286546111106873, 0.9245553612709045, 0.9190523624420166, 0.9037631154060364, 0.8983330726623535, 0.8939753770828247, 0.8876625895500183, 0.8864247798919678, 0.8792170882225037, 0.864150881767273, 0.855755627155304, 0.8470351099967957, 0.8407672047615051, 0.8423944711685181, 0.8244085311889648, 0.8271231055259705, 0.8286246657371521, 0.8135907649993896, 0.810163676738739, 0.795743465423584, 0.7929826974868774, 0.7861148715019226, 0.7791215777397156, 0.77482670545578, 0.7690364122390747, 0.764980137348175, 0.7570991516113281, 0.7529376149177551, 0.7448768615722656, 0.7508002519607544, 0.7338067293167114, 0.7349229454994202, 0.7280548214912415, 0.7424079775810242, 0.7201983332633972, 0.7120217680931091, 0.7142525911331177, 0.7096598744392395, 0.7107661962509155, 0.700515866279602, 0.6925938129425049, 0.6946263909339905, 0.6829332113265991, 0.6762481331825256, 0.670694887638092, 0.6673739552497864, 0.663562536239624, 0.6701899766921997, 0.6599467396736145, 0.6540800929069519, 0.6498036980628967, 0.6450185179710388, 0.642210841178894, 0.6402162313461304, 0.6420193314552307, 0.6371344923973083, 0.6333096623420715, 0.6236541867256165, 0.6238906383514404, 0.6178082227706909, 0.6144718527793884, 0.6151763796806335, 0.6091850996017456, 0.6118791103363037, 0.6107591986656189, 0.6016609072685242, 0.5969934463500977, 0.6058114767074585, 0.5932670831680298, 0.6023695468902588, 0.5883709788322449, 0.5876051187515259, 0.5836058259010315, 0.5825443863868713, 0.5777918100357056, 0.5830934047698975, 0.571557343006134, 0.5690999627113342, 0.5671210885047913, 0.5678537487983704, 0.5702874660491943, 0.5610413551330566, 0.5612857937812805, 0.554704487323761, 0.5548160672187805, 0.5524845719337463, 0.5507685542106628, 0.5572504997253418], 'accuracy': [0.7674418687820435, 0.7925064563751221, 0.8077519536018372, 0.8121446967124939, 0.8255813717842102, 0.8255813717842102, 0.830232560634613, 0.8395348787307739, 0.8382428884506226, 0.8563307523727417, 0.8395348787307739, 0.8521963953971863, 0.8645994663238525, 0.8638243079185486, 0.8594315052032471, 0.8777777552604675, 0.8733850121498108, 0.8785529732704163, 0.8785529732704163, 0.8720930218696594, 0.8710594177246094, 0.8855296969413757, 0.8937984704971313, 0.8984495997428894, 0.8984495997428894, 0.8966408371925354, 0.9100775122642517, 0.8992248177528381, 0.8899224996566772, 0.9033591747283936, 0.9031007885932922, 0.9157622456550598, 0.9116278886795044, 0.9152454733848572, 0.91886305809021, 0.91989666223526, 0.9224806427955627, 0.9186046719551086, 0.9250646233558655, 0.9240310192108154, 0.9276486039161682, 0.9173126816749573, 0.933074951171875, 0.933850109577179, 0.9328165650367737, 0.9152454733848572, 0.9325581192970276, 0.9403100609779358, 0.932041347026825, 0.932041347026825, 0.9325581192970276, 0.9364340901374817, 0.9405684471130371, 0.9361757040023804, 0.9436692595481873, 0.9454780220985413, 0.94625324010849, 0.9488372206687927, 0.9475452303886414, 0.9416020512580872, 0.9467700123786926, 0.9519379734992981, 0.9498708248138428, 0.9547803401947021, 0.9537467956542969, 0.9506459832191467, 0.9475452303886414, 0.9511628150939941, 0.9534883499145508, 0.9607235193252563, 0.9599483013153076, 0.957622766494751, 0.9638242721557617, 0.9550387859344482, 0.9617571234703064, 0.9599483013153076, 0.9573643207550049, 0.9614987373352051, 0.9669250845909119, 0.9540051817893982, 0.9633074998855591, 0.9547803401947021, 0.9645994901657104, 0.9638242721557617, 0.9658914804458618, 0.9658914804458618, 0.9643411040306091, 0.961240291595459, 0.9689922332763672, 0.9697674512863159, 0.9679586291313171, 0.9658914804458618, 0.9653746485710144, 0.9669250845909119, 0.9695090651512146, 0.9687338471412659, 0.9682170748710632, 0.970801055431366, 0.9720930457115173, 0.9638242721557617], 'val_loss': [1.2855554819107056, 1.281497836112976, 1.278128981590271, 1.2733843326568604, 1.2658604383468628, 1.2616894245147705, 1.2571642398834229, 1.2573965787887573, 1.2448500394821167, 1.2364757061004639, 1.2310876846313477, 1.2256841659545898, 1.2283101081848145, 1.2102521657943726, 1.209161400794983, 1.209097146987915, 1.2056423425674438, 1.2045519351959229, 1.2114920616149902, 1.2174121141433716, 1.220711350440979, 1.2159645557403564, 1.2024484872817993, 1.211641788482666, 1.2417758703231812, 1.2164944410324097, 1.2300680875778198, 1.3054225444793701, 1.2331137657165527, 1.2377359867095947, 1.2357553243637085, 1.2511733770370483, 1.245708703994751, 1.2546799182891846, 1.2547789812088013, 1.2520170211791992, 1.3260605335235596, 1.2708691358566284, 1.2694416046142578, 1.2774958610534668, 1.2940882444381714, 1.2810086011886597, 1.2808557748794556, 1.2826603651046753, 1.3321818113327026, 1.2907179594039917, 1.2914707660675049, 1.2907345294952393, 1.301416277885437, 1.3188025951385498, 1.3452225923538208, 1.3118319511413574, 1.3089556694030762, 1.3172669410705566, 1.3178685903549194, 1.3286415338516235, 1.3422261476516724, 1.3487529754638672, 1.3365505933761597, 1.3426356315612793, 1.3682063817977905, 1.3526997566223145, 1.353347659111023, 1.3524364233016968, 1.3609235286712646, 1.3724476099014282, 1.3808772563934326, 1.3741679191589355, 1.3747406005859375, 1.3976267576217651, 1.3930782079696655, 1.3891613483428955, 1.4010608196258545, 1.4014586210250854, 1.4043934345245361, 1.4050867557525635, 1.4085711240768433, 1.4145351648330688, 1.418952226638794, 1.4276742935180664, 1.4633822441101074, 1.4337090253829956, 1.4676804542541504, 1.5126864910125732, 1.4757708311080933, 1.4511369466781616, 1.45613431930542, 1.4617308378219604, 1.4725980758666992, 1.4808768033981323, 1.4896173477172852, 1.5894838571548462, 1.4960523843765259, 1.5204191207885742, 1.4913650751113892, 1.4973524808883667, 1.5054539442062378, 1.5516160726547241, 1.5549135208129883, 1.5234415531158447], 'val_accuracy': [0.6115702390670776, 0.6033057570457458, 0.5619834661483765, 0.5733470916748047, 0.6425619721412659, 0.6115702390670776, 0.6074380278587341, 0.56611567735672, 0.6167355179786682, 0.6322314143180847, 0.6239669322967529, 0.6342975497245789, 0.5971074104309082, 0.6456611752510071, 0.6384297609329224, 0.6311983466148376, 0.6353305578231812, 0.64462810754776, 0.6322314143180847, 0.6342975497245789, 0.6404958963394165, 0.6487603187561035, 0.6528925895690918, 0.6497933864593506, 0.6332644820213318, 0.6559917330741882, 0.6559917330741882, 0.6322314143180847, 0.6549586653709412, 0.6518595218658447, 0.6580578684806824, 0.6549586653709412, 0.6508264541625977, 0.6590909361839294, 0.6435950398445129, 0.6570248007774353, 0.6353305578231812, 0.6425619721412659, 0.6435950398445129, 0.6394628286361694, 0.6384297609329224, 0.6404958963394165, 0.6435950398445129, 0.6539255976676941, 0.6260330677032471, 0.6508264541625977, 0.6518595218658447, 0.6528925895690918, 0.6518595218658447, 0.6342975497245789, 0.6219007968902588, 0.6477272510528564, 0.6549586653709412, 0.6342975497245789, 0.6508264541625977, 0.6373966932296753, 0.6394628286361694, 0.6404958963394165, 0.6508264541625977, 0.6291322112083435, 0.6363636255264282, 0.6456611752510071, 0.6342975497245789, 0.6477272510528564, 0.64462810754776, 0.6404958963394165, 0.64462810754776, 0.6332644820213318, 0.6363636255264282, 0.6301652789115906, 0.6384297609329224, 0.6373966932296753, 0.6291322112083435, 0.6342975497245789, 0.6373966932296753, 0.6415289044380188, 0.6466942429542542, 0.6456611752510071, 0.6425619721412659, 0.6322314143180847, 0.6384297609329224, 0.6270661354064941, 0.6332644820213318, 0.6239669322967529, 0.6353305578231812, 0.6342975497245789, 0.6332644820213318, 0.6353305578231812, 0.6301652789115906, 0.6435950398445129, 0.625, 0.6167355179786682, 0.6311983466148376, 0.6270661354064941, 0.6384297609329224, 0.6301652789115906, 0.6342975497245789, 0.6373966932296753, 0.6208677887916565, 0.6260330677032471]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 29ms/step - loss: 0.6734 - accuracy: 0.9106 - val_loss: 1.1229 - val_accuracy: 0.6272\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.6598 - accuracy: 0.9219"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 0s 11ms/step - loss: 0.6282 - accuracy: 0.9329 - val_loss: 1.1186 - val_accuracy: 0.6164\n","Epoch 3/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6141 - accuracy: 0.9415 - val_loss: 1.1146 - val_accuracy: 0.6099\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6076 - accuracy: 0.9429 - val_loss: 1.1064 - val_accuracy: 0.6369\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6033 - accuracy: 0.9485 - val_loss: 1.1028 - val_accuracy: 0.6207\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5924 - accuracy: 0.9558 - val_loss: 1.0907 - val_accuracy: 0.6606\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5915 - accuracy: 0.9550 - val_loss: 1.0892 - val_accuracy: 0.6282\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5842 - accuracy: 0.9564 - val_loss: 1.0734 - val_accuracy: 0.6724\n","Epoch 9/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5966 - accuracy: 0.9480 - val_loss: 1.0807 - val_accuracy: 0.6325\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5800 - accuracy: 0.9577 - val_loss: 1.0775 - val_accuracy: 0.6379\n","Epoch 11/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5710 - accuracy: 0.9620 - val_loss: 1.0565 - val_accuracy: 0.6703\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5638 - accuracy: 0.9704 - val_loss: 1.0632 - val_accuracy: 0.6552\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5623 - accuracy: 0.9696 - val_loss: 1.0436 - val_accuracy: 0.6735\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5693 - accuracy: 0.9617 - val_loss: 1.0634 - val_accuracy: 0.6627\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5616 - accuracy: 0.9639 - val_loss: 1.0724 - val_accuracy: 0.6552\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5570 - accuracy: 0.9704 - val_loss: 1.0461 - val_accuracy: 0.6875\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5516 - accuracy: 0.9690 - val_loss: 1.0616 - val_accuracy: 0.6897\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5519 - accuracy: 0.9696 - val_loss: 1.0535 - val_accuracy: 0.6918\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5435 - accuracy: 0.9741 - val_loss: 1.0585 - val_accuracy: 0.7047\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5500 - accuracy: 0.9679 - val_loss: 1.0528 - val_accuracy: 0.7069\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5391 - accuracy: 0.9758 - val_loss: 1.0650 - val_accuracy: 0.7069\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5381 - accuracy: 0.9728 - val_loss: 1.0463 - val_accuracy: 0.7123\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5322 - accuracy: 0.9782 - val_loss: 1.0602 - val_accuracy: 0.7241\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5426 - accuracy: 0.9709 - val_loss: 1.0799 - val_accuracy: 0.7274\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5346 - accuracy: 0.9723 - val_loss: 1.0764 - val_accuracy: 0.7284\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5329 - accuracy: 0.9725 - val_loss: 1.0816 - val_accuracy: 0.7328\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5257 - accuracy: 0.9766 - val_loss: 1.0966 - val_accuracy: 0.7381\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5204 - accuracy: 0.9784 - val_loss: 1.1053 - val_accuracy: 0.7403\n","Epoch 29/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5221 - accuracy: 0.9749 - val_loss: 1.1298 - val_accuracy: 0.7403\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5229 - accuracy: 0.9744 - val_loss: 1.1324 - val_accuracy: 0.7403\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5202 - accuracy: 0.9784 - val_loss: 1.1196 - val_accuracy: 0.7284\n","Epoch 32/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5122 - accuracy: 0.9822 - val_loss: 1.1447 - val_accuracy: 0.7425\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5156 - accuracy: 0.9760 - val_loss: 1.1409 - val_accuracy: 0.7371\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5168 - accuracy: 0.9731 - val_loss: 1.1730 - val_accuracy: 0.7263\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5095 - accuracy: 0.9801 - val_loss: 1.1452 - val_accuracy: 0.7446\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5051 - accuracy: 0.9822 - val_loss: 1.1413 - val_accuracy: 0.7349\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5042 - accuracy: 0.9817 - val_loss: 1.1452 - val_accuracy: 0.7371\n","Epoch 38/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5023 - accuracy: 0.9828 - val_loss: 1.1509 - val_accuracy: 0.7403\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5029 - accuracy: 0.9801 - val_loss: 1.1648 - val_accuracy: 0.7328\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.9795 - val_loss: 1.1900 - val_accuracy: 0.7425\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4973 - accuracy: 0.9833 - val_loss: 1.1684 - val_accuracy: 0.7252\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4983 - accuracy: 0.9814 - val_loss: 1.1713 - val_accuracy: 0.7317\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5037 - accuracy: 0.9731 - val_loss: 1.2647 - val_accuracy: 0.7155\n","Epoch 44/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4986 - accuracy: 0.9790 - val_loss: 1.1702 - val_accuracy: 0.7349\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4895 - accuracy: 0.9860 - val_loss: 1.2182 - val_accuracy: 0.7209\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4896 - accuracy: 0.9857 - val_loss: 1.1731 - val_accuracy: 0.7263\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4897 - accuracy: 0.9822 - val_loss: 1.2465 - val_accuracy: 0.7177\n","Epoch 48/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4958 - accuracy: 0.9771 - val_loss: 1.2216 - val_accuracy: 0.7123\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4925 - accuracy: 0.9790 - val_loss: 1.2394 - val_accuracy: 0.7241\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4839 - accuracy: 0.9828 - val_loss: 1.2287 - val_accuracy: 0.7241\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4792 - accuracy: 0.9863 - val_loss: 1.2022 - val_accuracy: 0.7284\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4811 - accuracy: 0.9836 - val_loss: 1.2281 - val_accuracy: 0.7241\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4780 - accuracy: 0.9844 - val_loss: 1.2032 - val_accuracy: 0.7263\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4843 - accuracy: 0.9828 - val_loss: 1.2071 - val_accuracy: 0.7381\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4809 - accuracy: 0.9833 - val_loss: 1.2619 - val_accuracy: 0.7198\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4750 - accuracy: 0.9838 - val_loss: 1.2670 - val_accuracy: 0.7349\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4810 - accuracy: 0.9825 - val_loss: 1.2391 - val_accuracy: 0.7295\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4740 - accuracy: 0.9871 - val_loss: 1.2163 - val_accuracy: 0.7198\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4709 - accuracy: 0.9879 - val_loss: 1.2434 - val_accuracy: 0.7295\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4689 - accuracy: 0.9890 - val_loss: 1.2703 - val_accuracy: 0.7134\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4714 - accuracy: 0.9828 - val_loss: 1.2371 - val_accuracy: 0.7252\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4724 - accuracy: 0.9830 - val_loss: 1.2443 - val_accuracy: 0.7306\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4668 - accuracy: 0.9852 - val_loss: 1.2516 - val_accuracy: 0.7188\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4640 - accuracy: 0.9884 - val_loss: 1.2419 - val_accuracy: 0.7252\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4647 - accuracy: 0.9876 - val_loss: 1.2481 - val_accuracy: 0.7188\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4597 - accuracy: 0.9887 - val_loss: 1.2512 - val_accuracy: 0.7220\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4636 - accuracy: 0.9860 - val_loss: 1.2678 - val_accuracy: 0.7295\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4587 - accuracy: 0.9890 - val_loss: 1.2623 - val_accuracy: 0.7198\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4576 - accuracy: 0.9876 - val_loss: 1.2764 - val_accuracy: 0.7091\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4743 - accuracy: 0.9811 - val_loss: 1.2949 - val_accuracy: 0.7144\n","Epoch 71/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4752 - accuracy: 0.9793 - val_loss: 1.2875 - val_accuracy: 0.7306\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4565 - accuracy: 0.9868 - val_loss: 1.2688 - val_accuracy: 0.7241\n","Epoch 73/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4533 - accuracy: 0.9879 - val_loss: 1.2752 - val_accuracy: 0.7284\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4512 - accuracy: 0.9892 - val_loss: 1.2855 - val_accuracy: 0.7231\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4628 - accuracy: 0.9844 - val_loss: 1.3636 - val_accuracy: 0.7037\n","Epoch 76/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4533 - accuracy: 0.9857 - val_loss: 1.2845 - val_accuracy: 0.7166\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4492 - accuracy: 0.9884 - val_loss: 1.3139 - val_accuracy: 0.7026\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4571 - accuracy: 0.9838 - val_loss: 1.4130 - val_accuracy: 0.6972\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4575 - accuracy: 0.9849 - val_loss: 1.3144 - val_accuracy: 0.7252\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4467 - accuracy: 0.9908 - val_loss: 1.3181 - val_accuracy: 0.7091\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4513 - accuracy: 0.9838 - val_loss: 1.3498 - val_accuracy: 0.7231\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4578 - accuracy: 0.9825 - val_loss: 1.3133 - val_accuracy: 0.7112\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4431 - accuracy: 0.9908 - val_loss: 1.3091 - val_accuracy: 0.7220\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4484 - accuracy: 0.9855 - val_loss: 1.3172 - val_accuracy: 0.7166\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4422 - accuracy: 0.9884 - val_loss: 1.3226 - val_accuracy: 0.7058\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4392 - accuracy: 0.9933 - val_loss: 1.3159 - val_accuracy: 0.7166\n","Epoch 87/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4406 - accuracy: 0.9884 - val_loss: 1.3286 - val_accuracy: 0.7091\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4536 - accuracy: 0.9811 - val_loss: 1.3650 - val_accuracy: 0.7155\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4394 - accuracy: 0.9895 - val_loss: 1.3636 - val_accuracy: 0.7037\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4426 - accuracy: 0.9881 - val_loss: 1.3707 - val_accuracy: 0.7231\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4375 - accuracy: 0.9919 - val_loss: 1.3332 - val_accuracy: 0.7166\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4348 - accuracy: 0.9916 - val_loss: 1.3391 - val_accuracy: 0.7155\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4385 - accuracy: 0.9892 - val_loss: 1.3837 - val_accuracy: 0.7047\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4421 - accuracy: 0.9830 - val_loss: 1.3489 - val_accuracy: 0.7123\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.9916 - val_loss: 1.3655 - val_accuracy: 0.7101\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4333 - accuracy: 0.9898 - val_loss: 1.3501 - val_accuracy: 0.7101\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4293 - accuracy: 0.9925 - val_loss: 1.3629 - val_accuracy: 0.7080\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4285 - accuracy: 0.9916 - val_loss: 1.3663 - val_accuracy: 0.7144\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4270 - accuracy: 0.9933 - val_loss: 1.3689 - val_accuracy: 0.7047\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4255 - accuracy: 0.9941 - val_loss: 1.3757 - val_accuracy: 0.7069\n","{'loss': [0.6733936071395874, 0.6282448172569275, 0.6140910387039185, 0.6075944304466248, 0.6032728552818298, 0.5924009084701538, 0.5915379524230957, 0.5841974020004272, 0.5966141819953918, 0.5799752473831177, 0.5710375308990479, 0.5637755990028381, 0.5622748732566833, 0.5692740678787231, 0.5616185665130615, 0.5569719672203064, 0.5515655279159546, 0.5519497990608215, 0.5435367822647095, 0.5500392317771912, 0.5390552878379822, 0.5381490588188171, 0.5321535468101501, 0.5425627827644348, 0.5346086621284485, 0.5329130291938782, 0.5257126092910767, 0.5204128623008728, 0.5221427083015442, 0.5229007005691528, 0.5201859474182129, 0.5121602416038513, 0.5156061053276062, 0.5168018341064453, 0.5095221996307373, 0.5051451921463013, 0.5041872262954712, 0.5022938251495361, 0.5028514266014099, 0.5019612312316895, 0.4972541332244873, 0.49829068779945374, 0.5036723017692566, 0.4986143112182617, 0.48947593569755554, 0.48960959911346436, 0.48967328667640686, 0.4958227872848511, 0.492487370967865, 0.48387831449508667, 0.4791747033596039, 0.48114967346191406, 0.4779658913612366, 0.48425236344337463, 0.48088040947914124, 0.4749906063079834, 0.481005996465683, 0.47401314973831177, 0.4708970785140991, 0.4689158797264099, 0.4714116156101227, 0.47242143750190735, 0.4668397009372711, 0.4639924168586731, 0.46466726064682007, 0.45965054631233215, 0.4636181890964508, 0.4586651027202606, 0.4575950801372528, 0.4743356704711914, 0.47524493932724, 0.45645764470100403, 0.45328038930892944, 0.45124417543411255, 0.46278858184814453, 0.4533291459083557, 0.4492471218109131, 0.45707860589027405, 0.45751261711120605, 0.4467417597770691, 0.4512995779514313, 0.45783841609954834, 0.4430955946445465, 0.44835036993026733, 0.44215965270996094, 0.43923860788345337, 0.44061699509620667, 0.45356878638267517, 0.4393575191497803, 0.44257766008377075, 0.43746721744537354, 0.43484407663345337, 0.4385228753089905, 0.4421263039112091, 0.43289071321487427, 0.43327051401138306, 0.42927637696266174, 0.4285404086112976, 0.4270331561565399, 0.42550957202911377], 'accuracy': [0.9105603694915771, 0.9329202771186829, 0.9415409564971924, 0.9428879022598267, 0.9485452771186829, 0.9558189511299133, 0.9550107717514038, 0.9563577771186829, 0.9480064511299133, 0.9577047228813171, 0.9620150923728943, 0.970366358757019, 0.9695581793785095, 0.9617456793785095, 0.9639008641242981, 0.970366358757019, 0.9690194129943848, 0.9695581793785095, 0.9741379022598267, 0.9679418206214905, 0.9757543206214905, 0.9727909564971924, 0.978178858757019, 0.9709051847457886, 0.9722521305084229, 0.9725215435028076, 0.9765625, 0.9784482717514038, 0.974946141242981, 0.9744073152542114, 0.9784482717514038, 0.9822198152542114, 0.9760237336158752, 0.9730603694915771, 0.9800646305084229, 0.9822198152542114, 0.9816810488700867, 0.982758641242981, 0.9800646305084229, 0.9795258641242981, 0.9832974076271057, 0.9814116358757019, 0.9730603694915771, 0.9789870977401733, 0.985991358757019, 0.985722005367279, 0.9822198152542114, 0.9771012663841248, 0.9789870977401733, 0.982758641242981, 0.9862607717514038, 0.9835668206214905, 0.984375, 0.982758641242981, 0.9832974076271057, 0.9838362336158752, 0.9824892282485962, 0.9870689511299133, 0.9878771305084229, 0.9889547228813171, 0.982758641242981, 0.983027994632721, 0.9851831793785095, 0.9884159564971924, 0.9876077771186829, 0.9886853694915771, 0.985991358757019, 0.9889547228813171, 0.9876077771186829, 0.9811422228813171, 0.9792564511299133, 0.9867995977401733, 0.9878771305084229, 0.9892241358757019, 0.984375, 0.985722005367279, 0.9884159564971924, 0.9838362336158752, 0.9849137663841248, 0.990840494632721, 0.9838362336158752, 0.9824892282485962, 0.990840494632721, 0.9854525923728943, 0.9884159564971924, 0.9932650923728943, 0.9884159564971924, 0.9811422228813171, 0.9894935488700867, 0.9881465435028076, 0.9919180870056152, 0.9916487336158752, 0.9892241358757019, 0.983027994632721, 0.9916487336158752, 0.9897629022598267, 0.9924569129943848, 0.9916487336158752, 0.9932650923728943, 0.9940732717514038], 'val_loss': [1.122910737991333, 1.1186306476593018, 1.1146231889724731, 1.106381893157959, 1.1027973890304565, 1.0906533002853394, 1.0891847610473633, 1.0733689069747925, 1.0806854963302612, 1.077499508857727, 1.0565308332443237, 1.0632046461105347, 1.0435876846313477, 1.063419222831726, 1.0723519325256348, 1.0460662841796875, 1.0616097450256348, 1.0535075664520264, 1.0584800243377686, 1.0528253316879272, 1.0649646520614624, 1.0462571382522583, 1.060168981552124, 1.0798934698104858, 1.0763987302780151, 1.0816088914871216, 1.0966044664382935, 1.1052790880203247, 1.1298022270202637, 1.1323603391647339, 1.1196379661560059, 1.1447319984436035, 1.140894889831543, 1.172954797744751, 1.1452362537384033, 1.1413242816925049, 1.14515221118927, 1.1508560180664062, 1.1647957563400269, 1.1900122165679932, 1.1684165000915527, 1.171298623085022, 1.2647461891174316, 1.1702042818069458, 1.2181782722473145, 1.1730636358261108, 1.2465075254440308, 1.2215757369995117, 1.239435076713562, 1.2287065982818604, 1.2022252082824707, 1.2280691862106323, 1.203245759010315, 1.2071067094802856, 1.2619003057479858, 1.2670234441757202, 1.2390731573104858, 1.2163374423980713, 1.243369221687317, 1.2702735662460327, 1.237083077430725, 1.2442575693130493, 1.2515753507614136, 1.241880178451538, 1.248063325881958, 1.2512484788894653, 1.2677737474441528, 1.2622883319854736, 1.2764246463775635, 1.2948658466339111, 1.2874901294708252, 1.2688392400741577, 1.2752485275268555, 1.2854565382003784, 1.3635649681091309, 1.2845053672790527, 1.313886284828186, 1.4130221605300903, 1.3143577575683594, 1.3181124925613403, 1.3498258590698242, 1.3133453130722046, 1.3090858459472656, 1.3171844482421875, 1.3226110935211182, 1.3158546686172485, 1.328586220741272, 1.3650075197219849, 1.3636068105697632, 1.3706821203231812, 1.333180546760559, 1.339111566543579, 1.3836710453033447, 1.348854422569275, 1.3654805421829224, 1.350102186203003, 1.3628767728805542, 1.3662941455841064, 1.3689032793045044, 1.3756976127624512], 'val_accuracy': [0.6271551847457886, 0.6163793206214905, 0.6099137663841248, 0.6368534564971924, 0.6206896305084229, 0.6605603694915771, 0.6282327771186829, 0.6724137663841248, 0.6325430870056152, 0.6379310488700867, 0.670258641242981, 0.6551724076271057, 0.673491358757019, 0.662715494632721, 0.6551724076271057, 0.6875, 0.6896551847457886, 0.6918103694915771, 0.704741358757019, 0.7068965435028076, 0.7068965435028076, 0.712284505367279, 0.7241379022598267, 0.7273706793785095, 0.7284482717514038, 0.732758641242981, 0.7381465435028076, 0.7403017282485962, 0.7403017282485962, 0.7403017282485962, 0.7284482717514038, 0.7424569129943848, 0.7370689511299133, 0.7262930870056152, 0.7446120977401733, 0.7349137663841248, 0.7370689511299133, 0.7403017282485962, 0.732758641242981, 0.7424569129943848, 0.725215494632721, 0.7316810488700867, 0.7155172228813171, 0.7349137663841248, 0.7209051847457886, 0.7262930870056152, 0.7176724076271057, 0.712284505367279, 0.7241379022598267, 0.7241379022598267, 0.7284482717514038, 0.7241379022598267, 0.7262930870056152, 0.7381465435028076, 0.7198275923728943, 0.7349137663841248, 0.7295258641242981, 0.7198275923728943, 0.7295258641242981, 0.7133620977401733, 0.725215494632721, 0.7306034564971924, 0.71875, 0.725215494632721, 0.71875, 0.7219827771186829, 0.7295258641242981, 0.7198275923728943, 0.7090517282485962, 0.7144396305084229, 0.7306034564971924, 0.7241379022598267, 0.7284482717514038, 0.7230603694915771, 0.7036637663841248, 0.7165948152542114, 0.7025862336158752, 0.6971982717514038, 0.725215494632721, 0.7090517282485962, 0.7230603694915771, 0.7112069129943848, 0.7219827771186829, 0.7165948152542114, 0.7058189511299133, 0.7165948152542114, 0.7090517282485962, 0.7155172228813171, 0.7036637663841248, 0.7230603694915771, 0.7165948152542114, 0.7155172228813171, 0.704741358757019, 0.712284505367279, 0.7101293206214905, 0.7101293206214905, 0.7079741358757019, 0.7144396305084229, 0.704741358757019, 0.7068965435028076]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 30ms/step - loss: 0.6721 - accuracy: 0.9100 - val_loss: 1.1199 - val_accuracy: 0.6346\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.6065 - accuracy: 0.9453"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 0s 12ms/step - loss: 0.6394 - accuracy: 0.9315 - val_loss: 1.1154 - val_accuracy: 0.6256\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6270 - accuracy: 0.9380 - val_loss: 1.1087 - val_accuracy: 0.6584\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6192 - accuracy: 0.9372 - val_loss: 1.1031 - val_accuracy: 0.6595\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6077 - accuracy: 0.9477 - val_loss: 1.0954 - val_accuracy: 0.6686\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6050 - accuracy: 0.9448 - val_loss: 1.0909 - val_accuracy: 0.6663\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.9553 - val_loss: 1.0859 - val_accuracy: 0.6618\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5848 - accuracy: 0.9604 - val_loss: 1.0771 - val_accuracy: 0.6708\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5882 - accuracy: 0.9536 - val_loss: 1.0724 - val_accuracy: 0.6663\n","Epoch 10/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5795 - accuracy: 0.9564 - val_loss: 1.0853 - val_accuracy: 0.6346\n","Epoch 11/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5726 - accuracy: 0.9610 - val_loss: 1.0729 - val_accuracy: 0.6606\n","Epoch 12/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5679 - accuracy: 0.9652 - val_loss: 1.0784 - val_accuracy: 0.6516\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5637 - accuracy: 0.9694 - val_loss: 1.0534 - val_accuracy: 0.6799\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5641 - accuracy: 0.9624 - val_loss: 1.0533 - val_accuracy: 0.6697\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5566 - accuracy: 0.9697 - val_loss: 1.0369 - val_accuracy: 0.6844\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5594 - accuracy: 0.9641 - val_loss: 1.0499 - val_accuracy: 0.6799\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5503 - accuracy: 0.9714 - val_loss: 1.0596 - val_accuracy: 0.6810\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5554 - accuracy: 0.9672 - val_loss: 1.0573 - val_accuracy: 0.6934\n","Epoch 19/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5439 - accuracy: 0.9723 - val_loss: 1.0484 - val_accuracy: 0.7002\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5394 - accuracy: 0.9768 - val_loss: 1.0493 - val_accuracy: 0.7104\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5372 - accuracy: 0.9762 - val_loss: 1.0541 - val_accuracy: 0.7138\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5381 - accuracy: 0.9734 - val_loss: 1.0703 - val_accuracy: 0.7172\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5424 - accuracy: 0.9692 - val_loss: 1.0592 - val_accuracy: 0.7206\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5363 - accuracy: 0.9737 - val_loss: 1.0608 - val_accuracy: 0.7319\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5298 - accuracy: 0.9751 - val_loss: 1.0648 - val_accuracy: 0.7466\n","Epoch 26/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5252 - accuracy: 0.9802 - val_loss: 1.0949 - val_accuracy: 0.7387\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5268 - accuracy: 0.9754 - val_loss: 1.0834 - val_accuracy: 0.7410\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.9765 - val_loss: 1.1009 - val_accuracy: 0.7387\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5170 - accuracy: 0.9833 - val_loss: 1.1084 - val_accuracy: 0.7398\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5166 - accuracy: 0.9822 - val_loss: 1.1094 - val_accuracy: 0.7511\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5154 - accuracy: 0.9808 - val_loss: 1.1251 - val_accuracy: 0.7466\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5146 - accuracy: 0.9791 - val_loss: 1.1382 - val_accuracy: 0.7455\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5136 - accuracy: 0.9791 - val_loss: 1.1390 - val_accuracy: 0.7296\n","Epoch 34/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5154 - accuracy: 0.9740 - val_loss: 1.1503 - val_accuracy: 0.7421\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5125 - accuracy: 0.9779 - val_loss: 1.1756 - val_accuracy: 0.7104\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5133 - accuracy: 0.9768 - val_loss: 1.1549 - val_accuracy: 0.7387\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5045 - accuracy: 0.9822 - val_loss: 1.1487 - val_accuracy: 0.7376\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5075 - accuracy: 0.9813 - val_loss: 1.1680 - val_accuracy: 0.7353\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5069 - accuracy: 0.9776 - val_loss: 1.1789 - val_accuracy: 0.7432\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5059 - accuracy: 0.9785 - val_loss: 1.1890 - val_accuracy: 0.7308\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4986 - accuracy: 0.9810 - val_loss: 1.1931 - val_accuracy: 0.7432\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5013 - accuracy: 0.9810 - val_loss: 1.1784 - val_accuracy: 0.7319\n","Epoch 43/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5032 - accuracy: 0.9768 - val_loss: 1.1823 - val_accuracy: 0.7353\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4977 - accuracy: 0.9788 - val_loss: 1.1798 - val_accuracy: 0.7319\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4968 - accuracy: 0.9805 - val_loss: 1.1885 - val_accuracy: 0.7308\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4901 - accuracy: 0.9830 - val_loss: 1.1793 - val_accuracy: 0.7376\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4877 - accuracy: 0.9822 - val_loss: 1.1895 - val_accuracy: 0.7262\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4955 - accuracy: 0.9796 - val_loss: 1.2116 - val_accuracy: 0.7059\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4955 - accuracy: 0.9802 - val_loss: 1.2080 - val_accuracy: 0.7149\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4884 - accuracy: 0.9802 - val_loss: 1.2004 - val_accuracy: 0.7240\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4835 - accuracy: 0.9830 - val_loss: 1.2083 - val_accuracy: 0.7330\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4824 - accuracy: 0.9827 - val_loss: 1.2041 - val_accuracy: 0.7330\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4805 - accuracy: 0.9850 - val_loss: 1.2039 - val_accuracy: 0.7274\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4770 - accuracy: 0.9847 - val_loss: 1.2120 - val_accuracy: 0.7319\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4750 - accuracy: 0.9853 - val_loss: 1.2061 - val_accuracy: 0.7251\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4781 - accuracy: 0.9836 - val_loss: 1.2270 - val_accuracy: 0.7308\n","Epoch 57/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4729 - accuracy: 0.9844 - val_loss: 1.2207 - val_accuracy: 0.7262\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4717 - accuracy: 0.9867 - val_loss: 1.2257 - val_accuracy: 0.7319\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4713 - accuracy: 0.9861 - val_loss: 1.2274 - val_accuracy: 0.7217\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4832 - accuracy: 0.9791 - val_loss: 1.2430 - val_accuracy: 0.7149\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4809 - accuracy: 0.9779 - val_loss: 1.2605 - val_accuracy: 0.7183\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4687 - accuracy: 0.9859 - val_loss: 1.2543 - val_accuracy: 0.7002\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4687 - accuracy: 0.9867 - val_loss: 1.2482 - val_accuracy: 0.7240\n","Epoch 64/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4644 - accuracy: 0.9887 - val_loss: 1.2417 - val_accuracy: 0.7229\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4644 - accuracy: 0.9856 - val_loss: 1.2596 - val_accuracy: 0.7138\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4655 - accuracy: 0.9856 - val_loss: 1.2936 - val_accuracy: 0.7229\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 0.9839 - val_loss: 1.2505 - val_accuracy: 0.7229\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4601 - accuracy: 0.9887 - val_loss: 1.2754 - val_accuracy: 0.7206\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4634 - accuracy: 0.9844 - val_loss: 1.2761 - val_accuracy: 0.7115\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4638 - accuracy: 0.9859 - val_loss: 1.3013 - val_accuracy: 0.6980\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4625 - accuracy: 0.9856 - val_loss: 1.2626 - val_accuracy: 0.7296\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4562 - accuracy: 0.9898 - val_loss: 1.2585 - val_accuracy: 0.7274\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4571 - accuracy: 0.9870 - val_loss: 1.2967 - val_accuracy: 0.7240\n","Epoch 74/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4586 - accuracy: 0.9847 - val_loss: 1.2755 - val_accuracy: 0.7240\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4597 - accuracy: 0.9878 - val_loss: 1.2815 - val_accuracy: 0.7285\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4578 - accuracy: 0.9847 - val_loss: 1.2843 - val_accuracy: 0.7240\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4814 - accuracy: 0.9748 - val_loss: 1.3692 - val_accuracy: 0.7138\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4662 - accuracy: 0.9808 - val_loss: 1.2827 - val_accuracy: 0.7217\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4534 - accuracy: 0.9861 - val_loss: 1.2896 - val_accuracy: 0.7138\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4496 - accuracy: 0.9870 - val_loss: 1.3139 - val_accuracy: 0.7002\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4475 - accuracy: 0.9901 - val_loss: 1.3009 - val_accuracy: 0.7127\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4451 - accuracy: 0.9892 - val_loss: 1.3013 - val_accuracy: 0.7172\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4437 - accuracy: 0.9887 - val_loss: 1.3090 - val_accuracy: 0.7229\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4464 - accuracy: 0.9887 - val_loss: 1.3269 - val_accuracy: 0.7206\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4418 - accuracy: 0.9904 - val_loss: 1.3111 - val_accuracy: 0.7127\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4446 - accuracy: 0.9870 - val_loss: 1.3757 - val_accuracy: 0.7161\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4471 - accuracy: 0.9878 - val_loss: 1.3259 - val_accuracy: 0.7093\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4411 - accuracy: 0.9898 - val_loss: 1.3695 - val_accuracy: 0.6867\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4450 - accuracy: 0.9870 - val_loss: 1.4346 - val_accuracy: 0.7206\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4529 - accuracy: 0.9859 - val_loss: 1.3413 - val_accuracy: 0.7104\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4449 - accuracy: 0.9864 - val_loss: 1.3431 - val_accuracy: 0.6980\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4422 - accuracy: 0.9873 - val_loss: 1.4262 - val_accuracy: 0.7172\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4430 - accuracy: 0.9842 - val_loss: 1.4156 - val_accuracy: 0.6867\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4460 - accuracy: 0.9853 - val_loss: 1.3896 - val_accuracy: 0.7138\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4349 - accuracy: 0.9898 - val_loss: 1.3551 - val_accuracy: 0.7183\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4411 - accuracy: 0.9864 - val_loss: 1.3481 - val_accuracy: 0.7127\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4388 - accuracy: 0.9861 - val_loss: 1.3590 - val_accuracy: 0.6991\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4353 - accuracy: 0.9887 - val_loss: 1.3454 - val_accuracy: 0.7172\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4337 - accuracy: 0.9890 - val_loss: 1.4505 - val_accuracy: 0.7183\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4366 - accuracy: 0.9892 - val_loss: 1.4441 - val_accuracy: 0.7229\n","{'loss': [0.6721198558807373, 0.6394317150115967, 0.627028226852417, 0.6192104816436768, 0.6077012419700623, 0.6050052642822266, 0.5928230881690979, 0.5847983360290527, 0.5881500840187073, 0.5794597268104553, 0.5725628733634949, 0.5679337978363037, 0.5637326836585999, 0.564140260219574, 0.5566210150718689, 0.5594452619552612, 0.5502870082855225, 0.555429995059967, 0.5439439415931702, 0.539416491985321, 0.5371645092964172, 0.538125216960907, 0.5424386262893677, 0.5362776517868042, 0.5297610759735107, 0.5252256989479065, 0.5267762541770935, 0.5243219137191772, 0.517006516456604, 0.5165709853172302, 0.5154300928115845, 0.514596700668335, 0.5135654807090759, 0.5154114961624146, 0.5124760866165161, 0.5133216977119446, 0.5044560432434082, 0.5075355172157288, 0.5069375038146973, 0.505929708480835, 0.49861279129981995, 0.5013267397880554, 0.503234326839447, 0.49766111373901367, 0.4967805743217468, 0.4900522828102112, 0.4877190589904785, 0.49554339051246643, 0.49554139375686646, 0.4883796274662018, 0.4835144877433777, 0.48240989446640015, 0.48046013712882996, 0.47696802020072937, 0.47501257061958313, 0.4781471788883209, 0.4728907644748688, 0.4717102348804474, 0.47129303216934204, 0.4831858277320862, 0.480946809053421, 0.46866172552108765, 0.4687056541442871, 0.4643675982952118, 0.4644347131252289, 0.46553167700767517, 0.4672742187976837, 0.46005716919898987, 0.4633926451206207, 0.46383678913116455, 0.4625224471092224, 0.4562045931816101, 0.45706164836883545, 0.4585514962673187, 0.45974594354629517, 0.4578147530555725, 0.481401264667511, 0.46624627709388733, 0.4533829689025879, 0.44957277178764343, 0.4474889934062958, 0.44512057304382324, 0.4437146484851837, 0.44635236263275146, 0.44182923436164856, 0.44462156295776367, 0.4471190273761749, 0.4411460757255554, 0.4449943006038666, 0.4528504014015198, 0.4448640048503876, 0.4422394335269928, 0.4429781436920166, 0.44602760672569275, 0.4349169433116913, 0.4410610795021057, 0.4388491213321686, 0.43531134724617004, 0.43370363116264343, 0.43656933307647705], 'accuracy': [0.9100169539451599, 0.9315223693847656, 0.9380305409431458, 0.9371816515922546, 0.9476513862609863, 0.9448217153549194, 0.9552914500236511, 0.9603848457336426, 0.9535936713218689, 0.9564233422279358, 0.9609507918357849, 0.9651952385902405, 0.9694397449493408, 0.9623655676841736, 0.9697226881980896, 0.9640634059906006, 0.9714204668998718, 0.9671760201454163, 0.9722693562507629, 0.9767968058586121, 0.9762309193611145, 0.9734012484550476, 0.9691567420959473, 0.9736841917037964, 0.9750990271568298, 0.9801924228668213, 0.9753820300102234, 0.9765138626098633, 0.983305037021637, 0.9821732044219971, 0.9807583689689636, 0.9790605306625366, 0.9790605306625366, 0.9739671945571899, 0.9779286980628967, 0.9767968058586121, 0.9821732044219971, 0.9813242554664612, 0.977645754814148, 0.9784946441650391, 0.9810413122177124, 0.9810413122177124, 0.9767968058586121, 0.9787775874137878, 0.9804753661155701, 0.9830220937728882, 0.9821732044219971, 0.979626476764679, 0.9801924228668213, 0.9801924228668213, 0.9830220937728882, 0.9827390909194946, 0.9850028157234192, 0.9847198724746704, 0.9852858185768127, 0.9835879802703857, 0.9844368696212769, 0.9867005944252014, 0.9861347079277039, 0.9790605306625366, 0.9779286980628967, 0.9858517050743103, 0.9867005944252014, 0.9886813759803772, 0.9855687618255615, 0.9855687618255615, 0.9838709831237793, 0.9886813759803772, 0.9844368696212769, 0.9858517050743103, 0.9855687618255615, 0.9898132681846619, 0.986983597278595, 0.9847198724746704, 0.9878324866294861, 0.9847198724746704, 0.974816083908081, 0.9807583689689636, 0.9861347079277039, 0.986983597278595, 0.9900962114334106, 0.9892473220825195, 0.9886813759803772, 0.9886813759803772, 0.9903791546821594, 0.986983597278595, 0.9878324866294861, 0.9898132681846619, 0.986983597278595, 0.9858517050743103, 0.9864176511764526, 0.9872665405273438, 0.9841539263725281, 0.9852858185768127, 0.9898132681846619, 0.9864176511764526, 0.9861347079277039, 0.9886813759803772, 0.988964319229126, 0.9892473220825195], 'val_loss': [1.119933009147644, 1.1153630018234253, 1.1087158918380737, 1.1031384468078613, 1.0954222679138184, 1.0908739566802979, 1.0859423875808716, 1.0771478414535522, 1.0724488496780396, 1.085296392440796, 1.0729209184646606, 1.078433632850647, 1.0534024238586426, 1.0532859563827515, 1.0369194746017456, 1.0498871803283691, 1.0595873594284058, 1.0572865009307861, 1.048407793045044, 1.0492773056030273, 1.0541118383407593, 1.0702602863311768, 1.0591580867767334, 1.0608311891555786, 1.0647928714752197, 1.094947338104248, 1.0833656787872314, 1.10088050365448, 1.1083606481552124, 1.1093707084655762, 1.12514328956604, 1.1382055282592773, 1.1390048265457153, 1.1503260135650635, 1.175607681274414, 1.154866337776184, 1.1486790180206299, 1.1679527759552002, 1.1788651943206787, 1.1889793872833252, 1.193100094795227, 1.1784170866012573, 1.1823455095291138, 1.1798025369644165, 1.1885207891464233, 1.179322361946106, 1.1895054578781128, 1.2115893363952637, 1.2080116271972656, 1.2004456520080566, 1.2083171606063843, 1.2040824890136719, 1.2039008140563965, 1.2120169401168823, 1.2060624361038208, 1.2269508838653564, 1.2206593751907349, 1.2256754636764526, 1.2274070978164673, 1.2429646253585815, 1.2605178356170654, 1.254289984703064, 1.248186469078064, 1.241706371307373, 1.2596131563186646, 1.2936158180236816, 1.2504844665527344, 1.2754334211349487, 1.2760826349258423, 1.30134916305542, 1.2625515460968018, 1.2585358619689941, 1.2966901063919067, 1.2754955291748047, 1.2814913988113403, 1.2842711210250854, 1.369194507598877, 1.282718300819397, 1.2896448373794556, 1.3138818740844727, 1.3008840084075928, 1.301262378692627, 1.3090018033981323, 1.3269273042678833, 1.3110830783843994, 1.3757044076919556, 1.3258622884750366, 1.3694804906845093, 1.434552788734436, 1.341314673423767, 1.343053936958313, 1.4262382984161377, 1.4155926704406738, 1.3896483182907104, 1.355072021484375, 1.3480677604675293, 1.3590010404586792, 1.345350980758667, 1.450453519821167, 1.4441391229629517], 'val_accuracy': [0.6346153616905212, 0.6255655884742737, 0.6583710312843323, 0.6595022678375244, 0.668552041053772, 0.6662895679473877, 0.6617646813392639, 0.6708144545555115, 0.6662895679473877, 0.6346153616905212, 0.6606335043907166, 0.651583731174469, 0.679864227771759, 0.6696832776069641, 0.6843891143798828, 0.679864227771759, 0.6809954643249512, 0.6934388875961304, 0.7002262473106384, 0.7104072570800781, 0.7138009071350098, 0.7171945571899414, 0.720588207244873, 0.7319004535675049, 0.7466063499450684, 0.7386877536773682, 0.7409502267837524, 0.7386877536773682, 0.7398189902305603, 0.7511312365531921, 0.7466063499450684, 0.7454751133918762, 0.7296379804611206, 0.7420814633369446, 0.7104072570800781, 0.7386877536773682, 0.7375565767288208, 0.7352941036224365, 0.7432126402854919, 0.7307692170143127, 0.7432126402854919, 0.7319004535675049, 0.7352941036224365, 0.7319004535675049, 0.7307692170143127, 0.7375565767288208, 0.726244330406189, 0.7058823704719543, 0.7149321436882019, 0.7239819169044495, 0.733031690120697, 0.733031690120697, 0.7273755669593811, 0.7319004535675049, 0.7251130938529968, 0.7307692170143127, 0.726244330406189, 0.7319004535675049, 0.7217194437980652, 0.7149321436882019, 0.7183257937431335, 0.7002262473106384, 0.7239819169044495, 0.7228506803512573, 0.7138009071350098, 0.7228506803512573, 0.7228506803512573, 0.720588207244873, 0.7115384340286255, 0.6979637742042542, 0.7296379804611206, 0.7273755669593811, 0.7239819169044495, 0.7239819169044495, 0.7285068035125732, 0.7239819169044495, 0.7138009071350098, 0.7217194437980652, 0.7138009071350098, 0.7002262473106384, 0.7126696705818176, 0.7171945571899414, 0.7228506803512573, 0.720588207244873, 0.7126696705818176, 0.7160633206367493, 0.709276020526886, 0.6866515874862671, 0.720588207244873, 0.7104072570800781, 0.6979637742042542, 0.7171945571899414, 0.6866515874862671, 0.7138009071350098, 0.7183257937431335, 0.7126696705818176, 0.6990950107574463, 0.7171945571899414, 0.7183257937431335, 0.7228506803512573]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 29ms/step - loss: 0.7117 - accuracy: 0.8972 - val_loss: 1.1236 - val_accuracy: 0.5795\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.6701 - accuracy: 0.8984"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 18ms/step - loss: 0.6702 - accuracy: 0.9041 - val_loss: 1.1169 - val_accuracy: 0.6116\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6440 - accuracy: 0.9248 - val_loss: 1.1112 - val_accuracy: 0.6209\n","Epoch 4/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6357 - accuracy: 0.9310 - val_loss: 1.1077 - val_accuracy: 0.6105\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6346 - accuracy: 0.9336 - val_loss: 1.1037 - val_accuracy: 0.6178\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6258 - accuracy: 0.9362 - val_loss: 1.0958 - val_accuracy: 0.6157\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6123 - accuracy: 0.9437 - val_loss: 1.0900 - val_accuracy: 0.6198\n","Epoch 8/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6037 - accuracy: 0.9483 - val_loss: 1.1017 - val_accuracy: 0.6012\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6023 - accuracy: 0.9509 - val_loss: 1.0775 - val_accuracy: 0.6240\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6040 - accuracy: 0.9475 - val_loss: 1.0759 - val_accuracy: 0.6260\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5942 - accuracy: 0.9532 - val_loss: 1.0916 - val_accuracy: 0.6157\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5845 - accuracy: 0.9579 - val_loss: 1.1004 - val_accuracy: 0.6126\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5901 - accuracy: 0.9532 - val_loss: 1.0871 - val_accuracy: 0.6281\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5765 - accuracy: 0.9599 - val_loss: 1.0635 - val_accuracy: 0.6529\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5784 - accuracy: 0.9579 - val_loss: 1.0677 - val_accuracy: 0.6591\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5702 - accuracy: 0.9597 - val_loss: 1.0821 - val_accuracy: 0.6570\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5706 - accuracy: 0.9618 - val_loss: 1.1003 - val_accuracy: 0.6622\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5633 - accuracy: 0.9643 - val_loss: 1.1208 - val_accuracy: 0.6622\n","Epoch 19/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5695 - accuracy: 0.9550 - val_loss: 1.0576 - val_accuracy: 0.7087\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5672 - accuracy: 0.9587 - val_loss: 1.0596 - val_accuracy: 0.7159\n","Epoch 21/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5604 - accuracy: 0.9620 - val_loss: 1.0840 - val_accuracy: 0.7138\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5536 - accuracy: 0.9674 - val_loss: 1.0829 - val_accuracy: 0.7314\n","Epoch 23/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5519 - accuracy: 0.9682 - val_loss: 1.0963 - val_accuracy: 0.7273\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5485 - accuracy: 0.9690 - val_loss: 1.0892 - val_accuracy: 0.7293\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5512 - accuracy: 0.9643 - val_loss: 1.1097 - val_accuracy: 0.7283\n","Epoch 26/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5504 - accuracy: 0.9646 - val_loss: 1.1526 - val_accuracy: 0.7180\n","Epoch 27/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5465 - accuracy: 0.9641 - val_loss: 1.1355 - val_accuracy: 0.7252\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5430 - accuracy: 0.9672 - val_loss: 1.2058 - val_accuracy: 0.7087\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5569 - accuracy: 0.9556 - val_loss: 1.1824 - val_accuracy: 0.7180\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5451 - accuracy: 0.9646 - val_loss: 1.1424 - val_accuracy: 0.7283\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5428 - accuracy: 0.9638 - val_loss: 1.1503 - val_accuracy: 0.7304\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5314 - accuracy: 0.9698 - val_loss: 1.1883 - val_accuracy: 0.7066\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5319 - accuracy: 0.9721 - val_loss: 1.1552 - val_accuracy: 0.7262\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5271 - accuracy: 0.9713 - val_loss: 1.1758 - val_accuracy: 0.7190\n","Epoch 35/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5280 - accuracy: 0.9744 - val_loss: 1.1697 - val_accuracy: 0.7200\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5261 - accuracy: 0.9680 - val_loss: 1.3366 - val_accuracy: 0.6767\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5323 - accuracy: 0.9649 - val_loss: 1.2320 - val_accuracy: 0.7138\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5432 - accuracy: 0.9599 - val_loss: 1.2975 - val_accuracy: 0.6952\n","Epoch 39/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5353 - accuracy: 0.9625 - val_loss: 1.1931 - val_accuracy: 0.7242\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5137 - accuracy: 0.9770 - val_loss: 1.2010 - val_accuracy: 0.7242\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5113 - accuracy: 0.9767 - val_loss: 1.2074 - val_accuracy: 0.7304\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.9752 - val_loss: 1.2029 - val_accuracy: 0.7252\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5101 - accuracy: 0.9755 - val_loss: 1.2000 - val_accuracy: 0.7211\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5095 - accuracy: 0.9757 - val_loss: 1.2173 - val_accuracy: 0.7242\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5049 - accuracy: 0.9749 - val_loss: 1.2086 - val_accuracy: 0.7200\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5050 - accuracy: 0.9744 - val_loss: 1.2173 - val_accuracy: 0.7211\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5071 - accuracy: 0.9726 - val_loss: 1.2203 - val_accuracy: 0.7200\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5040 - accuracy: 0.9760 - val_loss: 1.2136 - val_accuracy: 0.7231\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4993 - accuracy: 0.9791 - val_loss: 1.2242 - val_accuracy: 0.7273\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5016 - accuracy: 0.9760 - val_loss: 1.2527 - val_accuracy: 0.7221\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4965 - accuracy: 0.9809 - val_loss: 1.2346 - val_accuracy: 0.7211\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4962 - accuracy: 0.9796 - val_loss: 1.2509 - val_accuracy: 0.7190\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4960 - accuracy: 0.9786 - val_loss: 1.2675 - val_accuracy: 0.7097\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5013 - accuracy: 0.9729 - val_loss: 1.2364 - val_accuracy: 0.7221\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4959 - accuracy: 0.9770 - val_loss: 1.2560 - val_accuracy: 0.7138\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4952 - accuracy: 0.9760 - val_loss: 1.2758 - val_accuracy: 0.7211\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4880 - accuracy: 0.9822 - val_loss: 1.2538 - val_accuracy: 0.7190\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5043 - accuracy: 0.9695 - val_loss: 1.2460 - val_accuracy: 0.7180\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4877 - accuracy: 0.9793 - val_loss: 1.2527 - val_accuracy: 0.7180\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4915 - accuracy: 0.9757 - val_loss: 1.2558 - val_accuracy: 0.7159\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4858 - accuracy: 0.9801 - val_loss: 1.2820 - val_accuracy: 0.7149\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4938 - accuracy: 0.9731 - val_loss: 1.2891 - val_accuracy: 0.7159\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4858 - accuracy: 0.9755 - val_loss: 1.2691 - val_accuracy: 0.7190\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4809 - accuracy: 0.9796 - val_loss: 1.2703 - val_accuracy: 0.7200\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4798 - accuracy: 0.9814 - val_loss: 1.2647 - val_accuracy: 0.7149\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4775 - accuracy: 0.9819 - val_loss: 1.2832 - val_accuracy: 0.7180\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4763 - accuracy: 0.9853 - val_loss: 1.2905 - val_accuracy: 0.7107\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4862 - accuracy: 0.9736 - val_loss: 1.2849 - val_accuracy: 0.7159\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4963 - accuracy: 0.9687 - val_loss: 1.2920 - val_accuracy: 0.7200\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4721 - accuracy: 0.9811 - val_loss: 1.3069 - val_accuracy: 0.7097\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4787 - accuracy: 0.9778 - val_loss: 1.3036 - val_accuracy: 0.7128\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4693 - accuracy: 0.9824 - val_loss: 1.3542 - val_accuracy: 0.7035\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4786 - accuracy: 0.9736 - val_loss: 1.2993 - val_accuracy: 0.7200\n","Epoch 74/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4784 - accuracy: 0.9742 - val_loss: 1.3431 - val_accuracy: 0.7076\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4685 - accuracy: 0.9814 - val_loss: 1.3424 - val_accuracy: 0.7097\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4724 - accuracy: 0.9793 - val_loss: 1.3053 - val_accuracy: 0.7190\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4655 - accuracy: 0.9817 - val_loss: 1.3438 - val_accuracy: 0.7097\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4714 - accuracy: 0.9780 - val_loss: 1.4071 - val_accuracy: 0.7014\n","Epoch 79/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4710 - accuracy: 0.9796 - val_loss: 1.3087 - val_accuracy: 0.7180\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4600 - accuracy: 0.9848 - val_loss: 1.3435 - val_accuracy: 0.7118\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4643 - accuracy: 0.9811 - val_loss: 1.3467 - val_accuracy: 0.7087\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4680 - accuracy: 0.9791 - val_loss: 1.3784 - val_accuracy: 0.7025\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4623 - accuracy: 0.9842 - val_loss: 1.3348 - val_accuracy: 0.7149\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4592 - accuracy: 0.9832 - val_loss: 1.3980 - val_accuracy: 0.6973\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4682 - accuracy: 0.9791 - val_loss: 1.4042 - val_accuracy: 0.6973\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4577 - accuracy: 0.9842 - val_loss: 1.3374 - val_accuracy: 0.7149\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4588 - accuracy: 0.9814 - val_loss: 1.4206 - val_accuracy: 0.7035\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4569 - accuracy: 0.9837 - val_loss: 1.3519 - val_accuracy: 0.7221\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4551 - accuracy: 0.9835 - val_loss: 1.3656 - val_accuracy: 0.7056\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4518 - accuracy: 0.9863 - val_loss: 1.3559 - val_accuracy: 0.7169\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4545 - accuracy: 0.9819 - val_loss: 1.3620 - val_accuracy: 0.7076\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4520 - accuracy: 0.9837 - val_loss: 1.3693 - val_accuracy: 0.7118\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4507 - accuracy: 0.9842 - val_loss: 1.4606 - val_accuracy: 0.6973\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.9713 - val_loss: 1.3658 - val_accuracy: 0.7200\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4483 - accuracy: 0.9858 - val_loss: 1.4196 - val_accuracy: 0.6973\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4668 - accuracy: 0.9734 - val_loss: 1.3744 - val_accuracy: 0.7138\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.9762 - val_loss: 1.3713 - val_accuracy: 0.7159\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4582 - accuracy: 0.9757 - val_loss: 1.4005 - val_accuracy: 0.7025\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4493 - accuracy: 0.9801 - val_loss: 1.4178 - val_accuracy: 0.7014\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4435 - accuracy: 0.9897 - val_loss: 1.3902 - val_accuracy: 0.7076\n","{'loss': [0.7116541862487793, 0.6701658368110657, 0.6440297961235046, 0.6357059478759766, 0.6345629692077637, 0.6258034110069275, 0.6123074889183044, 0.6036956310272217, 0.6022958159446716, 0.6039647459983826, 0.5941916704177856, 0.5844553709030151, 0.5901440382003784, 0.5765054225921631, 0.5783985257148743, 0.5702195167541504, 0.5706165432929993, 0.5633497834205627, 0.5695469975471497, 0.5671665072441101, 0.5603640675544739, 0.5535985231399536, 0.5518723130226135, 0.5485422015190125, 0.5512464046478271, 0.5504449009895325, 0.5465465784072876, 0.5429942607879639, 0.5568663477897644, 0.5451167821884155, 0.5427995920181274, 0.5313729047775269, 0.5319004058837891, 0.5270617604255676, 0.5280079245567322, 0.5261254906654358, 0.5323172807693481, 0.5431774258613586, 0.535331666469574, 0.5136843919754028, 0.5112782120704651, 0.5148609280586243, 0.5100914239883423, 0.5095251202583313, 0.5048578977584839, 0.5050157904624939, 0.5071142911911011, 0.5040309429168701, 0.4992757737636566, 0.5015705227851868, 0.49647584557533264, 0.4961652159690857, 0.49603986740112305, 0.5013415217399597, 0.49589234590530396, 0.49519890546798706, 0.48800814151763916, 0.5043463110923767, 0.48774972558021545, 0.4915286898612976, 0.48577621579170227, 0.49380165338516235, 0.48575007915496826, 0.4808902442455292, 0.4798359274864197, 0.4774572551250458, 0.47629299759864807, 0.4861806333065033, 0.49634116888046265, 0.47212210297584534, 0.47874191403388977, 0.4692508280277252, 0.4786328971385956, 0.478428453207016, 0.4684740900993347, 0.4723838269710541, 0.4655243158340454, 0.4713706970214844, 0.4710179567337036, 0.46003133058547974, 0.46426424384117126, 0.46801885962486267, 0.46233969926834106, 0.459240198135376, 0.4681963622570038, 0.45766958594322205, 0.45881086587905884, 0.4569390118122101, 0.4551316499710083, 0.45182862877845764, 0.4545131325721741, 0.45203515887260437, 0.4506523311138153, 0.46738895773887634, 0.44825243949890137, 0.4668160080909729, 0.46741440892219543, 0.4582207500934601, 0.4493233263492584, 0.4434739053249359], 'accuracy': [0.897157609462738, 0.9041343927383423, 0.9248061776161194, 0.9310077428817749, 0.9335917234420776, 0.9361757040023804, 0.9436692595481873, 0.9483203887939453, 0.950904369354248, 0.9475452303886414, 0.9532299637794495, 0.9578811526298523, 0.9532299637794495, 0.9599483013153076, 0.9578811526298523, 0.9596899151802063, 0.9617571234703064, 0.9643411040306091, 0.9550387859344482, 0.9586563110351562, 0.9620155096054077, 0.9674418568611145, 0.9682170748710632, 0.9689922332763672, 0.9643411040306091, 0.9645994901657104, 0.964082658290863, 0.9671834707260132, 0.9555555582046509, 0.9645994901657104, 0.9638242721557617, 0.9697674512863159, 0.9720930457115173, 0.9713178277015686, 0.974418580532074, 0.9679586291313171, 0.9648578763008118, 0.9599483013153076, 0.9625322818756104, 0.9770025610923767, 0.9767441749572754, 0.9751937985420227, 0.975452184677124, 0.9757105708122253, 0.9749354124069214, 0.974418580532074, 0.97260981798172, 0.9759690165519714, 0.9790697693824768, 0.9759690165519714, 0.9808785319328308, 0.9795865416526794, 0.9785529971122742, 0.9728682041168213, 0.9770025610923767, 0.9759690165519714, 0.9821705222129822, 0.9695090651512146, 0.9793281555175781, 0.9757105708122253, 0.9801033735275269, 0.9731265902519226, 0.975452184677124, 0.9795865416526794, 0.9813953638076782, 0.9819121360778809, 0.9852713346481323, 0.97364342212677, 0.9687338471412659, 0.9811369776725769, 0.9777777791023254, 0.9824289679527283, 0.97364342212677, 0.9741601943969727, 0.9813953638076782, 0.9793281555175781, 0.9816537499427795, 0.9780361652374268, 0.9795865416526794, 0.9847545027732849, 0.9811369776725769, 0.9790697693824768, 0.9842377305030823, 0.9832041263580322, 0.9790697693824768, 0.9842377305030823, 0.9813953638076782, 0.9837209582328796, 0.9834625124931335, 0.9863049387931824, 0.9819121360778809, 0.9837209582328796, 0.9842377305030823, 0.9713178277015686, 0.985788106918335, 0.9733850359916687, 0.9762274026870728, 0.9757105708122253, 0.9801033735275269, 0.9896640777587891], 'val_loss': [1.123556137084961, 1.1169447898864746, 1.111236810684204, 1.1077011823654175, 1.1036767959594727, 1.0958319902420044, 1.0899540185928345, 1.1017309427261353, 1.0775177478790283, 1.0759161710739136, 1.091628074645996, 1.1004350185394287, 1.0870592594146729, 1.063502311706543, 1.067721962928772, 1.0820807218551636, 1.1003127098083496, 1.120832085609436, 1.0575658082962036, 1.0596137046813965, 1.0839526653289795, 1.0828863382339478, 1.096305251121521, 1.0892359018325806, 1.1097208261489868, 1.1525822877883911, 1.1354917287826538, 1.2058186531066895, 1.182360291481018, 1.1423687934875488, 1.1503068208694458, 1.1882997751235962, 1.1551740169525146, 1.175784945487976, 1.169651746749878, 1.3366492986679077, 1.231967806816101, 1.2975255250930786, 1.193120002746582, 1.2009648084640503, 1.2073947191238403, 1.2028672695159912, 1.2000194787979126, 1.2172563076019287, 1.208580732345581, 1.2173289060592651, 1.2203264236450195, 1.2136046886444092, 1.2241753339767456, 1.2527470588684082, 1.2346171140670776, 1.2509409189224243, 1.2674776315689087, 1.2364490032196045, 1.2559599876403809, 1.2757893800735474, 1.253839373588562, 1.2459512948989868, 1.252744197845459, 1.2557851076126099, 1.2819863557815552, 1.2891191244125366, 1.269067406654358, 1.2703384160995483, 1.2646578550338745, 1.2832257747650146, 1.2905269861221313, 1.2849398851394653, 1.2920337915420532, 1.3068925142288208, 1.3036223649978638, 1.3541874885559082, 1.2992591857910156, 1.3431119918823242, 1.3423607349395752, 1.3053127527236938, 1.3438397645950317, 1.4070665836334229, 1.3086901903152466, 1.3435250520706177, 1.3467093706130981, 1.378432273864746, 1.3348021507263184, 1.3980443477630615, 1.404184341430664, 1.3374043703079224, 1.420567512512207, 1.3518751859664917, 1.3655669689178467, 1.355868935585022, 1.361953854560852, 1.369310975074768, 1.460567831993103, 1.3658243417739868, 1.4196224212646484, 1.374355435371399, 1.3712719678878784, 1.400451898574829, 1.4178234338760376, 1.390245795249939], 'val_accuracy': [0.5795454382896423, 0.6115702390670776, 0.6208677887916565, 0.6105371713638306, 0.6177685856819153, 0.6157024502754211, 0.6198347210884094, 0.6012396812438965, 0.6239669322967529, 0.6260330677032471, 0.6157024502754211, 0.6126033067703247, 0.6280992031097412, 0.6528925895690918, 0.6590909361839294, 0.6570248007774353, 0.6621900796890259, 0.6621900796890259, 0.7086777091026306, 0.7159090638160706, 0.7138429880142212, 0.7314049601554871, 0.7272727489471436, 0.7293388247489929, 0.7283057570457458, 0.7179751992225647, 0.7252066135406494, 0.7086777091026306, 0.7179751992225647, 0.7283057570457458, 0.73037189245224, 0.7066115736961365, 0.7262396812438965, 0.7190082669258118, 0.7200413346290588, 0.6766529083251953, 0.7138429880142212, 0.6952479481697083, 0.7241735458374023, 0.7241735458374023, 0.73037189245224, 0.7252066135406494, 0.7210744023323059, 0.7241735458374023, 0.7200413346290588, 0.7210744023323059, 0.7200413346290588, 0.7231404781341553, 0.7272727489471436, 0.7221074104309082, 0.7210744023323059, 0.7190082669258118, 0.7097107172012329, 0.7221074104309082, 0.7138429880142212, 0.7210744023323059, 0.7190082669258118, 0.7179751992225647, 0.7179751992225647, 0.7159090638160706, 0.7148760557174683, 0.7159090638160706, 0.7190082669258118, 0.7200413346290588, 0.7148760557174683, 0.7179751992225647, 0.71074378490448, 0.7159090638160706, 0.7200413346290588, 0.7097107172012329, 0.7128099203109741, 0.7035123705863953, 0.7200413346290588, 0.7076446413993835, 0.7097107172012329, 0.7190082669258118, 0.7097107172012329, 0.7014462947845459, 0.7179751992225647, 0.711776852607727, 0.7086777091026306, 0.702479362487793, 0.7148760557174683, 0.6973140239715576, 0.6973140239715576, 0.7148760557174683, 0.7035123705863953, 0.7221074104309082, 0.7055785059928894, 0.7169421315193176, 0.7076446413993835, 0.711776852607727, 0.6973140239715576, 0.7200413346290588, 0.6973140239715576, 0.7138429880142212, 0.7159090638160706, 0.702479362487793, 0.7014462947845459, 0.7076446413993835]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 27ms/step - loss: 0.5450 - accuracy: 0.9380 - val_loss: 1.0546 - val_accuracy: 0.6078\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.5330 - accuracy: 0.9219"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 16ms/step - loss: 0.4945 - accuracy: 0.9634 - val_loss: 1.0456 - val_accuracy: 0.6336\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4705 - accuracy: 0.9752 - val_loss: 1.0356 - val_accuracy: 0.6476\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4647 - accuracy: 0.9790 - val_loss: 1.0283 - val_accuracy: 0.6519\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4601 - accuracy: 0.9822 - val_loss: 1.0196 - val_accuracy: 0.6552\n","Epoch 6/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4663 - accuracy: 0.9741 - val_loss: 1.0272 - val_accuracy: 0.6358\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4683 - accuracy: 0.9760 - val_loss: 1.0118 - val_accuracy: 0.6638\n","Epoch 8/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4524 - accuracy: 0.9836 - val_loss: 0.9949 - val_accuracy: 0.6821\n","Epoch 9/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.9844 - val_loss: 0.9950 - val_accuracy: 0.6767\n","Epoch 10/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4487 - accuracy: 0.9838 - val_loss: 0.9911 - val_accuracy: 0.6756\n","Epoch 11/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4477 - accuracy: 0.9873 - val_loss: 0.9861 - val_accuracy: 0.6756\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4518 - accuracy: 0.9828 - val_loss: 1.0161 - val_accuracy: 0.6606\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4445 - accuracy: 0.9879 - val_loss: 0.9717 - val_accuracy: 0.6940\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4413 - accuracy: 0.9881 - val_loss: 1.0161 - val_accuracy: 0.6778\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4569 - accuracy: 0.9771 - val_loss: 0.9702 - val_accuracy: 0.7026\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4403 - accuracy: 0.9873 - val_loss: 0.9807 - val_accuracy: 0.7091\n","Epoch 17/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4423 - accuracy: 0.9900 - val_loss: 1.0760 - val_accuracy: 0.6843\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4417 - accuracy: 0.9852 - val_loss: 0.9898 - val_accuracy: 0.7123\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4365 - accuracy: 0.9881 - val_loss: 0.9896 - val_accuracy: 0.7274\n","Epoch 20/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4391 - accuracy: 0.9852 - val_loss: 0.9955 - val_accuracy: 0.7328\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4337 - accuracy: 0.9903 - val_loss: 0.9752 - val_accuracy: 0.7511\n","Epoch 22/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4480 - accuracy: 0.9814 - val_loss: 1.0653 - val_accuracy: 0.7414\n","Epoch 23/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4375 - accuracy: 0.9868 - val_loss: 0.9871 - val_accuracy: 0.7726\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4386 - accuracy: 0.9865 - val_loss: 0.9911 - val_accuracy: 0.7716\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4457 - accuracy: 0.9798 - val_loss: 1.0375 - val_accuracy: 0.7866\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4354 - accuracy: 0.9841 - val_loss: 1.0210 - val_accuracy: 0.7909\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4336 - accuracy: 0.9868 - val_loss: 1.0341 - val_accuracy: 0.7812\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4281 - accuracy: 0.9890 - val_loss: 1.0076 - val_accuracy: 0.7909\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4289 - accuracy: 0.9881 - val_loss: 1.0290 - val_accuracy: 0.7888\n","Epoch 30/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4253 - accuracy: 0.9919 - val_loss: 1.0215 - val_accuracy: 0.7931\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4229 - accuracy: 0.9922 - val_loss: 1.0352 - val_accuracy: 0.7866\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4263 - accuracy: 0.9892 - val_loss: 1.0936 - val_accuracy: 0.7845\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4371 - accuracy: 0.9825 - val_loss: 1.0770 - val_accuracy: 0.7780\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.9884 - val_loss: 1.0395 - val_accuracy: 0.7920\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4214 - accuracy: 0.9908 - val_loss: 1.0486 - val_accuracy: 0.7856\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4226 - accuracy: 0.9914 - val_loss: 1.0732 - val_accuracy: 0.7759\n","Epoch 37/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4229 - accuracy: 0.9906 - val_loss: 1.1034 - val_accuracy: 0.7694\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4220 - accuracy: 0.9884 - val_loss: 1.0780 - val_accuracy: 0.7780\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4204 - accuracy: 0.9892 - val_loss: 1.0643 - val_accuracy: 0.7802\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4153 - accuracy: 0.9927 - val_loss: 1.1309 - val_accuracy: 0.7662\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4174 - accuracy: 0.9911 - val_loss: 1.0811 - val_accuracy: 0.7856\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4187 - accuracy: 0.9911 - val_loss: 1.1377 - val_accuracy: 0.7619\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4354 - accuracy: 0.9806 - val_loss: 1.2640 - val_accuracy: 0.7500\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4254 - accuracy: 0.9860 - val_loss: 1.1058 - val_accuracy: 0.7812\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4158 - accuracy: 0.9900 - val_loss: 1.0901 - val_accuracy: 0.7748\n","Epoch 46/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.9860 - val_loss: 1.1468 - val_accuracy: 0.7629\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4155 - accuracy: 0.9890 - val_loss: 1.1330 - val_accuracy: 0.7651\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4108 - accuracy: 0.9919 - val_loss: 1.0966 - val_accuracy: 0.7802\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4124 - accuracy: 0.9906 - val_loss: 1.1554 - val_accuracy: 0.7791\n","Epoch 50/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4156 - accuracy: 0.9898 - val_loss: 1.1317 - val_accuracy: 0.7834\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4091 - accuracy: 0.9933 - val_loss: 1.1208 - val_accuracy: 0.7683\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4138 - accuracy: 0.9916 - val_loss: 1.1421 - val_accuracy: 0.7716\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4078 - accuracy: 0.9925 - val_loss: 1.1267 - val_accuracy: 0.7694\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4106 - accuracy: 0.9898 - val_loss: 1.2003 - val_accuracy: 0.7662\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.9900 - val_loss: 1.1672 - val_accuracy: 0.7619\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.9933 - val_loss: 1.1583 - val_accuracy: 0.7705\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4065 - accuracy: 0.9935 - val_loss: 1.1191 - val_accuracy: 0.7812\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4027 - accuracy: 0.9943 - val_loss: 1.1461 - val_accuracy: 0.7769\n","Epoch 59/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4078 - accuracy: 0.9906 - val_loss: 1.1522 - val_accuracy: 0.7640\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4020 - accuracy: 0.9925 - val_loss: 1.1230 - val_accuracy: 0.7769\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4035 - accuracy: 0.9927 - val_loss: 1.1308 - val_accuracy: 0.7759\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4078 - accuracy: 0.9898 - val_loss: 1.1654 - val_accuracy: 0.7780\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4020 - accuracy: 0.9919 - val_loss: 1.2014 - val_accuracy: 0.7629\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4067 - accuracy: 0.9887 - val_loss: 1.1421 - val_accuracy: 0.7716\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.9898 - val_loss: 1.1678 - val_accuracy: 0.7629\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.9930 - val_loss: 1.1495 - val_accuracy: 0.7694\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4062 - accuracy: 0.9881 - val_loss: 1.1927 - val_accuracy: 0.7543\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3977 - accuracy: 0.9935 - val_loss: 1.1412 - val_accuracy: 0.7726\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4041 - accuracy: 0.9900 - val_loss: 1.2051 - val_accuracy: 0.7694\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4063 - accuracy: 0.9892 - val_loss: 1.1770 - val_accuracy: 0.7608\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3965 - accuracy: 0.9930 - val_loss: 1.1533 - val_accuracy: 0.7726\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3987 - accuracy: 0.9916 - val_loss: 1.1530 - val_accuracy: 0.7629\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3943 - accuracy: 0.9949 - val_loss: 1.1650 - val_accuracy: 0.7683\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3940 - accuracy: 0.9952 - val_loss: 1.1677 - val_accuracy: 0.7672\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3949 - accuracy: 0.9922 - val_loss: 1.1835 - val_accuracy: 0.7575\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4032 - accuracy: 0.9876 - val_loss: 1.1665 - val_accuracy: 0.7640\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3943 - accuracy: 0.9922 - val_loss: 1.1712 - val_accuracy: 0.7683\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3921 - accuracy: 0.9938 - val_loss: 1.1640 - val_accuracy: 0.7672\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3901 - accuracy: 0.9938 - val_loss: 1.1878 - val_accuracy: 0.7672\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3903 - accuracy: 0.9954 - val_loss: 1.1790 - val_accuracy: 0.7608\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.9903 - val_loss: 1.1946 - val_accuracy: 0.7522\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3915 - accuracy: 0.9935 - val_loss: 1.1737 - val_accuracy: 0.7662\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3881 - accuracy: 0.9957 - val_loss: 1.2878 - val_accuracy: 0.7532\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4025 - accuracy: 0.9857 - val_loss: 1.1989 - val_accuracy: 0.7651\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.9884 - val_loss: 1.2020 - val_accuracy: 0.7640\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.9927 - val_loss: 1.3123 - val_accuracy: 0.7489\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3872 - accuracy: 0.9941 - val_loss: 1.2227 - val_accuracy: 0.7683\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3888 - accuracy: 0.9927 - val_loss: 1.2070 - val_accuracy: 0.7748\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3841 - accuracy: 0.9946 - val_loss: 1.1914 - val_accuracy: 0.7705\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3837 - accuracy: 0.9957 - val_loss: 1.2129 - val_accuracy: 0.7500\n","Epoch 91/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3878 - accuracy: 0.9922 - val_loss: 1.2005 - val_accuracy: 0.7586\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3841 - accuracy: 0.9943 - val_loss: 1.3719 - val_accuracy: 0.7435\n","Epoch 93/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3854 - accuracy: 0.9925 - val_loss: 1.2279 - val_accuracy: 0.7457\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3810 - accuracy: 0.9957 - val_loss: 1.2144 - val_accuracy: 0.7532\n","Epoch 95/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3822 - accuracy: 0.9949 - val_loss: 1.2104 - val_accuracy: 0.7500\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3805 - accuracy: 0.9949 - val_loss: 1.2404 - val_accuracy: 0.7705\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3805 - accuracy: 0.9962 - val_loss: 1.2217 - val_accuracy: 0.7532\n","Epoch 98/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3815 - accuracy: 0.9927 - val_loss: 1.2369 - val_accuracy: 0.7672\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3789 - accuracy: 0.9952 - val_loss: 1.2531 - val_accuracy: 0.7500\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3851 - accuracy: 0.9922 - val_loss: 1.2572 - val_accuracy: 0.7532\n","{'loss': [0.5449751615524292, 0.49454203248023987, 0.4705394208431244, 0.4646921157836914, 0.46012282371520996, 0.4662528336048126, 0.46833541989326477, 0.45236241817474365, 0.45206573605537415, 0.4486861526966095, 0.44771936535835266, 0.4517916440963745, 0.4445439279079437, 0.4412604570388794, 0.4569472670555115, 0.44029590487480164, 0.4422876834869385, 0.4416530430316925, 0.43648675084114075, 0.4391261339187622, 0.433702677488327, 0.4479568302631378, 0.43748027086257935, 0.4385837912559509, 0.44565337896347046, 0.43541449308395386, 0.4336382746696472, 0.4281458556652069, 0.4289384186267853, 0.42525508999824524, 0.4228545129299164, 0.4263356328010559, 0.4371222257614136, 0.4247107207775116, 0.4213618338108063, 0.4225739538669586, 0.42293640971183777, 0.4219513237476349, 0.42041897773742676, 0.4153106212615967, 0.4174237847328186, 0.41872289776802063, 0.4354069232940674, 0.42536461353302, 0.4158223867416382, 0.42265084385871887, 0.4155154526233673, 0.41081011295318604, 0.41243425011634827, 0.4155806601047516, 0.40905824303627014, 0.4138256907463074, 0.40778791904449463, 0.41057097911834717, 0.41125038266181946, 0.40880733728408813, 0.4064520597457886, 0.4027392268180847, 0.4077770709991455, 0.4019849896430969, 0.4035097360610962, 0.4077740013599396, 0.4019981622695923, 0.406733900308609, 0.40657907724380493, 0.4017738699913025, 0.4062434136867523, 0.3977147340774536, 0.4040973484516144, 0.40632012486457825, 0.39647176861763, 0.3987068831920624, 0.3943128287792206, 0.39395853877067566, 0.3949233889579773, 0.40321415662765503, 0.39429226517677307, 0.3921143412590027, 0.3901064991950989, 0.39026379585266113, 0.3951779007911682, 0.39147788286209106, 0.38810470700263977, 0.4025299549102783, 0.3976549506187439, 0.3915649354457855, 0.38721364736557007, 0.38875481486320496, 0.3841279149055481, 0.38366594910621643, 0.3877646327018738, 0.3840641677379608, 0.3854297697544098, 0.3809710144996643, 0.3822029232978821, 0.38048750162124634, 0.3805255889892578, 0.38151848316192627, 0.37886229157447815, 0.38505932688713074], 'accuracy': [0.9380387663841248, 0.9633620977401733, 0.975215494632721, 0.9789870977401733, 0.9822198152542114, 0.9741379022598267, 0.9760237336158752, 0.9835668206214905, 0.984375, 0.9838362336158752, 0.9873383641242981, 0.982758641242981, 0.9878771305084229, 0.9881465435028076, 0.9771012663841248, 0.9873383641242981, 0.9900323152542114, 0.9851831793785095, 0.9881465435028076, 0.9851831793785095, 0.9903017282485962, 0.9814116358757019, 0.9867995977401733, 0.9865301847457886, 0.9797952771186829, 0.9841055870056152, 0.9867995977401733, 0.9889547228813171, 0.9881465435028076, 0.9919180870056152, 0.9921875, 0.9892241358757019, 0.9824892282485962, 0.9884159564971924, 0.990840494632721, 0.9913793206214905, 0.990571141242981, 0.9884159564971924, 0.9892241358757019, 0.9927262663841248, 0.9911099076271057, 0.9911099076271057, 0.9806034564971924, 0.985991358757019, 0.9900323152542114, 0.985991358757019, 0.9889547228813171, 0.9919180870056152, 0.990571141242981, 0.9897629022598267, 0.9932650923728943, 0.9916487336158752, 0.9924569129943848, 0.9897629022598267, 0.9900323152542114, 0.9932650923728943, 0.993534505367279, 0.9943426847457886, 0.990571141242981, 0.9924569129943848, 0.9927262663841248, 0.9897629022598267, 0.9919180870056152, 0.9886853694915771, 0.9897629022598267, 0.9929956793785095, 0.9881465435028076, 0.993534505367279, 0.9900323152542114, 0.9892241358757019, 0.9929956793785095, 0.9916487336158752, 0.9948814511299133, 0.9951508641242981, 0.9921875, 0.9876077771186829, 0.9921875, 0.993803858757019, 0.993803858757019, 0.9954202771186829, 0.9903017282485962, 0.993534505367279, 0.9956896305084229, 0.985722005367279, 0.9884159564971924, 0.9927262663841248, 0.9940732717514038, 0.9927262663841248, 0.9946120977401733, 0.9956896305084229, 0.9921875, 0.9943426847457886, 0.9924569129943848, 0.9956896305084229, 0.9948814511299133, 0.9948814511299133, 0.9962284564971924, 0.9927262663841248, 0.9951508641242981, 0.9921875], 'val_loss': [1.0545718669891357, 1.045588731765747, 1.0355902910232544, 1.028309941291809, 1.0195754766464233, 1.027206540107727, 1.0117827653884888, 0.9948638677597046, 0.9949501156806946, 0.9911186099052429, 0.9861270189285278, 1.016132116317749, 0.9717267751693726, 1.016080617904663, 0.9702157378196716, 0.9806798100471497, 1.0760467052459717, 0.9898292422294617, 0.9895534515380859, 0.9954777359962463, 0.9752439856529236, 1.0653223991394043, 0.9871451258659363, 0.9910949468612671, 1.0374523401260376, 1.0209648609161377, 1.0341160297393799, 1.0076429843902588, 1.0289559364318848, 1.0215144157409668, 1.0352493524551392, 1.0936461687088013, 1.0770312547683716, 1.0395115613937378, 1.0486276149749756, 1.0732284784317017, 1.103418231010437, 1.0779848098754883, 1.0643285512924194, 1.130942940711975, 1.081109881401062, 1.1377121210098267, 1.2639837265014648, 1.105823278427124, 1.0901288986206055, 1.1468242406845093, 1.133026361465454, 1.0965970754623413, 1.1553905010223389, 1.1317299604415894, 1.1208099126815796, 1.1421340703964233, 1.126673936843872, 1.2002968788146973, 1.1672428846359253, 1.1582895517349243, 1.119106411933899, 1.1460623741149902, 1.1522178649902344, 1.1230298280715942, 1.130752682685852, 1.1654382944107056, 1.2013556957244873, 1.1421399116516113, 1.1678415536880493, 1.149489402770996, 1.192713975906372, 1.141187310218811, 1.2050607204437256, 1.177032232284546, 1.1533148288726807, 1.1530293226242065, 1.1650094985961914, 1.1677411794662476, 1.1834999322891235, 1.1665382385253906, 1.1711565256118774, 1.1639983654022217, 1.1878196001052856, 1.1789586544036865, 1.1946444511413574, 1.1737182140350342, 1.2877779006958008, 1.1988791227340698, 1.2020331621170044, 1.3122563362121582, 1.2227383852005005, 1.2070119380950928, 1.1913641691207886, 1.2129254341125488, 1.2005119323730469, 1.3719009160995483, 1.227921485900879, 1.2143936157226562, 1.2103772163391113, 1.2404062747955322, 1.2216531038284302, 1.236884355545044, 1.2531359195709229, 1.2572417259216309], 'val_accuracy': [0.607758641242981, 0.6336206793785095, 0.6476293206214905, 0.6519396305084229, 0.6551724076271057, 0.6357758641242981, 0.6637930870056152, 0.6821120977401733, 0.6767241358757019, 0.6756465435028076, 0.6756465435028076, 0.6605603694915771, 0.693965494632721, 0.6778017282485962, 0.7025862336158752, 0.7090517282485962, 0.6842672228813171, 0.712284505367279, 0.7273706793785095, 0.732758641242981, 0.7510775923728943, 0.7413793206214905, 0.7726293206214905, 0.7715517282485962, 0.7866379022598267, 0.7909482717514038, 0.78125, 0.7909482717514038, 0.7887930870056152, 0.7931034564971924, 0.7866379022598267, 0.7844827771186829, 0.7780172228813171, 0.7920258641242981, 0.7855603694915771, 0.7758620977401733, 0.7693965435028076, 0.7780172228813171, 0.7801724076271057, 0.7661637663841248, 0.7855603694915771, 0.7618534564971924, 0.75, 0.78125, 0.774784505367279, 0.7629310488700867, 0.7650862336158752, 0.7801724076271057, 0.7790948152542114, 0.7834051847457886, 0.7683189511299133, 0.7715517282485962, 0.7693965435028076, 0.7661637663841248, 0.7618534564971924, 0.7704741358757019, 0.78125, 0.7769396305084229, 0.764008641242981, 0.7769396305084229, 0.7758620977401733, 0.7780172228813171, 0.7629310488700867, 0.7715517282485962, 0.7629310488700867, 0.7693965435028076, 0.7543103694915771, 0.7726293206214905, 0.7693965435028076, 0.7607758641242981, 0.7726293206214905, 0.7629310488700867, 0.7683189511299133, 0.767241358757019, 0.7575430870056152, 0.764008641242981, 0.7683189511299133, 0.767241358757019, 0.767241358757019, 0.7607758641242981, 0.7521551847457886, 0.7661637663841248, 0.7532327771186829, 0.7650862336158752, 0.764008641242981, 0.7489224076271057, 0.7683189511299133, 0.774784505367279, 0.7704741358757019, 0.75, 0.7586206793785095, 0.743534505367279, 0.7456896305084229, 0.7532327771186829, 0.75, 0.7704741358757019, 0.7532327771186829, 0.767241358757019, 0.75, 0.7532327771186829]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 30ms/step - loss: 0.5312 - accuracy: 0.9454 - val_loss: 1.0453 - val_accuracy: 0.6459\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.4665 - accuracy: 0.9844"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 17ms/step - loss: 0.4889 - accuracy: 0.9660 - val_loss: 1.0382 - val_accuracy: 0.6652\n","Epoch 3/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4747 - accuracy: 0.9723 - val_loss: 1.0339 - val_accuracy: 0.6527\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4661 - accuracy: 0.9788 - val_loss: 1.0273 - val_accuracy: 0.6572\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4608 - accuracy: 0.9813 - val_loss: 1.0178 - val_accuracy: 0.6731\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4656 - accuracy: 0.9768 - val_loss: 1.0152 - val_accuracy: 0.6697\n","Epoch 7/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4573 - accuracy: 0.9819 - val_loss: 1.0132 - val_accuracy: 0.6606\n","Epoch 8/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4659 - accuracy: 0.9748 - val_loss: 1.0112 - val_accuracy: 0.6606\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4564 - accuracy: 0.9796 - val_loss: 0.9857 - val_accuracy: 0.6957\n","Epoch 10/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4560 - accuracy: 0.9830 - val_loss: 0.9923 - val_accuracy: 0.6900\n","Epoch 11/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4478 - accuracy: 0.9833 - val_loss: 0.9888 - val_accuracy: 0.6867\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4460 - accuracy: 0.9853 - val_loss: 0.9883 - val_accuracy: 0.6946\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4478 - accuracy: 0.9830 - val_loss: 0.9792 - val_accuracy: 0.6991\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4433 - accuracy: 0.9856 - val_loss: 0.9821 - val_accuracy: 0.7070\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4390 - accuracy: 0.9887 - val_loss: 0.9773 - val_accuracy: 0.7093\n","Epoch 16/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4414 - accuracy: 0.9884 - val_loss: 1.0772 - val_accuracy: 0.6731\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4399 - accuracy: 0.9859 - val_loss: 0.9680 - val_accuracy: 0.7183\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4448 - accuracy: 0.9847 - val_loss: 1.0064 - val_accuracy: 0.7217\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4339 - accuracy: 0.9901 - val_loss: 0.9776 - val_accuracy: 0.7296\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4374 - accuracy: 0.9892 - val_loss: 0.9993 - val_accuracy: 0.7489\n","Epoch 21/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4352 - accuracy: 0.9878 - val_loss: 0.9880 - val_accuracy: 0.7296\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4416 - accuracy: 0.9819 - val_loss: 0.9828 - val_accuracy: 0.7738\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4305 - accuracy: 0.9904 - val_loss: 0.9911 - val_accuracy: 0.7738\n","Epoch 24/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4448 - accuracy: 0.9816 - val_loss: 1.0222 - val_accuracy: 0.7398\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4355 - accuracy: 0.9853 - val_loss: 0.9799 - val_accuracy: 0.7862\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4275 - accuracy: 0.9892 - val_loss: 0.9806 - val_accuracy: 0.7885\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4261 - accuracy: 0.9918 - val_loss: 0.9769 - val_accuracy: 0.7919\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4250 - accuracy: 0.9918 - val_loss: 1.0516 - val_accuracy: 0.7715\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4373 - accuracy: 0.9844 - val_loss: 1.0071 - val_accuracy: 0.7828\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4305 - accuracy: 0.9873 - val_loss: 1.0189 - val_accuracy: 0.7930\n","Epoch 31/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.9898 - val_loss: 1.0670 - val_accuracy: 0.7805\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4282 - accuracy: 0.9878 - val_loss: 1.0046 - val_accuracy: 0.7975\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4261 - accuracy: 0.9887 - val_loss: 1.0154 - val_accuracy: 0.7805\n","Epoch 34/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4222 - accuracy: 0.9895 - val_loss: 1.0291 - val_accuracy: 0.7941\n","Epoch 35/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4214 - accuracy: 0.9901 - val_loss: 1.0590 - val_accuracy: 0.7636\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4291 - accuracy: 0.9875 - val_loss: 1.0513 - val_accuracy: 0.7952\n","Epoch 37/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4284 - accuracy: 0.9853 - val_loss: 1.0281 - val_accuracy: 0.7805\n","Epoch 38/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4215 - accuracy: 0.9887 - val_loss: 1.1538 - val_accuracy: 0.7421\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4207 - accuracy: 0.9915 - val_loss: 1.0291 - val_accuracy: 0.7839\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4167 - accuracy: 0.9904 - val_loss: 1.0261 - val_accuracy: 0.7930\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4177 - accuracy: 0.9912 - val_loss: 1.0497 - val_accuracy: 0.7896\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4168 - accuracy: 0.9904 - val_loss: 1.0469 - val_accuracy: 0.7726\n","Epoch 43/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4251 - accuracy: 0.9850 - val_loss: 1.0399 - val_accuracy: 0.7839\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4128 - accuracy: 0.9926 - val_loss: 1.0535 - val_accuracy: 0.7873\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4159 - accuracy: 0.9912 - val_loss: 1.0495 - val_accuracy: 0.7930\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4128 - accuracy: 0.9909 - val_loss: 1.0909 - val_accuracy: 0.7670\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4156 - accuracy: 0.9895 - val_loss: 1.0642 - val_accuracy: 0.7839\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4120 - accuracy: 0.9904 - val_loss: 1.0560 - val_accuracy: 0.7828\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4120 - accuracy: 0.9924 - val_loss: 1.0647 - val_accuracy: 0.7783\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4089 - accuracy: 0.9918 - val_loss: 1.0923 - val_accuracy: 0.7647\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.9898 - val_loss: 1.0594 - val_accuracy: 0.7885\n","Epoch 52/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4072 - accuracy: 0.9929 - val_loss: 1.0878 - val_accuracy: 0.7873\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.9878 - val_loss: 1.0676 - val_accuracy: 0.7919\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4068 - accuracy: 0.9924 - val_loss: 1.0736 - val_accuracy: 0.7896\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4052 - accuracy: 0.9924 - val_loss: 1.1185 - val_accuracy: 0.7794\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4077 - accuracy: 0.9915 - val_loss: 1.0705 - val_accuracy: 0.7794\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4028 - accuracy: 0.9932 - val_loss: 1.0835 - val_accuracy: 0.7919\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4052 - accuracy: 0.9907 - val_loss: 1.0812 - val_accuracy: 0.7839\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4024 - accuracy: 0.9935 - val_loss: 1.0939 - val_accuracy: 0.7885\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4052 - accuracy: 0.9909 - val_loss: 1.0950 - val_accuracy: 0.7715\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4010 - accuracy: 0.9935 - val_loss: 1.1487 - val_accuracy: 0.7771\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.9895 - val_loss: 1.0891 - val_accuracy: 0.7896\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3993 - accuracy: 0.9943 - val_loss: 1.0974 - val_accuracy: 0.7658\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4019 - accuracy: 0.9915 - val_loss: 1.1097 - val_accuracy: 0.7647\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 0.9938 - val_loss: 1.0953 - val_accuracy: 0.7851\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3993 - accuracy: 0.9921 - val_loss: 1.1050 - val_accuracy: 0.7771\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3970 - accuracy: 0.9926 - val_loss: 1.0966 - val_accuracy: 0.7805\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.9935 - val_loss: 1.1131 - val_accuracy: 0.7794\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4009 - accuracy: 0.9918 - val_loss: 1.1903 - val_accuracy: 0.7692\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3970 - accuracy: 0.9938 - val_loss: 1.1005 - val_accuracy: 0.7828\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3951 - accuracy: 0.9929 - val_loss: 1.1224 - val_accuracy: 0.7636\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4013 - accuracy: 0.9915 - val_loss: 1.2829 - val_accuracy: 0.7557\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3955 - accuracy: 0.9935 - val_loss: 1.1206 - val_accuracy: 0.7726\n","Epoch 74/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3964 - accuracy: 0.9926 - val_loss: 1.1138 - val_accuracy: 0.7783\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3975 - accuracy: 0.9918 - val_loss: 1.1442 - val_accuracy: 0.7839\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3948 - accuracy: 0.9915 - val_loss: 1.1146 - val_accuracy: 0.7839\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3986 - accuracy: 0.9907 - val_loss: 1.1590 - val_accuracy: 0.7726\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.9946 - val_loss: 1.1106 - val_accuracy: 0.7828\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3901 - accuracy: 0.9949 - val_loss: 1.1217 - val_accuracy: 0.7783\n","Epoch 80/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3907 - accuracy: 0.9921 - val_loss: 1.1254 - val_accuracy: 0.7771\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3999 - accuracy: 0.9901 - val_loss: 1.3474 - val_accuracy: 0.7466\n","Epoch 82/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3934 - accuracy: 0.9929 - val_loss: 1.1420 - val_accuracy: 0.7817\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3977 - accuracy: 0.9890 - val_loss: 1.1372 - val_accuracy: 0.7783\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3892 - accuracy: 0.9946 - val_loss: 1.1696 - val_accuracy: 0.7794\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3978 - accuracy: 0.9878 - val_loss: 1.1471 - val_accuracy: 0.7783\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3871 - accuracy: 0.9929 - val_loss: 1.1626 - val_accuracy: 0.7760\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3903 - accuracy: 0.9895 - val_loss: 1.1330 - val_accuracy: 0.7726\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3868 - accuracy: 0.9938 - val_loss: 1.1702 - val_accuracy: 0.7602\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3894 - accuracy: 0.9898 - val_loss: 1.1682 - val_accuracy: 0.7726\n","Epoch 90/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3872 - accuracy: 0.9921 - val_loss: 1.1492 - val_accuracy: 0.7749\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.9892 - val_loss: 1.1686 - val_accuracy: 0.7738\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3852 - accuracy: 0.9941 - val_loss: 1.1618 - val_accuracy: 0.7647\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3863 - accuracy: 0.9932 - val_loss: 1.2492 - val_accuracy: 0.7658\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3839 - accuracy: 0.9929 - val_loss: 1.1533 - val_accuracy: 0.7726\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3867 - accuracy: 0.9924 - val_loss: 1.1902 - val_accuracy: 0.7749\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3851 - accuracy: 0.9924 - val_loss: 1.2515 - val_accuracy: 0.7658\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3857 - accuracy: 0.9909 - val_loss: 1.1896 - val_accuracy: 0.7704\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3873 - accuracy: 0.9904 - val_loss: 1.2964 - val_accuracy: 0.7545\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.9932 - val_loss: 1.1699 - val_accuracy: 0.7726\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3790 - accuracy: 0.9921 - val_loss: 1.3224 - val_accuracy: 0.7557\n","{'loss': [0.5311764478683472, 0.48887336254119873, 0.4747468829154968, 0.4660639762878418, 0.46075424551963806, 0.46562597155570984, 0.45731672644615173, 0.46590009331703186, 0.4563700258731842, 0.4559818506240845, 0.4478209614753723, 0.4459584951400757, 0.4478062093257904, 0.4433363080024719, 0.4389696717262268, 0.44135287404060364, 0.4398528039455414, 0.4448074996471405, 0.43387624621391296, 0.43737298250198364, 0.4352128505706787, 0.44156935811042786, 0.43047231435775757, 0.4447537660598755, 0.43545758724212646, 0.42749327421188354, 0.42605674266815186, 0.42498794198036194, 0.4373306334018707, 0.43053194880485535, 0.4272826611995697, 0.42818397283554077, 0.4261156916618347, 0.4222460389137268, 0.42136329412460327, 0.4291335344314575, 0.428439736366272, 0.42152681946754456, 0.420672744512558, 0.4166811406612396, 0.4176657199859619, 0.41676971316337585, 0.42513322830200195, 0.41277962923049927, 0.4158819019794464, 0.41277942061424255, 0.4156125783920288, 0.4119594097137451, 0.4119895100593567, 0.40885668992996216, 0.41012001037597656, 0.40715551376342773, 0.4100691080093384, 0.4067719280719757, 0.40519940853118896, 0.40766581892967224, 0.40281304717063904, 0.4051884710788727, 0.40238428115844727, 0.40516090393066406, 0.4009987711906433, 0.40637075901031494, 0.39931243658065796, 0.40186071395874023, 0.39819633960723877, 0.39930060505867004, 0.39700326323509216, 0.3980617821216583, 0.40093424916267395, 0.39699944853782654, 0.3951238691806793, 0.4012549817562103, 0.3955063819885254, 0.3963981568813324, 0.39749255776405334, 0.394828736782074, 0.3986161947250366, 0.3911708891391754, 0.3901011049747467, 0.39069077372550964, 0.39993324875831604, 0.39337414503097534, 0.3976987302303314, 0.3892424404621124, 0.3977893888950348, 0.3871181309223175, 0.39034807682037354, 0.38677722215652466, 0.38942617177963257, 0.38715487718582153, 0.39268073439598083, 0.385220468044281, 0.38631829619407654, 0.383942574262619, 0.38667795062065125, 0.38511860370635986, 0.38571178913116455, 0.38728731870651245, 0.3859461843967438, 0.378997266292572], 'accuracy': [0.9453876614570618, 0.9660441279411316, 0.9722693562507629, 0.9787775874137878, 0.9813242554664612, 0.9767968058586121, 0.9818902015686035, 0.974816083908081, 0.979626476764679, 0.9830220937728882, 0.983305037021637, 0.9852858185768127, 0.9830220937728882, 0.9855687618255615, 0.9886813759803772, 0.9883984327316284, 0.9858517050743103, 0.9847198724746704, 0.9900962114334106, 0.9892473220825195, 0.9878324866294861, 0.9818902015686035, 0.9903791546821594, 0.9816072583198547, 0.9852858185768127, 0.9892473220825195, 0.9917939901351929, 0.9917939901351929, 0.9844368696212769, 0.9872665405273438, 0.9898132681846619, 0.9878324866294861, 0.9886813759803772, 0.9895302653312683, 0.9900962114334106, 0.9875495433807373, 0.9852858185768127, 0.9886813759803772, 0.9915110468864441, 0.9903791546821594, 0.9912280440330505, 0.9903791546821594, 0.9850028157234192, 0.992642879486084, 0.9912280440330505, 0.9909451007843018, 0.9895302653312683, 0.9903791546821594, 0.9923599362373352, 0.9917939901351929, 0.9898132681846619, 0.9929258823394775, 0.9878324866294861, 0.9923599362373352, 0.9923599362373352, 0.9915110468864441, 0.9932088255882263, 0.990662157535553, 0.9934917688369751, 0.9909451007843018, 0.9934917688369751, 0.9895302653312683, 0.994340717792511, 0.9915110468864441, 0.9937747716903687, 0.9920769929885864, 0.992642879486084, 0.9934917688369751, 0.9917939901351929, 0.9937747716903687, 0.9929258823394775, 0.9915110468864441, 0.9934917688369751, 0.992642879486084, 0.9917939901351929, 0.9915110468864441, 0.990662157535553, 0.9946236610412598, 0.9949066042900085, 0.9920769929885864, 0.9900962114334106, 0.9929258823394775, 0.988964319229126, 0.9946236610412598, 0.9878324866294861, 0.9929258823394775, 0.9895302653312683, 0.9937747716903687, 0.9898132681846619, 0.9920769929885864, 0.9892473220825195, 0.9940577149391174, 0.9932088255882263, 0.9929258823394775, 0.9923599362373352, 0.9923599362373352, 0.9909451007843018, 0.9903791546821594, 0.9932088255882263, 0.9920769929885864], 'val_loss': [1.0453063249588013, 1.0381555557250977, 1.0338693857192993, 1.0273373126983643, 1.0177584886550903, 1.015242338180542, 1.013206124305725, 1.0111576318740845, 0.985731840133667, 0.9922668933868408, 0.98879474401474, 0.9882760047912598, 0.979153573513031, 0.9820561408996582, 0.977259635925293, 1.077231526374817, 0.9679797887802124, 1.0064131021499634, 0.9776100516319275, 0.9993005990982056, 0.98801189661026, 0.9827524423599243, 0.9911026358604431, 1.0222458839416504, 0.9798980951309204, 0.9806075692176819, 0.9769353270530701, 1.0516154766082764, 1.007145643234253, 1.0189391374588013, 1.0669615268707275, 1.0046013593673706, 1.015441656112671, 1.029135823249817, 1.0589544773101807, 1.0512553453445435, 1.0280622243881226, 1.1537818908691406, 1.0290807485580444, 1.02614426612854, 1.0496634244918823, 1.0469212532043457, 1.039944052696228, 1.0534589290618896, 1.0495150089263916, 1.090922474861145, 1.0642186403274536, 1.0559651851654053, 1.064664363861084, 1.0922988653182983, 1.059362530708313, 1.087844729423523, 1.0675889253616333, 1.0736438035964966, 1.118524193763733, 1.0704926252365112, 1.0835351943969727, 1.0811526775360107, 1.093923568725586, 1.0949647426605225, 1.148749828338623, 1.0890722274780273, 1.097395658493042, 1.109676718711853, 1.0952996015548706, 1.104962944984436, 1.0965989828109741, 1.1130836009979248, 1.1902737617492676, 1.1004915237426758, 1.122351884841919, 1.2828855514526367, 1.120563268661499, 1.1138097047805786, 1.1442358493804932, 1.1146214008331299, 1.1590403318405151, 1.1106401681900024, 1.1217405796051025, 1.125386118888855, 1.3474433422088623, 1.1419676542282104, 1.1372376680374146, 1.1696428060531616, 1.1470571756362915, 1.1625940799713135, 1.1329971551895142, 1.170233130455017, 1.16823410987854, 1.1491811275482178, 1.1685985326766968, 1.1618082523345947, 1.2491744756698608, 1.1533267498016357, 1.1902366876602173, 1.251530408859253, 1.1895970106124878, 1.2963840961456299, 1.1699186563491821, 1.3224098682403564], 'val_accuracy': [0.6459276080131531, 0.6651583909988403, 0.6527149081230164, 0.6572397947311401, 0.6730769276618958, 0.6696832776069641, 0.6606335043907166, 0.6606335043907166, 0.6957013607025146, 0.6900452375411987, 0.6866515874862671, 0.6945701241493225, 0.6990950107574463, 0.7070135474205017, 0.709276020526886, 0.6730769276618958, 0.7183257937431335, 0.7217194437980652, 0.7296379804611206, 0.7488687634468079, 0.7296379804611206, 0.773755669593811, 0.773755669593811, 0.7398189902305603, 0.7861990928649902, 0.7884615659713745, 0.7918552160263062, 0.7714931964874268, 0.7828054428100586, 0.7929864525794983, 0.7805429697036743, 0.7975113391876221, 0.7805429697036743, 0.7941176295280457, 0.7635746598243713, 0.7952488660812378, 0.7805429697036743, 0.7420814633369446, 0.7839366793632507, 0.7929864525794983, 0.7895927429199219, 0.7726244330406189, 0.7839366793632507, 0.7873303294181824, 0.7929864525794983, 0.766968309879303, 0.7839366793632507, 0.7828054428100586, 0.7782805562019348, 0.7647058963775635, 0.7884615659713745, 0.7873303294181824, 0.7918552160263062, 0.7895927429199219, 0.779411792755127, 0.779411792755127, 0.7918552160263062, 0.7839366793632507, 0.7884615659713745, 0.7714931964874268, 0.7771493196487427, 0.7895927429199219, 0.7658371329307556, 0.7647058963775635, 0.7850678563117981, 0.7771493196487427, 0.7805429697036743, 0.779411792755127, 0.7692307829856873, 0.7828054428100586, 0.7635746598243713, 0.7556561231613159, 0.7726244330406189, 0.7782805562019348, 0.7839366793632507, 0.7839366793632507, 0.7726244330406189, 0.7828054428100586, 0.7782805562019348, 0.7771493196487427, 0.7466063499450684, 0.7816742062568665, 0.7782805562019348, 0.779411792755127, 0.7782805562019348, 0.7760180830955505, 0.7726244330406189, 0.7601810097694397, 0.7726244330406189, 0.7748869061470032, 0.773755669593811, 0.7647058963775635, 0.7658371329307556, 0.7726244330406189, 0.7748869061470032, 0.7658371329307556, 0.7703620195388794, 0.7545248866081238, 0.7726244330406189, 0.7556561231613159]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 27ms/step - loss: 0.5409 - accuracy: 0.9406 - val_loss: 1.0504 - val_accuracy: 0.6054\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.5351 - accuracy: 0.9453"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 17ms/step - loss: 0.5093 - accuracy: 0.9556 - val_loss: 1.0402 - val_accuracy: 0.6384\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4910 - accuracy: 0.9677 - val_loss: 1.0369 - val_accuracy: 0.6364\n","Epoch 4/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4899 - accuracy: 0.9651 - val_loss: 1.0319 - val_accuracy: 0.6281\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4769 - accuracy: 0.9757 - val_loss: 1.0287 - val_accuracy: 0.6291\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4797 - accuracy: 0.9698 - val_loss: 1.0273 - val_accuracy: 0.6198\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4781 - accuracy: 0.9713 - val_loss: 1.0128 - val_accuracy: 0.6446\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4669 - accuracy: 0.9775 - val_loss: 1.0005 - val_accuracy: 0.6643\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4728 - accuracy: 0.9729 - val_loss: 1.0584 - val_accuracy: 0.6136\n","Epoch 10/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4766 - accuracy: 0.9713 - val_loss: 0.9995 - val_accuracy: 0.6601\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4648 - accuracy: 0.9765 - val_loss: 1.0442 - val_accuracy: 0.6302\n","Epoch 12/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4591 - accuracy: 0.9788 - val_loss: 1.0398 - val_accuracy: 0.6395\n","Epoch 13/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4617 - accuracy: 0.9783 - val_loss: 1.0563 - val_accuracy: 0.6467\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4673 - accuracy: 0.9744 - val_loss: 1.0196 - val_accuracy: 0.6829\n","Epoch 15/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4571 - accuracy: 0.9796 - val_loss: 1.2107 - val_accuracy: 0.6219\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4671 - accuracy: 0.9749 - val_loss: 1.0317 - val_accuracy: 0.6860\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4500 - accuracy: 0.9835 - val_loss: 1.0038 - val_accuracy: 0.7149\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4512 - accuracy: 0.9832 - val_loss: 1.0012 - val_accuracy: 0.7438\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.9801 - val_loss: 1.0203 - val_accuracy: 0.7335\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4514 - accuracy: 0.9804 - val_loss: 0.9954 - val_accuracy: 0.7614\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4566 - accuracy: 0.9739 - val_loss: 1.0470 - val_accuracy: 0.7397\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4460 - accuracy: 0.9842 - val_loss: 1.0164 - val_accuracy: 0.7748\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4493 - accuracy: 0.9806 - val_loss: 1.0333 - val_accuracy: 0.7831\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4442 - accuracy: 0.9827 - val_loss: 1.0227 - val_accuracy: 0.7872\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4432 - accuracy: 0.9848 - val_loss: 1.0355 - val_accuracy: 0.7851\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4399 - accuracy: 0.9853 - val_loss: 1.0387 - val_accuracy: 0.7882\n","Epoch 27/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4467 - accuracy: 0.9786 - val_loss: 1.0523 - val_accuracy: 0.7769\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4427 - accuracy: 0.9829 - val_loss: 1.0698 - val_accuracy: 0.7789\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.9780 - val_loss: 1.1228 - val_accuracy: 0.7707\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4634 - accuracy: 0.9685 - val_loss: 1.0805 - val_accuracy: 0.7779\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4479 - accuracy: 0.9786 - val_loss: 1.0924 - val_accuracy: 0.7758\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4396 - accuracy: 0.9848 - val_loss: 1.1295 - val_accuracy: 0.7603\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4394 - accuracy: 0.9829 - val_loss: 1.0941 - val_accuracy: 0.7769\n","Epoch 34/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4350 - accuracy: 0.9855 - val_loss: 1.1031 - val_accuracy: 0.7789\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4340 - accuracy: 0.9863 - val_loss: 1.1422 - val_accuracy: 0.7593\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4392 - accuracy: 0.9824 - val_loss: 1.1791 - val_accuracy: 0.7510\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4398 - accuracy: 0.9786 - val_loss: 1.1258 - val_accuracy: 0.7707\n","Epoch 38/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4594 - accuracy: 0.9677 - val_loss: 1.1391 - val_accuracy: 0.7614\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4311 - accuracy: 0.9881 - val_loss: 1.1113 - val_accuracy: 0.7758\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4305 - accuracy: 0.9850 - val_loss: 1.1119 - val_accuracy: 0.7820\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4382 - accuracy: 0.9798 - val_loss: 1.1446 - val_accuracy: 0.7645\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4323 - accuracy: 0.9827 - val_loss: 1.1364 - val_accuracy: 0.7686\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4334 - accuracy: 0.9817 - val_loss: 1.1527 - val_accuracy: 0.7624\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4303 - accuracy: 0.9837 - val_loss: 1.1362 - val_accuracy: 0.7676\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4226 - accuracy: 0.9897 - val_loss: 1.1401 - val_accuracy: 0.7738\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4313 - accuracy: 0.9848 - val_loss: 1.1309 - val_accuracy: 0.7820\n","Epoch 47/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4243 - accuracy: 0.9879 - val_loss: 1.1392 - val_accuracy: 0.7748\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4432 - accuracy: 0.9773 - val_loss: 1.1237 - val_accuracy: 0.7779\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.9860 - val_loss: 1.1255 - val_accuracy: 0.7696\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4254 - accuracy: 0.9840 - val_loss: 1.1762 - val_accuracy: 0.7614\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.9827 - val_loss: 1.1514 - val_accuracy: 0.7769\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4203 - accuracy: 0.9889 - val_loss: 1.1440 - val_accuracy: 0.7758\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4225 - accuracy: 0.9863 - val_loss: 1.1703 - val_accuracy: 0.7593\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4223 - accuracy: 0.9863 - val_loss: 1.1567 - val_accuracy: 0.7717\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4253 - accuracy: 0.9814 - val_loss: 1.1857 - val_accuracy: 0.7634\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4476 - accuracy: 0.9739 - val_loss: 1.1662 - val_accuracy: 0.7624\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4199 - accuracy: 0.9858 - val_loss: 1.2490 - val_accuracy: 0.7438\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4284 - accuracy: 0.9814 - val_loss: 1.1578 - val_accuracy: 0.7738\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4160 - accuracy: 0.9868 - val_loss: 1.1967 - val_accuracy: 0.7583\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4164 - accuracy: 0.9884 - val_loss: 1.1619 - val_accuracy: 0.7769\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4137 - accuracy: 0.9891 - val_loss: 1.1778 - val_accuracy: 0.7645\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4144 - accuracy: 0.9868 - val_loss: 1.1686 - val_accuracy: 0.7696\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4141 - accuracy: 0.9879 - val_loss: 1.1943 - val_accuracy: 0.7655\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4111 - accuracy: 0.9917 - val_loss: 1.1698 - val_accuracy: 0.7707\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4102 - accuracy: 0.9917 - val_loss: 1.1950 - val_accuracy: 0.7603\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4113 - accuracy: 0.9884 - val_loss: 1.1912 - val_accuracy: 0.7645\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4142 - accuracy: 0.9873 - val_loss: 1.2137 - val_accuracy: 0.7614\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.9904 - val_loss: 1.1914 - val_accuracy: 0.7717\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4085 - accuracy: 0.9910 - val_loss: 1.2019 - val_accuracy: 0.7583\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4137 - accuracy: 0.9860 - val_loss: 1.3797 - val_accuracy: 0.7252\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4286 - accuracy: 0.9780 - val_loss: 1.2227 - val_accuracy: 0.7583\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4113 - accuracy: 0.9871 - val_loss: 1.2008 - val_accuracy: 0.7645\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4062 - accuracy: 0.9925 - val_loss: 1.2050 - val_accuracy: 0.7717\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4066 - accuracy: 0.9884 - val_loss: 1.1899 - val_accuracy: 0.7686\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4022 - accuracy: 0.9925 - val_loss: 1.2041 - val_accuracy: 0.7645\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.9873 - val_loss: 1.3877 - val_accuracy: 0.7252\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4107 - accuracy: 0.9868 - val_loss: 1.2312 - val_accuracy: 0.7583\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4095 - accuracy: 0.9853 - val_loss: 1.2136 - val_accuracy: 0.7572\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4037 - accuracy: 0.9889 - val_loss: 1.2248 - val_accuracy: 0.7665\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4084 - accuracy: 0.9873 - val_loss: 1.1952 - val_accuracy: 0.7665\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4163 - accuracy: 0.9832 - val_loss: 1.2348 - val_accuracy: 0.7562\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4041 - accuracy: 0.9894 - val_loss: 1.2389 - val_accuracy: 0.7541\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4264 - accuracy: 0.9770 - val_loss: 1.2935 - val_accuracy: 0.7552\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4093 - accuracy: 0.9835 - val_loss: 1.2206 - val_accuracy: 0.7583\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4010 - accuracy: 0.9902 - val_loss: 1.2211 - val_accuracy: 0.7624\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4048 - accuracy: 0.9863 - val_loss: 1.2121 - val_accuracy: 0.7624\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4014 - accuracy: 0.9886 - val_loss: 1.2458 - val_accuracy: 0.7593\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3961 - accuracy: 0.9925 - val_loss: 1.2552 - val_accuracy: 0.7541\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4015 - accuracy: 0.9876 - val_loss: 1.2297 - val_accuracy: 0.7572\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.9930 - val_loss: 1.2244 - val_accuracy: 0.7655\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3953 - accuracy: 0.9915 - val_loss: 1.2597 - val_accuracy: 0.7593\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4039 - accuracy: 0.9863 - val_loss: 1.2339 - val_accuracy: 0.7603\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3995 - accuracy: 0.9884 - val_loss: 1.2548 - val_accuracy: 0.7603\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4007 - accuracy: 0.9891 - val_loss: 1.2357 - val_accuracy: 0.7541\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4046 - accuracy: 0.9835 - val_loss: 1.2477 - val_accuracy: 0.7645\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3993 - accuracy: 0.9868 - val_loss: 1.2462 - val_accuracy: 0.7572\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3931 - accuracy: 0.9910 - val_loss: 1.3034 - val_accuracy: 0.7521\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3950 - accuracy: 0.9889 - val_loss: 1.3122 - val_accuracy: 0.7531\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4021 - accuracy: 0.9827 - val_loss: 1.2630 - val_accuracy: 0.7562\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3987 - accuracy: 0.9863 - val_loss: 1.2465 - val_accuracy: 0.7634\n","{'loss': [0.5409308671951294, 0.5093386173248291, 0.49098923802375793, 0.48987966775894165, 0.47689393162727356, 0.4796813130378723, 0.4781148433685303, 0.4668706953525543, 0.47280368208885193, 0.4765794575214386, 0.46479859948158264, 0.459050714969635, 0.4616697132587433, 0.46732550859451294, 0.45712795853614807, 0.46705615520477295, 0.450006365776062, 0.45124438405036926, 0.4533768594264984, 0.4514460265636444, 0.45659139752388, 0.44600710272789, 0.4493119716644287, 0.4441606104373932, 0.44318142533302307, 0.4399298429489136, 0.44673770666122437, 0.4427233934402466, 0.4511578679084778, 0.46335360407829285, 0.44786787033081055, 0.4396238625049591, 0.4394083619117737, 0.43502041697502136, 0.43398842215538025, 0.4391924738883972, 0.43977007269859314, 0.45944643020629883, 0.4310683310031891, 0.4304841458797455, 0.4382270574569702, 0.43226802349090576, 0.43340495228767395, 0.4302562475204468, 0.42255645990371704, 0.4312702715396881, 0.4243012070655823, 0.44318321347236633, 0.4242914021015167, 0.42540764808654785, 0.427286833524704, 0.4203420877456665, 0.42252805829048157, 0.42233651876449585, 0.4253253936767578, 0.44762474298477173, 0.41993483901023865, 0.4284003973007202, 0.4160163104534149, 0.41638368368148804, 0.41369837522506714, 0.4144378900527954, 0.41407153010368347, 0.41108158230781555, 0.41021984815597534, 0.4112800657749176, 0.41416651010513306, 0.41075026988983154, 0.408549040555954, 0.4136750400066376, 0.4285973608493805, 0.4112861156463623, 0.40619879961013794, 0.4066133201122284, 0.40218794345855713, 0.41133299469947815, 0.4107474684715271, 0.4094882011413574, 0.4037109315395355, 0.4083961844444275, 0.41634660959243774, 0.40406671166419983, 0.4264054596424103, 0.409324049949646, 0.40104490518569946, 0.4047620892524719, 0.40142011642456055, 0.39614856243133545, 0.40151071548461914, 0.395163357257843, 0.39528030157089233, 0.40388572216033936, 0.39952704310417175, 0.4007362127304077, 0.4045983850955963, 0.39933648705482483, 0.3930802047252655, 0.3949663043022156, 0.40205490589141846, 0.3987208902835846], 'accuracy': [0.9405684471130371, 0.9555555582046509, 0.9677002429962158, 0.9651162624359131, 0.9757105708122253, 0.9697674512863159, 0.9713178277015686, 0.9775193929672241, 0.9728682041168213, 0.9713178277015686, 0.9764857888221741, 0.9788113832473755, 0.9782945513725281, 0.974418580532074, 0.9795865416526794, 0.9749354124069214, 0.9834625124931335, 0.9832041263580322, 0.9801033735275269, 0.9803617596626282, 0.9739018082618713, 0.9842377305030823, 0.9806201457977295, 0.9826873540878296, 0.9847545027732849, 0.9852713346481323, 0.9785529971122742, 0.9829457402229309, 0.9780361652374268, 0.9684754610061646, 0.9785529971122742, 0.9847545027732849, 0.9829457402229309, 0.9855297207832336, 0.9863049387931824, 0.9824289679527283, 0.9785529971122742, 0.9677002429962158, 0.9881137013435364, 0.985012948513031, 0.9798449873924255, 0.9826873540878296, 0.9816537499427795, 0.9837209582328796, 0.9896640777587891, 0.9847545027732849, 0.9878553152084351, 0.9772610068321228, 0.9860464930534363, 0.983979344367981, 0.9826873540878296, 0.9888888597488403, 0.9863049387931824, 0.9863049387931824, 0.9813953638076782, 0.9739018082618713, 0.985788106918335, 0.9813953638076782, 0.986821711063385, 0.9883720874786377, 0.9891473054885864, 0.986821711063385, 0.9878553152084351, 0.9917312860488892, 0.9917312860488892, 0.9883720874786377, 0.9873384833335876, 0.9904392957687378, 0.9909560680389404, 0.9860464930534363, 0.9780361652374268, 0.9870800971984863, 0.9925064444541931, 0.9883720874786377, 0.9925064444541931, 0.9873384833335876, 0.986821711063385, 0.9852713346481323, 0.9888888597488403, 0.9873384833335876, 0.9832041263580322, 0.9894056916236877, 0.9770025610923767, 0.9834625124931335, 0.9901808500289917, 0.9863049387931824, 0.988630473613739, 0.9925064444541931, 0.987596869468689, 0.9930232763290405, 0.9914728403091431, 0.9863049387931824, 0.9883720874786377, 0.9891473054885864, 0.9834625124931335, 0.986821711063385, 0.9909560680389404, 0.9888888597488403, 0.9826873540878296, 0.9863049387931824], 'val_loss': [1.050390601158142, 1.0402454137802124, 1.0369226932525635, 1.0318812131881714, 1.0286649465560913, 1.0272575616836548, 1.0127743482589722, 1.0005172491073608, 1.0584102869033813, 0.9994899034500122, 1.0442354679107666, 1.0397988557815552, 1.0563161373138428, 1.0195610523223877, 1.2107197046279907, 1.0317156314849854, 1.0037578344345093, 1.0011788606643677, 1.0203042030334473, 0.9953805804252625, 1.046993613243103, 1.0164390802383423, 1.0333185195922852, 1.0227484703063965, 1.0355454683303833, 1.0386592149734497, 1.052315592765808, 1.0698169469833374, 1.1227927207946777, 1.0805063247680664, 1.0923885107040405, 1.129512906074524, 1.0941455364227295, 1.1031033992767334, 1.1421605348587036, 1.1791110038757324, 1.125810980796814, 1.139122486114502, 1.1112511157989502, 1.1119377613067627, 1.144649624824524, 1.1363704204559326, 1.1527304649353027, 1.1362392902374268, 1.140087366104126, 1.1308655738830566, 1.1391949653625488, 1.1236563920974731, 1.1255029439926147, 1.1761704683303833, 1.151389241218567, 1.143985390663147, 1.1703169345855713, 1.1567227840423584, 1.1856505870819092, 1.1661851406097412, 1.2490438222885132, 1.157751441001892, 1.1967321634292603, 1.1619302034378052, 1.1778244972229004, 1.1685817241668701, 1.1942731142044067, 1.1697826385498047, 1.1949635744094849, 1.1912239789962769, 1.2136577367782593, 1.1914077997207642, 1.2019362449645996, 1.3797240257263184, 1.2226850986480713, 1.200792670249939, 1.2049778699874878, 1.1899300813674927, 1.2040505409240723, 1.3877153396606445, 1.2312078475952148, 1.2135968208312988, 1.2248378992080688, 1.195194959640503, 1.234766960144043, 1.23891282081604, 1.293478012084961, 1.2206075191497803, 1.2210524082183838, 1.212136149406433, 1.2458109855651855, 1.2552306652069092, 1.2297354936599731, 1.2243505716323853, 1.2597379684448242, 1.2338610887527466, 1.2548410892486572, 1.2356834411621094, 1.2477325201034546, 1.2462480068206787, 1.3034287691116333, 1.3122087717056274, 1.2629672288894653, 1.2465403079986572], 'val_accuracy': [0.60537189245224, 0.6384297609329224, 0.6363636255264282, 0.6280992031097412, 0.6291322112083435, 0.6198347210884094, 0.64462810754776, 0.66425621509552, 0.6136363744735718, 0.6601239442825317, 0.6301652789115906, 0.6394628286361694, 0.6466942429542542, 0.682851254940033, 0.6219007968902588, 0.6859503984451294, 0.7148760557174683, 0.7438016533851624, 0.7334710955619812, 0.7613636255264282, 0.7396694421768188, 0.7747933864593506, 0.7830578684806824, 0.7871900796890259, 0.7851239442825317, 0.788223147392273, 0.7768595218658447, 0.7789255976676941, 0.7706611752510071, 0.7778925895690918, 0.7758264541625977, 0.7603305578231812, 0.7768595218658447, 0.7789255976676941, 0.7592975497245789, 0.7510330677032471, 0.7706611752510071, 0.7613636255264282, 0.7758264541625977, 0.7820248007774353, 0.7644628286361694, 0.7685950398445129, 0.7623966932296753, 0.7675619721412659, 0.7737603187561035, 0.7820248007774353, 0.7747933864593506, 0.7778925895690918, 0.76962810754776, 0.7613636255264282, 0.7768595218658447, 0.7758264541625977, 0.7592975497245789, 0.7716942429542542, 0.7634297609329224, 0.7623966932296753, 0.7438016533851624, 0.7737603187561035, 0.7582644820213318, 0.7768595218658447, 0.7644628286361694, 0.76962810754776, 0.7654958963394165, 0.7706611752510071, 0.7603305578231812, 0.7644628286361694, 0.7613636255264282, 0.7716942429542542, 0.7582644820213318, 0.7252066135406494, 0.7582644820213318, 0.7644628286361694, 0.7716942429542542, 0.7685950398445129, 0.7644628286361694, 0.7252066135406494, 0.7582644820213318, 0.7572314143180847, 0.7665289044380188, 0.7665289044380188, 0.7561983466148376, 0.7541322112083435, 0.7551652789115906, 0.7582644820213318, 0.7623966932296753, 0.7623966932296753, 0.7592975497245789, 0.7541322112083435, 0.7572314143180847, 0.7654958963394165, 0.7592975497245789, 0.7603305578231812, 0.7603305578231812, 0.7541322112083435, 0.7644628286361694, 0.7572314143180847, 0.7520661354064941, 0.7530992031097412, 0.7561983466148376, 0.7634297609329224]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 26ms/step - loss: 0.4911 - accuracy: 0.9494 - val_loss: 1.0081 - val_accuracy: 0.6455\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4305 - accuracy: 0.9766"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 16ms/step - loss: 0.4174 - accuracy: 0.9814 - val_loss: 0.9978 - val_accuracy: 0.6627\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4059 - accuracy: 0.9830 - val_loss: 0.9901 - val_accuracy: 0.6573\n","Epoch 4/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.9863 - val_loss: 0.9909 - val_accuracy: 0.6412\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4072 - accuracy: 0.9836 - val_loss: 0.9720 - val_accuracy: 0.6595\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3957 - accuracy: 0.9911 - val_loss: 0.9612 - val_accuracy: 0.6810\n","Epoch 7/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3973 - accuracy: 0.9903 - val_loss: 0.9710 - val_accuracy: 0.6616\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.9900 - val_loss: 0.9897 - val_accuracy: 0.6347\n","Epoch 9/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4092 - accuracy: 0.9820 - val_loss: 0.9588 - val_accuracy: 0.6746\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.9911 - val_loss: 0.9630 - val_accuracy: 0.6735\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3968 - accuracy: 0.9873 - val_loss: 0.9596 - val_accuracy: 0.6832\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 0.9911 - val_loss: 0.9984 - val_accuracy: 0.6627\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3929 - accuracy: 0.9908 - val_loss: 0.9613 - val_accuracy: 0.6929\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3866 - accuracy: 0.9949 - val_loss: 0.9330 - val_accuracy: 0.7069\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3862 - accuracy: 0.9935 - val_loss: 0.9633 - val_accuracy: 0.6994\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3861 - accuracy: 0.9941 - val_loss: 0.9581 - val_accuracy: 0.7155\n","Epoch 17/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3866 - accuracy: 0.9938 - val_loss: 0.9622 - val_accuracy: 0.7231\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3844 - accuracy: 0.9919 - val_loss: 0.9830 - val_accuracy: 0.7231\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3847 - accuracy: 0.9914 - val_loss: 0.9432 - val_accuracy: 0.7532\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3856 - accuracy: 0.9943 - val_loss: 0.9411 - val_accuracy: 0.7629\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3854 - accuracy: 0.9922 - val_loss: 0.9397 - val_accuracy: 0.7759\n","Epoch 22/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3803 - accuracy: 0.9943 - val_loss: 0.9393 - val_accuracy: 0.7834\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3853 - accuracy: 0.9908 - val_loss: 0.9189 - val_accuracy: 0.8006\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.9881 - val_loss: 1.0066 - val_accuracy: 0.7942\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.9865 - val_loss: 0.9620 - val_accuracy: 0.8006\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3804 - accuracy: 0.9925 - val_loss: 0.9451 - val_accuracy: 0.8093\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3786 - accuracy: 0.9952 - val_loss: 0.9458 - val_accuracy: 0.8190\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3795 - accuracy: 0.9933 - val_loss: 0.9441 - val_accuracy: 0.8211\n","Epoch 29/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3776 - accuracy: 0.9957 - val_loss: 0.9607 - val_accuracy: 0.8222\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3795 - accuracy: 0.9930 - val_loss: 0.9583 - val_accuracy: 0.8222\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3818 - accuracy: 0.9903 - val_loss: 0.9545 - val_accuracy: 0.8297\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3791 - accuracy: 0.9919 - val_loss: 0.9952 - val_accuracy: 0.8157\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3767 - accuracy: 0.9933 - val_loss: 0.9704 - val_accuracy: 0.8179\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3728 - accuracy: 0.9970 - val_loss: 0.9706 - val_accuracy: 0.8200\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3738 - accuracy: 0.9954 - val_loss: 0.9737 - val_accuracy: 0.8254\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3754 - accuracy: 0.9922 - val_loss: 0.9911 - val_accuracy: 0.8179\n","Epoch 37/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3734 - accuracy: 0.9952 - val_loss: 1.0172 - val_accuracy: 0.8071\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3821 - accuracy: 0.9898 - val_loss: 1.0204 - val_accuracy: 0.8071\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3734 - accuracy: 0.9941 - val_loss: 0.9817 - val_accuracy: 0.8233\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3714 - accuracy: 0.9960 - val_loss: 0.9871 - val_accuracy: 0.8179\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3968 - accuracy: 0.9838 - val_loss: 1.1677 - val_accuracy: 0.7888\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3788 - accuracy: 0.9908 - val_loss: 1.0363 - val_accuracy: 0.8050\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3707 - accuracy: 0.9962 - val_loss: 1.0011 - val_accuracy: 0.8233\n","Epoch 44/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3695 - accuracy: 0.9962 - val_loss: 1.0262 - val_accuracy: 0.8157\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3788 - accuracy: 0.9911 - val_loss: 1.0766 - val_accuracy: 0.7974\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3784 - accuracy: 0.9903 - val_loss: 1.0130 - val_accuracy: 0.8211\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3693 - accuracy: 0.9954 - val_loss: 1.0236 - val_accuracy: 0.8136\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3673 - accuracy: 0.9960 - val_loss: 1.0140 - val_accuracy: 0.8103\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3698 - accuracy: 0.9941 - val_loss: 1.0138 - val_accuracy: 0.8136\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3747 - accuracy: 0.9911 - val_loss: 1.0811 - val_accuracy: 0.8006\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3662 - accuracy: 0.9960 - val_loss: 1.0291 - val_accuracy: 0.8093\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.9954 - val_loss: 1.0284 - val_accuracy: 0.8179\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3638 - accuracy: 0.9962 - val_loss: 1.0281 - val_accuracy: 0.8103\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3680 - accuracy: 0.9930 - val_loss: 1.0363 - val_accuracy: 0.8157\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3664 - accuracy: 0.9938 - val_loss: 1.0263 - val_accuracy: 0.8222\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3637 - accuracy: 0.9976 - val_loss: 1.0618 - val_accuracy: 0.8017\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3741 - accuracy: 0.9900 - val_loss: 1.0453 - val_accuracy: 0.8071\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3663 - accuracy: 0.9960 - val_loss: 1.0499 - val_accuracy: 0.8136\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3633 - accuracy: 0.9952 - val_loss: 1.0327 - val_accuracy: 0.8125\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3621 - accuracy: 0.9962 - val_loss: 1.0526 - val_accuracy: 0.8017\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3624 - accuracy: 0.9943 - val_loss: 1.0356 - val_accuracy: 0.8147\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3614 - accuracy: 0.9954 - val_loss: 1.0461 - val_accuracy: 0.8103\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3614 - accuracy: 0.9957 - val_loss: 1.0493 - val_accuracy: 0.8125\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3594 - accuracy: 0.9968 - val_loss: 1.0558 - val_accuracy: 0.8060\n","Epoch 65/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3627 - accuracy: 0.9938 - val_loss: 1.0913 - val_accuracy: 0.7985\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3658 - accuracy: 0.9922 - val_loss: 1.0573 - val_accuracy: 0.8071\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3660 - accuracy: 0.9919 - val_loss: 1.0896 - val_accuracy: 0.8017\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3626 - accuracy: 0.9943 - val_loss: 1.1326 - val_accuracy: 0.7899\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3623 - accuracy: 0.9935 - val_loss: 1.0500 - val_accuracy: 0.8060\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3705 - accuracy: 0.9892 - val_loss: 1.3330 - val_accuracy: 0.7586\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3641 - accuracy: 0.9941 - val_loss: 1.0634 - val_accuracy: 0.8006\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3558 - accuracy: 0.9960 - val_loss: 1.0559 - val_accuracy: 0.8114\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3594 - accuracy: 0.9938 - val_loss: 1.0642 - val_accuracy: 0.8028\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3596 - accuracy: 0.9941 - val_loss: 1.0593 - val_accuracy: 0.7996\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3605 - accuracy: 0.9927 - val_loss: 1.0538 - val_accuracy: 0.8039\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3541 - accuracy: 0.9973 - val_loss: 1.0612 - val_accuracy: 0.8039\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3532 - accuracy: 0.9973 - val_loss: 1.0795 - val_accuracy: 0.7996\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3569 - accuracy: 0.9949 - val_loss: 1.1151 - val_accuracy: 0.7888\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3532 - accuracy: 0.9976 - val_loss: 1.0872 - val_accuracy: 0.8028\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3561 - accuracy: 0.9954 - val_loss: 1.1020 - val_accuracy: 0.7909\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3529 - accuracy: 0.9960 - val_loss: 1.0585 - val_accuracy: 0.8050\n","Epoch 82/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3518 - accuracy: 0.9968 - val_loss: 1.0711 - val_accuracy: 0.8082\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3520 - accuracy: 0.9954 - val_loss: 1.0789 - val_accuracy: 0.8050\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3521 - accuracy: 0.9962 - val_loss: 1.0827 - val_accuracy: 0.8071\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3519 - accuracy: 0.9957 - val_loss: 1.0858 - val_accuracy: 0.8039\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3583 - accuracy: 0.9908 - val_loss: 1.0843 - val_accuracy: 0.7942\n","Epoch 87/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3508 - accuracy: 0.9952 - val_loss: 1.0810 - val_accuracy: 0.8050\n","Epoch 88/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3499 - accuracy: 0.9962 - val_loss: 1.0887 - val_accuracy: 0.7974\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3558 - accuracy: 0.9927 - val_loss: 1.1373 - val_accuracy: 0.7931\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3493 - accuracy: 0.9954 - val_loss: 1.0869 - val_accuracy: 0.7996\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3569 - accuracy: 0.9908 - val_loss: 1.0865 - val_accuracy: 0.8006\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3516 - accuracy: 0.9946 - val_loss: 1.0927 - val_accuracy: 0.8028\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3480 - accuracy: 0.9965 - val_loss: 1.0834 - val_accuracy: 0.7963\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3466 - accuracy: 0.9968 - val_loss: 1.0959 - val_accuracy: 0.7931\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3499 - accuracy: 0.9949 - val_loss: 1.0966 - val_accuracy: 0.8028\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3449 - accuracy: 0.9965 - val_loss: 1.0897 - val_accuracy: 0.8114\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3458 - accuracy: 0.9968 - val_loss: 1.1276 - val_accuracy: 0.7866\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.9960 - val_loss: 1.1456 - val_accuracy: 0.7888\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3505 - accuracy: 0.9925 - val_loss: 1.1228 - val_accuracy: 0.7909\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3471 - accuracy: 0.9935 - val_loss: 1.0959 - val_accuracy: 0.8006\n","{'loss': [0.49111658334732056, 0.4173741042613983, 0.40586715936660767, 0.40518102049827576, 0.4071982502937317, 0.39570364356040955, 0.3973119258880615, 0.3957536518573761, 0.40918606519699097, 0.3929147720336914, 0.3968481421470642, 0.3900566101074219, 0.39286932349205017, 0.3866371512413025, 0.386183500289917, 0.38611698150634766, 0.3866048753261566, 0.3844493627548218, 0.38473448157310486, 0.3856489360332489, 0.3854130506515503, 0.38027244806289673, 0.38532698154449463, 0.3938165009021759, 0.39515990018844604, 0.3803952932357788, 0.37863340973854065, 0.37948837876319885, 0.3775853216648102, 0.37949517369270325, 0.38184043765068054, 0.37906602025032043, 0.3767450153827667, 0.37278926372528076, 0.3737700283527374, 0.3753770589828491, 0.37343186140060425, 0.3820558190345764, 0.37336021661758423, 0.37143322825431824, 0.39679789543151855, 0.37879252433776855, 0.37073346972465515, 0.36953315138816833, 0.378833144903183, 0.37844404578208923, 0.3692868649959564, 0.3673125207424164, 0.36975187063217163, 0.37469416856765747, 0.3661806285381317, 0.36559993028640747, 0.36381644010543823, 0.36796995997428894, 0.36643755435943604, 0.36372673511505127, 0.37409183382987976, 0.36625099182128906, 0.36330440640449524, 0.36213093996047974, 0.3624277710914612, 0.3613632321357727, 0.3614135980606079, 0.3594285249710083, 0.3626512289047241, 0.3658411204814911, 0.3659883737564087, 0.3625756502151489, 0.36229854822158813, 0.3704943060874939, 0.3641221821308136, 0.35581809282302856, 0.35938459634780884, 0.3596254289150238, 0.36046797037124634, 0.354056179523468, 0.3531929850578308, 0.35693612694740295, 0.35316920280456543, 0.3560812771320343, 0.3529449701309204, 0.3517819344997406, 0.35199517011642456, 0.35214170813560486, 0.35191231966018677, 0.3582812547683716, 0.35083407163619995, 0.3499153256416321, 0.3558024764060974, 0.3492627441883087, 0.35691800713539124, 0.3516339957714081, 0.3480481207370758, 0.3465966284275055, 0.3498998284339905, 0.3449476361274719, 0.345798134803772, 0.3448925018310547, 0.35053306818008423, 0.3471481204032898], 'accuracy': [0.9493534564971924, 0.9814116358757019, 0.983027994632721, 0.9862607717514038, 0.9835668206214905, 0.9911099076271057, 0.9903017282485962, 0.9900323152542114, 0.9819504022598267, 0.9911099076271057, 0.9873383641242981, 0.9911099076271057, 0.990840494632721, 0.9948814511299133, 0.993534505367279, 0.9940732717514038, 0.993803858757019, 0.9919180870056152, 0.9913793206214905, 0.9943426847457886, 0.9921875, 0.9943426847457886, 0.990840494632721, 0.9881465435028076, 0.9865301847457886, 0.9924569129943848, 0.9951508641242981, 0.9932650923728943, 0.9956896305084229, 0.9929956793785095, 0.9903017282485962, 0.9919180870056152, 0.9932650923728943, 0.9970366358757019, 0.9954202771186829, 0.9921875, 0.9951508641242981, 0.9897629022598267, 0.9940732717514038, 0.9959590435028076, 0.9838362336158752, 0.990840494632721, 0.9962284564971924, 0.9962284564971924, 0.9911099076271057, 0.9903017282485962, 0.9954202771186829, 0.9959590435028076, 0.9940732717514038, 0.9911099076271057, 0.9959590435028076, 0.9954202771186829, 0.9962284564971924, 0.9929956793785095, 0.993803858757019, 0.9975754022598267, 0.9900323152542114, 0.9959590435028076, 0.9951508641242981, 0.9962284564971924, 0.9943426847457886, 0.9954202771186829, 0.9956896305084229, 0.9967672228813171, 0.993803858757019, 0.9921875, 0.9919180870056152, 0.9943426847457886, 0.993534505367279, 0.9892241358757019, 0.9940732717514038, 0.9959590435028076, 0.993803858757019, 0.9940732717514038, 0.9927262663841248, 0.9973060488700867, 0.9973060488700867, 0.9948814511299133, 0.9975754022598267, 0.9954202771186829, 0.9959590435028076, 0.9967672228813171, 0.9954202771186829, 0.9962284564971924, 0.9956896305084229, 0.990840494632721, 0.9951508641242981, 0.9962284564971924, 0.9927262663841248, 0.9954202771186829, 0.990840494632721, 0.9946120977401733, 0.9964978694915771, 0.9967672228813171, 0.9948814511299133, 0.9964978694915771, 0.9967672228813171, 0.9959590435028076, 0.9924569129943848, 0.993534505367279], 'val_loss': [1.0081422328948975, 0.9977937340736389, 0.9901170134544373, 0.9908811450004578, 0.9719924926757812, 0.9611945152282715, 0.9710381627082825, 0.9896568655967712, 0.9588095545768738, 0.9629865884780884, 0.9595942497253418, 0.9984384179115295, 0.9613199830055237, 0.9329895973205566, 0.9633336663246155, 0.9580762982368469, 0.9621575474739075, 0.9829764366149902, 0.9432079195976257, 0.9410571455955505, 0.9396504759788513, 0.9392540454864502, 0.9189074039459229, 1.0066256523132324, 0.9620128273963928, 0.9451391696929932, 0.945839524269104, 0.9441092014312744, 0.9607433676719666, 0.958300769329071, 0.9545127749443054, 0.995247483253479, 0.9704360365867615, 0.9706329107284546, 0.9737041592597961, 0.9910556674003601, 1.0171573162078857, 1.0204358100891113, 0.9816996455192566, 0.9870899319648743, 1.167665719985962, 1.0362532138824463, 1.001062035560608, 1.0262010097503662, 1.0766106843948364, 1.0129575729370117, 1.0235532522201538, 1.0140281915664673, 1.0138458013534546, 1.0810742378234863, 1.0290985107421875, 1.0284159183502197, 1.0281102657318115, 1.0362708568572998, 1.0263473987579346, 1.0617599487304688, 1.0452669858932495, 1.0498965978622437, 1.0327410697937012, 1.0525810718536377, 1.035640835762024, 1.046100378036499, 1.0492942333221436, 1.0557647943496704, 1.0912888050079346, 1.0573487281799316, 1.0895586013793945, 1.1325594186782837, 1.0499874353408813, 1.332990050315857, 1.0633963346481323, 1.0559078454971313, 1.064152717590332, 1.0593068599700928, 1.053800106048584, 1.0611732006072998, 1.0795347690582275, 1.115149974822998, 1.0871570110321045, 1.1020106077194214, 1.0585342645645142, 1.0710902214050293, 1.0788917541503906, 1.0826787948608398, 1.085758924484253, 1.0843063592910767, 1.080963373184204, 1.088724970817566, 1.1373403072357178, 1.0869247913360596, 1.086474061012268, 1.0927408933639526, 1.0834294557571411, 1.0959193706512451, 1.096624732017517, 1.0897021293640137, 1.1276133060455322, 1.1455519199371338, 1.1228446960449219, 1.0958517789840698], 'val_accuracy': [0.6454741358757019, 0.662715494632721, 0.6573275923728943, 0.6411637663841248, 0.6594827771186829, 0.681034505367279, 0.6616379022598267, 0.6346982717514038, 0.6745689511299133, 0.673491358757019, 0.6831896305084229, 0.662715494632721, 0.6928879022598267, 0.7068965435028076, 0.6993534564971924, 0.7155172228813171, 0.7230603694915771, 0.7230603694915771, 0.7532327771186829, 0.7629310488700867, 0.7758620977401733, 0.7834051847457886, 0.8006465435028076, 0.7941810488700867, 0.8006465435028076, 0.8092672228813171, 0.818965494632721, 0.8211206793785095, 0.8221982717514038, 0.8221982717514038, 0.829741358757019, 0.8157327771186829, 0.8178879022598267, 0.8200430870056152, 0.8254310488700867, 0.8178879022598267, 0.8071120977401733, 0.8071120977401733, 0.8232758641242981, 0.8178879022598267, 0.7887930870056152, 0.8049569129943848, 0.8232758641242981, 0.8157327771186829, 0.7974137663841248, 0.8211206793785095, 0.8135775923728943, 0.8103448152542114, 0.8135775923728943, 0.8006465435028076, 0.8092672228813171, 0.8178879022598267, 0.8103448152542114, 0.8157327771186829, 0.8221982717514038, 0.8017241358757019, 0.8071120977401733, 0.8135775923728943, 0.8125, 0.8017241358757019, 0.8146551847457886, 0.8103448152542114, 0.8125, 0.806034505367279, 0.798491358757019, 0.8071120977401733, 0.8017241358757019, 0.7898706793785095, 0.806034505367279, 0.7586206793785095, 0.8006465435028076, 0.8114224076271057, 0.8028017282485962, 0.7995689511299133, 0.8038793206214905, 0.8038793206214905, 0.7995689511299133, 0.7887930870056152, 0.8028017282485962, 0.7909482717514038, 0.8049569129943848, 0.8081896305084229, 0.8049569129943848, 0.8071120977401733, 0.8038793206214905, 0.7941810488700867, 0.8049569129943848, 0.7974137663841248, 0.7931034564971924, 0.7995689511299133, 0.8006465435028076, 0.8028017282485962, 0.7963362336158752, 0.7931034564971924, 0.8028017282485962, 0.8114224076271057, 0.7866379022598267, 0.7887930870056152, 0.7909482717514038, 0.8006465435028076]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 31ms/step - loss: 0.4696 - accuracy: 0.9559 - val_loss: 1.0013 - val_accuracy: 0.6527\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.3813 - accuracy: 1.0000"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 19ms/step - loss: 0.4116 - accuracy: 0.9827 - val_loss: 0.9950 - val_accuracy: 0.6538\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4013 - accuracy: 0.9890 - val_loss: 0.9851 - val_accuracy: 0.6833\n","Epoch 4/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3960 - accuracy: 0.9890 - val_loss: 0.9785 - val_accuracy: 0.6753\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3952 - accuracy: 0.9926 - val_loss: 0.9690 - val_accuracy: 0.6912\n","Epoch 6/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3934 - accuracy: 0.9918 - val_loss: 0.9704 - val_accuracy: 0.6731\n","Epoch 7/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4030 - accuracy: 0.9847 - val_loss: 0.9586 - val_accuracy: 0.6878\n","Epoch 8/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3922 - accuracy: 0.9935 - val_loss: 0.9437 - val_accuracy: 0.7002\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3948 - accuracy: 0.9890 - val_loss: 0.9348 - val_accuracy: 0.6946\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3961 - accuracy: 0.9878 - val_loss: 0.9554 - val_accuracy: 0.6855\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3879 - accuracy: 0.9932 - val_loss: 0.9351 - val_accuracy: 0.7048\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3860 - accuracy: 0.9926 - val_loss: 0.9372 - val_accuracy: 0.7081\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3925 - accuracy: 0.9878 - val_loss: 0.9301 - val_accuracy: 0.7149\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3864 - accuracy: 0.9935 - val_loss: 0.9317 - val_accuracy: 0.7195\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3860 - accuracy: 0.9926 - val_loss: 0.9255 - val_accuracy: 0.7330\n","Epoch 16/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3834 - accuracy: 0.9932 - val_loss: 0.9524 - val_accuracy: 0.7229\n","Epoch 17/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3829 - accuracy: 0.9938 - val_loss: 0.9704 - val_accuracy: 0.7319\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3838 - accuracy: 0.9924 - val_loss: 0.9578 - val_accuracy: 0.7410\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3841 - accuracy: 0.9918 - val_loss: 0.9265 - val_accuracy: 0.7579\n","Epoch 20/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3822 - accuracy: 0.9926 - val_loss: 0.9284 - val_accuracy: 0.7590\n","Epoch 21/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.9929 - val_loss: 0.9561 - val_accuracy: 0.7749\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3820 - accuracy: 0.9935 - val_loss: 0.9389 - val_accuracy: 0.7771\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3849 - accuracy: 0.9909 - val_loss: 0.9533 - val_accuracy: 0.7964\n","Epoch 24/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3876 - accuracy: 0.9892 - val_loss: 1.0133 - val_accuracy: 0.7636\n","Epoch 25/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3852 - accuracy: 0.9901 - val_loss: 1.0066 - val_accuracy: 0.7907\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3812 - accuracy: 0.9926 - val_loss: 0.9161 - val_accuracy: 0.8111\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3815 - accuracy: 0.9935 - val_loss: 0.9336 - val_accuracy: 0.8179\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3774 - accuracy: 0.9926 - val_loss: 0.8954 - val_accuracy: 0.8201\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3850 - accuracy: 0.9898 - val_loss: 1.0290 - val_accuracy: 0.8032\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3905 - accuracy: 0.9861 - val_loss: 0.9194 - val_accuracy: 0.8122\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3830 - accuracy: 0.9909 - val_loss: 0.9035 - val_accuracy: 0.8258\n","Epoch 32/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3949 - accuracy: 0.9864 - val_loss: 1.0190 - val_accuracy: 0.8009\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3769 - accuracy: 0.9926 - val_loss: 0.9325 - val_accuracy: 0.8258\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3718 - accuracy: 0.9955 - val_loss: 0.9110 - val_accuracy: 0.8247\n","Epoch 35/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3734 - accuracy: 0.9935 - val_loss: 0.9285 - val_accuracy: 0.8213\n","Epoch 36/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3725 - accuracy: 0.9949 - val_loss: 0.9196 - val_accuracy: 0.8281\n","Epoch 37/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3715 - accuracy: 0.9935 - val_loss: 0.9284 - val_accuracy: 0.8235\n","Epoch 38/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3733 - accuracy: 0.9932 - val_loss: 0.9411 - val_accuracy: 0.8190\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3715 - accuracy: 0.9941 - val_loss: 0.9315 - val_accuracy: 0.8133\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.9966 - val_loss: 0.9533 - val_accuracy: 0.8224\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3684 - accuracy: 0.9958 - val_loss: 0.9354 - val_accuracy: 0.8247\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3690 - accuracy: 0.9958 - val_loss: 0.9321 - val_accuracy: 0.8235\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3730 - accuracy: 0.9932 - val_loss: 0.9373 - val_accuracy: 0.8269\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3734 - accuracy: 0.9918 - val_loss: 0.9603 - val_accuracy: 0.8111\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3728 - accuracy: 0.9932 - val_loss: 0.9371 - val_accuracy: 0.8213\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3675 - accuracy: 0.9949 - val_loss: 1.0247 - val_accuracy: 0.8133\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3677 - accuracy: 0.9935 - val_loss: 0.9624 - val_accuracy: 0.8088\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3692 - accuracy: 0.9949 - val_loss: 0.9822 - val_accuracy: 0.8133\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3646 - accuracy: 0.9955 - val_loss: 0.9468 - val_accuracy: 0.8201\n","Epoch 50/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.9901 - val_loss: 0.9627 - val_accuracy: 0.8088\n","Epoch 51/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4077 - accuracy: 0.9748 - val_loss: 1.0154 - val_accuracy: 0.8054\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3735 - accuracy: 0.9918 - val_loss: 0.9853 - val_accuracy: 0.8077\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3634 - accuracy: 0.9952 - val_loss: 0.9589 - val_accuracy: 0.8190\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3638 - accuracy: 0.9952 - val_loss: 0.9609 - val_accuracy: 0.8156\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3617 - accuracy: 0.9966 - val_loss: 0.9687 - val_accuracy: 0.8190\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3622 - accuracy: 0.9952 - val_loss: 0.9966 - val_accuracy: 0.8156\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3702 - accuracy: 0.9915 - val_loss: 1.0676 - val_accuracy: 0.7998\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3689 - accuracy: 0.9943 - val_loss: 0.9810 - val_accuracy: 0.8088\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3647 - accuracy: 0.9941 - val_loss: 0.9787 - val_accuracy: 0.8122\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3596 - accuracy: 0.9966 - val_loss: 0.9707 - val_accuracy: 0.8133\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3668 - accuracy: 0.9929 - val_loss: 1.0125 - val_accuracy: 0.7964\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3626 - accuracy: 0.9935 - val_loss: 0.9901 - val_accuracy: 0.8100\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3594 - accuracy: 0.9958 - val_loss: 0.9706 - val_accuracy: 0.8201\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3583 - accuracy: 0.9955 - val_loss: 0.9886 - val_accuracy: 0.8111\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3682 - accuracy: 0.9904 - val_loss: 0.9931 - val_accuracy: 0.8133\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3644 - accuracy: 0.9909 - val_loss: 1.0107 - val_accuracy: 0.8156\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 0.9941 - val_loss: 1.0012 - val_accuracy: 0.8111\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3581 - accuracy: 0.9960 - val_loss: 0.9980 - val_accuracy: 0.8213\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3562 - accuracy: 0.9963 - val_loss: 1.0265 - val_accuracy: 0.7998\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3874 - accuracy: 0.9791 - val_loss: 1.5497 - val_accuracy: 0.7432\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3884 - accuracy: 0.9788 - val_loss: 1.0301 - val_accuracy: 0.7919\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3591 - accuracy: 0.9949 - val_loss: 0.9896 - val_accuracy: 0.8122\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3550 - accuracy: 0.9966 - val_loss: 0.9875 - val_accuracy: 0.8145\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3546 - accuracy: 0.9958 - val_loss: 0.9947 - val_accuracy: 0.8145\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3559 - accuracy: 0.9943 - val_loss: 0.9946 - val_accuracy: 0.8156\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3543 - accuracy: 0.9952 - val_loss: 0.9910 - val_accuracy: 0.8213\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3534 - accuracy: 0.9955 - val_loss: 1.0043 - val_accuracy: 0.8145\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3535 - accuracy: 0.9958 - val_loss: 0.9969 - val_accuracy: 0.8179\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3522 - accuracy: 0.9960 - val_loss: 1.0036 - val_accuracy: 0.8190\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3522 - accuracy: 0.9955 - val_loss: 1.0067 - val_accuracy: 0.8145\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3521 - accuracy: 0.9952 - val_loss: 0.9961 - val_accuracy: 0.8190\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3551 - accuracy: 0.9952 - val_loss: 1.0200 - val_accuracy: 0.8100\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3512 - accuracy: 0.9955 - val_loss: 1.0086 - val_accuracy: 0.8032\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3529 - accuracy: 0.9958 - val_loss: 1.0723 - val_accuracy: 0.7862\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3658 - accuracy: 0.9887 - val_loss: 1.0363 - val_accuracy: 0.7998\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3614 - accuracy: 0.9909 - val_loss: 1.0275 - val_accuracy: 0.8122\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3494 - accuracy: 0.9966 - val_loss: 1.0327 - val_accuracy: 0.8100\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3508 - accuracy: 0.9958 - val_loss: 1.0468 - val_accuracy: 0.8043\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3551 - accuracy: 0.9924 - val_loss: 1.1295 - val_accuracy: 0.7828\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3507 - accuracy: 0.9952 - val_loss: 1.0213 - val_accuracy: 0.8088\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3513 - accuracy: 0.9946 - val_loss: 1.1212 - val_accuracy: 0.7862\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3605 - accuracy: 0.9904 - val_loss: 1.0378 - val_accuracy: 0.8054\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3516 - accuracy: 0.9946 - val_loss: 1.0288 - val_accuracy: 0.8111\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3490 - accuracy: 0.9955 - val_loss: 1.0257 - val_accuracy: 0.8100\n","Epoch 95/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3484 - accuracy: 0.9949 - val_loss: 1.0505 - val_accuracy: 0.8077\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3486 - accuracy: 0.9955 - val_loss: 1.0959 - val_accuracy: 0.7975\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3475 - accuracy: 0.9960 - val_loss: 1.0368 - val_accuracy: 0.8066\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3473 - accuracy: 0.9975 - val_loss: 1.0398 - val_accuracy: 0.8100\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3438 - accuracy: 0.9975 - val_loss: 1.0673 - val_accuracy: 0.7964\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3522 - accuracy: 0.9921 - val_loss: 1.0438 - val_accuracy: 0.8077\n","{'loss': [0.46961063146591187, 0.411632776260376, 0.40134620666503906, 0.39596793055534363, 0.3952185809612274, 0.39344918727874756, 0.4030437767505646, 0.3922109007835388, 0.3947945535182953, 0.39612460136413574, 0.38785335421562195, 0.38599899411201477, 0.39247000217437744, 0.38635095953941345, 0.3859904408454895, 0.38336288928985596, 0.3828555643558502, 0.3838273584842682, 0.3841409981250763, 0.38217926025390625, 0.3840586543083191, 0.38199490308761597, 0.38486048579216003, 0.38760611414909363, 0.38520264625549316, 0.3811573088169098, 0.38153135776519775, 0.3774362802505493, 0.3849841356277466, 0.3904672861099243, 0.38297274708747864, 0.39492055773735046, 0.37693464756011963, 0.3717518746852875, 0.37339314818382263, 0.3724510371685028, 0.3715153932571411, 0.37332168221473694, 0.3715243935585022, 0.3700525462627411, 0.36837026476860046, 0.3689563572406769, 0.37302902340888977, 0.37343475222587585, 0.3728411793708801, 0.3675491511821747, 0.36768418550491333, 0.36922621726989746, 0.3646179735660553, 0.3705044984817505, 0.4076980948448181, 0.3734826445579529, 0.3634432256221771, 0.36381131410598755, 0.36171966791152954, 0.362214595079422, 0.37019315361976624, 0.3689253628253937, 0.36474645137786865, 0.35962149500846863, 0.3668058514595032, 0.36264026165008545, 0.3594498932361603, 0.35828420519828796, 0.3681519031524658, 0.36440229415893555, 0.359108030796051, 0.3580513000488281, 0.3562298119068146, 0.3873600959777832, 0.38835519552230835, 0.3591197431087494, 0.3550030291080475, 0.3545700013637543, 0.3559059202671051, 0.3543136715888977, 0.3533756732940674, 0.35350167751312256, 0.35219481587409973, 0.3522372245788574, 0.35212036967277527, 0.35509759187698364, 0.3512323796749115, 0.3528865873813629, 0.3658275008201599, 0.36142659187316895, 0.34938308596611023, 0.3508363664150238, 0.3550780415534973, 0.35066017508506775, 0.3513070046901703, 0.36054614186286926, 0.3515615463256836, 0.3490068018436432, 0.34843629598617554, 0.34861108660697937, 0.3475320339202881, 0.3472941815853119, 0.34384170174598694, 0.352227121591568], 'accuracy': [0.9558573961257935, 0.9827390909194946, 0.988964319229126, 0.988964319229126, 0.992642879486084, 0.9917939901351929, 0.9847198724746704, 0.9934917688369751, 0.988964319229126, 0.9878324866294861, 0.9932088255882263, 0.992642879486084, 0.9878324866294861, 0.9934917688369751, 0.992642879486084, 0.9932088255882263, 0.9937747716903687, 0.9923599362373352, 0.9917939901351929, 0.992642879486084, 0.9929258823394775, 0.9934917688369751, 0.9909451007843018, 0.9892473220825195, 0.9900962114334106, 0.992642879486084, 0.9934917688369751, 0.992642879486084, 0.9898132681846619, 0.9861347079277039, 0.9909451007843018, 0.9864176511764526, 0.992642879486084, 0.9954725503921509, 0.9934917688369751, 0.9949066042900085, 0.9934917688369751, 0.9932088255882263, 0.9940577149391174, 0.9966044425964355, 0.9957554936408997, 0.9957554936408997, 0.9932088255882263, 0.9917939901351929, 0.9932088255882263, 0.9949066042900085, 0.9934917688369751, 0.9949066042900085, 0.9954725503921509, 0.9900962114334106, 0.974816083908081, 0.9917939901351929, 0.9951896071434021, 0.9951896071434021, 0.9966044425964355, 0.9951896071434021, 0.9915110468864441, 0.994340717792511, 0.9940577149391174, 0.9966044425964355, 0.9929258823394775, 0.9934917688369751, 0.9957554936408997, 0.9954725503921509, 0.9903791546821594, 0.9909451007843018, 0.9940577149391174, 0.9960384964942932, 0.996321439743042, 0.9790605306625366, 0.9787775874137878, 0.9949066042900085, 0.9966044425964355, 0.9957554936408997, 0.994340717792511, 0.9951896071434021, 0.9954725503921509, 0.9957554936408997, 0.9960384964942932, 0.9954725503921509, 0.9951896071434021, 0.9951896071434021, 0.9954725503921509, 0.9957554936408997, 0.9886813759803772, 0.9909451007843018, 0.9966044425964355, 0.9957554936408997, 0.9923599362373352, 0.9951896071434021, 0.9946236610412598, 0.9903791546821594, 0.9946236610412598, 0.9954725503921509, 0.9949066042900085, 0.9954725503921509, 0.9960384964942932, 0.9974533319473267, 0.9974533319473267, 0.9920769929885864], 'val_loss': [1.0013210773468018, 0.9950335621833801, 0.9850627779960632, 0.9785076379776001, 0.9689707159996033, 0.9704493284225464, 0.9586174488067627, 0.9436562061309814, 0.9348141551017761, 0.9554080963134766, 0.9350634813308716, 0.9372245073318481, 0.9300671815872192, 0.9316924810409546, 0.925546407699585, 0.9524401426315308, 0.9704106450080872, 0.9578095078468323, 0.9265055060386658, 0.9284475445747375, 0.9561379551887512, 0.9389257431030273, 0.9532920122146606, 1.0132951736450195, 1.0066057443618774, 0.9161303043365479, 0.9336360692977905, 0.8953544497489929, 1.0290260314941406, 0.9194437861442566, 0.9034615755081177, 1.019018292427063, 0.9324716329574585, 0.9110423922538757, 0.9285168051719666, 0.9196147918701172, 0.9283625483512878, 0.9410821795463562, 0.9314925074577332, 0.9533178210258484, 0.9353507161140442, 0.9320745468139648, 0.9372649788856506, 0.9603233337402344, 0.9370640516281128, 1.0247160196304321, 0.962407112121582, 0.9821871519088745, 0.9468346238136292, 0.962710976600647, 1.0153918266296387, 0.9853275418281555, 0.9589216709136963, 0.9608635306358337, 0.9687076210975647, 0.9965549111366272, 1.0676429271697998, 0.9810115098953247, 0.9787270426750183, 0.9706712961196899, 1.0124573707580566, 0.9900570511817932, 0.9706140160560608, 0.9885762333869934, 0.9930558204650879, 1.0107061862945557, 1.0011812448501587, 0.9979907274246216, 1.0265082120895386, 1.549731969833374, 1.030091404914856, 0.9895882606506348, 0.9874529838562012, 0.9947206377983093, 0.9945716261863708, 0.9909865856170654, 1.0043363571166992, 0.9968546628952026, 1.0036113262176514, 1.0066794157028198, 0.9960589408874512, 1.0200210809707642, 1.0085691213607788, 1.0723105669021606, 1.0362802743911743, 1.0274509191513062, 1.0327149629592896, 1.0468189716339111, 1.129535436630249, 1.0212669372558594, 1.1212283372879028, 1.0377706289291382, 1.0288270711898804, 1.02571702003479, 1.0504528284072876, 1.0958667993545532, 1.0367811918258667, 1.0397776365280151, 1.0673131942749023, 1.0437828302383423], 'val_accuracy': [0.6527149081230164, 0.6538461446762085, 0.6832579374313354, 0.6753393411636353, 0.6911764740943909, 0.6730769276618958, 0.6877828240394592, 0.7002262473106384, 0.6945701241493225, 0.685520350933075, 0.7047511339187622, 0.7081447839736938, 0.7149321436882019, 0.7194570302963257, 0.733031690120697, 0.7228506803512573, 0.7319004535675049, 0.7409502267837524, 0.7579185366630554, 0.7590497732162476, 0.7748869061470032, 0.7771493196487427, 0.7963801026344299, 0.7635746598243713, 0.790723979473114, 0.8110859990119934, 0.8178732991218567, 0.820135772228241, 0.8031674027442932, 0.8122171759605408, 0.8257918357849121, 0.8009049892425537, 0.8257918357849121, 0.8246606588363647, 0.8212669491767883, 0.8280543088912964, 0.8235294222831726, 0.8190045356750488, 0.8133484125137329, 0.8223981857299805, 0.8246606588363647, 0.8235294222831726, 0.8269230723381042, 0.8110859990119934, 0.8212669491767883, 0.8133484125137329, 0.8088235259056091, 0.8133484125137329, 0.820135772228241, 0.8088235259056091, 0.8054298758506775, 0.807692289352417, 0.8190045356750488, 0.8156108856201172, 0.8190045356750488, 0.8156108856201172, 0.7997737526893616, 0.8088235259056091, 0.8122171759605408, 0.8133484125137329, 0.7963801026344299, 0.8099547624588013, 0.820135772228241, 0.8110859990119934, 0.8133484125137329, 0.8156108856201172, 0.8110859990119934, 0.8212669491767883, 0.7997737526893616, 0.7432126402854919, 0.7918552160263062, 0.8122171759605408, 0.814479649066925, 0.814479649066925, 0.8156108856201172, 0.8212669491767883, 0.814479649066925, 0.8178732991218567, 0.8190045356750488, 0.814479649066925, 0.8190045356750488, 0.8099547624588013, 0.8031674027442932, 0.7861990928649902, 0.7997737526893616, 0.8122171759605408, 0.8099547624588013, 0.8042986392974854, 0.7828054428100586, 0.8088235259056091, 0.7861990928649902, 0.8054298758506775, 0.8110859990119934, 0.8099547624588013, 0.807692289352417, 0.7975113391876221, 0.8065611124038696, 0.8099547624588013, 0.7963801026344299, 0.807692289352417]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 28ms/step - loss: 0.4643 - accuracy: 0.9571 - val_loss: 1.0088 - val_accuracy: 0.6209\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.4323 - accuracy: 0.9609"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 16ms/step - loss: 0.4371 - accuracy: 0.9693 - val_loss: 1.0020 - val_accuracy: 0.6219\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4179 - accuracy: 0.9817 - val_loss: 0.9881 - val_accuracy: 0.6488\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4136 - accuracy: 0.9819 - val_loss: 0.9804 - val_accuracy: 0.6519\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4275 - accuracy: 0.9729 - val_loss: 0.9785 - val_accuracy: 0.6446\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.9829 - val_loss: 0.9728 - val_accuracy: 0.6457\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4026 - accuracy: 0.9899 - val_loss: 0.9828 - val_accuracy: 0.6364\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4169 - accuracy: 0.9793 - val_loss: 0.9739 - val_accuracy: 0.6508\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4070 - accuracy: 0.9842 - val_loss: 0.9651 - val_accuracy: 0.6601\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.9871 - val_loss: 0.9797 - val_accuracy: 0.6560\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3999 - accuracy: 0.9889 - val_loss: 0.9769 - val_accuracy: 0.6612\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4012 - accuracy: 0.9853 - val_loss: 0.9652 - val_accuracy: 0.6870\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4089 - accuracy: 0.9822 - val_loss: 1.0228 - val_accuracy: 0.6684\n","Epoch 14/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3990 - accuracy: 0.9879 - val_loss: 0.9875 - val_accuracy: 0.6870\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3956 - accuracy: 0.9894 - val_loss: 0.9602 - val_accuracy: 0.7087\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4059 - accuracy: 0.9824 - val_loss: 1.2470 - val_accuracy: 0.6446\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4073 - accuracy: 0.9798 - val_loss: 1.0052 - val_accuracy: 0.7221\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3953 - accuracy: 0.9884 - val_loss: 0.9561 - val_accuracy: 0.7541\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3982 - accuracy: 0.9886 - val_loss: 1.0458 - val_accuracy: 0.7304\n","Epoch 20/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4019 - accuracy: 0.9835 - val_loss: 1.1249 - val_accuracy: 0.7242\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3980 - accuracy: 0.9855 - val_loss: 0.9727 - val_accuracy: 0.7810\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3902 - accuracy: 0.9920 - val_loss: 0.9494 - val_accuracy: 0.8006\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3908 - accuracy: 0.9910 - val_loss: 0.9622 - val_accuracy: 0.8079\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3982 - accuracy: 0.9837 - val_loss: 0.9768 - val_accuracy: 0.7975\n","Epoch 25/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3887 - accuracy: 0.9925 - val_loss: 0.9653 - val_accuracy: 0.8068\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3874 - accuracy: 0.9917 - val_loss: 0.9731 - val_accuracy: 0.8079\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3857 - accuracy: 0.9907 - val_loss: 0.9700 - val_accuracy: 0.8037\n","Epoch 28/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3855 - accuracy: 0.9920 - val_loss: 1.0383 - val_accuracy: 0.7944\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3876 - accuracy: 0.9910 - val_loss: 0.9934 - val_accuracy: 0.8099\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.9897 - val_loss: 1.0229 - val_accuracy: 0.8006\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3878 - accuracy: 0.9904 - val_loss: 1.0070 - val_accuracy: 0.8079\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3850 - accuracy: 0.9920 - val_loss: 1.0510 - val_accuracy: 0.7975\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3962 - accuracy: 0.9837 - val_loss: 1.1903 - val_accuracy: 0.7707\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4240 - accuracy: 0.9700 - val_loss: 1.0820 - val_accuracy: 0.7882\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4131 - accuracy: 0.9778 - val_loss: 1.0378 - val_accuracy: 0.8099\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.9879 - val_loss: 1.0103 - val_accuracy: 0.8006\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3849 - accuracy: 0.9902 - val_loss: 1.0266 - val_accuracy: 0.8068\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3891 - accuracy: 0.9863 - val_loss: 1.0278 - val_accuracy: 0.8110\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3819 - accuracy: 0.9920 - val_loss: 1.0286 - val_accuracy: 0.8017\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3855 - accuracy: 0.9886 - val_loss: 1.0725 - val_accuracy: 0.7975\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3872 - accuracy: 0.9879 - val_loss: 1.0424 - val_accuracy: 0.8048\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3808 - accuracy: 0.9904 - val_loss: 1.0485 - val_accuracy: 0.8006\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3805 - accuracy: 0.9902 - val_loss: 1.0282 - val_accuracy: 0.8068\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3930 - accuracy: 0.9827 - val_loss: 1.0311 - val_accuracy: 0.8079\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3787 - accuracy: 0.9915 - val_loss: 1.0453 - val_accuracy: 0.7996\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3788 - accuracy: 0.9897 - val_loss: 1.0422 - val_accuracy: 0.7975\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3797 - accuracy: 0.9904 - val_loss: 1.1044 - val_accuracy: 0.7975\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3814 - accuracy: 0.9884 - val_loss: 1.0365 - val_accuracy: 0.8099\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3802 - accuracy: 0.9891 - val_loss: 1.0430 - val_accuracy: 0.8037\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3772 - accuracy: 0.9899 - val_loss: 1.0491 - val_accuracy: 0.8037\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3741 - accuracy: 0.9920 - val_loss: 1.0474 - val_accuracy: 0.8017\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3800 - accuracy: 0.9889 - val_loss: 1.0451 - val_accuracy: 0.7996\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3757 - accuracy: 0.9902 - val_loss: 1.0536 - val_accuracy: 0.7944\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3756 - accuracy: 0.9902 - val_loss: 1.0637 - val_accuracy: 0.8027\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3776 - accuracy: 0.9897 - val_loss: 1.0524 - val_accuracy: 0.8048\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3713 - accuracy: 0.9946 - val_loss: 1.0982 - val_accuracy: 0.7872\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3841 - accuracy: 0.9881 - val_loss: 1.1032 - val_accuracy: 0.7996\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3751 - accuracy: 0.9904 - val_loss: 1.1500 - val_accuracy: 0.7831\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3735 - accuracy: 0.9912 - val_loss: 1.0851 - val_accuracy: 0.7975\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3795 - accuracy: 0.9879 - val_loss: 1.0907 - val_accuracy: 0.7913\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3711 - accuracy: 0.9920 - val_loss: 1.0751 - val_accuracy: 0.8017\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3773 - accuracy: 0.9873 - val_loss: 1.0688 - val_accuracy: 0.8058\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3791 - accuracy: 0.9871 - val_loss: 1.0894 - val_accuracy: 0.8037\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3688 - accuracy: 0.9946 - val_loss: 1.0727 - val_accuracy: 0.7996\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3678 - accuracy: 0.9930 - val_loss: 1.1227 - val_accuracy: 0.7810\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3744 - accuracy: 0.9891 - val_loss: 1.1882 - val_accuracy: 0.7789\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3702 - accuracy: 0.9922 - val_loss: 1.0625 - val_accuracy: 0.8058\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3675 - accuracy: 0.9930 - val_loss: 1.0694 - val_accuracy: 0.8079\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3667 - accuracy: 0.9928 - val_loss: 1.1180 - val_accuracy: 0.7831\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3680 - accuracy: 0.9925 - val_loss: 1.0839 - val_accuracy: 0.7986\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.9935 - val_loss: 1.0848 - val_accuracy: 0.7955\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.9922 - val_loss: 1.1131 - val_accuracy: 0.7903\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3632 - accuracy: 0.9948 - val_loss: 1.0831 - val_accuracy: 0.8037\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3655 - accuracy: 0.9933 - val_loss: 1.0887 - val_accuracy: 0.7996\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3660 - accuracy: 0.9930 - val_loss: 1.1701 - val_accuracy: 0.7831\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3853 - accuracy: 0.9819 - val_loss: 1.2122 - val_accuracy: 0.7738\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.9881 - val_loss: 1.0817 - val_accuracy: 0.8099\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.9941 - val_loss: 1.0993 - val_accuracy: 0.7955\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3619 - accuracy: 0.9951 - val_loss: 1.1752 - val_accuracy: 0.7789\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3629 - accuracy: 0.9938 - val_loss: 1.0965 - val_accuracy: 0.7996\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3731 - accuracy: 0.9873 - val_loss: 1.1107 - val_accuracy: 0.8027\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3878 - accuracy: 0.9788 - val_loss: 1.2474 - val_accuracy: 0.7758\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3751 - accuracy: 0.9863 - val_loss: 1.1810 - val_accuracy: 0.7851\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3649 - accuracy: 0.9907 - val_loss: 1.1192 - val_accuracy: 0.7924\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3590 - accuracy: 0.9951 - val_loss: 1.2249 - val_accuracy: 0.7738\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3851 - accuracy: 0.9773 - val_loss: 1.2052 - val_accuracy: 0.7676\n","Epoch 87/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3805 - accuracy: 0.9829 - val_loss: 1.2227 - val_accuracy: 0.7738\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3632 - accuracy: 0.9902 - val_loss: 1.1618 - val_accuracy: 0.7779\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3569 - accuracy: 0.9951 - val_loss: 1.1197 - val_accuracy: 0.7955\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.9930 - val_loss: 1.1474 - val_accuracy: 0.7831\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3654 - accuracy: 0.9897 - val_loss: 1.1353 - val_accuracy: 0.7924\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3673 - accuracy: 0.9879 - val_loss: 1.1414 - val_accuracy: 0.7903\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3616 - accuracy: 0.9904 - val_loss: 1.1590 - val_accuracy: 0.7831\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3550 - accuracy: 0.9946 - val_loss: 1.1246 - val_accuracy: 0.7944\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3593 - accuracy: 0.9912 - val_loss: 1.1332 - val_accuracy: 0.7893\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.9946 - val_loss: 1.1517 - val_accuracy: 0.7831\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3547 - accuracy: 0.9941 - val_loss: 1.1927 - val_accuracy: 0.7851\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3606 - accuracy: 0.9899 - val_loss: 1.1244 - val_accuracy: 0.7893\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3841 - accuracy: 0.9780 - val_loss: 1.3724 - val_accuracy: 0.7417\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3720 - accuracy: 0.9842 - val_loss: 1.1477 - val_accuracy: 0.7893\n","{'loss': [0.4643392264842987, 0.43710240721702576, 0.4179234206676483, 0.4136009216308594, 0.4274906814098358, 0.40989381074905396, 0.4025513827800751, 0.41691911220550537, 0.40695759654045105, 0.4016936719417572, 0.39993512630462646, 0.40123358368873596, 0.40891358256340027, 0.39904075860977173, 0.39564451575279236, 0.4059026837348938, 0.4072958528995514, 0.3952901363372803, 0.39822131395339966, 0.4018990099430084, 0.3979559540748596, 0.3902091383934021, 0.39078521728515625, 0.3982321321964264, 0.38867929577827454, 0.3874110281467438, 0.3856986165046692, 0.3854874074459076, 0.3875997066497803, 0.388444185256958, 0.3877830505371094, 0.3850133717060089, 0.3961676061153412, 0.4239833354949951, 0.41306403279304504, 0.3897125720977783, 0.38493987917900085, 0.3890968859195709, 0.3819419741630554, 0.3855460584163666, 0.38724687695503235, 0.380761057138443, 0.3804546594619751, 0.39299890398979187, 0.37872013449668884, 0.3787974417209625, 0.37974753975868225, 0.3813796043395996, 0.38024666905403137, 0.37718597054481506, 0.3741081953048706, 0.37996068596839905, 0.37567824125289917, 0.3755694627761841, 0.37756258249282837, 0.37126365303993225, 0.38414135575294495, 0.3750590682029724, 0.37352049350738525, 0.37950950860977173, 0.3710534870624542, 0.3772951066493988, 0.3790946304798126, 0.3687925338745117, 0.36775797605514526, 0.3744480609893799, 0.3702465891838074, 0.36749836802482605, 0.36670389771461487, 0.3679615557193756, 0.36520713567733765, 0.36827731132507324, 0.36322203278541565, 0.36546316742897034, 0.3660069406032562, 0.3852883577346802, 0.36963319778442383, 0.3639565706253052, 0.3619391620159149, 0.3628625273704529, 0.37307530641555786, 0.38784921169281006, 0.37505602836608887, 0.3649047911167145, 0.35902145504951477, 0.3851371109485626, 0.38051101565361023, 0.363240122795105, 0.356888085603714, 0.3590174615383148, 0.3653537631034851, 0.36732274293899536, 0.3615889549255371, 0.3549509644508362, 0.3593407869338989, 0.35392141342163086, 0.3547344207763672, 0.36055120825767517, 0.38405123353004456, 0.37202176451683044], 'accuracy': [0.9571059346199036, 0.9692506194114685, 0.9816537499427795, 0.9819121360778809, 0.9728682041168213, 0.9829457402229309, 0.9899224638938904, 0.9793281555175781, 0.9842377305030823, 0.9870800971984863, 0.9888888597488403, 0.9852713346481323, 0.9821705222129822, 0.9878553152084351, 0.9894056916236877, 0.9824289679527283, 0.9798449873924255, 0.9883720874786377, 0.988630473613739, 0.9834625124931335, 0.9855297207832336, 0.9919896721839905, 0.9909560680389404, 0.9837209582328796, 0.9925064444541931, 0.9917312860488892, 0.9906976819038391, 0.9919896721839905, 0.9909560680389404, 0.9896640777587891, 0.9904392957687378, 0.9919896721839905, 0.9837209582328796, 0.9700258374214172, 0.9777777791023254, 0.9878553152084351, 0.9901808500289917, 0.9863049387931824, 0.9919896721839905, 0.988630473613739, 0.9878553152084351, 0.9904392957687378, 0.9901808500289917, 0.9826873540878296, 0.9914728403091431, 0.9896640777587891, 0.9904392957687378, 0.9883720874786377, 0.9891473054885864, 0.9899224638938904, 0.9919896721839905, 0.9888888597488403, 0.9901808500289917, 0.9901808500289917, 0.9896640777587891, 0.9945736527442932, 0.9881137013435364, 0.9904392957687378, 0.9912144541740417, 0.9878553152084351, 0.9919896721839905, 0.9873384833335876, 0.9870800971984863, 0.9945736527442932, 0.9930232763290405, 0.9891473054885864, 0.9922480583190918, 0.9930232763290405, 0.9927648305892944, 0.9925064444541931, 0.9935400485992432, 0.9922480583190918, 0.9948320388793945, 0.9932816624641418, 0.9930232763290405, 0.9819121360778809, 0.9881137013435364, 0.9940568208694458, 0.9950904250144958, 0.9937984347343445, 0.9873384833335876, 0.9788113832473755, 0.9863049387931824, 0.9906976819038391, 0.9950904250144958, 0.9772610068321228, 0.9829457402229309, 0.9901808500289917, 0.9950904250144958, 0.9930232763290405, 0.9896640777587891, 0.9878553152084351, 0.9904392957687378, 0.9945736527442932, 0.9912144541740417, 0.9945736527442932, 0.9940568208694458, 0.9899224638938904, 0.9780361652374268, 0.9842377305030823], 'val_loss': [1.0088099241256714, 1.0019772052764893, 0.988144040107727, 0.9804150462150574, 0.9784804582595825, 0.9728187322616577, 0.9827991724014282, 0.9739454984664917, 0.9651366472244263, 0.9796774387359619, 0.9769425988197327, 0.9651780724525452, 1.0228036642074585, 0.9874610304832458, 0.960213840007782, 1.2469606399536133, 1.0051946640014648, 0.9560922384262085, 1.0457522869110107, 1.124912142753601, 0.9727268815040588, 0.9493547677993774, 0.9621894955635071, 0.9768392443656921, 0.9652974009513855, 0.9730913639068604, 0.9699698090553284, 1.038319706916809, 0.9934167265892029, 1.0228838920593262, 1.0070120096206665, 1.050955891609192, 1.1903245449066162, 1.0819891691207886, 1.0377635955810547, 1.0103343725204468, 1.0266120433807373, 1.0278310775756836, 1.0285911560058594, 1.072510004043579, 1.042359709739685, 1.0485355854034424, 1.0282230377197266, 1.0310696363449097, 1.0453299283981323, 1.0422497987747192, 1.104445219039917, 1.036516785621643, 1.0430123805999756, 1.0490740537643433, 1.0474292039871216, 1.0450736284255981, 1.053574562072754, 1.0637046098709106, 1.0523942708969116, 1.098218321800232, 1.1031908988952637, 1.1499526500701904, 1.0851491689682007, 1.0906864404678345, 1.0750571489334106, 1.068841576576233, 1.0893845558166504, 1.0727072954177856, 1.1227400302886963, 1.1882381439208984, 1.0624831914901733, 1.0694072246551514, 1.1179521083831787, 1.0839314460754395, 1.0848236083984375, 1.113098382949829, 1.083068609237671, 1.0886683464050293, 1.1701085567474365, 1.2121580839157104, 1.0816683769226074, 1.0992608070373535, 1.1752244234085083, 1.0965126752853394, 1.110724925994873, 1.24739670753479, 1.1810064315795898, 1.1192253828048706, 1.2248575687408447, 1.205237627029419, 1.2227364778518677, 1.1617623567581177, 1.1197426319122314, 1.1473956108093262, 1.1352839469909668, 1.1413633823394775, 1.1590406894683838, 1.1246007680892944, 1.133211374282837, 1.1516913175582886, 1.192684531211853, 1.1243996620178223, 1.3723562955856323, 1.1476619243621826], 'val_accuracy': [0.6208677887916565, 0.6219007968902588, 0.6487603187561035, 0.6518595218658447, 0.64462810754776, 0.6456611752510071, 0.6363636255264282, 0.6508264541625977, 0.6601239442825317, 0.6559917330741882, 0.6611570119857788, 0.6869834661483765, 0.6683884263038635, 0.6869834661483765, 0.7086777091026306, 0.64462810754776, 0.7221074104309082, 0.7541322112083435, 0.73037189245224, 0.7241735458374023, 0.7809917330741882, 0.8006198406219482, 0.807851254940033, 0.797520637512207, 0.8068181872367859, 0.807851254940033, 0.8037189841270447, 0.7944214940071106, 0.8099173307418823, 0.8006198406219482, 0.807851254940033, 0.797520637512207, 0.7706611752510071, 0.788223147392273, 0.8099173307418823, 0.8006198406219482, 0.8068181872367859, 0.8109503984451294, 0.8016529083251953, 0.797520637512207, 0.8047520518302917, 0.8006198406219482, 0.8068181872367859, 0.807851254940033, 0.7995867729187012, 0.797520637512207, 0.797520637512207, 0.8099173307418823, 0.8037189841270447, 0.8037189841270447, 0.8016529083251953, 0.7995867729187012, 0.7944214940071106, 0.8026859760284424, 0.8047520518302917, 0.7871900796890259, 0.7995867729187012, 0.7830578684806824, 0.797520637512207, 0.7913222908973694, 0.8016529083251953, 0.8057851195335388, 0.8037189841270447, 0.7995867729187012, 0.7809917330741882, 0.7789255976676941, 0.8057851195335388, 0.807851254940033, 0.7830578684806824, 0.7985537052154541, 0.7954545617103577, 0.7902892827987671, 0.8037189841270447, 0.7995867729187012, 0.7830578684806824, 0.7737603187561035, 0.8099173307418823, 0.7954545617103577, 0.7789255976676941, 0.7995867729187012, 0.8026859760284424, 0.7758264541625977, 0.7851239442825317, 0.7923553586006165, 0.7737603187561035, 0.7675619721412659, 0.7737603187561035, 0.7778925895690918, 0.7954545617103577, 0.7830578684806824, 0.7923553586006165, 0.7902892827987671, 0.7830578684806824, 0.7944214940071106, 0.78925621509552, 0.7830578684806824, 0.7851239442825317, 0.78925621509552, 0.7417355179786682, 0.78925621509552]}\n","32/32 [==============================] - 0s 3ms/step\n"]}],"source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717501312825,"user_tz":-360,"elapsed":14,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"7b7f747a-f44f-44d7-e701-6ec26b49eb20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.554      0.559   0.514  0.536        0.514        0.595   \n","1        1     0.576      0.594   0.482  0.532        0.482        0.671   \n","2        2     0.586      0.631   0.416  0.501        0.416        0.757   \n","3        0     0.659      0.677   0.610  0.641        0.610        0.709   \n","4        1     0.653      0.649   0.667  0.658        0.667        0.640   \n","5        2     0.677      0.690   0.643  0.665        0.643        0.711   \n","6        0     0.719      0.733   0.688  0.710        0.688        0.749   \n","7        1     0.749      0.737   0.773  0.754        0.773        0.725   \n","8        2     0.765      0.735   0.829  0.779        0.829        0.701   \n","9        0     0.775      0.753   0.817  0.784        0.817        0.732   \n","10       1     0.785      0.762   0.828  0.794        0.828        0.742   \n","11       2     0.818      0.815   0.823  0.819        0.823        0.813   \n","12       0     0.813      0.814   0.812  0.813        0.812        0.814   \n","13       1     0.815      0.806   0.829  0.818        0.829        0.801   \n","14       2     0.834      0.843   0.821  0.832        0.821        0.847   \n","\n","    Kappa  \n","0   0.109  \n","1   0.153  \n","2   0.173  \n","3   0.318  \n","4   0.306  \n","5   0.353  \n","6   0.437  \n","7   0.497  \n","8   0.530  \n","9   0.549  \n","10  0.569  \n","11  0.637  \n","12  0.626  \n","13  0.630  \n","14  0.669  "],"text/html":["\n","  <div id=\"df-bf2e6797-4b4e-4f43-84f2-a989d0f995a0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.554</td>\n","      <td>0.559</td>\n","      <td>0.514</td>\n","      <td>0.536</td>\n","      <td>0.514</td>\n","      <td>0.595</td>\n","      <td>0.109</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.576</td>\n","      <td>0.594</td>\n","      <td>0.482</td>\n","      <td>0.532</td>\n","      <td>0.482</td>\n","      <td>0.671</td>\n","      <td>0.153</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.586</td>\n","      <td>0.631</td>\n","      <td>0.416</td>\n","      <td>0.501</td>\n","      <td>0.416</td>\n","      <td>0.757</td>\n","      <td>0.173</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.659</td>\n","      <td>0.677</td>\n","      <td>0.610</td>\n","      <td>0.641</td>\n","      <td>0.610</td>\n","      <td>0.709</td>\n","      <td>0.318</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.653</td>\n","      <td>0.649</td>\n","      <td>0.667</td>\n","      <td>0.658</td>\n","      <td>0.667</td>\n","      <td>0.640</td>\n","      <td>0.306</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.677</td>\n","      <td>0.690</td>\n","      <td>0.643</td>\n","      <td>0.665</td>\n","      <td>0.643</td>\n","      <td>0.711</td>\n","      <td>0.353</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.719</td>\n","      <td>0.733</td>\n","      <td>0.688</td>\n","      <td>0.710</td>\n","      <td>0.688</td>\n","      <td>0.749</td>\n","      <td>0.437</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.749</td>\n","      <td>0.737</td>\n","      <td>0.773</td>\n","      <td>0.754</td>\n","      <td>0.773</td>\n","      <td>0.725</td>\n","      <td>0.497</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.765</td>\n","      <td>0.735</td>\n","      <td>0.829</td>\n","      <td>0.779</td>\n","      <td>0.829</td>\n","      <td>0.701</td>\n","      <td>0.530</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.775</td>\n","      <td>0.753</td>\n","      <td>0.817</td>\n","      <td>0.784</td>\n","      <td>0.817</td>\n","      <td>0.732</td>\n","      <td>0.549</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.785</td>\n","      <td>0.762</td>\n","      <td>0.828</td>\n","      <td>0.794</td>\n","      <td>0.828</td>\n","      <td>0.742</td>\n","      <td>0.569</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.818</td>\n","      <td>0.815</td>\n","      <td>0.823</td>\n","      <td>0.819</td>\n","      <td>0.823</td>\n","      <td>0.813</td>\n","      <td>0.637</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.813</td>\n","      <td>0.814</td>\n","      <td>0.812</td>\n","      <td>0.813</td>\n","      <td>0.812</td>\n","      <td>0.814</td>\n","      <td>0.626</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.815</td>\n","      <td>0.806</td>\n","      <td>0.829</td>\n","      <td>0.818</td>\n","      <td>0.829</td>\n","      <td>0.801</td>\n","      <td>0.630</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.834</td>\n","      <td>0.843</td>\n","      <td>0.821</td>\n","      <td>0.832</td>\n","      <td>0.821</td>\n","      <td>0.847</td>\n","      <td>0.669</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf2e6797-4b4e-4f43-84f2-a989d0f995a0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bf2e6797-4b4e-4f43-84f2-a989d0f995a0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bf2e6797-4b4e-4f43-84f2-a989d0f995a0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a5967608-fadd-4ba7-9afd-f4fc125f1be3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5967608-fadd-4ba7-9afd-f4fc125f1be3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a5967608-fadd-4ba7-9afd-f4fc125f1be3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0951186226821666,\n        \"min\": 0.554,\n        \"max\": 0.834,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.775,\n          0.818,\n          0.554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08511745386453327,\n        \"min\": 0.559,\n        \"max\": 0.843,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.753,\n          0.815,\n          0.559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14297245822018942,\n        \"min\": 0.416,\n        \"max\": 0.829,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.817,\n          0.823,\n          0.514\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11445052996611159,\n        \"min\": 0.501,\n        \"max\": 0.832,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.784,\n          0.819,\n          0.536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14297245822018942,\n        \"min\": 0.416,\n        \"max\": 0.829,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.817,\n          0.823,\n          0.514\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06822776979667862,\n        \"min\": 0.595,\n        \"max\": 0.847,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.732,\n          0.813,\n          0.595\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1899858892003248,\n        \"min\": 0.109,\n        \"max\": 0.669,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.549,\n          0.637,\n          0.109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}],"source":["metrics_df_CNN.round(3)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717501313306,"user_tz":-360,"elapsed":489,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN/Delta_time_CNN.csv', index = False)"]},{"cell_type":"markdown","source":["#GRU"],"metadata":{"id":"DrLcSb1d64Jm"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"ieXSN-9PI4Dx","executionInfo":{"status":"ok","timestamp":1717501313308,"user_tz":-360,"elapsed":2,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Delta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Delta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"id":"z4EG6mCS7ARu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717502560247,"user_tz":-360,"elapsed":160146,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"a4181a7f-bcea-4c4e-bcb2-ea6d0d805a0e"},"execution_count":19,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.4309 - accuracy: 0.4833"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 49ms/step - loss: 1.4308 - accuracy: 0.4838 - val_loss: 1.4278 - val_accuracy: 0.4838\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4249 - accuracy: 0.5121 - val_loss: 1.4226 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4199 - accuracy: 0.5100 - val_loss: 1.4174 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4145 - accuracy: 0.5094 - val_loss: 1.4122 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.4092 - accuracy: 0.5202 - val_loss: 1.4070 - val_accuracy: 0.4957\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4035 - accuracy: 0.5353 - val_loss: 1.4019 - val_accuracy: 0.5022\n","Epoch 7/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.3986 - accuracy: 0.5318 - val_loss: 1.3968 - val_accuracy: 0.5194\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3932 - accuracy: 0.5407 - val_loss: 1.3917 - val_accuracy: 0.5065\n","Epoch 9/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3877 - accuracy: 0.5474 - val_loss: 1.3866 - val_accuracy: 0.5205\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3828 - accuracy: 0.5364 - val_loss: 1.3816 - val_accuracy: 0.5151\n","Epoch 11/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.3774 - accuracy: 0.5539 - val_loss: 1.3765 - val_accuracy: 0.5474\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3722 - accuracy: 0.5539 - val_loss: 1.3717 - val_accuracy: 0.5043\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3669 - accuracy: 0.5585 - val_loss: 1.3667 - val_accuracy: 0.5205\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3622 - accuracy: 0.5356 - val_loss: 1.3616 - val_accuracy: 0.5205\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3561 - accuracy: 0.5628 - val_loss: 1.3569 - val_accuracy: 0.5194\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3511 - accuracy: 0.5628 - val_loss: 1.3522 - val_accuracy: 0.5054\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3462 - accuracy: 0.5501 - val_loss: 1.3471 - val_accuracy: 0.5312\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3399 - accuracy: 0.5703 - val_loss: 1.3417 - val_accuracy: 0.5280\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3344 - accuracy: 0.5754 - val_loss: 1.3360 - val_accuracy: 0.5647\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3300 - accuracy: 0.5652 - val_loss: 1.3333 - val_accuracy: 0.5119\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3232 - accuracy: 0.5841 - val_loss: 1.3270 - val_accuracy: 0.5259\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3168 - accuracy: 0.5843 - val_loss: 1.3199 - val_accuracy: 0.5765\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3109 - accuracy: 0.5897 - val_loss: 1.3174 - val_accuracy: 0.5323\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3054 - accuracy: 0.5824 - val_loss: 1.3159 - val_accuracy: 0.5183\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3003 - accuracy: 0.5927 - val_loss: 1.3054 - val_accuracy: 0.5463\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2921 - accuracy: 0.5997 - val_loss: 1.2984 - val_accuracy: 0.5830\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2842 - accuracy: 0.6072 - val_loss: 1.2942 - val_accuracy: 0.5647\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2774 - accuracy: 0.6175 - val_loss: 1.2913 - val_accuracy: 0.5506\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2711 - accuracy: 0.6129 - val_loss: 1.2856 - val_accuracy: 0.5528\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2632 - accuracy: 0.6193 - val_loss: 1.2786 - val_accuracy: 0.5797\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2552 - accuracy: 0.6288 - val_loss: 1.2739 - val_accuracy: 0.5894\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2503 - accuracy: 0.6282 - val_loss: 1.2696 - val_accuracy: 0.5819\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2423 - accuracy: 0.6323 - val_loss: 1.2659 - val_accuracy: 0.5894\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2348 - accuracy: 0.6390 - val_loss: 1.2627 - val_accuracy: 0.5776\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2259 - accuracy: 0.6457 - val_loss: 1.2615 - val_accuracy: 0.5765\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2153 - accuracy: 0.6506 - val_loss: 1.2760 - val_accuracy: 0.5366\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2092 - accuracy: 0.6598 - val_loss: 1.2645 - val_accuracy: 0.5517\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2033 - accuracy: 0.6568 - val_loss: 1.2516 - val_accuracy: 0.5808\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1994 - accuracy: 0.6581 - val_loss: 1.2556 - val_accuracy: 0.5636\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1870 - accuracy: 0.6587 - val_loss: 1.2547 - val_accuracy: 0.5560\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1790 - accuracy: 0.6759 - val_loss: 1.2471 - val_accuracy: 0.5733\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1722 - accuracy: 0.6700 - val_loss: 1.2508 - val_accuracy: 0.5636\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1620 - accuracy: 0.6800 - val_loss: 1.2430 - val_accuracy: 0.5841\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1565 - accuracy: 0.6805 - val_loss: 1.2481 - val_accuracy: 0.5582\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1461 - accuracy: 0.6948 - val_loss: 1.2434 - val_accuracy: 0.5668\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1387 - accuracy: 0.6913 - val_loss: 1.2564 - val_accuracy: 0.5582\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1349 - accuracy: 0.6948 - val_loss: 1.2480 - val_accuracy: 0.5614\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1219 - accuracy: 0.7053 - val_loss: 1.2590 - val_accuracy: 0.5528\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1173 - accuracy: 0.6950 - val_loss: 1.2628 - val_accuracy: 0.5453\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1066 - accuracy: 0.7037 - val_loss: 1.2477 - val_accuracy: 0.5614\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0955 - accuracy: 0.7182 - val_loss: 1.2407 - val_accuracy: 0.5560\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0910 - accuracy: 0.7214 - val_loss: 1.2431 - val_accuracy: 0.5593\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0715 - accuracy: 0.7301 - val_loss: 1.2417 - val_accuracy: 0.5614\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0692 - accuracy: 0.7290 - val_loss: 1.2402 - val_accuracy: 0.5560\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0629 - accuracy: 0.7349 - val_loss: 1.2457 - val_accuracy: 0.5550\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0549 - accuracy: 0.7298 - val_loss: 1.2435 - val_accuracy: 0.5603\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0432 - accuracy: 0.7371 - val_loss: 1.2443 - val_accuracy: 0.5550\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0346 - accuracy: 0.7468 - val_loss: 1.2431 - val_accuracy: 0.5657\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0255 - accuracy: 0.7584 - val_loss: 1.2486 - val_accuracy: 0.5582\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0185 - accuracy: 0.7497 - val_loss: 1.2677 - val_accuracy: 0.5668\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0069 - accuracy: 0.7554 - val_loss: 1.2673 - val_accuracy: 0.5647\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9999 - accuracy: 0.7624 - val_loss: 1.2630 - val_accuracy: 0.5603\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9854 - accuracy: 0.7710 - val_loss: 1.2573 - val_accuracy: 0.5550\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9820 - accuracy: 0.7716 - val_loss: 1.2928 - val_accuracy: 0.5582\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9672 - accuracy: 0.7783 - val_loss: 1.2574 - val_accuracy: 0.5603\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9629 - accuracy: 0.7775 - val_loss: 1.2749 - val_accuracy: 0.5603\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9552 - accuracy: 0.7834 - val_loss: 1.2956 - val_accuracy: 0.5636\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9510 - accuracy: 0.7753 - val_loss: 1.2744 - val_accuracy: 0.5593\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9347 - accuracy: 0.7909 - val_loss: 1.2697 - val_accuracy: 0.5625\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9291 - accuracy: 0.7931 - val_loss: 1.2955 - val_accuracy: 0.5496\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9169 - accuracy: 0.7985 - val_loss: 1.2812 - val_accuracy: 0.5582\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9092 - accuracy: 0.7966 - val_loss: 1.2897 - val_accuracy: 0.5690\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9058 - accuracy: 0.7953 - val_loss: 1.2857 - val_accuracy: 0.5657\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8957 - accuracy: 0.8071 - val_loss: 1.2946 - val_accuracy: 0.5625\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8929 - accuracy: 0.8052 - val_loss: 1.2969 - val_accuracy: 0.5571\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8705 - accuracy: 0.8198 - val_loss: 1.3127 - val_accuracy: 0.5431\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8754 - accuracy: 0.8112 - val_loss: 1.3106 - val_accuracy: 0.5560\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8607 - accuracy: 0.8235 - val_loss: 1.3042 - val_accuracy: 0.5636\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8430 - accuracy: 0.8359 - val_loss: 1.3377 - val_accuracy: 0.5485\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8548 - accuracy: 0.8198 - val_loss: 1.3237 - val_accuracy: 0.5668\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8405 - accuracy: 0.8273 - val_loss: 1.3207 - val_accuracy: 0.5603\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8260 - accuracy: 0.8303 - val_loss: 1.3286 - val_accuracy: 0.5668\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8212 - accuracy: 0.8354 - val_loss: 1.3395 - val_accuracy: 0.5560\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8020 - accuracy: 0.8473 - val_loss: 1.3554 - val_accuracy: 0.5517\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7966 - accuracy: 0.8516 - val_loss: 1.3578 - val_accuracy: 0.5593\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7909 - accuracy: 0.8454 - val_loss: 1.3600 - val_accuracy: 0.5679\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7797 - accuracy: 0.8486 - val_loss: 1.3720 - val_accuracy: 0.5517\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7729 - accuracy: 0.8570 - val_loss: 1.4036 - val_accuracy: 0.5463\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7722 - accuracy: 0.8529 - val_loss: 1.3984 - val_accuracy: 0.5388\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7633 - accuracy: 0.8594 - val_loss: 1.3859 - val_accuracy: 0.5819\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7555 - accuracy: 0.8596 - val_loss: 1.3883 - val_accuracy: 0.5690\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7404 - accuracy: 0.8586 - val_loss: 1.3919 - val_accuracy: 0.5744\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7339 - accuracy: 0.8656 - val_loss: 1.4100 - val_accuracy: 0.5625\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7353 - accuracy: 0.8607 - val_loss: 1.4169 - val_accuracy: 0.5560\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7186 - accuracy: 0.8739 - val_loss: 1.4481 - val_accuracy: 0.5463\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7232 - accuracy: 0.8696 - val_loss: 1.5157 - val_accuracy: 0.5463\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7232 - accuracy: 0.8631 - val_loss: 1.4334 - val_accuracy: 0.5733\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7071 - accuracy: 0.8772 - val_loss: 1.4345 - val_accuracy: 0.5841\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7021 - accuracy: 0.8788 - val_loss: 1.4385 - val_accuracy: 0.5733\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7027 - accuracy: 0.8707 - val_loss: 1.4396 - val_accuracy: 0.5722\n","{'loss': [1.430801510810852, 1.4249461889266968, 1.41994047164917, 1.4145431518554688, 1.4092106819152832, 1.403521180152893, 1.398584246635437, 1.3931858539581299, 1.3877006769180298, 1.3828177452087402, 1.37735116481781, 1.372236728668213, 1.366881012916565, 1.3622069358825684, 1.3561007976531982, 1.3511089086532593, 1.346171259880066, 1.339903712272644, 1.33441960811615, 1.3300186395645142, 1.3231759071350098, 1.3168216943740845, 1.3108774423599243, 1.3053679466247559, 1.3003370761871338, 1.2921332120895386, 1.2841897010803223, 1.2773520946502686, 1.2711273431777954, 1.2631958723068237, 1.2551931142807007, 1.2502728700637817, 1.2422853708267212, 1.234803557395935, 1.2259221076965332, 1.2152533531188965, 1.2092399597167969, 1.203258991241455, 1.1993659734725952, 1.1869924068450928, 1.1790448427200317, 1.1722475290298462, 1.1619731187820435, 1.1564944982528687, 1.1460957527160645, 1.138655185699463, 1.1348952054977417, 1.1219350099563599, 1.1173306703567505, 1.1065696477890015, 1.0954585075378418, 1.091039776802063, 1.0715446472167969, 1.06923508644104, 1.0629242658615112, 1.0548527240753174, 1.0431808233261108, 1.034637689590454, 1.0254865884780884, 1.0185418128967285, 1.0068827867507935, 0.9998966455459595, 0.9854068756103516, 0.9820446372032166, 0.9671804904937744, 0.9629464149475098, 0.9552408456802368, 0.9510245323181152, 0.9346855282783508, 0.9291384220123291, 0.9168877005577087, 0.9092310070991516, 0.9057624340057373, 0.8956674933433533, 0.8928718566894531, 0.8705270290374756, 0.8754230737686157, 0.8606528043746948, 0.8430150151252747, 0.8547589778900146, 0.8404691219329834, 0.825973391532898, 0.82120680809021, 0.8019760847091675, 0.7966328859329224, 0.7908695936203003, 0.7796922922134399, 0.7729032039642334, 0.7722412347793579, 0.7633484601974487, 0.7555410861968994, 0.7403973340988159, 0.7338798642158508, 0.7352780699729919, 0.7186156511306763, 0.7232102751731873, 0.7232099175453186, 0.7071385383605957, 0.7021348476409912, 0.7027231454849243], 'accuracy': [0.48383620381355286, 0.5121228694915771, 0.5099676847457886, 0.509428858757019, 0.5202047228813171, 0.5352909564971924, 0.5317887663841248, 0.540678858757019, 0.5474137663841248, 0.5363685488700867, 0.5538793206214905, 0.5538793206214905, 0.5584590435028076, 0.5355603694915771, 0.5627694129943848, 0.5627694129943848, 0.5501077771186829, 0.5703125, 0.5754310488700867, 0.5651939511299133, 0.5840517282485962, 0.584321141242981, 0.5897090435028076, 0.5824353694915771, 0.5926724076271057, 0.5996767282485962, 0.6072198152542114, 0.6174569129943848, 0.6128771305084229, 0.6193426847457886, 0.6287715435028076, 0.6282327771186829, 0.6322737336158752, 0.639008641242981, 0.6457435488700867, 0.6505926847457886, 0.6597521305084229, 0.6567887663841248, 0.6581357717514038, 0.6586745977401733, 0.6759159564971924, 0.6699892282485962, 0.6799569129943848, 0.6804956793785095, 0.6947737336158752, 0.6912715435028076, 0.6947737336158752, 0.7052801847457886, 0.6950430870056152, 0.7036637663841248, 0.7182112336158752, 0.7214439511299133, 0.7300646305084229, 0.7289870977401733, 0.7349137663841248, 0.7297952771186829, 0.7370689511299133, 0.7467672228813171, 0.7583512663841248, 0.7497305870056152, 0.7553879022598267, 0.7623922228813171, 0.7710129022598267, 0.7715517282485962, 0.7782866358757019, 0.7774784564971924, 0.7834051847457886, 0.7753232717514038, 0.7909482717514038, 0.7931034564971924, 0.798491358757019, 0.7966055870056152, 0.795258641242981, 0.8071120977401733, 0.8052262663841248, 0.8197737336158752, 0.811152994632721, 0.8235452771186829, 0.8359375, 0.8197737336158752, 0.8273168206214905, 0.8302801847457886, 0.8353987336158752, 0.8472521305084229, 0.8515625, 0.845366358757019, 0.8485991358757019, 0.8569504022598267, 0.852909505367279, 0.859375, 0.8596444129943848, 0.8585668206214905, 0.865571141242981, 0.860722005367279, 0.8739224076271057, 0.8696120977401733, 0.8631465435028076, 0.8771551847457886, 0.8787715435028076, 0.8706896305084229], 'val_loss': [1.4278435707092285, 1.4226081371307373, 1.4173874855041504, 1.4121962785720825, 1.4070370197296143, 1.4019070863723755, 1.3967812061309814, 1.3917124271392822, 1.3866373300552368, 1.3816323280334473, 1.3765283823013306, 1.371737003326416, 1.3667051792144775, 1.3616493940353394, 1.356892704963684, 1.352165699005127, 1.347104787826538, 1.3417447805404663, 1.336029291152954, 1.33328378200531, 1.3269803524017334, 1.3198837041854858, 1.317359209060669, 1.315904140472412, 1.305436134338379, 1.2983906269073486, 1.2942240238189697, 1.2912797927856445, 1.2856237888336182, 1.2785815000534058, 1.2739439010620117, 1.2695525884628296, 1.2658908367156982, 1.2626993656158447, 1.2615169286727905, 1.2760146856307983, 1.2645187377929688, 1.2516207695007324, 1.255614161491394, 1.2546908855438232, 1.2471201419830322, 1.2507704496383667, 1.242996335029602, 1.2480664253234863, 1.2433720827102661, 1.2563871145248413, 1.2479910850524902, 1.2589620351791382, 1.2627568244934082, 1.247721552848816, 1.2407279014587402, 1.2430810928344727, 1.2416784763336182, 1.2401598691940308, 1.2456750869750977, 1.2434552907943726, 1.2442694902420044, 1.2430624961853027, 1.248626947402954, 1.2677379846572876, 1.26734459400177, 1.262977957725525, 1.2572875022888184, 1.2927701473236084, 1.2574232816696167, 1.274855613708496, 1.2955559492111206, 1.2743960618972778, 1.269705891609192, 1.2954801321029663, 1.281246542930603, 1.289710283279419, 1.28572416305542, 1.2946195602416992, 1.296939492225647, 1.312657117843628, 1.3106216192245483, 1.3041985034942627, 1.3377095460891724, 1.3237215280532837, 1.3206956386566162, 1.328579068183899, 1.3395490646362305, 1.3554487228393555, 1.3577953577041626, 1.3599779605865479, 1.372033715248108, 1.4036200046539307, 1.398444652557373, 1.3859151601791382, 1.3883041143417358, 1.3919341564178467, 1.4099509716033936, 1.416930913925171, 1.4480769634246826, 1.5156537294387817, 1.433447241783142, 1.4344639778137207, 1.4385180473327637, 1.439564824104309], 'val_accuracy': [0.48383620381355286, 0.48491379618644714, 0.48491379618644714, 0.4881465435028076, 0.49568966031074524, 0.5021551847457886, 0.5193965435028076, 0.506465494632721, 0.5204741358757019, 0.5150862336158752, 0.5474137663841248, 0.5043103694915771, 0.5204741358757019, 0.5204741358757019, 0.5193965435028076, 0.5053879022598267, 0.53125, 0.5280172228813171, 0.5646551847457886, 0.5118534564971924, 0.5258620977401733, 0.576508641242981, 0.5323275923728943, 0.5183189511299133, 0.5463362336158752, 0.5829741358757019, 0.5646551847457886, 0.5506465435028076, 0.5528017282485962, 0.579741358757019, 0.5894396305084229, 0.5818965435028076, 0.5894396305084229, 0.5775862336158752, 0.576508641242981, 0.5366379022598267, 0.5517241358757019, 0.5808189511299133, 0.5635775923728943, 0.556034505367279, 0.5732758641242981, 0.5635775923728943, 0.5840517282485962, 0.5581896305084229, 0.5668103694915771, 0.5581896305084229, 0.5614224076271057, 0.5528017282485962, 0.545258641242981, 0.5614224076271057, 0.556034505367279, 0.5592672228813171, 0.5614224076271057, 0.556034505367279, 0.5549569129943848, 0.5603448152542114, 0.5549569129943848, 0.5657327771186829, 0.5581896305084229, 0.5668103694915771, 0.5646551847457886, 0.5603448152542114, 0.5549569129943848, 0.5581896305084229, 0.5603448152542114, 0.5603448152542114, 0.5635775923728943, 0.5592672228813171, 0.5625, 0.5495689511299133, 0.5581896305084229, 0.568965494632721, 0.5657327771186829, 0.5625, 0.5571120977401733, 0.5431034564971924, 0.556034505367279, 0.5635775923728943, 0.548491358757019, 0.5668103694915771, 0.5603448152542114, 0.5668103694915771, 0.556034505367279, 0.5517241358757019, 0.5592672228813171, 0.5678879022598267, 0.5517241358757019, 0.5463362336158752, 0.5387930870056152, 0.5818965435028076, 0.568965494632721, 0.5743534564971924, 0.5625, 0.556034505367279, 0.5463362336158752, 0.5463362336158752, 0.5732758641242981, 0.5840517282485962, 0.5732758641242981, 0.5721982717514038]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 1.4310 - accuracy: 0.4975"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 50ms/step - loss: 1.4307 - accuracy: 0.4977 - val_loss: 1.4280 - val_accuracy: 0.5204\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4257 - accuracy: 0.4980 - val_loss: 1.4229 - val_accuracy: 0.5238\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4202 - accuracy: 0.5195 - val_loss: 1.4179 - val_accuracy: 0.5215\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4150 - accuracy: 0.5187 - val_loss: 1.4128 - val_accuracy: 0.5294\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4099 - accuracy: 0.5221 - val_loss: 1.4079 - val_accuracy: 0.4853\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4047 - accuracy: 0.5272 - val_loss: 1.4029 - val_accuracy: 0.4842\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3998 - accuracy: 0.5405 - val_loss: 1.3980 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3942 - accuracy: 0.5668 - val_loss: 1.3931 - val_accuracy: 0.4932\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3895 - accuracy: 0.5439 - val_loss: 1.3883 - val_accuracy: 0.4977\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3842 - accuracy: 0.5546 - val_loss: 1.3834 - val_accuracy: 0.5136\n","Epoch 11/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.3790 - accuracy: 0.5586 - val_loss: 1.3786 - val_accuracy: 0.5373\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3741 - accuracy: 0.5543 - val_loss: 1.3738 - val_accuracy: 0.5283\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3686 - accuracy: 0.5614 - val_loss: 1.3690 - val_accuracy: 0.5373\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3630 - accuracy: 0.5798 - val_loss: 1.3642 - val_accuracy: 0.5260\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3578 - accuracy: 0.5753 - val_loss: 1.3595 - val_accuracy: 0.5158\n","Epoch 16/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3525 - accuracy: 0.5671 - val_loss: 1.3548 - val_accuracy: 0.5328\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3463 - accuracy: 0.5815 - val_loss: 1.3501 - val_accuracy: 0.5317\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3407 - accuracy: 0.5733 - val_loss: 1.3453 - val_accuracy: 0.5317\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3351 - accuracy: 0.5705 - val_loss: 1.3406 - val_accuracy: 0.5407\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3292 - accuracy: 0.5787 - val_loss: 1.3358 - val_accuracy: 0.5339\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3232 - accuracy: 0.5832 - val_loss: 1.3315 - val_accuracy: 0.5407\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3162 - accuracy: 0.5908 - val_loss: 1.3271 - val_accuracy: 0.5351\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3098 - accuracy: 0.5911 - val_loss: 1.3228 - val_accuracy: 0.5430\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3044 - accuracy: 0.5894 - val_loss: 1.3189 - val_accuracy: 0.5475\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2973 - accuracy: 0.6067 - val_loss: 1.3152 - val_accuracy: 0.5475\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2906 - accuracy: 0.6022 - val_loss: 1.3113 - val_accuracy: 0.5385\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2841 - accuracy: 0.6002 - val_loss: 1.3077 - val_accuracy: 0.5475\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2784 - accuracy: 0.6084 - val_loss: 1.3053 - val_accuracy: 0.5486\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2720 - accuracy: 0.6154 - val_loss: 1.3010 - val_accuracy: 0.5419\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2632 - accuracy: 0.6214 - val_loss: 1.2998 - val_accuracy: 0.5452\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2572 - accuracy: 0.6299 - val_loss: 1.2952 - val_accuracy: 0.5475\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2527 - accuracy: 0.6222 - val_loss: 1.2941 - val_accuracy: 0.5486\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2477 - accuracy: 0.6214 - val_loss: 1.2880 - val_accuracy: 0.5532\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2358 - accuracy: 0.6392 - val_loss: 1.2857 - val_accuracy: 0.5509\n","Epoch 35/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.2277 - accuracy: 0.6454 - val_loss: 1.2842 - val_accuracy: 0.5566\n","Epoch 36/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2248 - accuracy: 0.6437 - val_loss: 1.2803 - val_accuracy: 0.5554\n","Epoch 37/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2137 - accuracy: 0.6627 - val_loss: 1.2783 - val_accuracy: 0.5611\n","Epoch 38/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2085 - accuracy: 0.6525 - val_loss: 1.2758 - val_accuracy: 0.5543\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1984 - accuracy: 0.6669 - val_loss: 1.2747 - val_accuracy: 0.5532\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1920 - accuracy: 0.6735 - val_loss: 1.2725 - val_accuracy: 0.5532\n","Epoch 41/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.1815 - accuracy: 0.6774 - val_loss: 1.2703 - val_accuracy: 0.5656\n","Epoch 42/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1760 - accuracy: 0.6791 - val_loss: 1.2688 - val_accuracy: 0.5667\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1714 - accuracy: 0.6774 - val_loss: 1.2680 - val_accuracy: 0.5679\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1614 - accuracy: 0.6802 - val_loss: 1.2659 - val_accuracy: 0.5713\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1562 - accuracy: 0.6814 - val_loss: 1.2630 - val_accuracy: 0.5690\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1488 - accuracy: 0.6927 - val_loss: 1.2637 - val_accuracy: 0.5611\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1345 - accuracy: 0.7009 - val_loss: 1.2709 - val_accuracy: 0.5509\n","Epoch 48/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1259 - accuracy: 0.7051 - val_loss: 1.2703 - val_accuracy: 0.5566\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1235 - accuracy: 0.7037 - val_loss: 1.2691 - val_accuracy: 0.5566\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1136 - accuracy: 0.7066 - val_loss: 1.2639 - val_accuracy: 0.5792\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0983 - accuracy: 0.7204 - val_loss: 1.2700 - val_accuracy: 0.5554\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0995 - accuracy: 0.7204 - val_loss: 1.2749 - val_accuracy: 0.5520\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0840 - accuracy: 0.7323 - val_loss: 1.2699 - val_accuracy: 0.5600\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0773 - accuracy: 0.7306 - val_loss: 1.2697 - val_accuracy: 0.5622\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0618 - accuracy: 0.7467 - val_loss: 1.2721 - val_accuracy: 0.5792\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0684 - accuracy: 0.7334 - val_loss: 1.2746 - val_accuracy: 0.5543\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0554 - accuracy: 0.7377 - val_loss: 1.2710 - val_accuracy: 0.5713\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0493 - accuracy: 0.7388 - val_loss: 1.2715 - val_accuracy: 0.5679\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0325 - accuracy: 0.7558 - val_loss: 1.2776 - val_accuracy: 0.5566\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0277 - accuracy: 0.7524 - val_loss: 1.2793 - val_accuracy: 0.5622\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0134 - accuracy: 0.7586 - val_loss: 1.2867 - val_accuracy: 0.5543\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0050 - accuracy: 0.7620 - val_loss: 1.3027 - val_accuracy: 0.5543\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9989 - accuracy: 0.7649 - val_loss: 1.2887 - val_accuracy: 0.5713\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9931 - accuracy: 0.7634 - val_loss: 1.2979 - val_accuracy: 0.5577\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9810 - accuracy: 0.7816 - val_loss: 1.3057 - val_accuracy: 0.5486\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9815 - accuracy: 0.7750 - val_loss: 1.2912 - val_accuracy: 0.5611\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9653 - accuracy: 0.7835 - val_loss: 1.3043 - val_accuracy: 0.5566\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9475 - accuracy: 0.7937 - val_loss: 1.2992 - val_accuracy: 0.5656\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9467 - accuracy: 0.7909 - val_loss: 1.3043 - val_accuracy: 0.5633\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9409 - accuracy: 0.7920 - val_loss: 1.3130 - val_accuracy: 0.5611\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9339 - accuracy: 0.7934 - val_loss: 1.3086 - val_accuracy: 0.5600\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9194 - accuracy: 0.7977 - val_loss: 1.3177 - val_accuracy: 0.5622\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9101 - accuracy: 0.8098 - val_loss: 1.3177 - val_accuracy: 0.5645\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9027 - accuracy: 0.8138 - val_loss: 1.3322 - val_accuracy: 0.5543\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8947 - accuracy: 0.8104 - val_loss: 1.3275 - val_accuracy: 0.5600\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8897 - accuracy: 0.8104 - val_loss: 1.3316 - val_accuracy: 0.5656\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8850 - accuracy: 0.8141 - val_loss: 1.3367 - val_accuracy: 0.5656\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8650 - accuracy: 0.8231 - val_loss: 1.3455 - val_accuracy: 0.5645\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8610 - accuracy: 0.8257 - val_loss: 1.3689 - val_accuracy: 0.5588\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8653 - accuracy: 0.8248 - val_loss: 1.3525 - val_accuracy: 0.5633\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8548 - accuracy: 0.8234 - val_loss: 1.4206 - val_accuracy: 0.5475\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8410 - accuracy: 0.8302 - val_loss: 1.3692 - val_accuracy: 0.5645\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8289 - accuracy: 0.8356 - val_loss: 1.3668 - val_accuracy: 0.5611\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8206 - accuracy: 0.8356 - val_loss: 1.3671 - val_accuracy: 0.5622\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8134 - accuracy: 0.8415 - val_loss: 1.3865 - val_accuracy: 0.5667\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8036 - accuracy: 0.8512 - val_loss: 1.3844 - val_accuracy: 0.5713\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8096 - accuracy: 0.8455 - val_loss: 1.4027 - val_accuracy: 0.5611\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8020 - accuracy: 0.8447 - val_loss: 1.3852 - val_accuracy: 0.5622\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7980 - accuracy: 0.8444 - val_loss: 1.3971 - val_accuracy: 0.5656\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7794 - accuracy: 0.8546 - val_loss: 1.4002 - val_accuracy: 0.5588\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7737 - accuracy: 0.8557 - val_loss: 1.4123 - val_accuracy: 0.5622\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7610 - accuracy: 0.8582 - val_loss: 1.4108 - val_accuracy: 0.5656\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7522 - accuracy: 0.8639 - val_loss: 1.4240 - val_accuracy: 0.5566\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7664 - accuracy: 0.8514 - val_loss: 1.4593 - val_accuracy: 0.5566\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7474 - accuracy: 0.8656 - val_loss: 1.4255 - val_accuracy: 0.5566\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7386 - accuracy: 0.8636 - val_loss: 1.4465 - val_accuracy: 0.5611\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7265 - accuracy: 0.8786 - val_loss: 1.4450 - val_accuracy: 0.5622\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7252 - accuracy: 0.8653 - val_loss: 1.4957 - val_accuracy: 0.5520\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7333 - accuracy: 0.8647 - val_loss: 1.4577 - val_accuracy: 0.5600\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7128 - accuracy: 0.8755 - val_loss: 1.4570 - val_accuracy: 0.5566\n","{'loss': [1.4307249784469604, 1.425654411315918, 1.4201600551605225, 1.4150471687316895, 1.409925937652588, 1.404678463935852, 1.3998068571090698, 1.3942224979400635, 1.389464020729065, 1.3841779232025146, 1.3790287971496582, 1.3741270303726196, 1.3686347007751465, 1.3630481958389282, 1.3577882051467896, 1.3524984121322632, 1.3462620973587036, 1.3406656980514526, 1.3351128101348877, 1.3291668891906738, 1.3232334852218628, 1.3162082433700562, 1.3098176717758179, 1.3044002056121826, 1.2972859144210815, 1.2905884981155396, 1.2841416597366333, 1.2783571481704712, 1.271979570388794, 1.2631995677947998, 1.2571568489074707, 1.2526750564575195, 1.247665524482727, 1.2358146905899048, 1.22770094871521, 1.2248128652572632, 1.2136509418487549, 1.2084935903549194, 1.1983548402786255, 1.192036747932434, 1.181526780128479, 1.1760046482086182, 1.1714223623275757, 1.1614389419555664, 1.1561901569366455, 1.1487953662872314, 1.1344674825668335, 1.1259435415267944, 1.1235288381576538, 1.113585114479065, 1.0983058214187622, 1.0995017290115356, 1.0840426683425903, 1.07728111743927, 1.0618131160736084, 1.0683518648147583, 1.055416464805603, 1.04928457736969, 1.0325086116790771, 1.0276883840560913, 1.0133556127548218, 1.0049934387207031, 0.9989157319068909, 0.9931337237358093, 0.9809557795524597, 0.981454610824585, 0.9653242826461792, 0.9475197792053223, 0.9466992020606995, 0.9408937096595764, 0.9339267611503601, 0.919441819190979, 0.9101144075393677, 0.9026743173599243, 0.894669234752655, 0.8897027969360352, 0.8850398063659668, 0.8650280237197876, 0.8610430955886841, 0.8652811646461487, 0.854806661605835, 0.8410018682479858, 0.8289018273353577, 0.8205751776695251, 0.8134080767631531, 0.803550124168396, 0.8095602989196777, 0.8020496368408203, 0.7979768514633179, 0.7793800234794617, 0.7737481594085693, 0.760970950126648, 0.7522175908088684, 0.7663525938987732, 0.7473974823951721, 0.7386160492897034, 0.7265037298202515, 0.725208044052124, 0.7332538962364197, 0.7127927541732788], 'accuracy': [0.49773627519607544, 0.4980192482471466, 0.5195246338844299, 0.5186757445335388, 0.5220713019371033, 0.5271646976470947, 0.5404640436172485, 0.5667798519134521, 0.5438596606254578, 0.5546123385429382, 0.558573842048645, 0.5543293952941895, 0.5614035129547119, 0.5797962546348572, 0.5752688050270081, 0.5670627951622009, 0.5814940333366394, 0.573288083076477, 0.5704584121704102, 0.5786644220352173, 0.5831918716430664, 0.5908319354057312, 0.59111487865448, 0.5894170999526978, 0.6066780090332031, 0.602150559425354, 0.6001697778701782, 0.6083757877349854, 0.6154499053955078, 0.6213921904563904, 0.6298811435699463, 0.6222410798072815, 0.6213921904563904, 0.6392189860343933, 0.6454442739486694, 0.6437464356422424, 0.66270512342453, 0.6525183916091919, 0.6669496297836304, 0.6734578609466553, 0.6774193644523621, 0.6791171431541443, 0.6774193644523621, 0.680249035358429, 0.6813808679580688, 0.6926994919776917, 0.7009055018424988, 0.7051499485969543, 0.7037351727485657, 0.7065647840499878, 0.7204301357269287, 0.7204301357269287, 0.7323146462440491, 0.7306168675422668, 0.7467458844184875, 0.7334465384483337, 0.7376909852027893, 0.738822877407074, 0.7558007836341858, 0.7524052262306213, 0.7586304545402527, 0.7620260119438171, 0.764855682849884, 0.7634408473968506, 0.7815506458282471, 0.7750424742698669, 0.7835314273834229, 0.793718159198761, 0.7908884882926941, 0.7920203804969788, 0.7934352159500122, 0.7976796627044678, 0.8098471760749817, 0.8138087391853333, 0.810413122177124, 0.810413122177124, 0.814091682434082, 0.8231465816497803, 0.8256932497024536, 0.8248443603515625, 0.823429524898529, 0.8302206993103027, 0.835597038269043, 0.835597038269043, 0.8415393233299255, 0.8511601686477661, 0.8455008268356323, 0.8446519374847412, 0.8443689942359924, 0.8545557260513306, 0.8556876182556152, 0.8582342863082886, 0.8638936281204224, 0.8514431118965149, 0.8655914068222046, 0.8636106252670288, 0.8786078095436096, 0.865308403968811, 0.8647425174713135, 0.875495195388794], 'val_loss': [1.4280039072036743, 1.4229084253311157, 1.417853832244873, 1.4128390550613403, 1.407853126525879, 1.4029052257537842, 1.397988200187683, 1.3931164741516113, 1.388256311416626, 1.3834182024002075, 1.3785966634750366, 1.373793363571167, 1.3690234422683716, 1.3642457723617554, 1.3595377206802368, 1.3547641038894653, 1.3500733375549316, 1.3452661037445068, 1.3405553102493286, 1.3358368873596191, 1.3314687013626099, 1.3271056413650513, 1.322792887687683, 1.318873643875122, 1.3151775598526, 1.3112964630126953, 1.3076695203781128, 1.305277943611145, 1.3009734153747559, 1.2998175621032715, 1.2951918840408325, 1.2940785884857178, 1.2880321741104126, 1.2857449054718018, 1.284179925918579, 1.2803047895431519, 1.278313398361206, 1.275844693183899, 1.274720311164856, 1.2725367546081543, 1.2703421115875244, 1.2687543630599976, 1.2679990530014038, 1.2658966779708862, 1.2630475759506226, 1.2636696100234985, 1.270851492881775, 1.2703038454055786, 1.2690563201904297, 1.2639468908309937, 1.2699575424194336, 1.2748526334762573, 1.2698849439620972, 1.269703984260559, 1.2720741033554077, 1.2745997905731201, 1.271027684211731, 1.271548867225647, 1.277626395225525, 1.2793326377868652, 1.2867251634597778, 1.3027451038360596, 1.2887200117111206, 1.2979223728179932, 1.3056637048721313, 1.291236400604248, 1.304339051246643, 1.299249529838562, 1.304293155670166, 1.312978744506836, 1.3085576295852661, 1.3176597356796265, 1.3176850080490112, 1.3322300910949707, 1.3274755477905273, 1.3316274881362915, 1.3367172479629517, 1.345518946647644, 1.368882417678833, 1.3524577617645264, 1.420630931854248, 1.3692002296447754, 1.3667980432510376, 1.3670508861541748, 1.3864877223968506, 1.3844285011291504, 1.402659296989441, 1.385246753692627, 1.3971320390701294, 1.400214672088623, 1.4122520685195923, 1.4108397960662842, 1.424047589302063, 1.4592911005020142, 1.425472617149353, 1.4464776515960693, 1.4450334310531616, 1.4956748485565186, 1.457653284072876, 1.4569729566574097], 'val_accuracy': [0.5203620195388794, 0.523755669593811, 0.5214931964874268, 0.529411792755127, 0.4852941036224365, 0.4841628968715668, 0.4954751133918762, 0.49321267008781433, 0.4977375566959381, 0.5135746598243713, 0.5373303294181824, 0.5282805562019348, 0.5373303294181824, 0.5260180830955505, 0.5158371329307556, 0.5328054428100586, 0.5316742062568665, 0.5316742062568665, 0.540723979473114, 0.5339366793632507, 0.540723979473114, 0.5350678563117981, 0.5429864525794983, 0.5475113391876221, 0.5475113391876221, 0.5384615659713745, 0.5475113391876221, 0.5486425161361694, 0.5418552160263062, 0.5452488660812378, 0.5475113391876221, 0.5486425161361694, 0.5531674027442932, 0.5509049892425537, 0.5565611124038696, 0.5554298758506775, 0.5610859990119934, 0.5542986392974854, 0.5531674027442932, 0.5531674027442932, 0.5656108856201172, 0.5667420625686646, 0.5678732991218567, 0.5712669491767883, 0.5690045356750488, 0.5610859990119934, 0.5509049892425537, 0.5565611124038696, 0.5565611124038696, 0.5791855454444885, 0.5554298758506775, 0.5520362257957458, 0.5599547624588013, 0.5622171759605408, 0.5791855454444885, 0.5542986392974854, 0.5712669491767883, 0.5678732991218567, 0.5565611124038696, 0.5622171759605408, 0.5542986392974854, 0.5542986392974854, 0.5712669491767883, 0.557692289352417, 0.5486425161361694, 0.5610859990119934, 0.5565611124038696, 0.5656108856201172, 0.5633484125137329, 0.5610859990119934, 0.5599547624588013, 0.5622171759605408, 0.564479649066925, 0.5542986392974854, 0.5599547624588013, 0.5656108856201172, 0.5656108856201172, 0.564479649066925, 0.5588235259056091, 0.5633484125137329, 0.5475113391876221, 0.564479649066925, 0.5610859990119934, 0.5622171759605408, 0.5667420625686646, 0.5712669491767883, 0.5610859990119934, 0.5622171759605408, 0.5656108856201172, 0.5588235259056091, 0.5622171759605408, 0.5656108856201172, 0.5565611124038696, 0.5565611124038696, 0.5565611124038696, 0.5610859990119934, 0.5622171759605408, 0.5520362257957458, 0.5599547624588013, 0.5565611124038696]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 46ms/step - loss: 1.4306 - accuracy: 0.4943 - val_loss: 1.4275 - val_accuracy: 0.5176\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 13ms/step - loss: 1.4249 - accuracy: 0.5059 - val_loss: 1.4220 - val_accuracy: 0.4897\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4193 - accuracy: 0.5132 - val_loss: 1.4165 - val_accuracy: 0.5207\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4138 - accuracy: 0.5039 - val_loss: 1.4110 - val_accuracy: 0.4917\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4081 - accuracy: 0.5194 - val_loss: 1.4056 - val_accuracy: 0.4835\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4026 - accuracy: 0.5274 - val_loss: 1.4002 - val_accuracy: 0.4886\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3971 - accuracy: 0.5274 - val_loss: 1.3948 - val_accuracy: 0.4917\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3916 - accuracy: 0.5202 - val_loss: 1.3895 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3863 - accuracy: 0.5305 - val_loss: 1.3842 - val_accuracy: 0.4959\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3809 - accuracy: 0.5328 - val_loss: 1.3789 - val_accuracy: 0.4897\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3756 - accuracy: 0.5362 - val_loss: 1.3736 - val_accuracy: 0.5072\n","Epoch 12/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3696 - accuracy: 0.5548 - val_loss: 1.3684 - val_accuracy: 0.5320\n","Epoch 13/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3646 - accuracy: 0.5470 - val_loss: 1.3632 - val_accuracy: 0.5124\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3595 - accuracy: 0.5465 - val_loss: 1.3580 - val_accuracy: 0.5393\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3542 - accuracy: 0.5537 - val_loss: 1.3528 - val_accuracy: 0.5486\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3485 - accuracy: 0.5599 - val_loss: 1.3476 - val_accuracy: 0.5362\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3431 - accuracy: 0.5615 - val_loss: 1.3425 - val_accuracy: 0.5351\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3378 - accuracy: 0.5556 - val_loss: 1.3373 - val_accuracy: 0.5372\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3322 - accuracy: 0.5703 - val_loss: 1.3324 - val_accuracy: 0.5165\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3267 - accuracy: 0.5641 - val_loss: 1.3267 - val_accuracy: 0.5351\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3214 - accuracy: 0.5592 - val_loss: 1.3224 - val_accuracy: 0.5083\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3154 - accuracy: 0.5713 - val_loss: 1.3162 - val_accuracy: 0.5403\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3091 - accuracy: 0.5762 - val_loss: 1.3112 - val_accuracy: 0.5444\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3025 - accuracy: 0.5873 - val_loss: 1.3058 - val_accuracy: 0.5455\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2972 - accuracy: 0.5827 - val_loss: 1.3005 - val_accuracy: 0.5589\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2891 - accuracy: 0.5948 - val_loss: 1.2954 - val_accuracy: 0.5486\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2821 - accuracy: 0.6013 - val_loss: 1.2901 - val_accuracy: 0.5713\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2758 - accuracy: 0.5977 - val_loss: 1.2855 - val_accuracy: 0.5640\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2708 - accuracy: 0.5904 - val_loss: 1.2830 - val_accuracy: 0.5393\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2640 - accuracy: 0.5928 - val_loss: 1.2852 - val_accuracy: 0.5134\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2552 - accuracy: 0.6103 - val_loss: 1.2724 - val_accuracy: 0.5785\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2481 - accuracy: 0.6178 - val_loss: 1.2676 - val_accuracy: 0.5702\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2399 - accuracy: 0.6282 - val_loss: 1.2641 - val_accuracy: 0.5733\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2315 - accuracy: 0.6372 - val_loss: 1.2673 - val_accuracy: 0.5351\n","Epoch 35/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.2247 - accuracy: 0.6359 - val_loss: 1.2595 - val_accuracy: 0.5816\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2165 - accuracy: 0.6357 - val_loss: 1.2565 - val_accuracy: 0.5692\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2083 - accuracy: 0.6481 - val_loss: 1.2550 - val_accuracy: 0.5651\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2023 - accuracy: 0.6406 - val_loss: 1.2565 - val_accuracy: 0.5506\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1971 - accuracy: 0.6457 - val_loss: 1.2519 - val_accuracy: 0.5640\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1846 - accuracy: 0.6667 - val_loss: 1.2479 - val_accuracy: 0.5733\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1789 - accuracy: 0.6654 - val_loss: 1.2490 - val_accuracy: 0.5713\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1723 - accuracy: 0.6661 - val_loss: 1.2467 - val_accuracy: 0.5548\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1619 - accuracy: 0.6718 - val_loss: 1.2438 - val_accuracy: 0.5610\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1550 - accuracy: 0.6721 - val_loss: 1.2518 - val_accuracy: 0.5465\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1468 - accuracy: 0.6796 - val_loss: 1.2447 - val_accuracy: 0.5599\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1421 - accuracy: 0.6760 - val_loss: 1.2806 - val_accuracy: 0.5289\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1393 - accuracy: 0.6703 - val_loss: 1.2437 - val_accuracy: 0.5527\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1191 - accuracy: 0.6987 - val_loss: 1.2610 - val_accuracy: 0.5393\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1157 - accuracy: 0.6922 - val_loss: 1.2444 - val_accuracy: 0.5486\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1122 - accuracy: 0.6873 - val_loss: 1.2444 - val_accuracy: 0.5620\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0965 - accuracy: 0.7049 - val_loss: 1.2430 - val_accuracy: 0.5640\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0927 - accuracy: 0.6992 - val_loss: 1.2434 - val_accuracy: 0.5640\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0811 - accuracy: 0.7127 - val_loss: 1.2456 - val_accuracy: 0.5568\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0707 - accuracy: 0.7116 - val_loss: 1.2539 - val_accuracy: 0.5599\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0686 - accuracy: 0.7137 - val_loss: 1.2621 - val_accuracy: 0.5382\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0590 - accuracy: 0.7178 - val_loss: 1.2549 - val_accuracy: 0.5496\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0498 - accuracy: 0.7274 - val_loss: 1.2495 - val_accuracy: 0.5620\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0400 - accuracy: 0.7357 - val_loss: 1.2550 - val_accuracy: 0.5599\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0312 - accuracy: 0.7289 - val_loss: 1.2587 - val_accuracy: 0.5517\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0233 - accuracy: 0.7432 - val_loss: 1.2570 - val_accuracy: 0.5610\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0148 - accuracy: 0.7344 - val_loss: 1.2726 - val_accuracy: 0.5486\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0009 - accuracy: 0.7558 - val_loss: 1.2759 - val_accuracy: 0.5455\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9985 - accuracy: 0.7481 - val_loss: 1.2669 - val_accuracy: 0.5610\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9847 - accuracy: 0.7571 - val_loss: 1.2697 - val_accuracy: 0.5486\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9830 - accuracy: 0.7576 - val_loss: 1.2687 - val_accuracy: 0.5589\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9815 - accuracy: 0.7514 - val_loss: 1.2750 - val_accuracy: 0.5599\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9631 - accuracy: 0.7672 - val_loss: 1.2745 - val_accuracy: 0.5589\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9516 - accuracy: 0.7724 - val_loss: 1.2911 - val_accuracy: 0.5486\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9445 - accuracy: 0.7760 - val_loss: 1.3101 - val_accuracy: 0.5496\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9448 - accuracy: 0.7729 - val_loss: 1.2910 - val_accuracy: 0.5599\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9305 - accuracy: 0.7762 - val_loss: 1.2915 - val_accuracy: 0.5579\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9222 - accuracy: 0.7783 - val_loss: 1.2967 - val_accuracy: 0.5568\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9122 - accuracy: 0.7902 - val_loss: 1.3063 - val_accuracy: 0.5651\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9205 - accuracy: 0.7783 - val_loss: 1.3355 - val_accuracy: 0.5527\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9075 - accuracy: 0.7842 - val_loss: 1.3009 - val_accuracy: 0.5548\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8819 - accuracy: 0.8041 - val_loss: 1.3064 - val_accuracy: 0.5692\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8806 - accuracy: 0.7953 - val_loss: 1.3119 - val_accuracy: 0.5558\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8648 - accuracy: 0.8106 - val_loss: 1.3288 - val_accuracy: 0.5537\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8667 - accuracy: 0.7992 - val_loss: 1.3576 - val_accuracy: 0.5610\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8706 - accuracy: 0.8057 - val_loss: 1.3201 - val_accuracy: 0.5651\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8664 - accuracy: 0.7956 - val_loss: 1.3383 - val_accuracy: 0.5527\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8466 - accuracy: 0.8168 - val_loss: 1.3234 - val_accuracy: 0.5651\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8368 - accuracy: 0.8147 - val_loss: 1.3498 - val_accuracy: 0.5610\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8280 - accuracy: 0.8243 - val_loss: 1.3326 - val_accuracy: 0.5692\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8265 - accuracy: 0.8269 - val_loss: 1.3470 - val_accuracy: 0.5568\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8067 - accuracy: 0.8307 - val_loss: 1.3502 - val_accuracy: 0.5661\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8024 - accuracy: 0.8302 - val_loss: 1.3564 - val_accuracy: 0.5713\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8026 - accuracy: 0.8261 - val_loss: 1.4049 - val_accuracy: 0.5393\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7989 - accuracy: 0.8274 - val_loss: 1.3608 - val_accuracy: 0.5599\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7879 - accuracy: 0.8282 - val_loss: 1.3642 - val_accuracy: 0.5558\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7766 - accuracy: 0.8411 - val_loss: 1.4193 - val_accuracy: 0.5413\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7754 - accuracy: 0.8380 - val_loss: 1.3887 - val_accuracy: 0.5692\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7631 - accuracy: 0.8437 - val_loss: 1.3888 - val_accuracy: 0.5723\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7566 - accuracy: 0.8532 - val_loss: 1.4037 - val_accuracy: 0.5496\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7469 - accuracy: 0.8517 - val_loss: 1.4062 - val_accuracy: 0.5764\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7403 - accuracy: 0.8517 - val_loss: 1.4082 - val_accuracy: 0.5754\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7315 - accuracy: 0.8597 - val_loss: 1.4161 - val_accuracy: 0.5744\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7208 - accuracy: 0.8739 - val_loss: 1.4305 - val_accuracy: 0.5723\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7200 - accuracy: 0.8607 - val_loss: 1.4361 - val_accuracy: 0.5610\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7236 - accuracy: 0.8602 - val_loss: 1.4514 - val_accuracy: 0.5486\n","{'loss': [1.4305756092071533, 1.4248896837234497, 1.4192925691604614, 1.4138472080230713, 1.4080814123153687, 1.4025596380233765, 1.3971110582351685, 1.3915505409240723, 1.3862868547439575, 1.3808557987213135, 1.3756377696990967, 1.3696448802947998, 1.364600419998169, 1.3595157861709595, 1.354161024093628, 1.3484746217727661, 1.343101978302002, 1.3377827405929565, 1.3322490453720093, 1.3267093896865845, 1.3213646411895752, 1.315409541130066, 1.3091140985488892, 1.302463412284851, 1.2972270250320435, 1.2891446352005005, 1.282051920890808, 1.2757714986801147, 1.2708046436309814, 1.2639931440353394, 1.2552275657653809, 1.248091697692871, 1.239906668663025, 1.2315269708633423, 1.2247105836868286, 1.2165437936782837, 1.2083384990692139, 1.2022714614868164, 1.1970633268356323, 1.1845817565917969, 1.1789485216140747, 1.1722522974014282, 1.1619471311569214, 1.1549909114837646, 1.146762728691101, 1.142060399055481, 1.139338493347168, 1.1190871000289917, 1.1157163381576538, 1.1122337579727173, 1.0964808464050293, 1.0927201509475708, 1.0811136960983276, 1.070732831954956, 1.068610429763794, 1.0589911937713623, 1.0498002767562866, 1.039974331855774, 1.0311962366104126, 1.0233269929885864, 1.0147528648376465, 1.0009126663208008, 0.9984604716300964, 0.9847146272659302, 0.9830061793327332, 0.9814993143081665, 0.9630784392356873, 0.9515762329101562, 0.9445120096206665, 0.9448131918907166, 0.9305309653282166, 0.9222109913825989, 0.9121735692024231, 0.9205241799354553, 0.9075000882148743, 0.8818597793579102, 0.8805975317955017, 0.8647980093955994, 0.8666876554489136, 0.8705537915229797, 0.8664347529411316, 0.8465718030929565, 0.8367576599121094, 0.827966570854187, 0.8265174627304077, 0.8066866993904114, 0.8024157285690308, 0.8026401400566101, 0.798944354057312, 0.787878692150116, 0.7766082286834717, 0.7754209041595459, 0.7630725502967834, 0.7566390633583069, 0.7469015717506409, 0.7402709722518921, 0.7314784526824951, 0.7207948565483093, 0.7200273871421814, 0.7235563397407532], 'accuracy': [0.4943152368068695, 0.5059431791305542, 0.513178288936615, 0.5038759708404541, 0.5193798542022705, 0.52739018201828, 0.52739018201828, 0.5201550126075745, 0.5304909348487854, 0.5328165292739868, 0.5361757278442383, 0.5547803640365601, 0.5470284223556519, 0.5465116500854492, 0.55374675989151, 0.5599483251571655, 0.5614987015724182, 0.5555555820465088, 0.5702842473983765, 0.564082682132721, 0.5591731071472168, 0.5713178515434265, 0.5762273669242859, 0.5873385071754456, 0.5826873183250427, 0.5948320627212524, 0.6012920141220093, 0.5976744294166565, 0.5904392600059509, 0.5927648544311523, 0.6103359460830688, 0.617829442024231, 0.6281653642654419, 0.6372092962265015, 0.6359173059463501, 0.6356589198112488, 0.648061990737915, 0.6405684947967529, 0.6457364559173584, 0.6666666865348816, 0.6653746962547302, 0.6661498546600342, 0.6718346476554871, 0.6720930337905884, 0.6795865893363953, 0.6759690046310425, 0.6702842116355896, 0.6987079977989197, 0.6922480463981628, 0.6873385310173035, 0.7049095630645752, 0.6992248296737671, 0.7126615047454834, 0.7116279006004333, 0.7136951088905334, 0.7178294658660889, 0.7273901700973511, 0.7356589436531067, 0.7289405465126038, 0.7431524395942688, 0.7343669533729553, 0.7558139562606812, 0.748062014579773, 0.7571059465408325, 0.7576227188110352, 0.7514212131500244, 0.7671834826469421, 0.7723514437675476, 0.7759689688682556, 0.7728682160377502, 0.7762274146080017, 0.778294563293457, 0.7901808619499207, 0.778294563293457, 0.7842377424240112, 0.8041343688964844, 0.7953488230705261, 0.8105943202972412, 0.7992247939109802, 0.8056847453117371, 0.7956072092056274, 0.8167958855628967, 0.8147286772727966, 0.8242893815040588, 0.8268733620643616, 0.8307493329048157, 0.830232560634613, 0.8260982036590576, 0.827390193939209, 0.8281653523445129, 0.8410852551460266, 0.8379845023155212, 0.8436692357063293, 0.8532299995422363, 0.8516795635223389, 0.8516795635223389, 0.8596899509429932, 0.8739017844200134, 0.8607234954833984, 0.8602067232131958], 'val_loss': [1.427524447441101, 1.4220097064971924, 1.4164965152740479, 1.4110411405563354, 1.4056134223937988, 1.4002031087875366, 1.394829273223877, 1.389497995376587, 1.3841683864593506, 1.37890625, 1.3736110925674438, 1.3683600425720215, 1.3632255792617798, 1.3579736948013306, 1.3527997732162476, 1.3475887775421143, 1.3425496816635132, 1.337317705154419, 1.332403540611267, 1.326658010482788, 1.3224385976791382, 1.3162306547164917, 1.311166524887085, 1.3057819604873657, 1.3004984855651855, 1.2953815460205078, 1.2900972366333008, 1.285492181777954, 1.2829569578170776, 1.285221815109253, 1.272417426109314, 1.2675998210906982, 1.264106035232544, 1.2672505378723145, 1.2594505548477173, 1.2565090656280518, 1.2550350427627563, 1.2564994096755981, 1.2519382238388062, 1.2479138374328613, 1.248972773551941, 1.2466520071029663, 1.243778944015503, 1.2518409490585327, 1.2446858882904053, 1.2805585861206055, 1.2437077760696411, 1.2609946727752686, 1.2443821430206299, 1.2443913221359253, 1.243027687072754, 1.2434427738189697, 1.2456324100494385, 1.2538535594940186, 1.2620903253555298, 1.2548896074295044, 1.2494782209396362, 1.2549512386322021, 1.2586743831634521, 1.2570157051086426, 1.2726043462753296, 1.275936484336853, 1.2669484615325928, 1.2696683406829834, 1.268664836883545, 1.275002121925354, 1.274517297744751, 1.2910876274108887, 1.3101069927215576, 1.2910090684890747, 1.291548728942871, 1.2966712713241577, 1.3062840700149536, 1.335469365119934, 1.300923466682434, 1.3064167499542236, 1.3118704557418823, 1.3288170099258423, 1.3575596809387207, 1.320073127746582, 1.3383216857910156, 1.3234304189682007, 1.3498252630233765, 1.3325656652450562, 1.3470300436019897, 1.35023033618927, 1.3563522100448608, 1.4049046039581299, 1.3607821464538574, 1.3642055988311768, 1.4193367958068848, 1.3887348175048828, 1.3888485431671143, 1.4036692380905151, 1.406182885169983, 1.4082163572311401, 1.4161165952682495, 1.430494785308838, 1.4361473321914673, 1.4514175653457642], 'val_accuracy': [0.5175619721412659, 0.48966941237449646, 0.5206611752510071, 0.4917355477809906, 0.4834710657596588, 0.4886363744735718, 0.4917355477809906, 0.4886363744735718, 0.4958677589893341, 0.48966941237449646, 0.5072314143180847, 0.5320248007774353, 0.5123966932296753, 0.53925621509552, 0.5485537052154541, 0.5361570119857788, 0.5351239442825317, 0.5371900796890259, 0.5165289044380188, 0.5351239442825317, 0.5082644820213318, 0.5402892827987671, 0.5444214940071106, 0.5454545617103577, 0.55888432264328, 0.5485537052154541, 0.5712810158729553, 0.5640496015548706, 0.53925621509552, 0.5134297609329224, 0.5785123705863953, 0.5702479481697083, 0.5733470916748047, 0.5351239442825317, 0.5816115736961365, 0.5692148804664612, 0.5650826692581177, 0.5506198406219482, 0.5640496015548706, 0.5733470916748047, 0.5712810158729553, 0.5547520518302917, 0.5609503984451294, 0.5464876294136047, 0.5599173307418823, 0.5289255976676941, 0.5526859760284424, 0.53925621509552, 0.5485537052154541, 0.5619834661483765, 0.5640496015548706, 0.5640496015548706, 0.5568181872367859, 0.5599173307418823, 0.538223147392273, 0.5495867729187012, 0.5619834661483765, 0.5599173307418823, 0.5516529083251953, 0.5609503984451294, 0.5485537052154541, 0.5454545617103577, 0.5609503984451294, 0.5485537052154541, 0.55888432264328, 0.5599173307418823, 0.55888432264328, 0.5485537052154541, 0.5495867729187012, 0.5599173307418823, 0.557851254940033, 0.5568181872367859, 0.5650826692581177, 0.5526859760284424, 0.5547520518302917, 0.5692148804664612, 0.5557851195335388, 0.5537189841270447, 0.5609503984451294, 0.5650826692581177, 0.5526859760284424, 0.5650826692581177, 0.5609503984451294, 0.5692148804664612, 0.5568181872367859, 0.56611567735672, 0.5712810158729553, 0.53925621509552, 0.5599173307418823, 0.5557851195335388, 0.5413222908973694, 0.5692148804664612, 0.5723140239715576, 0.5495867729187012, 0.5764462947845459, 0.5754132270812988, 0.5743801593780518, 0.5723140239715576, 0.5609503984451294, 0.5485537052154541]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 6s 51ms/step - loss: 0.9356 - accuracy: 0.7328 - val_loss: 1.0947 - val_accuracy: 0.5830\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9175 - accuracy: 0.7540 - val_loss: 1.0915 - val_accuracy: 0.6315\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8962 - accuracy: 0.7662 - val_loss: 1.0877 - val_accuracy: 0.6034\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8903 - accuracy: 0.7643 - val_loss: 1.0839 - val_accuracy: 0.6401\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8820 - accuracy: 0.7710 - val_loss: 1.0799 - val_accuracy: 0.6228\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8687 - accuracy: 0.7737 - val_loss: 1.0753 - val_accuracy: 0.6304\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8589 - accuracy: 0.7831 - val_loss: 1.0710 - val_accuracy: 0.6153\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8543 - accuracy: 0.7823 - val_loss: 1.0659 - val_accuracy: 0.6347\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8508 - accuracy: 0.7826 - val_loss: 1.0603 - val_accuracy: 0.6401\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8329 - accuracy: 0.7955 - val_loss: 1.0558 - val_accuracy: 0.6293\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8252 - accuracy: 0.7939 - val_loss: 1.0490 - val_accuracy: 0.6455\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8184 - accuracy: 0.8044 - val_loss: 1.0421 - val_accuracy: 0.6476\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8053 - accuracy: 0.8114 - val_loss: 1.0355 - val_accuracy: 0.6487\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8010 - accuracy: 0.8047 - val_loss: 1.0288 - val_accuracy: 0.6466\n","Epoch 15/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7928 - accuracy: 0.8109 - val_loss: 1.0211 - val_accuracy: 0.6541\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7858 - accuracy: 0.8125 - val_loss: 1.0144 - val_accuracy: 0.6509\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7788 - accuracy: 0.8284 - val_loss: 1.0117 - val_accuracy: 0.6412\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7679 - accuracy: 0.8217 - val_loss: 1.0027 - val_accuracy: 0.6606\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7625 - accuracy: 0.8200 - val_loss: 0.9984 - val_accuracy: 0.6530\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7457 - accuracy: 0.8381 - val_loss: 0.9981 - val_accuracy: 0.6670\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7462 - accuracy: 0.8265 - val_loss: 1.0027 - val_accuracy: 0.6509\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7454 - accuracy: 0.8338 - val_loss: 1.0030 - val_accuracy: 0.6692\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7332 - accuracy: 0.8330 - val_loss: 1.0042 - val_accuracy: 0.6670\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7236 - accuracy: 0.8456 - val_loss: 1.0029 - val_accuracy: 0.6692\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7128 - accuracy: 0.8513 - val_loss: 1.0176 - val_accuracy: 0.6713\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7096 - accuracy: 0.8499 - val_loss: 1.0279 - val_accuracy: 0.6746\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7013 - accuracy: 0.8510 - val_loss: 1.0197 - val_accuracy: 0.6756\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7066 - accuracy: 0.8438 - val_loss: 1.0525 - val_accuracy: 0.6703\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7073 - accuracy: 0.8451 - val_loss: 1.0464 - val_accuracy: 0.6703\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.8631 - val_loss: 1.0426 - val_accuracy: 0.6713\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6807 - accuracy: 0.8586 - val_loss: 1.0531 - val_accuracy: 0.6681\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6698 - accuracy: 0.8631 - val_loss: 1.0569 - val_accuracy: 0.6638\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6575 - accuracy: 0.8661 - val_loss: 1.0680 - val_accuracy: 0.6681\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6583 - accuracy: 0.8704 - val_loss: 1.0813 - val_accuracy: 0.6713\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6510 - accuracy: 0.8702 - val_loss: 1.1127 - val_accuracy: 0.6670\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6501 - accuracy: 0.8707 - val_loss: 1.0742 - val_accuracy: 0.6692\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6453 - accuracy: 0.8691 - val_loss: 1.0880 - val_accuracy: 0.6692\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6396 - accuracy: 0.8742 - val_loss: 1.0854 - val_accuracy: 0.6595\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6269 - accuracy: 0.8782 - val_loss: 1.1294 - val_accuracy: 0.6573\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6234 - accuracy: 0.8793 - val_loss: 1.1273 - val_accuracy: 0.6638\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6231 - accuracy: 0.8780 - val_loss: 1.1104 - val_accuracy: 0.6627\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6168 - accuracy: 0.8844 - val_loss: 1.1063 - val_accuracy: 0.6627\n","Epoch 43/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6146 - accuracy: 0.8844 - val_loss: 1.1127 - val_accuracy: 0.6649\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6039 - accuracy: 0.8850 - val_loss: 1.1162 - val_accuracy: 0.6595\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6150 - accuracy: 0.8758 - val_loss: 1.1862 - val_accuracy: 0.6509\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6068 - accuracy: 0.8790 - val_loss: 1.1566 - val_accuracy: 0.6584\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5948 - accuracy: 0.8842 - val_loss: 1.1163 - val_accuracy: 0.6552\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5946 - accuracy: 0.8928 - val_loss: 1.1252 - val_accuracy: 0.6606\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5804 - accuracy: 0.8947 - val_loss: 1.1300 - val_accuracy: 0.6562\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5716 - accuracy: 0.8949 - val_loss: 1.1710 - val_accuracy: 0.6487\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5723 - accuracy: 0.8963 - val_loss: 1.1663 - val_accuracy: 0.6595\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5663 - accuracy: 0.8998 - val_loss: 1.1723 - val_accuracy: 0.6606\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5670 - accuracy: 0.9009 - val_loss: 1.2114 - val_accuracy: 0.6412\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5551 - accuracy: 0.9068 - val_loss: 1.1800 - val_accuracy: 0.6487\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5620 - accuracy: 0.8995 - val_loss: 1.1651 - val_accuracy: 0.6606\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5424 - accuracy: 0.9071 - val_loss: 1.1668 - val_accuracy: 0.6562\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5487 - accuracy: 0.9046 - val_loss: 1.1734 - val_accuracy: 0.6649\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5458 - accuracy: 0.9046 - val_loss: 1.1826 - val_accuracy: 0.6616\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5408 - accuracy: 0.9041 - val_loss: 1.1643 - val_accuracy: 0.6670\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5308 - accuracy: 0.9103 - val_loss: 1.2088 - val_accuracy: 0.6562\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5323 - accuracy: 0.9154 - val_loss: 1.2592 - val_accuracy: 0.6466\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5278 - accuracy: 0.9122 - val_loss: 1.2359 - val_accuracy: 0.6455\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5161 - accuracy: 0.9149 - val_loss: 1.2486 - val_accuracy: 0.6509\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5101 - accuracy: 0.9227 - val_loss: 1.2298 - val_accuracy: 0.6487\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5087 - accuracy: 0.9205 - val_loss: 1.2593 - val_accuracy: 0.6487\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5116 - accuracy: 0.9149 - val_loss: 1.2429 - val_accuracy: 0.6616\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5018 - accuracy: 0.9224 - val_loss: 1.2458 - val_accuracy: 0.6638\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4958 - accuracy: 0.9238 - val_loss: 1.2736 - val_accuracy: 0.6519\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4975 - accuracy: 0.9230 - val_loss: 1.2568 - val_accuracy: 0.6606\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4914 - accuracy: 0.9224 - val_loss: 1.2701 - val_accuracy: 0.6541\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4834 - accuracy: 0.9251 - val_loss: 1.3218 - val_accuracy: 0.6455\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4862 - accuracy: 0.9192 - val_loss: 1.3195 - val_accuracy: 0.6541\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4881 - accuracy: 0.9232 - val_loss: 1.3242 - val_accuracy: 0.6584\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4814 - accuracy: 0.9265 - val_loss: 1.2735 - val_accuracy: 0.6595\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4767 - accuracy: 0.9351 - val_loss: 1.3045 - val_accuracy: 0.6509\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4698 - accuracy: 0.9329 - val_loss: 1.3042 - val_accuracy: 0.6562\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4649 - accuracy: 0.9316 - val_loss: 1.3148 - val_accuracy: 0.6584\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4734 - accuracy: 0.9289 - val_loss: 1.3100 - val_accuracy: 0.6649\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4841 - accuracy: 0.9240 - val_loss: 1.3100 - val_accuracy: 0.6455\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4587 - accuracy: 0.9343 - val_loss: 1.3222 - val_accuracy: 0.6487\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4577 - accuracy: 0.9329 - val_loss: 1.3391 - val_accuracy: 0.6541\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4606 - accuracy: 0.9332 - val_loss: 1.3776 - val_accuracy: 0.6455\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4514 - accuracy: 0.9383 - val_loss: 1.3635 - val_accuracy: 0.6541\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4586 - accuracy: 0.9337 - val_loss: 1.4100 - val_accuracy: 0.6466\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4455 - accuracy: 0.9394 - val_loss: 1.3906 - val_accuracy: 0.6509\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4533 - accuracy: 0.9300 - val_loss: 1.3645 - val_accuracy: 0.6433\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4318 - accuracy: 0.9469 - val_loss: 1.3531 - val_accuracy: 0.6509\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4386 - accuracy: 0.9388 - val_loss: 1.3841 - val_accuracy: 0.6487\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.9434 - val_loss: 1.3845 - val_accuracy: 0.6606\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4274 - accuracy: 0.9450 - val_loss: 1.4468 - val_accuracy: 0.6455\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.9491 - val_loss: 1.4032 - val_accuracy: 0.6422\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4552 - accuracy: 0.9294 - val_loss: 1.4335 - val_accuracy: 0.6476\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4371 - accuracy: 0.9380 - val_loss: 1.4068 - val_accuracy: 0.6509\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4222 - accuracy: 0.9499 - val_loss: 1.3988 - val_accuracy: 0.6487\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4246 - accuracy: 0.9423 - val_loss: 1.5375 - val_accuracy: 0.6412\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4126 - accuracy: 0.9491 - val_loss: 1.4273 - val_accuracy: 0.6562\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4139 - accuracy: 0.9480 - val_loss: 1.4398 - val_accuracy: 0.6433\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4034 - accuracy: 0.9537 - val_loss: 1.4631 - val_accuracy: 0.6487\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4112 - accuracy: 0.9475 - val_loss: 1.4571 - val_accuracy: 0.6476\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4083 - accuracy: 0.9507 - val_loss: 1.4600 - val_accuracy: 0.6519\n","{'loss': [0.9356309771537781, 0.9175131320953369, 0.8962127566337585, 0.8902681469917297, 0.8819565773010254, 0.8687272071838379, 0.8588610291481018, 0.854345977306366, 0.8507746458053589, 0.8329059481620789, 0.8251725435256958, 0.8184009194374084, 0.8053057193756104, 0.8010463118553162, 0.7928045392036438, 0.7857980132102966, 0.7787858843803406, 0.7678523659706116, 0.7624941468238831, 0.7456672191619873, 0.746203601360321, 0.7454216480255127, 0.733161985874176, 0.7235604524612427, 0.7127559781074524, 0.7096384167671204, 0.7013373374938965, 0.7066362500190735, 0.7072659730911255, 0.6799746751785278, 0.6807274222373962, 0.6697821021080017, 0.6575499176979065, 0.6582908630371094, 0.6509620547294617, 0.6500676870346069, 0.6452524662017822, 0.6396246552467346, 0.6269456744194031, 0.6233772039413452, 0.6231005191802979, 0.6167801022529602, 0.6145572662353516, 0.6038599610328674, 0.6150396466255188, 0.6068352460861206, 0.5948250889778137, 0.5946133136749268, 0.5803746581077576, 0.5716350078582764, 0.5722936391830444, 0.5662671327590942, 0.5669955611228943, 0.5551102161407471, 0.5619500279426575, 0.5424413084983826, 0.5486595630645752, 0.5457935929298401, 0.5407569408416748, 0.5307615399360657, 0.5323182940483093, 0.5278493762016296, 0.516111433506012, 0.5100652575492859, 0.5086898803710938, 0.51163649559021, 0.5018232464790344, 0.49577566981315613, 0.49746617674827576, 0.4913546144962311, 0.4834241271018982, 0.48621439933776855, 0.48812776803970337, 0.4814148247241974, 0.47672075033187866, 0.469823956489563, 0.46486252546310425, 0.473371297121048, 0.4841369092464447, 0.45873451232910156, 0.457670122385025, 0.4605586528778076, 0.45136332511901855, 0.45861372351646423, 0.44553476572036743, 0.4533000886440277, 0.4318481981754303, 0.43859249353408813, 0.43294718861579895, 0.427407443523407, 0.4219866991043091, 0.4551851749420166, 0.437057763338089, 0.42222312092781067, 0.424638569355011, 0.41259321570396423, 0.4138765335083008, 0.4033944606781006, 0.4112452566623688, 0.40829938650131226], 'accuracy': [0.732758641242981, 0.7540409564971924, 0.7661637663841248, 0.764277994632721, 0.7710129022598267, 0.7737069129943848, 0.7831357717514038, 0.7823275923728943, 0.782597005367279, 0.795527994632721, 0.7939116358757019, 0.8044180870056152, 0.8114224076271057, 0.8046875, 0.810883641242981, 0.8125, 0.8283944129943848, 0.821659505367279, 0.8200430870056152, 0.8380926847457886, 0.826508641242981, 0.8337823152542114, 0.8329741358757019, 0.8456357717514038, 0.8512930870056152, 0.849946141242981, 0.8510237336158752, 0.84375, 0.845097005367279, 0.8631465435028076, 0.8585668206214905, 0.8631465435028076, 0.8661099076271057, 0.8704202771186829, 0.8701508641242981, 0.8706896305084229, 0.8690732717514038, 0.8741918206214905, 0.8782327771186829, 0.8793103694915771, 0.8779633641242981, 0.884428858757019, 0.884428858757019, 0.8849676847457886, 0.8758081793785095, 0.8790409564971924, 0.884159505367279, 0.8927801847457886, 0.8946659564971924, 0.8949353694915771, 0.8962823152542114, 0.899784505367279, 0.9008620977401733, 0.9067887663841248, 0.8995150923728943, 0.9070581793785095, 0.904633641242981, 0.904633641242981, 0.9040948152542114, 0.9102909564971924, 0.915409505367279, 0.9121767282485962, 0.9148706793785095, 0.9226831793785095, 0.920527994632721, 0.9148706793785095, 0.9224137663841248, 0.9237607717514038, 0.9229525923728943, 0.9224137663841248, 0.9251077771186829, 0.9191810488700867, 0.923222005367279, 0.9264547228813171, 0.9350754022598267, 0.9329202771186829, 0.9315732717514038, 0.9288793206214905, 0.9240301847457886, 0.9342672228813171, 0.9329202771186829, 0.9331896305084229, 0.9383081793785095, 0.9337284564971924, 0.9393857717514038, 0.9299569129943848, 0.946928858757019, 0.938847005367279, 0.9434267282485962, 0.9450430870056152, 0.9490840435028076, 0.9294180870056152, 0.9380387663841248, 0.9498922228813171, 0.9423491358757019, 0.9490840435028076, 0.9480064511299133, 0.9536637663841248, 0.9474676847457886, 0.9507004022598267], 'val_loss': [1.0946571826934814, 1.0915319919586182, 1.0876879692077637, 1.083885669708252, 1.0799150466918945, 1.0753031969070435, 1.070982813835144, 1.0658602714538574, 1.0603077411651611, 1.0558100938796997, 1.0489850044250488, 1.0421369075775146, 1.0355114936828613, 1.0287625789642334, 1.0211291313171387, 1.0143513679504395, 1.0117303133010864, 1.002686858177185, 0.9983509182929993, 0.9980673789978027, 1.0027012825012207, 1.003012776374817, 1.0042455196380615, 1.0029094219207764, 1.0176445245742798, 1.0279031991958618, 1.0196573734283447, 1.0524919033050537, 1.0464237928390503, 1.04258131980896, 1.0531175136566162, 1.056937575340271, 1.0680139064788818, 1.0813428163528442, 1.1127005815505981, 1.0741709470748901, 1.0880472660064697, 1.0854233503341675, 1.1294336318969727, 1.127259612083435, 1.1103730201721191, 1.1063350439071655, 1.1126666069030762, 1.1161887645721436, 1.1861696243286133, 1.1566176414489746, 1.1162748336791992, 1.1252280473709106, 1.1300123929977417, 1.1709531545639038, 1.1662611961364746, 1.1723170280456543, 1.2114288806915283, 1.1799921989440918, 1.1650779247283936, 1.1667816638946533, 1.1734106540679932, 1.1826425790786743, 1.1643218994140625, 1.2088167667388916, 1.2592037916183472, 1.2358907461166382, 1.2486058473587036, 1.229806661605835, 1.2593390941619873, 1.2429181337356567, 1.2458126544952393, 1.2736237049102783, 1.2568281888961792, 1.270134687423706, 1.321842074394226, 1.3195406198501587, 1.3241832256317139, 1.2735079526901245, 1.3044743537902832, 1.3041521310806274, 1.3148019313812256, 1.3099596500396729, 1.3099693059921265, 1.3222222328186035, 1.339097023010254, 1.3775780200958252, 1.3635326623916626, 1.4100441932678223, 1.3906067609786987, 1.3644864559173584, 1.3531097173690796, 1.3841389417648315, 1.3844993114471436, 1.4467713832855225, 1.4032338857650757, 1.4334968328475952, 1.4068111181259155, 1.3987857103347778, 1.5374956130981445, 1.4273247718811035, 1.4398483037948608, 1.4631428718566895, 1.4571326971054077, 1.4599813222885132], 'val_accuracy': [0.5829741358757019, 0.631465494632721, 0.6034482717514038, 0.6400862336158752, 0.6228448152542114, 0.6303879022598267, 0.6153017282485962, 0.6346982717514038, 0.6400862336158752, 0.6293103694915771, 0.6454741358757019, 0.6476293206214905, 0.6487069129943848, 0.6465517282485962, 0.6540948152542114, 0.6508620977401733, 0.6411637663841248, 0.6605603694915771, 0.6530172228813171, 0.6670258641242981, 0.6508620977401733, 0.6691810488700867, 0.6670258641242981, 0.6691810488700867, 0.6713362336158752, 0.6745689511299133, 0.6756465435028076, 0.670258641242981, 0.670258641242981, 0.6713362336158752, 0.6681034564971924, 0.6637930870056152, 0.6681034564971924, 0.6713362336158752, 0.6670258641242981, 0.6691810488700867, 0.6691810488700867, 0.6594827771186829, 0.6573275923728943, 0.6637930870056152, 0.662715494632721, 0.662715494632721, 0.6648706793785095, 0.6594827771186829, 0.6508620977401733, 0.6584051847457886, 0.6551724076271057, 0.6605603694915771, 0.65625, 0.6487069129943848, 0.6594827771186829, 0.6605603694915771, 0.6411637663841248, 0.6487069129943848, 0.6605603694915771, 0.65625, 0.6648706793785095, 0.6616379022598267, 0.6670258641242981, 0.65625, 0.6465517282485962, 0.6454741358757019, 0.6508620977401733, 0.6487069129943848, 0.6487069129943848, 0.6616379022598267, 0.6637930870056152, 0.6519396305084229, 0.6605603694915771, 0.6540948152542114, 0.6454741358757019, 0.6540948152542114, 0.6584051847457886, 0.6594827771186829, 0.6508620977401733, 0.65625, 0.6584051847457886, 0.6648706793785095, 0.6454741358757019, 0.6487069129943848, 0.6540948152542114, 0.6454741358757019, 0.6540948152542114, 0.6465517282485962, 0.6508620977401733, 0.6433189511299133, 0.6508620977401733, 0.6487069129943848, 0.6605603694915771, 0.6454741358757019, 0.642241358757019, 0.6476293206214905, 0.6508620977401733, 0.6487069129943848, 0.6411637663841248, 0.65625, 0.6433189511299133, 0.6487069129943848, 0.6476293206214905, 0.6519396305084229]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.9217 - accuracy: 0.7519"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 53ms/step - loss: 0.9200 - accuracy: 0.7521 - val_loss: 1.0954 - val_accuracy: 0.5600\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9141 - accuracy: 0.7496 - val_loss: 1.0924 - val_accuracy: 0.5566\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8951 - accuracy: 0.7685 - val_loss: 1.0891 - val_accuracy: 0.5588\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8792 - accuracy: 0.7739 - val_loss: 1.0852 - val_accuracy: 0.6278\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8645 - accuracy: 0.7838 - val_loss: 1.0814 - val_accuracy: 0.6369\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8655 - accuracy: 0.7801 - val_loss: 1.0773 - val_accuracy: 0.6403\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8626 - accuracy: 0.7759 - val_loss: 1.0734 - val_accuracy: 0.6335\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8394 - accuracy: 0.8008 - val_loss: 1.0684 - val_accuracy: 0.6471\n","Epoch 9/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.8289 - accuracy: 0.8011 - val_loss: 1.0638 - val_accuracy: 0.6414\n","Epoch 10/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8249 - accuracy: 0.8050 - val_loss: 1.0597 - val_accuracy: 0.6041\n","Epoch 11/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.8216 - accuracy: 0.7937 - val_loss: 1.0524 - val_accuracy: 0.6493\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8095 - accuracy: 0.8081 - val_loss: 1.0457 - val_accuracy: 0.6493\n","Epoch 13/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8002 - accuracy: 0.8138 - val_loss: 1.0404 - val_accuracy: 0.6437\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8005 - accuracy: 0.8084 - val_loss: 1.0395 - val_accuracy: 0.6154\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7943 - accuracy: 0.8065 - val_loss: 1.0304 - val_accuracy: 0.6516\n","Epoch 16/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7774 - accuracy: 0.8243 - val_loss: 1.0277 - val_accuracy: 0.6244\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7852 - accuracy: 0.8130 - val_loss: 1.0150 - val_accuracy: 0.6606\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7543 - accuracy: 0.8325 - val_loss: 1.0108 - val_accuracy: 0.6663\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7518 - accuracy: 0.8339 - val_loss: 1.0161 - val_accuracy: 0.6391\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7556 - accuracy: 0.8308 - val_loss: 1.0081 - val_accuracy: 0.6742\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7414 - accuracy: 0.8410 - val_loss: 1.0048 - val_accuracy: 0.6742\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7418 - accuracy: 0.8347 - val_loss: 1.0046 - val_accuracy: 0.6753\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7388 - accuracy: 0.8364 - val_loss: 1.0049 - val_accuracy: 0.6776\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7265 - accuracy: 0.8438 - val_loss: 1.0231 - val_accuracy: 0.6595\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7145 - accuracy: 0.8480 - val_loss: 1.0384 - val_accuracy: 0.6505\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7237 - accuracy: 0.8373 - val_loss: 1.0325 - val_accuracy: 0.6538\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7109 - accuracy: 0.8472 - val_loss: 1.0229 - val_accuracy: 0.6697\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6951 - accuracy: 0.8526 - val_loss: 1.0286 - val_accuracy: 0.6595\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.8625 - val_loss: 1.0372 - val_accuracy: 0.6686\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6788 - accuracy: 0.8616 - val_loss: 1.0438 - val_accuracy: 0.6742\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6896 - accuracy: 0.8571 - val_loss: 1.0477 - val_accuracy: 0.6663\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6756 - accuracy: 0.8625 - val_loss: 1.0537 - val_accuracy: 0.6629\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6756 - accuracy: 0.8659 - val_loss: 1.0599 - val_accuracy: 0.6618\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6617 - accuracy: 0.8707 - val_loss: 1.0579 - val_accuracy: 0.6629\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6537 - accuracy: 0.8693 - val_loss: 1.0780 - val_accuracy: 0.6674\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6641 - accuracy: 0.8582 - val_loss: 1.0783 - val_accuracy: 0.6663\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6464 - accuracy: 0.8715 - val_loss: 1.0740 - val_accuracy: 0.6629\n","Epoch 38/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6348 - accuracy: 0.8809 - val_loss: 1.0763 - val_accuracy: 0.6629\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6306 - accuracy: 0.8834 - val_loss: 1.0971 - val_accuracy: 0.6629\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6333 - accuracy: 0.8749 - val_loss: 1.0842 - val_accuracy: 0.6606\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6224 - accuracy: 0.8803 - val_loss: 1.1036 - val_accuracy: 0.6606\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6228 - accuracy: 0.8789 - val_loss: 1.0965 - val_accuracy: 0.6618\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6092 - accuracy: 0.8831 - val_loss: 1.1076 - val_accuracy: 0.6606\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6024 - accuracy: 0.8916 - val_loss: 1.1045 - val_accuracy: 0.6708\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6007 - accuracy: 0.8916 - val_loss: 1.1128 - val_accuracy: 0.6629\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5931 - accuracy: 0.8925 - val_loss: 1.1252 - val_accuracy: 0.6629\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5929 - accuracy: 0.8905 - val_loss: 1.1290 - val_accuracy: 0.6595\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5845 - accuracy: 0.9018 - val_loss: 1.1280 - val_accuracy: 0.6606\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5810 - accuracy: 0.8964 - val_loss: 1.1316 - val_accuracy: 0.6663\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5756 - accuracy: 0.8922 - val_loss: 1.1678 - val_accuracy: 0.6697\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5720 - accuracy: 0.9038 - val_loss: 1.1465 - val_accuracy: 0.6731\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5725 - accuracy: 0.8922 - val_loss: 1.1370 - val_accuracy: 0.6561\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5613 - accuracy: 0.8998 - val_loss: 1.1485 - val_accuracy: 0.6629\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5533 - accuracy: 0.9103 - val_loss: 1.1603 - val_accuracy: 0.6618\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5556 - accuracy: 0.9044 - val_loss: 1.1602 - val_accuracy: 0.6550\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5499 - accuracy: 0.9078 - val_loss: 1.1716 - val_accuracy: 0.6663\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5482 - accuracy: 0.9089 - val_loss: 1.1734 - val_accuracy: 0.6606\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5496 - accuracy: 0.9046 - val_loss: 1.2175 - val_accuracy: 0.6425\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5586 - accuracy: 0.8990 - val_loss: 1.1777 - val_accuracy: 0.6674\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5542 - accuracy: 0.9015 - val_loss: 1.2139 - val_accuracy: 0.6595\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5287 - accuracy: 0.9109 - val_loss: 1.1799 - val_accuracy: 0.6663\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5250 - accuracy: 0.9171 - val_loss: 1.2015 - val_accuracy: 0.6697\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5198 - accuracy: 0.9174 - val_loss: 1.1927 - val_accuracy: 0.6595\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5128 - accuracy: 0.9216 - val_loss: 1.2368 - val_accuracy: 0.6584\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5155 - accuracy: 0.9191 - val_loss: 1.2037 - val_accuracy: 0.6731\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5111 - accuracy: 0.9145 - val_loss: 1.2176 - val_accuracy: 0.6618\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5048 - accuracy: 0.9233 - val_loss: 1.2118 - val_accuracy: 0.6697\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4986 - accuracy: 0.9222 - val_loss: 1.2292 - val_accuracy: 0.6618\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5086 - accuracy: 0.9202 - val_loss: 1.2208 - val_accuracy: 0.6652\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5025 - accuracy: 0.9202 - val_loss: 1.2585 - val_accuracy: 0.6663\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5063 - accuracy: 0.9157 - val_loss: 1.2660 - val_accuracy: 0.6640\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4995 - accuracy: 0.9165 - val_loss: 1.2459 - val_accuracy: 0.6606\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4890 - accuracy: 0.9290 - val_loss: 1.2365 - val_accuracy: 0.6584\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4812 - accuracy: 0.9293 - val_loss: 1.2582 - val_accuracy: 0.6686\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4769 - accuracy: 0.9335 - val_loss: 1.2537 - val_accuracy: 0.6663\n","Epoch 76/100\n","28/28 [==============================] - 1s 51ms/step - loss: 0.4750 - accuracy: 0.9293 - val_loss: 1.2780 - val_accuracy: 0.6787\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4650 - accuracy: 0.9360 - val_loss: 1.2983 - val_accuracy: 0.6493\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4711 - accuracy: 0.9298 - val_loss: 1.3368 - val_accuracy: 0.6459\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4715 - accuracy: 0.9287 - val_loss: 1.2921 - val_accuracy: 0.6652\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4621 - accuracy: 0.9329 - val_loss: 1.2913 - val_accuracy: 0.6527\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4687 - accuracy: 0.9321 - val_loss: 1.2965 - val_accuracy: 0.6629\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4657 - accuracy: 0.9307 - val_loss: 1.2870 - val_accuracy: 0.6584\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4564 - accuracy: 0.9332 - val_loss: 1.3043 - val_accuracy: 0.6686\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4485 - accuracy: 0.9417 - val_loss: 1.3087 - val_accuracy: 0.6538\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4505 - accuracy: 0.9372 - val_loss: 1.3062 - val_accuracy: 0.6686\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4410 - accuracy: 0.9454 - val_loss: 1.3125 - val_accuracy: 0.6584\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4529 - accuracy: 0.9304 - val_loss: 1.3569 - val_accuracy: 0.6629\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4558 - accuracy: 0.9327 - val_loss: 1.3097 - val_accuracy: 0.6595\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4339 - accuracy: 0.9437 - val_loss: 1.3180 - val_accuracy: 0.6663\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4311 - accuracy: 0.9451 - val_loss: 1.3351 - val_accuracy: 0.6584\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4329 - accuracy: 0.9403 - val_loss: 1.3251 - val_accuracy: 0.6606\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4315 - accuracy: 0.9437 - val_loss: 1.3643 - val_accuracy: 0.6471\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4300 - accuracy: 0.9445 - val_loss: 1.4057 - val_accuracy: 0.6527\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4233 - accuracy: 0.9468 - val_loss: 1.3740 - val_accuracy: 0.6629\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4317 - accuracy: 0.9403 - val_loss: 1.3694 - val_accuracy: 0.6618\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4210 - accuracy: 0.9477 - val_loss: 1.3756 - val_accuracy: 0.6663\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4201 - accuracy: 0.9451 - val_loss: 1.3775 - val_accuracy: 0.6482\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4143 - accuracy: 0.9519 - val_loss: 1.3748 - val_accuracy: 0.6550\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4118 - accuracy: 0.9513 - val_loss: 1.4075 - val_accuracy: 0.6538\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4088 - accuracy: 0.9539 - val_loss: 1.4037 - val_accuracy: 0.6595\n","{'loss': [0.9199764728546143, 0.9141476154327393, 0.8950825333595276, 0.8791572451591492, 0.8645098209381104, 0.86545729637146, 0.8625550270080566, 0.8394380211830139, 0.8289181590080261, 0.8248727917671204, 0.8216257691383362, 0.8094676733016968, 0.8001901507377625, 0.8005022406578064, 0.7942784428596497, 0.777380645275116, 0.7851589918136597, 0.7542923092842102, 0.7517552971839905, 0.7556253671646118, 0.741421103477478, 0.7418442964553833, 0.7388046383857727, 0.726514458656311, 0.7145488262176514, 0.723696231842041, 0.7109160423278809, 0.6950516700744629, 0.6899011135101318, 0.6788244843482971, 0.6895955204963684, 0.6755657196044922, 0.6756069660186768, 0.6616642475128174, 0.6536959409713745, 0.6640595197677612, 0.6463527679443359, 0.6347609162330627, 0.6306003332138062, 0.6333422064781189, 0.6223860383033752, 0.6227893233299255, 0.6092415452003479, 0.6023760437965393, 0.6007081866264343, 0.5931023359298706, 0.5929333567619324, 0.5844869017601013, 0.5809940099716187, 0.5755755305290222, 0.5719790458679199, 0.5725444555282593, 0.5612848401069641, 0.5533344149589539, 0.5556285977363586, 0.5498664379119873, 0.5481755137443542, 0.5496429800987244, 0.5586437582969666, 0.5541565418243408, 0.5287372469902039, 0.5249500274658203, 0.5197952389717102, 0.5127777457237244, 0.5154674649238586, 0.5111252069473267, 0.5048310160636902, 0.49862298369407654, 0.5086027383804321, 0.5024815201759338, 0.5063258409500122, 0.49950113892555237, 0.48898306488990784, 0.48123982548713684, 0.4768948256969452, 0.4749775230884552, 0.465023010969162, 0.4710576832294464, 0.4714876413345337, 0.46210283041000366, 0.4687329828739166, 0.4656645357608795, 0.4563802182674408, 0.44853439927101135, 0.45050832629203796, 0.4409678876399994, 0.4528575539588928, 0.45581576228141785, 0.4339057505130768, 0.43109866976737976, 0.4328692853450775, 0.4315320551395416, 0.4300059378147125, 0.423257440328598, 0.43171340227127075, 0.4209974706172943, 0.4200930595397949, 0.4142891764640808, 0.4117639660835266, 0.4087800681591034], 'accuracy': [0.7521222233772278, 0.7495755553245544, 0.768534243106842, 0.7739105820655823, 0.7838143706321716, 0.7801358103752136, 0.7758913636207581, 0.8007922768592834, 0.801075279712677, 0.8050367832183838, 0.793718159198761, 0.8081493973731995, 0.8138087391853333, 0.808432400226593, 0.8064516186714172, 0.8242784142494202, 0.8129597902297974, 0.8324844241142273, 0.8338992595672607, 0.8307866454124451, 0.8409733772277832, 0.8347481489181519, 0.8364459276199341, 0.8438030481338501, 0.8480475544929504, 0.83729487657547, 0.8471986651420593, 0.8525750041007996, 0.8624787926673889, 0.8616299033164978, 0.8571024537086487, 0.8624787926673889, 0.8658743500709534, 0.870684802532196, 0.8692699670791626, 0.8582342863082886, 0.8715336918830872, 0.8808715343475342, 0.8834182024002075, 0.8749292492866516, 0.8803055882453918, 0.8788907527923584, 0.8831352591514587, 0.8916242122650146, 0.8916242122650146, 0.8924731016159058, 0.8904923796653748, 0.9018110036849976, 0.8964346647262573, 0.892190158367157, 0.9037917256355286, 0.892190158367157, 0.8998302221298218, 0.9102999567985535, 0.9043576717376709, 0.9077532291412354, 0.90888512134552, 0.9046406149864197, 0.8989813327789307, 0.901528000831604, 0.9108659029006958, 0.9170911312103271, 0.9173740744590759, 0.9216185808181763, 0.9190718531608582, 0.914544403553009, 0.9233163595199585, 0.9221844673156738, 0.9202037453651428, 0.9202037453651428, 0.9156762957572937, 0.9165251851081848, 0.9289756417274475, 0.9292586445808411, 0.9335030913352966, 0.9292586445808411, 0.9360498189926147, 0.9298245906829834, 0.9286926984786987, 0.9329372048377991, 0.9320882558822632, 0.9306734800338745, 0.9332201480865479, 0.9417091012001038, 0.9371816515922546, 0.9453876614570618, 0.930390477180481, 0.9326542019844055, 0.9436898827552795, 0.945104718208313, 0.9402942657470703, 0.9436898827552795, 0.9445387721061707, 0.9468024969100952, 0.9402942657470703, 0.9476513862609863, 0.945104718208313, 0.9518958926200867, 0.9513299465179443, 0.9538766145706177], 'val_loss': [1.095425009727478, 1.0924067497253418, 1.0891354084014893, 1.08523428440094, 1.0813853740692139, 1.0772852897644043, 1.073441743850708, 1.0684311389923096, 1.063846230506897, 1.0597203969955444, 1.0524225234985352, 1.045704960823059, 1.0403567552566528, 1.0394618511199951, 1.0304031372070312, 1.027716875076294, 1.0149613618850708, 1.0108065605163574, 1.0160609483718872, 1.0081380605697632, 1.004789113998413, 1.004604458808899, 1.0049175024032593, 1.0231410264968872, 1.038448452949524, 1.032474160194397, 1.0229229927062988, 1.028617024421692, 1.0372142791748047, 1.0438190698623657, 1.0477200746536255, 1.0537360906600952, 1.059885859489441, 1.0578536987304688, 1.078015923500061, 1.078302025794983, 1.074023723602295, 1.0762550830841064, 1.0971142053604126, 1.0841803550720215, 1.1036304235458374, 1.096497893333435, 1.1076438426971436, 1.1044880151748657, 1.1128255128860474, 1.1252171993255615, 1.1289994716644287, 1.1279748678207397, 1.131598711013794, 1.167759656906128, 1.146535038948059, 1.1369736194610596, 1.1485316753387451, 1.1603376865386963, 1.1601537466049194, 1.1715534925460815, 1.1734002828598022, 1.2174509763717651, 1.1777061223983765, 1.2138848304748535, 1.1798698902130127, 1.201539158821106, 1.1926871538162231, 1.2367745637893677, 1.2036741971969604, 1.2176240682601929, 1.2118170261383057, 1.2292218208312988, 1.2207660675048828, 1.2585325241088867, 1.265950083732605, 1.2459038496017456, 1.2365347146987915, 1.2582457065582275, 1.2537386417388916, 1.2780110836029053, 1.2983360290527344, 1.3368401527404785, 1.2921463251113892, 1.2912975549697876, 1.2964601516723633, 1.287037968635559, 1.3043136596679688, 1.3086509704589844, 1.3062188625335693, 1.3125149011611938, 1.356927514076233, 1.3096516132354736, 1.3180019855499268, 1.3350898027420044, 1.3250764608383179, 1.3642616271972656, 1.4056649208068848, 1.3740110397338867, 1.3694043159484863, 1.375603437423706, 1.3775056600570679, 1.374770164489746, 1.407542109489441, 1.4036928415298462], 'val_accuracy': [0.5599547624588013, 0.5565611124038696, 0.5588235259056091, 0.627828061580658, 0.6368778347969055, 0.6402714848518372, 0.6334841847419739, 0.6470588445663452, 0.6414027214050293, 0.6040723919868469, 0.6493212580680847, 0.6493212580680847, 0.6436651349067688, 0.6153846383094788, 0.651583731174469, 0.6244344115257263, 0.6606335043907166, 0.6662895679473877, 0.639140248298645, 0.6742081642150879, 0.6742081642150879, 0.6753393411636353, 0.6776018142700195, 0.6595022678375244, 0.6504524946212769, 0.6538461446762085, 0.6696832776069641, 0.6595022678375244, 0.668552041053772, 0.6742081642150879, 0.6662895679473877, 0.662895917892456, 0.6617646813392639, 0.662895917892456, 0.6674208045005798, 0.6662895679473877, 0.662895917892456, 0.662895917892456, 0.662895917892456, 0.6606335043907166, 0.6606335043907166, 0.6617646813392639, 0.6606335043907166, 0.6708144545555115, 0.662895917892456, 0.662895917892456, 0.6595022678375244, 0.6606335043907166, 0.6662895679473877, 0.6696832776069641, 0.6730769276618958, 0.6561086177825928, 0.662895917892456, 0.6617646813392639, 0.6549773812294006, 0.6662895679473877, 0.6606335043907166, 0.6425339579582214, 0.6674208045005798, 0.6595022678375244, 0.6662895679473877, 0.6696832776069641, 0.6595022678375244, 0.6583710312843323, 0.6730769276618958, 0.6617646813392639, 0.6696832776069641, 0.6617646813392639, 0.6651583909988403, 0.6662895679473877, 0.6640271544456482, 0.6606335043907166, 0.6583710312843323, 0.668552041053772, 0.6662895679473877, 0.6787330508232117, 0.6493212580680847, 0.6459276080131531, 0.6651583909988403, 0.6527149081230164, 0.662895917892456, 0.6583710312843323, 0.668552041053772, 0.6538461446762085, 0.668552041053772, 0.6583710312843323, 0.662895917892456, 0.6595022678375244, 0.6662895679473877, 0.6583710312843323, 0.6606335043907166, 0.6470588445663452, 0.6527149081230164, 0.662895917892456, 0.6617646813392639, 0.6662895679473877, 0.6481900215148926, 0.6549773812294006, 0.6538461446762085, 0.6595022678375244]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.9372 - accuracy: 0.7319"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 52ms/step - loss: 0.9354 - accuracy: 0.7331 - val_loss: 1.0942 - val_accuracy: 0.5640\n","Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9136 - accuracy: 0.7491 - val_loss: 1.0906 - val_accuracy: 0.5713\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9111 - accuracy: 0.7465 - val_loss: 1.0867 - val_accuracy: 0.6095\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8877 - accuracy: 0.7685 - val_loss: 1.0826 - val_accuracy: 0.6126\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8968 - accuracy: 0.7561 - val_loss: 1.0784 - val_accuracy: 0.6250\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8749 - accuracy: 0.7690 - val_loss: 1.0737 - val_accuracy: 0.6167\n","Epoch 7/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8705 - accuracy: 0.7757 - val_loss: 1.0689 - val_accuracy: 0.6178\n","Epoch 8/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8543 - accuracy: 0.7845 - val_loss: 1.0629 - val_accuracy: 0.6415\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8428 - accuracy: 0.7881 - val_loss: 1.0562 - val_accuracy: 0.6457\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8357 - accuracy: 0.7876 - val_loss: 1.0500 - val_accuracy: 0.6415\n","Epoch 11/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8291 - accuracy: 0.7866 - val_loss: 1.0437 - val_accuracy: 0.6374\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8220 - accuracy: 0.7925 - val_loss: 1.0360 - val_accuracy: 0.6353\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8097 - accuracy: 0.8034 - val_loss: 1.0298 - val_accuracy: 0.6436\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8008 - accuracy: 0.8078 - val_loss: 1.0212 - val_accuracy: 0.6415\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7997 - accuracy: 0.8039 - val_loss: 1.0154 - val_accuracy: 0.6343\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7982 - accuracy: 0.8005 - val_loss: 1.0152 - val_accuracy: 0.6436\n","Epoch 17/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7931 - accuracy: 0.8052 - val_loss: 1.0203 - val_accuracy: 0.6188\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7785 - accuracy: 0.8119 - val_loss: 1.0030 - val_accuracy: 0.6374\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7607 - accuracy: 0.8248 - val_loss: 1.0025 - val_accuracy: 0.6312\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7626 - accuracy: 0.8233 - val_loss: 1.0080 - val_accuracy: 0.6457\n","Epoch 21/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7608 - accuracy: 0.8199 - val_loss: 1.0070 - val_accuracy: 0.6457\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7422 - accuracy: 0.8320 - val_loss: 1.0183 - val_accuracy: 0.6446\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7501 - accuracy: 0.8269 - val_loss: 1.0248 - val_accuracy: 0.6477\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7409 - accuracy: 0.8261 - val_loss: 1.0293 - val_accuracy: 0.6550\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7282 - accuracy: 0.8331 - val_loss: 1.0367 - val_accuracy: 0.6467\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7185 - accuracy: 0.8411 - val_loss: 1.0454 - val_accuracy: 0.6581\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7158 - accuracy: 0.8421 - val_loss: 1.0585 - val_accuracy: 0.6550\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7208 - accuracy: 0.8328 - val_loss: 1.0990 - val_accuracy: 0.6333\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7171 - accuracy: 0.8315 - val_loss: 1.0627 - val_accuracy: 0.6498\n","Epoch 30/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6965 - accuracy: 0.8432 - val_loss: 1.0675 - val_accuracy: 0.6601\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6846 - accuracy: 0.8530 - val_loss: 1.0989 - val_accuracy: 0.6467\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7033 - accuracy: 0.8372 - val_loss: 1.1059 - val_accuracy: 0.6364\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6796 - accuracy: 0.8514 - val_loss: 1.1093 - val_accuracy: 0.6539\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6832 - accuracy: 0.8424 - val_loss: 1.0961 - val_accuracy: 0.6529\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6666 - accuracy: 0.8558 - val_loss: 1.1383 - val_accuracy: 0.6333\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6622 - accuracy: 0.8623 - val_loss: 1.1036 - val_accuracy: 0.6508\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6538 - accuracy: 0.8599 - val_loss: 1.1077 - val_accuracy: 0.6477\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6521 - accuracy: 0.8574 - val_loss: 1.1145 - val_accuracy: 0.6508\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6454 - accuracy: 0.8651 - val_loss: 1.1239 - val_accuracy: 0.6477\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6313 - accuracy: 0.8724 - val_loss: 1.1289 - val_accuracy: 0.6436\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6271 - accuracy: 0.8721 - val_loss: 1.1407 - val_accuracy: 0.6477\n","Epoch 42/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6293 - accuracy: 0.8742 - val_loss: 1.1382 - val_accuracy: 0.6612\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6214 - accuracy: 0.8703 - val_loss: 1.1622 - val_accuracy: 0.6405\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6202 - accuracy: 0.8749 - val_loss: 1.1453 - val_accuracy: 0.6446\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6184 - accuracy: 0.8698 - val_loss: 1.1556 - val_accuracy: 0.6395\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6144 - accuracy: 0.8765 - val_loss: 1.1662 - val_accuracy: 0.6415\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6025 - accuracy: 0.8871 - val_loss: 1.1701 - val_accuracy: 0.6353\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6025 - accuracy: 0.8755 - val_loss: 1.1635 - val_accuracy: 0.6415\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6028 - accuracy: 0.8796 - val_loss: 1.1689 - val_accuracy: 0.6467\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5971 - accuracy: 0.8767 - val_loss: 1.1740 - val_accuracy: 0.6508\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5880 - accuracy: 0.8798 - val_loss: 1.1759 - val_accuracy: 0.6477\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5785 - accuracy: 0.8925 - val_loss: 1.1844 - val_accuracy: 0.6457\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5724 - accuracy: 0.8953 - val_loss: 1.1914 - val_accuracy: 0.6488\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5621 - accuracy: 0.8930 - val_loss: 1.1996 - val_accuracy: 0.6508\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5748 - accuracy: 0.8829 - val_loss: 1.2075 - val_accuracy: 0.6426\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5659 - accuracy: 0.8959 - val_loss: 1.2167 - val_accuracy: 0.6446\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5619 - accuracy: 0.8922 - val_loss: 1.2146 - val_accuracy: 0.6519\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5551 - accuracy: 0.8956 - val_loss: 1.2283 - val_accuracy: 0.6364\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5416 - accuracy: 0.9088 - val_loss: 1.2263 - val_accuracy: 0.6519\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5393 - accuracy: 0.9031 - val_loss: 1.2328 - val_accuracy: 0.6436\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5403 - accuracy: 0.8992 - val_loss: 1.2323 - val_accuracy: 0.6477\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5342 - accuracy: 0.9088 - val_loss: 1.2555 - val_accuracy: 0.6374\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5424 - accuracy: 0.8997 - val_loss: 1.2496 - val_accuracy: 0.6529\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5378 - accuracy: 0.9008 - val_loss: 1.3001 - val_accuracy: 0.6374\n","Epoch 65/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5262 - accuracy: 0.9057 - val_loss: 1.2856 - val_accuracy: 0.6395\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5210 - accuracy: 0.9106 - val_loss: 1.2762 - val_accuracy: 0.6436\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5242 - accuracy: 0.9041 - val_loss: 1.2747 - val_accuracy: 0.6384\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5118 - accuracy: 0.9140 - val_loss: 1.2791 - val_accuracy: 0.6467\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5150 - accuracy: 0.9103 - val_loss: 1.2842 - val_accuracy: 0.6477\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5102 - accuracy: 0.9127 - val_loss: 1.3712 - val_accuracy: 0.6188\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5161 - accuracy: 0.9065 - val_loss: 1.2938 - val_accuracy: 0.6395\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4979 - accuracy: 0.9147 - val_loss: 1.3164 - val_accuracy: 0.6374\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4987 - accuracy: 0.9134 - val_loss: 1.3170 - val_accuracy: 0.6312\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4996 - accuracy: 0.9147 - val_loss: 1.3280 - val_accuracy: 0.6364\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4876 - accuracy: 0.9222 - val_loss: 1.3454 - val_accuracy: 0.6384\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4855 - accuracy: 0.9183 - val_loss: 1.3374 - val_accuracy: 0.6353\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4882 - accuracy: 0.9183 - val_loss: 1.3450 - val_accuracy: 0.6384\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4819 - accuracy: 0.9173 - val_loss: 1.3543 - val_accuracy: 0.6395\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4789 - accuracy: 0.9230 - val_loss: 1.3453 - val_accuracy: 0.6488\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4771 - accuracy: 0.9207 - val_loss: 1.3751 - val_accuracy: 0.6353\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4767 - accuracy: 0.9222 - val_loss: 1.3530 - val_accuracy: 0.6333\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4673 - accuracy: 0.9264 - val_loss: 1.3750 - val_accuracy: 0.6364\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4676 - accuracy: 0.9245 - val_loss: 1.3772 - val_accuracy: 0.6436\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4649 - accuracy: 0.9245 - val_loss: 1.3856 - val_accuracy: 0.6395\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4626 - accuracy: 0.9258 - val_loss: 1.4397 - val_accuracy: 0.6312\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4621 - accuracy: 0.9264 - val_loss: 1.3936 - val_accuracy: 0.6415\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4566 - accuracy: 0.9310 - val_loss: 1.3997 - val_accuracy: 0.6415\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4555 - accuracy: 0.9266 - val_loss: 1.4276 - val_accuracy: 0.6343\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4502 - accuracy: 0.9292 - val_loss: 1.4204 - val_accuracy: 0.6457\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4519 - accuracy: 0.9302 - val_loss: 1.4421 - val_accuracy: 0.6322\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4609 - accuracy: 0.9204 - val_loss: 1.4062 - val_accuracy: 0.6364\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4416 - accuracy: 0.9357 - val_loss: 1.4219 - val_accuracy: 0.6395\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4478 - accuracy: 0.9253 - val_loss: 1.4495 - val_accuracy: 0.6322\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4464 - accuracy: 0.9276 - val_loss: 1.4659 - val_accuracy: 0.6281\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4470 - accuracy: 0.9258 - val_loss: 1.4326 - val_accuracy: 0.6405\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4317 - accuracy: 0.9390 - val_loss: 1.4451 - val_accuracy: 0.6343\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4202 - accuracy: 0.9455 - val_loss: 1.4750 - val_accuracy: 0.6364\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4241 - accuracy: 0.9390 - val_loss: 1.4640 - val_accuracy: 0.6333\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4246 - accuracy: 0.9385 - val_loss: 1.4820 - val_accuracy: 0.6364\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4246 - accuracy: 0.9362 - val_loss: 1.4890 - val_accuracy: 0.6457\n","{'loss': [0.9353957176208496, 0.913598358631134, 0.9110585451126099, 0.8877262473106384, 0.8967919945716858, 0.8749284148216248, 0.8705251812934875, 0.8543363809585571, 0.8428413271903992, 0.8357123732566833, 0.8291320204734802, 0.8220424056053162, 0.8096969723701477, 0.8007696270942688, 0.7996805906295776, 0.7981716394424438, 0.7931498289108276, 0.7784966826438904, 0.7607226371765137, 0.762636125087738, 0.7607879042625427, 0.742153525352478, 0.7501348853111267, 0.7409452199935913, 0.7282271385192871, 0.7184522747993469, 0.7158116698265076, 0.7207880616188049, 0.7171244025230408, 0.6964733600616455, 0.6846364736557007, 0.7033265829086304, 0.6796068549156189, 0.6832011938095093, 0.6666446924209595, 0.6621692180633545, 0.6537883281707764, 0.6521018147468567, 0.6453962922096252, 0.6313016414642334, 0.6270808577537537, 0.6292870044708252, 0.6214397549629211, 0.6201676726341248, 0.6183937191963196, 0.6143836975097656, 0.6024587750434875, 0.6025075912475586, 0.602767288684845, 0.5971229076385498, 0.5879857540130615, 0.5785277485847473, 0.5723913908004761, 0.562070369720459, 0.5748353600502014, 0.5659027695655823, 0.56191486120224, 0.5550845861434937, 0.5415861010551453, 0.5393195748329163, 0.5403016805648804, 0.5341511368751526, 0.5423658490180969, 0.5378151535987854, 0.5261536240577698, 0.5209543108940125, 0.5242125391960144, 0.5117843151092529, 0.5149729251861572, 0.5101689696311951, 0.5160514116287231, 0.4979255199432373, 0.4987359046936035, 0.49960899353027344, 0.4875890910625458, 0.4854716956615448, 0.4881818890571594, 0.48188790678977966, 0.47886455059051514, 0.4770874083042145, 0.4767020344734192, 0.467281699180603, 0.46757104992866516, 0.4648750126361847, 0.462565153837204, 0.46206924319267273, 0.4565856456756592, 0.45545706152915955, 0.45021483302116394, 0.45192039012908936, 0.4608977437019348, 0.4416416585445404, 0.4477541446685791, 0.44638121128082275, 0.44697055220603943, 0.43172651529312134, 0.4202241599559784, 0.4240887761116028, 0.424590140581131, 0.42459723353385925], 'accuracy': [0.733074963092804, 0.749095618724823, 0.7465116381645203, 0.7684754729270935, 0.7560723423957825, 0.7689922451972961, 0.7757105827331543, 0.7844961285591125, 0.7881137132644653, 0.7875968813896179, 0.7865633368492126, 0.7925064563751221, 0.8033591508865356, 0.8077519536018372, 0.8038759827613831, 0.8005167841911316, 0.8051679730415344, 0.8118863105773926, 0.8248062133789062, 0.8232558369636536, 0.8198966383934021, 0.832041323184967, 0.8268733620643616, 0.8260982036590576, 0.8330749273300171, 0.8410852551460266, 0.8421188592910767, 0.8328165411949158, 0.8315245509147644, 0.8431524634361267, 0.8529715538024902, 0.8372092843055725, 0.8514211773872375, 0.842377245426178, 0.8558139801025391, 0.8622739315032959, 0.8599483370780945, 0.8573643565177917, 0.8651162981987, 0.8723514080047607, 0.8720930218696594, 0.8741602301597595, 0.8702842593193054, 0.8749353885650635, 0.869767427444458, 0.8764857649803162, 0.8870801329612732, 0.8754522204399109, 0.8795865774154663, 0.8767442107200623, 0.8798449635505676, 0.89250648021698, 0.895348846912384, 0.8930232524871826, 0.882945716381073, 0.8958656191825867, 0.8922480344772339, 0.8956072330474854, 0.9087855219841003, 0.9031007885932922, 0.8992248177528381, 0.9087855219841003, 0.8997415900230408, 0.9007751941680908, 0.905684769153595, 0.9105943441390991, 0.9041343927383423, 0.9139534831047058, 0.910335898399353, 0.9126614928245544, 0.9064599275588989, 0.9147287011146545, 0.9134367108345032, 0.9147287011146545, 0.9222221970558167, 0.9183462262153625, 0.9183462262153625, 0.9173126816749573, 0.9229974150657654, 0.920671820640564, 0.9222221970558167, 0.9263566136360168, 0.9245477914810181, 0.9245477914810181, 0.9258397817611694, 0.9263566136360168, 0.9310077428817749, 0.9266149997711182, 0.9291989803314209, 0.930232584476471, 0.9204134345054626, 0.9356589317321777, 0.9253230094909668, 0.9276486039161682, 0.9258397817611694, 0.9390180706977844, 0.9454780220985413, 0.9390180706977844, 0.9385012984275818, 0.9361757040023804], 'val_loss': [1.0941832065582275, 1.0905790328979492, 1.086727261543274, 1.0825539827346802, 1.0783601999282837, 1.073735237121582, 1.0688796043395996, 1.062934160232544, 1.056221842765808, 1.0500235557556152, 1.043684482574463, 1.0359541177749634, 1.0297584533691406, 1.0211739540100098, 1.0153874158859253, 1.0151996612548828, 1.0202562808990479, 1.003012776374817, 1.0025213956832886, 1.0080249309539795, 1.0070385932922363, 1.0183461904525757, 1.0248332023620605, 1.0293190479278564, 1.0367482900619507, 1.045398473739624, 1.0585383176803589, 1.098958969116211, 1.0626661777496338, 1.067507028579712, 1.0989264249801636, 1.1059027910232544, 1.109296441078186, 1.0961109399795532, 1.138264775276184, 1.1035723686218262, 1.1077133417129517, 1.1144541501998901, 1.123858094215393, 1.1288836002349854, 1.1406821012496948, 1.1381961107254028, 1.162231683731079, 1.1452735662460327, 1.1556131839752197, 1.1661661863327026, 1.170100212097168, 1.1634677648544312, 1.1688728332519531, 1.174039363861084, 1.1759166717529297, 1.1844418048858643, 1.1914184093475342, 1.199621558189392, 1.2074798345565796, 1.2167361974716187, 1.2146342992782593, 1.2283223867416382, 1.226326823234558, 1.2327779531478882, 1.2322652339935303, 1.2554991245269775, 1.2495595216751099, 1.3001048564910889, 1.285577654838562, 1.2761824131011963, 1.2746663093566895, 1.2791470289230347, 1.2841687202453613, 1.3712092638015747, 1.2937556505203247, 1.316402792930603, 1.31698477268219, 1.328019380569458, 1.3453847169876099, 1.3374117612838745, 1.3450291156768799, 1.3543423414230347, 1.3452579975128174, 1.3751343488693237, 1.3530068397521973, 1.3749892711639404, 1.377211093902588, 1.3855596780776978, 1.4396902322769165, 1.3936057090759277, 1.3996620178222656, 1.4276326894760132, 1.4204002618789673, 1.442089557647705, 1.4061598777770996, 1.4219390153884888, 1.4495488405227661, 1.465926170349121, 1.4325954914093018, 1.4450809955596924, 1.4750195741653442, 1.4639899730682373, 1.4820430278778076, 1.4890421628952026], 'val_accuracy': [0.5640496015548706, 0.5712810158729553, 0.6095041036605835, 0.6126033067703247, 0.625, 0.6167355179786682, 0.6177685856819153, 0.6415289044380188, 0.6456611752510071, 0.6415289044380188, 0.6373966932296753, 0.6353305578231812, 0.6435950398445129, 0.6415289044380188, 0.6342975497245789, 0.6435950398445129, 0.6188016533851624, 0.6373966932296753, 0.6311983466148376, 0.6456611752510071, 0.6456611752510071, 0.64462810754776, 0.6477272510528564, 0.6549586653709412, 0.6466942429542542, 0.6580578684806824, 0.6549586653709412, 0.6332644820213318, 0.6497933864593506, 0.6601239442825317, 0.6466942429542542, 0.6363636255264282, 0.6539255976676941, 0.6528925895690918, 0.6332644820213318, 0.6508264541625977, 0.6477272510528564, 0.6508264541625977, 0.6477272510528564, 0.6435950398445129, 0.6477272510528564, 0.6611570119857788, 0.6404958963394165, 0.64462810754776, 0.6394628286361694, 0.6415289044380188, 0.6353305578231812, 0.6415289044380188, 0.6466942429542542, 0.6508264541625977, 0.6477272510528564, 0.6456611752510071, 0.6487603187561035, 0.6508264541625977, 0.6425619721412659, 0.64462810754776, 0.6518595218658447, 0.6363636255264282, 0.6518595218658447, 0.6435950398445129, 0.6477272510528564, 0.6373966932296753, 0.6528925895690918, 0.6373966932296753, 0.6394628286361694, 0.6435950398445129, 0.6384297609329224, 0.6466942429542542, 0.6477272510528564, 0.6188016533851624, 0.6394628286361694, 0.6373966932296753, 0.6311983466148376, 0.6363636255264282, 0.6384297609329224, 0.6353305578231812, 0.6384297609329224, 0.6394628286361694, 0.6487603187561035, 0.6353305578231812, 0.6332644820213318, 0.6363636255264282, 0.6435950398445129, 0.6394628286361694, 0.6311983466148376, 0.6415289044380188, 0.6415289044380188, 0.6342975497245789, 0.6456611752510071, 0.6322314143180847, 0.6363636255264282, 0.6394628286361694, 0.6322314143180847, 0.6280992031097412, 0.6404958963394165, 0.6342975497245789, 0.6363636255264282, 0.6332644820213318, 0.6363636255264282, 0.6456611752510071]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.5485 - accuracy: 0.8816"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 9s 51ms/step - loss: 0.5588 - accuracy: 0.8798 - val_loss: 0.9542 - val_accuracy: 0.5916\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5406 - accuracy: 0.8939 - val_loss: 0.9495 - val_accuracy: 0.6099\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5227 - accuracy: 0.8947 - val_loss: 0.9436 - val_accuracy: 0.6239\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5036 - accuracy: 0.9046 - val_loss: 0.9379 - val_accuracy: 0.6681\n","Epoch 5/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4968 - accuracy: 0.9046 - val_loss: 0.9334 - val_accuracy: 0.6401\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5142 - accuracy: 0.8952 - val_loss: 0.9269 - val_accuracy: 0.6584\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4892 - accuracy: 0.9130 - val_loss: 0.9194 - val_accuracy: 0.6843\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4826 - accuracy: 0.9122 - val_loss: 0.9115 - val_accuracy: 0.6864\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4894 - accuracy: 0.9076 - val_loss: 0.9062 - val_accuracy: 0.6832\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4696 - accuracy: 0.9178 - val_loss: 0.9007 - val_accuracy: 0.6886\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4628 - accuracy: 0.9200 - val_loss: 0.8927 - val_accuracy: 0.6864\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4669 - accuracy: 0.9186 - val_loss: 0.8817 - val_accuracy: 0.6789\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4578 - accuracy: 0.9230 - val_loss: 0.8879 - val_accuracy: 0.6886\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4514 - accuracy: 0.9300 - val_loss: 0.8787 - val_accuracy: 0.6853\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4491 - accuracy: 0.9221 - val_loss: 0.8697 - val_accuracy: 0.6821\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4531 - accuracy: 0.9197 - val_loss: 0.8737 - val_accuracy: 0.6843\n","Epoch 17/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4550 - accuracy: 0.9162 - val_loss: 0.8789 - val_accuracy: 0.6832\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4465 - accuracy: 0.9240 - val_loss: 0.8783 - val_accuracy: 0.7015\n","Epoch 19/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4362 - accuracy: 0.9310 - val_loss: 0.8746 - val_accuracy: 0.7101\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4411 - accuracy: 0.9259 - val_loss: 0.9011 - val_accuracy: 0.7047\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4313 - accuracy: 0.9289 - val_loss: 0.8836 - val_accuracy: 0.7295\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.9321 - val_loss: 0.8822 - val_accuracy: 0.7241\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4242 - accuracy: 0.9372 - val_loss: 0.8974 - val_accuracy: 0.7349\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4190 - accuracy: 0.9367 - val_loss: 0.8973 - val_accuracy: 0.7414\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4192 - accuracy: 0.9313 - val_loss: 0.8911 - val_accuracy: 0.7511\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4115 - accuracy: 0.9402 - val_loss: 0.9224 - val_accuracy: 0.7500\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4234 - accuracy: 0.9316 - val_loss: 0.9581 - val_accuracy: 0.7381\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4092 - accuracy: 0.9386 - val_loss: 0.9456 - val_accuracy: 0.7446\n","Epoch 29/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4019 - accuracy: 0.9448 - val_loss: 0.9314 - val_accuracy: 0.7619\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4069 - accuracy: 0.9380 - val_loss: 0.9487 - val_accuracy: 0.7575\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4043 - accuracy: 0.9383 - val_loss: 1.0099 - val_accuracy: 0.7446\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4183 - accuracy: 0.9316 - val_loss: 0.9814 - val_accuracy: 0.7468\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3955 - accuracy: 0.9469 - val_loss: 0.9951 - val_accuracy: 0.7565\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3987 - accuracy: 0.9399 - val_loss: 0.9843 - val_accuracy: 0.7543\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.9502 - val_loss: 0.9819 - val_accuracy: 0.7608\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3944 - accuracy: 0.9459 - val_loss: 0.9872 - val_accuracy: 0.7435\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4046 - accuracy: 0.9324 - val_loss: 1.0446 - val_accuracy: 0.7403\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3853 - accuracy: 0.9475 - val_loss: 1.0525 - val_accuracy: 0.7371\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3871 - accuracy: 0.9440 - val_loss: 1.0134 - val_accuracy: 0.7489\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3739 - accuracy: 0.9537 - val_loss: 1.0124 - val_accuracy: 0.7522\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3774 - accuracy: 0.9480 - val_loss: 1.0153 - val_accuracy: 0.7478\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3743 - accuracy: 0.9523 - val_loss: 1.0222 - val_accuracy: 0.7468\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3746 - accuracy: 0.9518 - val_loss: 1.0261 - val_accuracy: 0.7478\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3783 - accuracy: 0.9480 - val_loss: 1.0712 - val_accuracy: 0.7403\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3809 - accuracy: 0.9442 - val_loss: 1.0418 - val_accuracy: 0.7435\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3659 - accuracy: 0.9550 - val_loss: 1.0095 - val_accuracy: 0.7575\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3720 - accuracy: 0.9477 - val_loss: 1.0790 - val_accuracy: 0.7392\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3734 - accuracy: 0.9494 - val_loss: 1.0275 - val_accuracy: 0.7457\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3645 - accuracy: 0.9512 - val_loss: 1.0372 - val_accuracy: 0.7425\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3553 - accuracy: 0.9588 - val_loss: 1.0431 - val_accuracy: 0.7468\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3544 - accuracy: 0.9555 - val_loss: 1.0637 - val_accuracy: 0.7522\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3633 - accuracy: 0.9523 - val_loss: 1.0655 - val_accuracy: 0.7414\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.9477 - val_loss: 1.0829 - val_accuracy: 0.7425\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3616 - accuracy: 0.9518 - val_loss: 1.1131 - val_accuracy: 0.7392\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3687 - accuracy: 0.9510 - val_loss: 1.1019 - val_accuracy: 0.7392\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3511 - accuracy: 0.9566 - val_loss: 1.1854 - val_accuracy: 0.7263\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3565 - accuracy: 0.9531 - val_loss: 1.0656 - val_accuracy: 0.7500\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3586 - accuracy: 0.9539 - val_loss: 1.0776 - val_accuracy: 0.7371\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3572 - accuracy: 0.9515 - val_loss: 1.1146 - val_accuracy: 0.7425\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3507 - accuracy: 0.9569 - val_loss: 1.0893 - val_accuracy: 0.7500\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3419 - accuracy: 0.9585 - val_loss: 1.0788 - val_accuracy: 0.7317\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.9574 - val_loss: 1.0866 - val_accuracy: 0.7328\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3414 - accuracy: 0.9604 - val_loss: 1.0915 - val_accuracy: 0.7532\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.9572 - val_loss: 1.1348 - val_accuracy: 0.7468\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3305 - accuracy: 0.9690 - val_loss: 1.1020 - val_accuracy: 0.7414\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3431 - accuracy: 0.9566 - val_loss: 1.0911 - val_accuracy: 0.7446\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3349 - accuracy: 0.9634 - val_loss: 1.1318 - val_accuracy: 0.7403\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3325 - accuracy: 0.9604 - val_loss: 1.1026 - val_accuracy: 0.7468\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3326 - accuracy: 0.9615 - val_loss: 1.1328 - val_accuracy: 0.7381\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3377 - accuracy: 0.9617 - val_loss: 1.1126 - val_accuracy: 0.7381\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3446 - accuracy: 0.9558 - val_loss: 1.1319 - val_accuracy: 0.7360\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3355 - accuracy: 0.9572 - val_loss: 1.1194 - val_accuracy: 0.7338\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3380 - accuracy: 0.9566 - val_loss: 1.1328 - val_accuracy: 0.7349\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3417 - accuracy: 0.9564 - val_loss: 1.1813 - val_accuracy: 0.7306\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3301 - accuracy: 0.9631 - val_loss: 1.2066 - val_accuracy: 0.7241\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3441 - accuracy: 0.9499 - val_loss: 1.1472 - val_accuracy: 0.7360\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3260 - accuracy: 0.9626 - val_loss: 1.1283 - val_accuracy: 0.7338\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3187 - accuracy: 0.9690 - val_loss: 1.1876 - val_accuracy: 0.7317\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3231 - accuracy: 0.9599 - val_loss: 1.2148 - val_accuracy: 0.7349\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3235 - accuracy: 0.9631 - val_loss: 1.1731 - val_accuracy: 0.7414\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3207 - accuracy: 0.9639 - val_loss: 1.1410 - val_accuracy: 0.7446\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3167 - accuracy: 0.9690 - val_loss: 1.1664 - val_accuracy: 0.7425\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3117 - accuracy: 0.9682 - val_loss: 1.1841 - val_accuracy: 0.7500\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3152 - accuracy: 0.9631 - val_loss: 1.1714 - val_accuracy: 0.7435\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3121 - accuracy: 0.9693 - val_loss: 1.1915 - val_accuracy: 0.7371\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3121 - accuracy: 0.9650 - val_loss: 1.1825 - val_accuracy: 0.7317\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3114 - accuracy: 0.9658 - val_loss: 1.1824 - val_accuracy: 0.7198\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3137 - accuracy: 0.9655 - val_loss: 1.2088 - val_accuracy: 0.7306\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3083 - accuracy: 0.9679 - val_loss: 1.1915 - val_accuracy: 0.7295\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3098 - accuracy: 0.9679 - val_loss: 1.2529 - val_accuracy: 0.7306\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3045 - accuracy: 0.9698 - val_loss: 1.1897 - val_accuracy: 0.7435\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3037 - accuracy: 0.9709 - val_loss: 1.2143 - val_accuracy: 0.7252\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3030 - accuracy: 0.9728 - val_loss: 1.2093 - val_accuracy: 0.7295\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3039 - accuracy: 0.9690 - val_loss: 1.2249 - val_accuracy: 0.7295\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3021 - accuracy: 0.9725 - val_loss: 1.2341 - val_accuracy: 0.7306\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2958 - accuracy: 0.9744 - val_loss: 1.2676 - val_accuracy: 0.7295\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2957 - accuracy: 0.9709 - val_loss: 1.2615 - val_accuracy: 0.7295\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3034 - accuracy: 0.9655 - val_loss: 1.3640 - val_accuracy: 0.7263\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2954 - accuracy: 0.9736 - val_loss: 1.2929 - val_accuracy: 0.7252\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2962 - accuracy: 0.9733 - val_loss: 1.3139 - val_accuracy: 0.7274\n","{'loss': [0.558750569820404, 0.5405870079994202, 0.5227152109146118, 0.5036466717720032, 0.49679329991340637, 0.5142226219177246, 0.4891969859600067, 0.48255455493927, 0.48936691880226135, 0.4696176052093506, 0.4627879559993744, 0.46693891286849976, 0.45776429772377014, 0.4514468014240265, 0.4491415321826935, 0.4531177878379822, 0.4549756646156311, 0.4464762806892395, 0.4362141489982605, 0.44112884998321533, 0.43133628368377686, 0.4291435778141022, 0.4242187440395355, 0.41902706027030945, 0.41921311616897583, 0.4115065932273865, 0.4233507215976715, 0.4092397689819336, 0.4019404351711273, 0.4069206118583679, 0.40426817536354065, 0.4183342158794403, 0.39547234773635864, 0.3987028896808624, 0.3880034387111664, 0.3944089710712433, 0.4046385884284973, 0.38529589772224426, 0.3871312439441681, 0.37388545274734497, 0.3773568570613861, 0.3742726147174835, 0.3746498227119446, 0.37832269072532654, 0.3808855414390564, 0.36593806743621826, 0.3720007538795471, 0.37335121631622314, 0.36448222398757935, 0.35534247756004333, 0.35435518622398376, 0.3633398115634918, 0.36335068941116333, 0.36160922050476074, 0.3687208890914917, 0.3511364161968231, 0.35648080706596375, 0.3586461842060089, 0.35721951723098755, 0.35074546933174133, 0.3419169485569, 0.3434198200702667, 0.34142395853996277, 0.3418232500553131, 0.33048033714294434, 0.3431449234485626, 0.3349256217479706, 0.3325278162956238, 0.3325961232185364, 0.33768323063850403, 0.344594269990921, 0.335517555475235, 0.33797168731689453, 0.3416689932346344, 0.3300926387310028, 0.3440868854522705, 0.32600897550582886, 0.3186601400375366, 0.3231474757194519, 0.3234853148460388, 0.32065466046333313, 0.316679447889328, 0.3116638958454132, 0.3151954412460327, 0.3120884597301483, 0.3120584785938263, 0.31144165992736816, 0.3137238025665283, 0.30829620361328125, 0.30979645252227783, 0.30450624227523804, 0.3037233054637909, 0.30300185084342957, 0.3038952946662903, 0.3020513355731964, 0.2958155572414398, 0.295671284198761, 0.3033911883831024, 0.29542872309684753, 0.296230286359787], 'accuracy': [0.8798491358757019, 0.8938577771186829, 0.8946659564971924, 0.904633641242981, 0.904633641242981, 0.8952047228813171, 0.9129849076271057, 0.9121767282485962, 0.907597005367279, 0.9178340435028076, 0.9199892282485962, 0.9186422228813171, 0.9229525923728943, 0.9299569129943848, 0.9221444129943848, 0.9197198152542114, 0.9162176847457886, 0.9240301847457886, 0.931034505367279, 0.9259159564971924, 0.9288793206214905, 0.9321120977401733, 0.9372305870056152, 0.9366918206214905, 0.931303858757019, 0.9401939511299133, 0.9315732717514038, 0.9385775923728943, 0.9447737336158752, 0.9380387663841248, 0.9383081793785095, 0.9315732717514038, 0.946928858757019, 0.9399245977401733, 0.9501616358757019, 0.9458512663841248, 0.9323814511299133, 0.9474676847457886, 0.943965494632721, 0.9536637663841248, 0.9480064511299133, 0.9523168206214905, 0.951777994632721, 0.9480064511299133, 0.9442349076271057, 0.9550107717514038, 0.9477370977401733, 0.9493534564971924, 0.9512392282485962, 0.9587823152542114, 0.9555495977401733, 0.9523168206214905, 0.9477370977401733, 0.951777994632721, 0.9509698152542114, 0.9566271305084229, 0.953125, 0.9539331793785095, 0.951508641242981, 0.9568965435028076, 0.9585129022598267, 0.9574353694915771, 0.9603987336158752, 0.9571659564971924, 0.9690194129943848, 0.9566271305084229, 0.9633620977401733, 0.9603987336158752, 0.9614762663841248, 0.9617456793785095, 0.9558189511299133, 0.9571659564971924, 0.9566271305084229, 0.9563577771186829, 0.9630926847457886, 0.9498922228813171, 0.962553858757019, 0.9690194129943848, 0.9598599076271057, 0.9630926847457886, 0.9639008641242981, 0.9690194129943848, 0.9682112336158752, 0.9630926847457886, 0.9692887663841248, 0.9649784564971924, 0.9657866358757019, 0.9655172228813171, 0.9679418206214905, 0.9679418206214905, 0.9698275923728943, 0.9709051847457886, 0.9727909564971924, 0.9690194129943848, 0.9725215435028076, 0.9744073152542114, 0.9709051847457886, 0.9655172228813171, 0.9735991358757019, 0.9733297228813171], 'val_loss': [0.9542045593261719, 0.9494582414627075, 0.9436225891113281, 0.9379037618637085, 0.9334433078765869, 0.9269376397132874, 0.9194386601448059, 0.9115062355995178, 0.9062327742576599, 0.9006540775299072, 0.8926512598991394, 0.8816639184951782, 0.8878639936447144, 0.8786691427230835, 0.8697273135185242, 0.8736938238143921, 0.8788663148880005, 0.8783270120620728, 0.8745823502540588, 0.9010891914367676, 0.8836013674736023, 0.8822110891342163, 0.8973519802093506, 0.8972544074058533, 0.8911133408546448, 0.9224046468734741, 0.9581076502799988, 0.9455892443656921, 0.9313803911209106, 0.9486609697341919, 1.009861707687378, 0.9814051985740662, 0.9950525760650635, 0.9842953085899353, 0.9819242358207703, 0.9872132539749146, 1.044585108757019, 1.0525388717651367, 1.0134011507034302, 1.0123896598815918, 1.015258550643921, 1.02220618724823, 1.026149034500122, 1.0712443590164185, 1.0418331623077393, 1.0094709396362305, 1.078981637954712, 1.0275218486785889, 1.0372406244277954, 1.0430771112442017, 1.0637307167053223, 1.0654926300048828, 1.0828768014907837, 1.1131367683410645, 1.1018725633621216, 1.1854455471038818, 1.0656129121780396, 1.0776351690292358, 1.1146316528320312, 1.0893161296844482, 1.0787791013717651, 1.0865665674209595, 1.091546654701233, 1.1347793340682983, 1.1019752025604248, 1.0911017656326294, 1.131836175918579, 1.1025645732879639, 1.1327883005142212, 1.1125904321670532, 1.1319156885147095, 1.119416356086731, 1.13279128074646, 1.1813013553619385, 1.2065874338150024, 1.1472495794296265, 1.12826406955719, 1.187628149986267, 1.2148293256759644, 1.173082947731018, 1.1410257816314697, 1.1664478778839111, 1.1841098070144653, 1.1713857650756836, 1.1915115118026733, 1.1825125217437744, 1.1824164390563965, 1.208783507347107, 1.1914660930633545, 1.252938985824585, 1.1897369623184204, 1.2143113613128662, 1.2092872858047485, 1.2249032258987427, 1.234086513519287, 1.267643928527832, 1.261488437652588, 1.363983392715454, 1.2928835153579712, 1.3138808012008667], 'val_accuracy': [0.5915948152542114, 0.6099137663841248, 0.6239224076271057, 0.6681034564971924, 0.6400862336158752, 0.6584051847457886, 0.6842672228813171, 0.6864224076271057, 0.6831896305084229, 0.6885775923728943, 0.6864224076271057, 0.6788793206214905, 0.6885775923728943, 0.6853448152542114, 0.6821120977401733, 0.6842672228813171, 0.6831896305084229, 0.701508641242981, 0.7101293206214905, 0.704741358757019, 0.7295258641242981, 0.7241379022598267, 0.7349137663841248, 0.7413793206214905, 0.7510775923728943, 0.75, 0.7381465435028076, 0.7446120977401733, 0.7618534564971924, 0.7575430870056152, 0.7446120977401733, 0.7467672228813171, 0.756465494632721, 0.7543103694915771, 0.7607758641242981, 0.743534505367279, 0.7403017282485962, 0.7370689511299133, 0.7489224076271057, 0.7521551847457886, 0.7478448152542114, 0.7467672228813171, 0.7478448152542114, 0.7403017282485962, 0.743534505367279, 0.7575430870056152, 0.7392241358757019, 0.7456896305084229, 0.7424569129943848, 0.7467672228813171, 0.7521551847457886, 0.7413793206214905, 0.7424569129943848, 0.7392241358757019, 0.7392241358757019, 0.7262930870056152, 0.75, 0.7370689511299133, 0.7424569129943848, 0.75, 0.7316810488700867, 0.732758641242981, 0.7532327771186829, 0.7467672228813171, 0.7413793206214905, 0.7446120977401733, 0.7403017282485962, 0.7467672228813171, 0.7381465435028076, 0.7381465435028076, 0.735991358757019, 0.7338362336158752, 0.7349137663841248, 0.7306034564971924, 0.7241379022598267, 0.735991358757019, 0.7338362336158752, 0.7316810488700867, 0.7349137663841248, 0.7413793206214905, 0.7446120977401733, 0.7424569129943848, 0.75, 0.743534505367279, 0.7370689511299133, 0.7316810488700867, 0.7198275923728943, 0.7306034564971924, 0.7295258641242981, 0.7306034564971924, 0.743534505367279, 0.725215494632721, 0.7295258641242981, 0.7295258641242981, 0.7306034564971924, 0.7295258641242981, 0.7295258641242981, 0.7262930870056152, 0.725215494632721, 0.7273706793785095]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.5470 - accuracy: 0.8804"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 58ms/step - loss: 0.5525 - accuracy: 0.8778 - val_loss: 0.9530 - val_accuracy: 0.6007\n","Epoch 2/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5236 - accuracy: 0.8933 - val_loss: 0.9473 - val_accuracy: 0.6335\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5107 - accuracy: 0.9001 - val_loss: 0.9433 - val_accuracy: 0.6369\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5025 - accuracy: 0.9103 - val_loss: 0.9376 - val_accuracy: 0.6527\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4946 - accuracy: 0.9078 - val_loss: 0.9331 - val_accuracy: 0.6369\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4987 - accuracy: 0.9046 - val_loss: 0.9260 - val_accuracy: 0.6561\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4875 - accuracy: 0.9111 - val_loss: 0.9183 - val_accuracy: 0.6618\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4848 - accuracy: 0.9095 - val_loss: 0.9114 - val_accuracy: 0.6697\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4678 - accuracy: 0.9123 - val_loss: 0.9071 - val_accuracy: 0.6538\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4778 - accuracy: 0.9103 - val_loss: 0.8942 - val_accuracy: 0.6697\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4650 - accuracy: 0.9202 - val_loss: 0.8904 - val_accuracy: 0.6618\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4565 - accuracy: 0.9244 - val_loss: 0.8807 - val_accuracy: 0.6753\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4697 - accuracy: 0.9140 - val_loss: 0.8809 - val_accuracy: 0.6606\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4594 - accuracy: 0.9228 - val_loss: 0.8695 - val_accuracy: 0.6787\n","Epoch 15/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.4629 - accuracy: 0.9191 - val_loss: 0.8666 - val_accuracy: 0.6719\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4472 - accuracy: 0.9321 - val_loss: 0.8592 - val_accuracy: 0.6923\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4513 - accuracy: 0.9202 - val_loss: 0.8653 - val_accuracy: 0.6946\n","Epoch 18/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4468 - accuracy: 0.9270 - val_loss: 0.8805 - val_accuracy: 0.6889\n","Epoch 19/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4391 - accuracy: 0.9301 - val_loss: 0.8672 - val_accuracy: 0.7183\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4344 - accuracy: 0.9293 - val_loss: 0.8753 - val_accuracy: 0.7093\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4273 - accuracy: 0.9327 - val_loss: 0.8737 - val_accuracy: 0.7296\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.9312 - val_loss: 0.8793 - val_accuracy: 0.7285\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4321 - accuracy: 0.9310 - val_loss: 0.8736 - val_accuracy: 0.7364\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4212 - accuracy: 0.9358 - val_loss: 0.8822 - val_accuracy: 0.7455\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4118 - accuracy: 0.9372 - val_loss: 0.8882 - val_accuracy: 0.7624\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4185 - accuracy: 0.9360 - val_loss: 0.9085 - val_accuracy: 0.7477\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4077 - accuracy: 0.9409 - val_loss: 0.9362 - val_accuracy: 0.7681\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4068 - accuracy: 0.9383 - val_loss: 0.9126 - val_accuracy: 0.7681\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4084 - accuracy: 0.9360 - val_loss: 0.9136 - val_accuracy: 0.7602\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4007 - accuracy: 0.9400 - val_loss: 0.9129 - val_accuracy: 0.7783\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4032 - accuracy: 0.9386 - val_loss: 0.9269 - val_accuracy: 0.7692\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4053 - accuracy: 0.9403 - val_loss: 0.9321 - val_accuracy: 0.7749\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3888 - accuracy: 0.9474 - val_loss: 0.9347 - val_accuracy: 0.7647\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3944 - accuracy: 0.9445 - val_loss: 0.9541 - val_accuracy: 0.7647\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3956 - accuracy: 0.9400 - val_loss: 0.9500 - val_accuracy: 0.7681\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4080 - accuracy: 0.9397 - val_loss: 0.9538 - val_accuracy: 0.7760\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3961 - accuracy: 0.9406 - val_loss: 0.9532 - val_accuracy: 0.7681\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3901 - accuracy: 0.9420 - val_loss: 0.9647 - val_accuracy: 0.7704\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3988 - accuracy: 0.9394 - val_loss: 0.9615 - val_accuracy: 0.7704\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3886 - accuracy: 0.9454 - val_loss: 1.0206 - val_accuracy: 0.7636\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3788 - accuracy: 0.9488 - val_loss: 0.9648 - val_accuracy: 0.7670\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3743 - accuracy: 0.9533 - val_loss: 0.9726 - val_accuracy: 0.7692\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3728 - accuracy: 0.9502 - val_loss: 0.9727 - val_accuracy: 0.7670\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3758 - accuracy: 0.9525 - val_loss: 0.9746 - val_accuracy: 0.7760\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 0.9454 - val_loss: 1.0041 - val_accuracy: 0.7545\n","Epoch 46/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3847 - accuracy: 0.9440 - val_loss: 0.9954 - val_accuracy: 0.7670\n","Epoch 47/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3709 - accuracy: 0.9542 - val_loss: 0.9960 - val_accuracy: 0.7760\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3715 - accuracy: 0.9485 - val_loss: 1.0236 - val_accuracy: 0.7590\n","Epoch 49/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3632 - accuracy: 0.9584 - val_loss: 1.0186 - val_accuracy: 0.7602\n","Epoch 50/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3665 - accuracy: 0.9502 - val_loss: 1.0184 - val_accuracy: 0.7590\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3666 - accuracy: 0.9488 - val_loss: 1.0226 - val_accuracy: 0.7658\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3723 - accuracy: 0.9474 - val_loss: 1.0155 - val_accuracy: 0.7681\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3610 - accuracy: 0.9533 - val_loss: 1.0342 - val_accuracy: 0.7624\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3604 - accuracy: 0.9527 - val_loss: 1.0291 - val_accuracy: 0.7670\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3504 - accuracy: 0.9587 - val_loss: 1.0207 - val_accuracy: 0.7715\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3561 - accuracy: 0.9559 - val_loss: 1.0344 - val_accuracy: 0.7477\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3538 - accuracy: 0.9593 - val_loss: 1.0500 - val_accuracy: 0.7590\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3510 - accuracy: 0.9544 - val_loss: 1.0240 - val_accuracy: 0.7738\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3449 - accuracy: 0.9635 - val_loss: 1.0267 - val_accuracy: 0.7624\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3365 - accuracy: 0.9649 - val_loss: 1.0480 - val_accuracy: 0.7670\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3461 - accuracy: 0.9561 - val_loss: 1.0391 - val_accuracy: 0.7692\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3400 - accuracy: 0.9618 - val_loss: 1.0505 - val_accuracy: 0.7658\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3457 - accuracy: 0.9590 - val_loss: 1.0495 - val_accuracy: 0.7704\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3399 - accuracy: 0.9570 - val_loss: 1.0653 - val_accuracy: 0.7602\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3431 - accuracy: 0.9573 - val_loss: 1.0981 - val_accuracy: 0.7602\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3518 - accuracy: 0.9525 - val_loss: 1.0668 - val_accuracy: 0.7726\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3567 - accuracy: 0.9491 - val_loss: 1.0749 - val_accuracy: 0.7636\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3409 - accuracy: 0.9604 - val_loss: 1.1172 - val_accuracy: 0.7353\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3396 - accuracy: 0.9610 - val_loss: 1.0633 - val_accuracy: 0.7749\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3366 - accuracy: 0.9607 - val_loss: 1.0809 - val_accuracy: 0.7568\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3263 - accuracy: 0.9658 - val_loss: 1.0889 - val_accuracy: 0.7636\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3334 - accuracy: 0.9601 - val_loss: 1.0995 - val_accuracy: 0.7545\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3356 - accuracy: 0.9618 - val_loss: 1.0705 - val_accuracy: 0.7704\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3237 - accuracy: 0.9643 - val_loss: 1.0816 - val_accuracy: 0.7658\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3236 - accuracy: 0.9629 - val_loss: 1.0970 - val_accuracy: 0.7715\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3269 - accuracy: 0.9621 - val_loss: 1.1075 - val_accuracy: 0.7523\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3178 - accuracy: 0.9686 - val_loss: 1.0940 - val_accuracy: 0.7636\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3285 - accuracy: 0.9607 - val_loss: 1.0987 - val_accuracy: 0.7681\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3328 - accuracy: 0.9587 - val_loss: 1.0934 - val_accuracy: 0.7557\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3341 - accuracy: 0.9601 - val_loss: 1.1236 - val_accuracy: 0.7647\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3176 - accuracy: 0.9658 - val_loss: 1.1088 - val_accuracy: 0.7523\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3224 - accuracy: 0.9632 - val_loss: 1.1827 - val_accuracy: 0.7330\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3232 - accuracy: 0.9618 - val_loss: 1.0958 - val_accuracy: 0.7568\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3187 - accuracy: 0.9649 - val_loss: 1.1311 - val_accuracy: 0.7590\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3102 - accuracy: 0.9711 - val_loss: 1.1287 - val_accuracy: 0.7534\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3091 - accuracy: 0.9728 - val_loss: 1.1476 - val_accuracy: 0.7647\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3097 - accuracy: 0.9694 - val_loss: 1.1426 - val_accuracy: 0.7636\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3075 - accuracy: 0.9706 - val_loss: 1.1363 - val_accuracy: 0.7443\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3102 - accuracy: 0.9706 - val_loss: 1.1592 - val_accuracy: 0.7432\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3490 - accuracy: 0.9468 - val_loss: 1.2705 - val_accuracy: 0.7443\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3254 - accuracy: 0.9578 - val_loss: 1.1350 - val_accuracy: 0.7511\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3107 - accuracy: 0.9666 - val_loss: 1.1525 - val_accuracy: 0.7511\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3031 - accuracy: 0.9723 - val_loss: 1.1438 - val_accuracy: 0.7590\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3062 - accuracy: 0.9649 - val_loss: 1.1709 - val_accuracy: 0.7398\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3067 - accuracy: 0.9683 - val_loss: 1.2261 - val_accuracy: 0.7545\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.9703 - val_loss: 1.1553 - val_accuracy: 0.7511\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2980 - accuracy: 0.9689 - val_loss: 1.1838 - val_accuracy: 0.7523\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3115 - accuracy: 0.9632 - val_loss: 1.1677 - val_accuracy: 0.7692\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2972 - accuracy: 0.9714 - val_loss: 1.1712 - val_accuracy: 0.7523\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3040 - accuracy: 0.9692 - val_loss: 1.1968 - val_accuracy: 0.7613\n","{'loss': [0.552522599697113, 0.5236266851425171, 0.5107393264770508, 0.5025334358215332, 0.4945910573005676, 0.4987441301345825, 0.48748698830604553, 0.4848283529281616, 0.4678162932395935, 0.47780582308769226, 0.46498966217041016, 0.45648449659347534, 0.4696752429008484, 0.4594323933124542, 0.4629215598106384, 0.4471568465232849, 0.45134633779525757, 0.4467921257019043, 0.43912965059280396, 0.43439623713493347, 0.4272541403770447, 0.4291470944881439, 0.43212535977363586, 0.4211721122264862, 0.41180744767189026, 0.41846656799316406, 0.4076783359050751, 0.40679267048835754, 0.40837985277175903, 0.40068575739860535, 0.403153657913208, 0.40529242157936096, 0.38875460624694824, 0.3944261372089386, 0.39560672640800476, 0.407967746257782, 0.3960573673248291, 0.39007142186164856, 0.398805171251297, 0.3885587453842163, 0.3787904381752014, 0.37432974576950073, 0.3728393614292145, 0.375784307718277, 0.38418322801589966, 0.3846590518951416, 0.3709217309951782, 0.3715139925479889, 0.3632068336009979, 0.36646774411201477, 0.3666383624076843, 0.3723274767398834, 0.3609873652458191, 0.3604297637939453, 0.3504384160041809, 0.35611382126808167, 0.35383141040802, 0.3509652316570282, 0.34489378333091736, 0.33651983737945557, 0.34607166051864624, 0.34001997113227844, 0.3457055985927582, 0.3398844003677368, 0.34313637018203735, 0.35180774331092834, 0.35669681429862976, 0.3409378230571747, 0.33957943320274353, 0.3366224467754364, 0.32631298899650574, 0.33335375785827637, 0.3355814814567566, 0.3237304389476776, 0.32355839014053345, 0.32686346769332886, 0.3178215026855469, 0.3285205662250519, 0.33277496695518494, 0.3340742588043213, 0.31760257482528687, 0.3224365711212158, 0.3232007324695587, 0.3187478184700012, 0.31020525097846985, 0.3091078996658325, 0.3097059428691864, 0.3074653744697571, 0.310225248336792, 0.3490086495876312, 0.3254401981830597, 0.3106772005558014, 0.30311670899391174, 0.30617108941078186, 0.3066777288913727, 0.3041265904903412, 0.2979709804058075, 0.3115193545818329, 0.29719555377960205, 0.3039550185203552], 'accuracy': [0.8777589201927185, 0.8933219909667969, 0.9001131653785706, 0.9102999567985535, 0.9077532291412354, 0.9046406149864197, 0.9111488461494446, 0.9094510674476624, 0.9122806787490845, 0.9102999567985535, 0.9202037453651428, 0.9244481921195984, 0.9139785170555115, 0.9227504134178162, 0.9190718531608582, 0.9320882558822632, 0.9202037453651428, 0.9269949197769165, 0.9301075339317322, 0.9292586445808411, 0.9326542019844055, 0.9312393665313721, 0.9309564232826233, 0.9357668161392212, 0.9371816515922546, 0.9360498189926147, 0.9408602118492126, 0.9383135437965393, 0.9360498189926147, 0.9400113224983215, 0.9385964870452881, 0.9402942657470703, 0.9473684430122375, 0.9445387721061707, 0.9400113224983215, 0.9397283792495728, 0.9405772686004639, 0.9419921040534973, 0.9394453763961792, 0.9453876614570618, 0.9487832188606262, 0.9533106684684753, 0.9501980543136597, 0.9524617791175842, 0.9453876614570618, 0.9439728260040283, 0.9541596174240112, 0.9485002756118774, 0.9584040641784668, 0.9501980543136597, 0.9487832188606262, 0.9473684430122375, 0.9533106684684753, 0.9527447819709778, 0.9586870670318604, 0.9558573961257935, 0.9592529535293579, 0.95444256067276, 0.9634974598884583, 0.9649122953414917, 0.9561403393745422, 0.961799681186676, 0.9589700102806091, 0.9569892287254333, 0.9572722315788269, 0.9524617791175842, 0.9490662217140198, 0.9603848457336426, 0.9609507918357849, 0.9606677889823914, 0.9657611846923828, 0.960101842880249, 0.961799681186676, 0.9643463492393494, 0.9629315137863159, 0.9620826244354248, 0.9685908555984497, 0.9606677889823914, 0.9586870670318604, 0.960101842880249, 0.9657611846923828, 0.9632145166397095, 0.961799681186676, 0.9649122953414917, 0.971137523651123, 0.9728353023529053, 0.9694397449493408, 0.9705715775489807, 0.9705715775489807, 0.9468024969100952, 0.9578381180763245, 0.9666100740432739, 0.9722693562507629, 0.9649122953414917, 0.9683078527450562, 0.9702886343002319, 0.9688737988471985, 0.9632145166397095, 0.9714204668998718, 0.9691567420959473], 'val_loss': [0.9529570937156677, 0.9473354816436768, 0.9432685375213623, 0.9376254081726074, 0.9330600500106812, 0.9260036945343018, 0.918269693851471, 0.9114243388175964, 0.9070701003074646, 0.8942200541496277, 0.8903525471687317, 0.880711555480957, 0.8808763027191162, 0.8694784045219421, 0.8665574193000793, 0.8592188358306885, 0.865303635597229, 0.8804767727851868, 0.8672178983688354, 0.8753435611724854, 0.8737289905548096, 0.8793030977249146, 0.8736089468002319, 0.8822166919708252, 0.8882414698600769, 0.9085126519203186, 0.9361514449119568, 0.9125701785087585, 0.9135996699333191, 0.912941038608551, 0.9268832206726074, 0.9320793151855469, 0.9347341060638428, 0.954054594039917, 0.9500056505203247, 0.9538418054580688, 0.9531882405281067, 0.9647117257118225, 0.9615036845207214, 1.0205628871917725, 0.9647872447967529, 0.9726362228393555, 0.9727334976196289, 0.9745670557022095, 1.0041084289550781, 0.9954257011413574, 0.9960024952888489, 1.0236448049545288, 1.0186131000518799, 1.0184422731399536, 1.0225932598114014, 1.0155423879623413, 1.0341721773147583, 1.0290557146072388, 1.020700216293335, 1.034368634223938, 1.0500046014785767, 1.0240163803100586, 1.0267325639724731, 1.0479695796966553, 1.0391137599945068, 1.0504589080810547, 1.0495237112045288, 1.065289855003357, 1.0980663299560547, 1.0667794942855835, 1.074939250946045, 1.1171659231185913, 1.063346266746521, 1.0809382200241089, 1.0889298915863037, 1.0994783639907837, 1.0705379247665405, 1.0816078186035156, 1.096960186958313, 1.1075178384780884, 1.0939970016479492, 1.098706603050232, 1.0933637619018555, 1.1235764026641846, 1.1087833642959595, 1.1827123165130615, 1.095754861831665, 1.1310714483261108, 1.1286941766738892, 1.147581934928894, 1.1426281929016113, 1.1362606287002563, 1.1592146158218384, 1.2704582214355469, 1.134968638420105, 1.1524900197982788, 1.143805980682373, 1.1708647012710571, 1.2260836362838745, 1.1553236246109009, 1.183764100074768, 1.1676902770996094, 1.1712424755096436, 1.196763038635254], 'val_accuracy': [0.6006787419319153, 0.6334841847419739, 0.6368778347969055, 0.6527149081230164, 0.6368778347969055, 0.6561086177825928, 0.6617646813392639, 0.6696832776069641, 0.6538461446762085, 0.6696832776069641, 0.6617646813392639, 0.6753393411636353, 0.6606335043907166, 0.6787330508232117, 0.6719456911087036, 0.692307710647583, 0.6945701241493225, 0.6889140009880066, 0.7183257937431335, 0.709276020526886, 0.7296379804611206, 0.7285068035125732, 0.7364253401756287, 0.7454751133918762, 0.7624434232711792, 0.7477375268936157, 0.7680995464324951, 0.7680995464324951, 0.7601810097694397, 0.7782805562019348, 0.7692307829856873, 0.7748869061470032, 0.7647058963775635, 0.7647058963775635, 0.7680995464324951, 0.7760180830955505, 0.7680995464324951, 0.7703620195388794, 0.7703620195388794, 0.7635746598243713, 0.766968309879303, 0.7692307829856873, 0.766968309879303, 0.7760180830955505, 0.7545248866081238, 0.766968309879303, 0.7760180830955505, 0.7590497732162476, 0.7601810097694397, 0.7590497732162476, 0.7658371329307556, 0.7680995464324951, 0.7624434232711792, 0.766968309879303, 0.7714931964874268, 0.7477375268936157, 0.7590497732162476, 0.773755669593811, 0.7624434232711792, 0.766968309879303, 0.7692307829856873, 0.7658371329307556, 0.7703620195388794, 0.7601810097694397, 0.7601810097694397, 0.7726244330406189, 0.7635746598243713, 0.7352941036224365, 0.7748869061470032, 0.7567873597145081, 0.7635746598243713, 0.7545248866081238, 0.7703620195388794, 0.7658371329307556, 0.7714931964874268, 0.7522624731063843, 0.7635746598243713, 0.7680995464324951, 0.7556561231613159, 0.7647058963775635, 0.7522624731063843, 0.733031690120697, 0.7567873597145081, 0.7590497732162476, 0.7533936500549316, 0.7647058963775635, 0.7635746598243713, 0.7443438768386841, 0.7432126402854919, 0.7443438768386841, 0.7511312365531921, 0.7511312365531921, 0.7590497732162476, 0.7398189902305603, 0.7545248866081238, 0.7511312365531921, 0.7522624731063843, 0.7692307829856873, 0.7522624731063843, 0.7613122463226318]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 47ms/step - loss: 0.6031 - accuracy: 0.8669 - val_loss: 0.9491 - val_accuracy: 0.6426\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5772 - accuracy: 0.8736 - val_loss: 0.9457 - val_accuracy: 0.6147\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5472 - accuracy: 0.8788 - val_loss: 0.9399 - val_accuracy: 0.6353\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5316 - accuracy: 0.8886 - val_loss: 0.9339 - val_accuracy: 0.6426\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5314 - accuracy: 0.8904 - val_loss: 0.9293 - val_accuracy: 0.6240\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5322 - accuracy: 0.8884 - val_loss: 0.9200 - val_accuracy: 0.6612\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5177 - accuracy: 0.8953 - val_loss: 0.9127 - val_accuracy: 0.6643\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5150 - accuracy: 0.8920 - val_loss: 0.9098 - val_accuracy: 0.6364\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4995 - accuracy: 0.9044 - val_loss: 0.8930 - val_accuracy: 0.6787\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5105 - accuracy: 0.8966 - val_loss: 0.8856 - val_accuracy: 0.6787\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4894 - accuracy: 0.9098 - val_loss: 0.8820 - val_accuracy: 0.6612\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5016 - accuracy: 0.8984 - val_loss: 0.8709 - val_accuracy: 0.6777\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4896 - accuracy: 0.9044 - val_loss: 0.8608 - val_accuracy: 0.6870\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4774 - accuracy: 0.9085 - val_loss: 0.8732 - val_accuracy: 0.6725\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4709 - accuracy: 0.9129 - val_loss: 0.8696 - val_accuracy: 0.6860\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4726 - accuracy: 0.9054 - val_loss: 0.8655 - val_accuracy: 0.7004\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4605 - accuracy: 0.9191 - val_loss: 0.8695 - val_accuracy: 0.7066\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4590 - accuracy: 0.9163 - val_loss: 0.9075 - val_accuracy: 0.6911\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4577 - accuracy: 0.9163 - val_loss: 0.8712 - val_accuracy: 0.7283\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4585 - accuracy: 0.9132 - val_loss: 0.8835 - val_accuracy: 0.7221\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4523 - accuracy: 0.9199 - val_loss: 0.9351 - val_accuracy: 0.7056\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4538 - accuracy: 0.9207 - val_loss: 0.8998 - val_accuracy: 0.7283\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4461 - accuracy: 0.9251 - val_loss: 0.9059 - val_accuracy: 0.7273\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4417 - accuracy: 0.9204 - val_loss: 0.9593 - val_accuracy: 0.7252\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4462 - accuracy: 0.9158 - val_loss: 0.9345 - val_accuracy: 0.7293\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4458 - accuracy: 0.9186 - val_loss: 0.9478 - val_accuracy: 0.7262\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4306 - accuracy: 0.9276 - val_loss: 0.9537 - val_accuracy: 0.7252\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4346 - accuracy: 0.9251 - val_loss: 1.0133 - val_accuracy: 0.7273\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4556 - accuracy: 0.9140 - val_loss: 0.9604 - val_accuracy: 0.7190\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4243 - accuracy: 0.9238 - val_loss: 0.9683 - val_accuracy: 0.7262\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4269 - accuracy: 0.9258 - val_loss: 0.9892 - val_accuracy: 0.7407\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4260 - accuracy: 0.9269 - val_loss: 0.9928 - val_accuracy: 0.7273\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.9251 - val_loss: 1.0275 - val_accuracy: 0.7211\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4230 - accuracy: 0.9289 - val_loss: 1.0191 - val_accuracy: 0.7273\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4287 - accuracy: 0.9284 - val_loss: 1.0350 - val_accuracy: 0.7200\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4304 - accuracy: 0.9276 - val_loss: 1.0619 - val_accuracy: 0.7118\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4113 - accuracy: 0.9326 - val_loss: 1.0224 - val_accuracy: 0.7262\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4132 - accuracy: 0.9331 - val_loss: 1.0605 - val_accuracy: 0.7293\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4113 - accuracy: 0.9336 - val_loss: 1.0274 - val_accuracy: 0.7211\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4015 - accuracy: 0.9344 - val_loss: 1.0433 - val_accuracy: 0.7345\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4051 - accuracy: 0.9346 - val_loss: 1.0438 - val_accuracy: 0.7283\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4029 - accuracy: 0.9351 - val_loss: 1.0527 - val_accuracy: 0.7252\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3937 - accuracy: 0.9413 - val_loss: 1.0606 - val_accuracy: 0.7211\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3986 - accuracy: 0.9341 - val_loss: 1.0880 - val_accuracy: 0.7231\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3986 - accuracy: 0.9359 - val_loss: 1.0513 - val_accuracy: 0.7273\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3947 - accuracy: 0.9357 - val_loss: 1.1387 - val_accuracy: 0.6942\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.9331 - val_loss: 1.0660 - val_accuracy: 0.7283\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3939 - accuracy: 0.9395 - val_loss: 1.0980 - val_accuracy: 0.7293\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3855 - accuracy: 0.9419 - val_loss: 1.0935 - val_accuracy: 0.7293\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3843 - accuracy: 0.9439 - val_loss: 1.0924 - val_accuracy: 0.7366\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3843 - accuracy: 0.9390 - val_loss: 1.0919 - val_accuracy: 0.7242\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3752 - accuracy: 0.9455 - val_loss: 1.1194 - val_accuracy: 0.7200\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3792 - accuracy: 0.9452 - val_loss: 1.1023 - val_accuracy: 0.7242\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.9478 - val_loss: 1.1141 - val_accuracy: 0.7242\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3753 - accuracy: 0.9429 - val_loss: 1.1458 - val_accuracy: 0.7180\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3826 - accuracy: 0.9390 - val_loss: 1.1055 - val_accuracy: 0.7262\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3675 - accuracy: 0.9478 - val_loss: 1.1142 - val_accuracy: 0.7221\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3684 - accuracy: 0.9522 - val_loss: 1.1129 - val_accuracy: 0.7262\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3647 - accuracy: 0.9478 - val_loss: 1.1213 - val_accuracy: 0.7242\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3820 - accuracy: 0.9388 - val_loss: 1.0935 - val_accuracy: 0.7273\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3637 - accuracy: 0.9483 - val_loss: 1.1166 - val_accuracy: 0.7190\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3628 - accuracy: 0.9478 - val_loss: 1.2620 - val_accuracy: 0.7035\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3790 - accuracy: 0.9339 - val_loss: 1.1503 - val_accuracy: 0.7128\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3623 - accuracy: 0.9473 - val_loss: 1.1322 - val_accuracy: 0.7169\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3576 - accuracy: 0.9504 - val_loss: 1.1334 - val_accuracy: 0.7200\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3550 - accuracy: 0.9514 - val_loss: 1.1526 - val_accuracy: 0.6994\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3663 - accuracy: 0.9413 - val_loss: 1.1450 - val_accuracy: 0.7221\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3492 - accuracy: 0.9553 - val_loss: 1.1517 - val_accuracy: 0.7200\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3624 - accuracy: 0.9444 - val_loss: 1.1735 - val_accuracy: 0.7107\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3507 - accuracy: 0.9514 - val_loss: 1.1712 - val_accuracy: 0.7200\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3526 - accuracy: 0.9514 - val_loss: 1.2132 - val_accuracy: 0.7128\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3496 - accuracy: 0.9475 - val_loss: 1.1794 - val_accuracy: 0.7211\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3472 - accuracy: 0.9530 - val_loss: 1.1665 - val_accuracy: 0.7149\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3384 - accuracy: 0.9563 - val_loss: 1.1872 - val_accuracy: 0.7190\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3408 - accuracy: 0.9561 - val_loss: 1.1898 - val_accuracy: 0.7180\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3341 - accuracy: 0.9610 - val_loss: 1.1830 - val_accuracy: 0.7180\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3323 - accuracy: 0.9581 - val_loss: 1.2334 - val_accuracy: 0.7056\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3344 - accuracy: 0.9605 - val_loss: 1.1928 - val_accuracy: 0.7128\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3344 - accuracy: 0.9605 - val_loss: 1.2351 - val_accuracy: 0.7107\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3331 - accuracy: 0.9571 - val_loss: 1.2245 - val_accuracy: 0.7128\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3376 - accuracy: 0.9574 - val_loss: 1.2597 - val_accuracy: 0.7118\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3437 - accuracy: 0.9519 - val_loss: 1.2351 - val_accuracy: 0.7169\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.9532 - val_loss: 1.2689 - val_accuracy: 0.7159\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3302 - accuracy: 0.9589 - val_loss: 1.2624 - val_accuracy: 0.7097\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3309 - accuracy: 0.9579 - val_loss: 1.2501 - val_accuracy: 0.7056\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3274 - accuracy: 0.9630 - val_loss: 1.2672 - val_accuracy: 0.7138\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.9566 - val_loss: 1.2546 - val_accuracy: 0.7107\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3286 - accuracy: 0.9605 - val_loss: 1.2532 - val_accuracy: 0.7087\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3292 - accuracy: 0.9545 - val_loss: 1.2628 - val_accuracy: 0.7138\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3240 - accuracy: 0.9605 - val_loss: 1.2608 - val_accuracy: 0.7076\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3202 - accuracy: 0.9576 - val_loss: 1.2804 - val_accuracy: 0.7118\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3219 - accuracy: 0.9574 - val_loss: 1.2590 - val_accuracy: 0.7138\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3143 - accuracy: 0.9628 - val_loss: 1.2802 - val_accuracy: 0.6973\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3245 - accuracy: 0.9571 - val_loss: 1.2806 - val_accuracy: 0.7087\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3205 - accuracy: 0.9607 - val_loss: 1.2717 - val_accuracy: 0.7076\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3118 - accuracy: 0.9680 - val_loss: 1.3003 - val_accuracy: 0.7004\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3170 - accuracy: 0.9584 - val_loss: 1.3087 - val_accuracy: 0.7014\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3116 - accuracy: 0.9659 - val_loss: 1.3254 - val_accuracy: 0.7056\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3133 - accuracy: 0.9620 - val_loss: 1.3139 - val_accuracy: 0.7087\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3068 - accuracy: 0.9680 - val_loss: 1.3117 - val_accuracy: 0.7056\n","{'loss': [0.6030846834182739, 0.5772491097450256, 0.5472193360328674, 0.5316369533538818, 0.5313773155212402, 0.5321736335754395, 0.5177052021026611, 0.5150001049041748, 0.4995039105415344, 0.510511577129364, 0.48942968249320984, 0.5016109943389893, 0.48964574933052063, 0.4773661494255066, 0.4708893299102783, 0.47260311245918274, 0.4604555070400238, 0.4589521884918213, 0.45772305130958557, 0.45854198932647705, 0.4523410499095917, 0.45377305150032043, 0.4460749626159668, 0.4416813254356384, 0.4461687505245209, 0.44580182433128357, 0.430622398853302, 0.4345831871032715, 0.4555826783180237, 0.4243294596672058, 0.4268699884414673, 0.4259730279445648, 0.4208049476146698, 0.4229675531387329, 0.4287078082561493, 0.4303513467311859, 0.4112982749938965, 0.4131850302219391, 0.41131359338760376, 0.4015320837497711, 0.40509843826293945, 0.4029295742511749, 0.39373722672462463, 0.39856642484664917, 0.3986055552959442, 0.39465203881263733, 0.3963608145713806, 0.39386966824531555, 0.3854857385158539, 0.3842514753341675, 0.38434913754463196, 0.37520816922187805, 0.37922632694244385, 0.37038454413414, 0.3752868175506592, 0.3825847804546356, 0.367484450340271, 0.3683546483516693, 0.3646693527698517, 0.3819975256919861, 0.36370721459388733, 0.3627602159976959, 0.37895044684410095, 0.36233440041542053, 0.35756567120552063, 0.3549736440181732, 0.36631056666374207, 0.3491566777229309, 0.3623627722263336, 0.35073867440223694, 0.35257813334465027, 0.3495526909828186, 0.3471600413322449, 0.338428258895874, 0.34077319502830505, 0.33408123254776, 0.3322508931159973, 0.3344250023365021, 0.3343874514102936, 0.3331020176410675, 0.33756759762763977, 0.34369784593582153, 0.3434144854545593, 0.33020922541618347, 0.3309082090854645, 0.3273646831512451, 0.33079954981803894, 0.32857194542884827, 0.32916274666786194, 0.3239528238773346, 0.3201705813407898, 0.3218633830547333, 0.3143300712108612, 0.3245396316051483, 0.320534348487854, 0.31175023317337036, 0.31697022914886475, 0.3115531802177429, 0.3133026957511902, 0.30681440234184265], 'accuracy': [0.866925060749054, 0.8736433982849121, 0.8788113594055176, 0.8886305093765259, 0.8904392719268799, 0.8883720636367798, 0.895348846912384, 0.8919896483421326, 0.9043927788734436, 0.8966408371925354, 0.9098191261291504, 0.8984495997428894, 0.9043927788734436, 0.908527135848999, 0.9129198789596558, 0.9054263830184937, 0.9191214442253113, 0.9162790775299072, 0.9162790775299072, 0.9131782650947571, 0.91989666223526, 0.920671820640564, 0.9250646233558655, 0.9204134345054626, 0.9157622456550598, 0.9186046719551086, 0.9276486039161682, 0.9250646233558655, 0.9139534831047058, 0.9237726330757141, 0.9258397817611694, 0.9268733859062195, 0.9250646233558655, 0.9289405941963196, 0.9284237623214722, 0.9276486039161682, 0.9325581192970276, 0.933074951171875, 0.9335917234420776, 0.9343669414520264, 0.9346253275871277, 0.9351420998573303, 0.9413436651229858, 0.934108555316925, 0.935917317867279, 0.9356589317321777, 0.933074951171875, 0.9395349025726318, 0.9418604373931885, 0.9439276456832886, 0.9390180706977844, 0.9454780220985413, 0.9452196359634399, 0.9478036165237427, 0.9428940415382385, 0.9390180706977844, 0.9478036165237427, 0.9521963596343994, 0.9478036165237427, 0.9387596845626831, 0.9483203887939453, 0.9478036165237427, 0.933850109577179, 0.94728684425354, 0.9503875970840454, 0.9514212012290955, 0.9413436651229858, 0.9552971720695496, 0.9444444179534912, 0.9514212012290955, 0.9514212012290955, 0.9475452303886414, 0.9529715776443481, 0.9563307762145996, 0.9560723304748535, 0.9609819054603577, 0.9581395387649536, 0.960465133190155, 0.960465133190155, 0.9571059346199036, 0.9573643207550049, 0.9519379734992981, 0.9532299637794495, 0.9589147567749023, 0.9578811526298523, 0.9630491137504578, 0.9565891623497009, 0.960465133190155, 0.9545219540596008, 0.960465133190155, 0.957622766494751, 0.9573643207550049, 0.9627906680107117, 0.9571059346199036, 0.9607235193252563, 0.9679586291313171, 0.9583979249000549, 0.9658914804458618, 0.9620155096054077, 0.9679586291313171], 'val_loss': [0.9491095542907715, 0.9456933736801147, 0.9398958086967468, 0.9338762164115906, 0.9293291568756104, 0.9199986457824707, 0.9126667380332947, 0.9098247289657593, 0.8930337429046631, 0.8856146335601807, 0.8819865584373474, 0.8709408640861511, 0.8608236908912659, 0.8732192516326904, 0.8696282505989075, 0.8655439019203186, 0.8695032000541687, 0.9074622392654419, 0.8711610436439514, 0.8834818601608276, 0.9350715279579163, 0.8998046517372131, 0.9059498310089111, 0.9592590928077698, 0.9345004558563232, 0.947785496711731, 0.9536783695220947, 1.0133397579193115, 0.9604151248931885, 0.9683271050453186, 0.9891573786735535, 0.9928445219993591, 1.0275219678878784, 1.0190571546554565, 1.0349637269973755, 1.0619193315505981, 1.0224095582962036, 1.060457468032837, 1.0273864269256592, 1.0433263778686523, 1.0437783002853394, 1.052673578262329, 1.0606125593185425, 1.088026762008667, 1.0513228178024292, 1.1386932134628296, 1.0660051107406616, 1.098007321357727, 1.093538761138916, 1.0924232006072998, 1.0918567180633545, 1.1194018125534058, 1.1022862195968628, 1.114086627960205, 1.1458094120025635, 1.1055363416671753, 1.114174723625183, 1.1128602027893066, 1.1212525367736816, 1.0935167074203491, 1.1166250705718994, 1.2620214223861694, 1.150313138961792, 1.132184386253357, 1.133431077003479, 1.1526354551315308, 1.1450082063674927, 1.1517291069030762, 1.1735351085662842, 1.171209454536438, 1.213158369064331, 1.1794017553329468, 1.1664704084396362, 1.187235713005066, 1.18978750705719, 1.183013677597046, 1.2334237098693848, 1.1928256750106812, 1.2350963354110718, 1.2245432138442993, 1.2596930265426636, 1.235127568244934, 1.2689433097839355, 1.2623661756515503, 1.2501397132873535, 1.267169713973999, 1.2546097040176392, 1.2531589269638062, 1.2627619504928589, 1.2608484029769897, 1.2803772687911987, 1.2590347528457642, 1.2802436351776123, 1.2806109189987183, 1.2717435359954834, 1.3003358840942383, 1.3087260723114014, 1.3253562450408936, 1.3138883113861084, 1.3116804361343384], 'val_accuracy': [0.6425619721412659, 0.6146694421768188, 0.6353305578231812, 0.6425619721412659, 0.6239669322967529, 0.6611570119857788, 0.66425621509552, 0.6363636255264282, 0.6787189841270447, 0.6787189841270447, 0.6611570119857788, 0.6776859760284424, 0.6869834661483765, 0.672520637512207, 0.6859503984451294, 0.7004132270812988, 0.7066115736961365, 0.69111567735672, 0.7283057570457458, 0.7221074104309082, 0.7055785059928894, 0.7283057570457458, 0.7272727489471436, 0.7252066135406494, 0.7293388247489929, 0.7262396812438965, 0.7252066135406494, 0.7272727489471436, 0.7190082669258118, 0.7262396812438965, 0.7407024502754211, 0.7272727489471436, 0.7210744023323059, 0.7272727489471436, 0.7200413346290588, 0.711776852607727, 0.7262396812438965, 0.7293388247489929, 0.7210744023323059, 0.7345041036605835, 0.7283057570457458, 0.7252066135406494, 0.7210744023323059, 0.7231404781341553, 0.7272727489471436, 0.6942148804664612, 0.7283057570457458, 0.7293388247489929, 0.7293388247489929, 0.7365702390670776, 0.7241735458374023, 0.7200413346290588, 0.7241735458374023, 0.7241735458374023, 0.7179751992225647, 0.7262396812438965, 0.7221074104309082, 0.7262396812438965, 0.7241735458374023, 0.7272727489471436, 0.7190082669258118, 0.7035123705863953, 0.7128099203109741, 0.7169421315193176, 0.7200413346290588, 0.6993801593780518, 0.7221074104309082, 0.7200413346290588, 0.71074378490448, 0.7200413346290588, 0.7128099203109741, 0.7210744023323059, 0.7148760557174683, 0.7190082669258118, 0.7179751992225647, 0.7179751992225647, 0.7055785059928894, 0.7128099203109741, 0.71074378490448, 0.7128099203109741, 0.711776852607727, 0.7169421315193176, 0.7159090638160706, 0.7097107172012329, 0.7055785059928894, 0.7138429880142212, 0.71074378490448, 0.7086777091026306, 0.7138429880142212, 0.7076446413993835, 0.711776852607727, 0.7138429880142212, 0.6973140239715576, 0.7086777091026306, 0.7076446413993835, 0.7004132270812988, 0.7014462947845459, 0.7055785059928894, 0.7086777091026306, 0.7055785059928894]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.4278 - accuracy: 0.9216"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 49ms/step - loss: 0.4319 - accuracy: 0.9208 - val_loss: 0.8891 - val_accuracy: 0.5819\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3762 - accuracy: 0.9405 - val_loss: 0.8818 - val_accuracy: 0.6067\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3643 - accuracy: 0.9480 - val_loss: 0.8756 - val_accuracy: 0.6153\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3611 - accuracy: 0.9461 - val_loss: 0.8654 - val_accuracy: 0.6681\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3645 - accuracy: 0.9440 - val_loss: 0.8575 - val_accuracy: 0.6767\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3438 - accuracy: 0.9518 - val_loss: 0.8534 - val_accuracy: 0.6659\n","Epoch 7/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3357 - accuracy: 0.9553 - val_loss: 0.8381 - val_accuracy: 0.6972\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3352 - accuracy: 0.9558 - val_loss: 0.8363 - val_accuracy: 0.6821\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3389 - accuracy: 0.9518 - val_loss: 0.8261 - val_accuracy: 0.6994\n","Epoch 10/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3349 - accuracy: 0.9569 - val_loss: 0.8150 - val_accuracy: 0.7004\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3386 - accuracy: 0.9469 - val_loss: 0.8158 - val_accuracy: 0.6950\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3283 - accuracy: 0.9566 - val_loss: 0.8053 - val_accuracy: 0.7069\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3257 - accuracy: 0.9539 - val_loss: 0.8029 - val_accuracy: 0.7037\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3317 - accuracy: 0.9537 - val_loss: 0.8074 - val_accuracy: 0.6972\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3340 - accuracy: 0.9520 - val_loss: 0.8120 - val_accuracy: 0.7037\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3194 - accuracy: 0.9599 - val_loss: 0.8200 - val_accuracy: 0.7134\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3189 - accuracy: 0.9596 - val_loss: 0.8285 - val_accuracy: 0.7231\n","Epoch 18/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3104 - accuracy: 0.9655 - val_loss: 0.8229 - val_accuracy: 0.7317\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3144 - accuracy: 0.9572 - val_loss: 0.8282 - val_accuracy: 0.7328\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3200 - accuracy: 0.9593 - val_loss: 0.8192 - val_accuracy: 0.7511\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3107 - accuracy: 0.9626 - val_loss: 0.8264 - val_accuracy: 0.7672\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3112 - accuracy: 0.9609 - val_loss: 0.8235 - val_accuracy: 0.7780\n","Epoch 23/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.3095 - accuracy: 0.9607 - val_loss: 0.8085 - val_accuracy: 0.7909\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3137 - accuracy: 0.9607 - val_loss: 0.8073 - val_accuracy: 0.7974\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3028 - accuracy: 0.9650 - val_loss: 0.8319 - val_accuracy: 0.7920\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3103 - accuracy: 0.9609 - val_loss: 0.8163 - val_accuracy: 0.8093\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3210 - accuracy: 0.9520 - val_loss: 0.9611 - val_accuracy: 0.7683\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3102 - accuracy: 0.9626 - val_loss: 0.8057 - val_accuracy: 0.8125\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3018 - accuracy: 0.9685 - val_loss: 0.8754 - val_accuracy: 0.7974\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3024 - accuracy: 0.9661 - val_loss: 0.8364 - val_accuracy: 0.8103\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3075 - accuracy: 0.9612 - val_loss: 0.9169 - val_accuracy: 0.7931\n","Epoch 32/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3061 - accuracy: 0.9644 - val_loss: 0.8667 - val_accuracy: 0.8136\n","Epoch 33/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2942 - accuracy: 0.9712 - val_loss: 0.8608 - val_accuracy: 0.8233\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2926 - accuracy: 0.9704 - val_loss: 0.8638 - val_accuracy: 0.8200\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3035 - accuracy: 0.9631 - val_loss: 0.8985 - val_accuracy: 0.8103\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3041 - accuracy: 0.9612 - val_loss: 0.8789 - val_accuracy: 0.8168\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2985 - accuracy: 0.9655 - val_loss: 0.8960 - val_accuracy: 0.8071\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2951 - accuracy: 0.9682 - val_loss: 0.8619 - val_accuracy: 0.8147\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2885 - accuracy: 0.9682 - val_loss: 0.8809 - val_accuracy: 0.8179\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2857 - accuracy: 0.9720 - val_loss: 0.8727 - val_accuracy: 0.8071\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2943 - accuracy: 0.9658 - val_loss: 0.9042 - val_accuracy: 0.7931\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3051 - accuracy: 0.9593 - val_loss: 0.8843 - val_accuracy: 0.8125\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2900 - accuracy: 0.9671 - val_loss: 0.8969 - val_accuracy: 0.8103\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2872 - accuracy: 0.9725 - val_loss: 0.8869 - val_accuracy: 0.8082\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2863 - accuracy: 0.9706 - val_loss: 0.8992 - val_accuracy: 0.8103\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2816 - accuracy: 0.9674 - val_loss: 0.9002 - val_accuracy: 0.8093\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2860 - accuracy: 0.9671 - val_loss: 0.8734 - val_accuracy: 0.8190\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2762 - accuracy: 0.9723 - val_loss: 0.9111 - val_accuracy: 0.8147\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2764 - accuracy: 0.9733 - val_loss: 0.9018 - val_accuracy: 0.8114\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2745 - accuracy: 0.9768 - val_loss: 0.9061 - val_accuracy: 0.8211\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2905 - accuracy: 0.9661 - val_loss: 1.0910 - val_accuracy: 0.7705\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2940 - accuracy: 0.9626 - val_loss: 1.0196 - val_accuracy: 0.7791\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2909 - accuracy: 0.9663 - val_loss: 0.8971 - val_accuracy: 0.8039\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2768 - accuracy: 0.9747 - val_loss: 0.9271 - val_accuracy: 0.8082\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2689 - accuracy: 0.9784 - val_loss: 0.9318 - val_accuracy: 0.8093\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2717 - accuracy: 0.9758 - val_loss: 0.9213 - val_accuracy: 0.8147\n","Epoch 57/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.2684 - accuracy: 0.9776 - val_loss: 0.9128 - val_accuracy: 0.8244\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2742 - accuracy: 0.9723 - val_loss: 1.0655 - val_accuracy: 0.7705\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2672 - accuracy: 0.9771 - val_loss: 0.9294 - val_accuracy: 0.8103\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2663 - accuracy: 0.9747 - val_loss: 0.9576 - val_accuracy: 0.8082\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2672 - accuracy: 0.9776 - val_loss: 0.9759 - val_accuracy: 0.8060\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2695 - accuracy: 0.9776 - val_loss: 1.1202 - val_accuracy: 0.7662\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2762 - accuracy: 0.9690 - val_loss: 1.0177 - val_accuracy: 0.7877\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2735 - accuracy: 0.9739 - val_loss: 0.9609 - val_accuracy: 0.7931\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2738 - accuracy: 0.9723 - val_loss: 0.9857 - val_accuracy: 0.8028\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2808 - accuracy: 0.9698 - val_loss: 0.9627 - val_accuracy: 0.8050\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2663 - accuracy: 0.9771 - val_loss: 0.9606 - val_accuracy: 0.7974\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2689 - accuracy: 0.9714 - val_loss: 0.9576 - val_accuracy: 0.8028\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2603 - accuracy: 0.9798 - val_loss: 0.9991 - val_accuracy: 0.7931\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2615 - accuracy: 0.9771 - val_loss: 0.9963 - val_accuracy: 0.7996\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2620 - accuracy: 0.9776 - val_loss: 0.9926 - val_accuracy: 0.8050\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2630 - accuracy: 0.9774 - val_loss: 0.9606 - val_accuracy: 0.8114\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2566 - accuracy: 0.9795 - val_loss: 0.9716 - val_accuracy: 0.8082\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2597 - accuracy: 0.9771 - val_loss: 0.9898 - val_accuracy: 0.8039\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2587 - accuracy: 0.9766 - val_loss: 1.0322 - val_accuracy: 0.7963\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2714 - accuracy: 0.9733 - val_loss: 1.0278 - val_accuracy: 0.7974\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2587 - accuracy: 0.9779 - val_loss: 0.9611 - val_accuracy: 0.8147\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2576 - accuracy: 0.9793 - val_loss: 0.9755 - val_accuracy: 0.8147\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2618 - accuracy: 0.9782 - val_loss: 1.1358 - val_accuracy: 0.7834\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2701 - accuracy: 0.9731 - val_loss: 0.9624 - val_accuracy: 0.8028\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2589 - accuracy: 0.9755 - val_loss: 1.0184 - val_accuracy: 0.7963\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2583 - accuracy: 0.9760 - val_loss: 1.0246 - val_accuracy: 0.7974\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2575 - accuracy: 0.9771 - val_loss: 1.0042 - val_accuracy: 0.7985\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2525 - accuracy: 0.9798 - val_loss: 1.0384 - val_accuracy: 0.7856\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2507 - accuracy: 0.9779 - val_loss: 0.9740 - val_accuracy: 0.8060\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2471 - accuracy: 0.9798 - val_loss: 1.0003 - val_accuracy: 0.7996\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2762 - accuracy: 0.9674 - val_loss: 0.9914 - val_accuracy: 0.7996\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2601 - accuracy: 0.9758 - val_loss: 1.0390 - val_accuracy: 0.7866\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2594 - accuracy: 0.9758 - val_loss: 1.0310 - val_accuracy: 0.7834\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2483 - accuracy: 0.9795 - val_loss: 1.0242 - val_accuracy: 0.7942\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2503 - accuracy: 0.9798 - val_loss: 1.0154 - val_accuracy: 0.7942\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2500 - accuracy: 0.9795 - val_loss: 1.0304 - val_accuracy: 0.7856\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2410 - accuracy: 0.9825 - val_loss: 1.0240 - val_accuracy: 0.7920\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.9825 - val_loss: 1.0189 - val_accuracy: 0.7920\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2451 - accuracy: 0.9806 - val_loss: 1.0204 - val_accuracy: 0.8060\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2450 - accuracy: 0.9833 - val_loss: 1.0810 - val_accuracy: 0.7856\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2434 - accuracy: 0.9787 - val_loss: 1.1774 - val_accuracy: 0.7748\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2441 - accuracy: 0.9809 - val_loss: 1.0450 - val_accuracy: 0.7953\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2510 - accuracy: 0.9766 - val_loss: 1.0305 - val_accuracy: 0.7974\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2512 - accuracy: 0.9736 - val_loss: 1.0374 - val_accuracy: 0.7996\n","{'loss': [0.431915283203125, 0.3762096166610718, 0.3643469512462616, 0.361084908246994, 0.364483505487442, 0.3437933027744293, 0.3356597125530243, 0.3351755440235138, 0.33888494968414307, 0.3348710238933563, 0.33855128288269043, 0.32831576466560364, 0.325693815946579, 0.33172720670700073, 0.33395543694496155, 0.31940019130706787, 0.31887534260749817, 0.31044262647628784, 0.3143920600414276, 0.3199637532234192, 0.31072184443473816, 0.31117361783981323, 0.30952560901641846, 0.3136589229106903, 0.30284345149993896, 0.3102560043334961, 0.3209654688835144, 0.3101806044578552, 0.3018060624599457, 0.30235058069229126, 0.30751681327819824, 0.30607539415359497, 0.29418787360191345, 0.2926473319530487, 0.3035328984260559, 0.30408915877342224, 0.298539936542511, 0.2951243817806244, 0.28845348954200745, 0.2857381999492645, 0.2942519783973694, 0.30505913496017456, 0.289999783039093, 0.28721049427986145, 0.2862686216831207, 0.2816437780857086, 0.2860495448112488, 0.27620652318000793, 0.2763693928718567, 0.27449989318847656, 0.2904898226261139, 0.29403966665267944, 0.2908882796764374, 0.27676981687545776, 0.26892924308776855, 0.271748811006546, 0.2683970630168915, 0.2742498517036438, 0.26723819971084595, 0.2663193941116333, 0.2672087848186493, 0.2695407569408417, 0.2762429118156433, 0.2734525501728058, 0.27377182245254517, 0.2807607650756836, 0.26626309752464294, 0.26894453167915344, 0.26034781336784363, 0.2615039646625519, 0.26198723912239075, 0.26303601264953613, 0.2565748989582062, 0.25974413752555847, 0.2587394416332245, 0.2714427709579468, 0.25868064165115356, 0.25759178400039673, 0.2618142366409302, 0.27013394236564636, 0.2589041590690613, 0.25832369923591614, 0.2574932277202606, 0.2525215446949005, 0.25071030855178833, 0.24712437391281128, 0.2762155830860138, 0.260075181722641, 0.2594375014305115, 0.24825426936149597, 0.25033658742904663, 0.24999560415744781, 0.24101130664348602, 0.2461245208978653, 0.24514999985694885, 0.24503648281097412, 0.24340778589248657, 0.24413441121578217, 0.2510169446468353, 0.25124114751815796], 'accuracy': [0.9207974076271057, 0.9404633641242981, 0.9480064511299133, 0.9461206793785095, 0.943965494632721, 0.951777994632721, 0.9552801847457886, 0.9558189511299133, 0.951777994632721, 0.9568965435028076, 0.946928858757019, 0.9566271305084229, 0.9539331793785095, 0.9536637663841248, 0.9520474076271057, 0.9598599076271057, 0.959590494632721, 0.9655172228813171, 0.9571659564971924, 0.959321141242981, 0.962553858757019, 0.9609375, 0.9606680870056152, 0.9606680870056152, 0.9649784564971924, 0.9609375, 0.9520474076271057, 0.962553858757019, 0.9684805870056152, 0.9660560488700867, 0.9612069129943848, 0.9644396305084229, 0.9711745977401733, 0.970366358757019, 0.9630926847457886, 0.9612069129943848, 0.9655172228813171, 0.9682112336158752, 0.9682112336158752, 0.9719827771186829, 0.9657866358757019, 0.959321141242981, 0.967133641242981, 0.9725215435028076, 0.9706357717514038, 0.967402994632721, 0.967133641242981, 0.9722521305084229, 0.9733297228813171, 0.9768319129943848, 0.9660560488700867, 0.962553858757019, 0.9663254022598267, 0.9746767282485962, 0.9784482717514038, 0.9757543206214905, 0.9776400923728943, 0.9722521305084229, 0.9771012663841248, 0.9746767282485962, 0.9776400923728943, 0.9776400923728943, 0.9690194129943848, 0.9738685488700867, 0.9722521305084229, 0.9698275923728943, 0.9771012663841248, 0.9714439511299133, 0.9797952771186829, 0.9771012663841248, 0.9776400923728943, 0.9773706793785095, 0.9795258641242981, 0.9771012663841248, 0.9765625, 0.9733297228813171, 0.977909505367279, 0.9792564511299133, 0.978178858757019, 0.9730603694915771, 0.9754849076271057, 0.9760237336158752, 0.9771012663841248, 0.9797952771186829, 0.977909505367279, 0.9797952771186829, 0.967402994632721, 0.9757543206214905, 0.9757543206214905, 0.9795258641242981, 0.9797952771186829, 0.9795258641242981, 0.9824892282485962, 0.9824892282485962, 0.9806034564971924, 0.9832974076271057, 0.9787176847457886, 0.9808728694915771, 0.9765625, 0.9735991358757019], 'val_loss': [0.8891488313674927, 0.8818453550338745, 0.8755719661712646, 0.8653823733329773, 0.8574674725532532, 0.853437066078186, 0.8381025195121765, 0.8363074064254761, 0.8261202573776245, 0.8150379657745361, 0.815833330154419, 0.8053165674209595, 0.8028823733329773, 0.807405948638916, 0.8120333552360535, 0.8200491666793823, 0.8285143375396729, 0.8228801488876343, 0.8282119631767273, 0.8192493915557861, 0.8264229893684387, 0.823543906211853, 0.8084604144096375, 0.8073062300682068, 0.8319124579429626, 0.8163144588470459, 0.9611455202102661, 0.8057429194450378, 0.8753653168678284, 0.8364390730857849, 0.9168910980224609, 0.8666527271270752, 0.8607786893844604, 0.8638229966163635, 0.8985065221786499, 0.878926157951355, 0.8960481286048889, 0.8618552088737488, 0.8808774352073669, 0.8727067708969116, 0.9041690230369568, 0.8843281865119934, 0.8969340920448303, 0.8869198560714722, 0.8991981744766235, 0.900176465511322, 0.8733965754508972, 0.9111431241035461, 0.9017800688743591, 0.9061301946640015, 1.0909675359725952, 1.0196294784545898, 0.8970780372619629, 0.9271281957626343, 0.9317828416824341, 0.9212648272514343, 0.9128032326698303, 1.0655035972595215, 0.9294321537017822, 0.9576436877250671, 0.9758726954460144, 1.120158314704895, 1.0176897048950195, 0.9609304070472717, 0.9856641292572021, 0.9627317786216736, 0.9605931043624878, 0.9575631618499756, 0.9991122484207153, 0.9963445067405701, 0.9925834536552429, 0.9606306552886963, 0.9716126918792725, 0.9897544980049133, 1.0322239398956299, 1.0278029441833496, 0.9611097574234009, 0.9754754900932312, 1.1357969045639038, 0.9624468684196472, 1.0183731317520142, 1.024587869644165, 1.0042091608047485, 1.0383857488632202, 0.9740238189697266, 1.000288486480713, 0.991439700126648, 1.03901207447052, 1.0310341119766235, 1.0241843461990356, 1.0153920650482178, 1.0303593873977661, 1.0240260362625122, 1.0188937187194824, 1.0203970670700073, 1.0810285806655884, 1.1774166822433472, 1.0449953079223633, 1.0304937362670898, 1.0373786687850952], 'val_accuracy': [0.5818965435028076, 0.6066810488700867, 0.6153017282485962, 0.6681034564971924, 0.6767241358757019, 0.6659482717514038, 0.6971982717514038, 0.6821120977401733, 0.6993534564971924, 0.7004310488700867, 0.6950430870056152, 0.7068965435028076, 0.7036637663841248, 0.6971982717514038, 0.7036637663841248, 0.7133620977401733, 0.7230603694915771, 0.7316810488700867, 0.732758641242981, 0.7510775923728943, 0.767241358757019, 0.7780172228813171, 0.7909482717514038, 0.7974137663841248, 0.7920258641242981, 0.8092672228813171, 0.7683189511299133, 0.8125, 0.7974137663841248, 0.8103448152542114, 0.7931034564971924, 0.8135775923728943, 0.8232758641242981, 0.8200430870056152, 0.8103448152542114, 0.8168103694915771, 0.8071120977401733, 0.8146551847457886, 0.8178879022598267, 0.8071120977401733, 0.7931034564971924, 0.8125, 0.8103448152542114, 0.8081896305084229, 0.8103448152542114, 0.8092672228813171, 0.818965494632721, 0.8146551847457886, 0.8114224076271057, 0.8211206793785095, 0.7704741358757019, 0.7790948152542114, 0.8038793206214905, 0.8081896305084229, 0.8092672228813171, 0.8146551847457886, 0.8243534564971924, 0.7704741358757019, 0.8103448152542114, 0.8081896305084229, 0.806034505367279, 0.7661637663841248, 0.787715494632721, 0.7931034564971924, 0.8028017282485962, 0.8049569129943848, 0.7974137663841248, 0.8028017282485962, 0.7931034564971924, 0.7995689511299133, 0.8049569129943848, 0.8114224076271057, 0.8081896305084229, 0.8038793206214905, 0.7963362336158752, 0.7974137663841248, 0.8146551847457886, 0.8146551847457886, 0.7834051847457886, 0.8028017282485962, 0.7963362336158752, 0.7974137663841248, 0.798491358757019, 0.7855603694915771, 0.806034505367279, 0.7995689511299133, 0.7995689511299133, 0.7866379022598267, 0.7834051847457886, 0.7941810488700867, 0.7941810488700867, 0.7855603694915771, 0.7920258641242981, 0.7920258641242981, 0.806034505367279, 0.7855603694915771, 0.774784505367279, 0.795258641242981, 0.7974137663841248, 0.7995689511299133]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","24/28 [========================>.....] - ETA: 0s - loss: 0.3924 - accuracy: 0.9284"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 51ms/step - loss: 0.3961 - accuracy: 0.9270 - val_loss: 0.8839 - val_accuracy: 0.6176\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.9301 - val_loss: 0.8819 - val_accuracy: 0.5962\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3603 - accuracy: 0.9451 - val_loss: 0.8740 - val_accuracy: 0.6244\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3577 - accuracy: 0.9471 - val_loss: 0.8640 - val_accuracy: 0.6493\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3513 - accuracy: 0.9496 - val_loss: 0.8559 - val_accuracy: 0.6742\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3420 - accuracy: 0.9522 - val_loss: 0.8494 - val_accuracy: 0.6799\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3498 - accuracy: 0.9491 - val_loss: 0.8409 - val_accuracy: 0.6833\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3477 - accuracy: 0.9445 - val_loss: 0.8292 - val_accuracy: 0.6844\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3402 - accuracy: 0.9536 - val_loss: 0.8195 - val_accuracy: 0.6991\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3357 - accuracy: 0.9536 - val_loss: 0.8190 - val_accuracy: 0.6923\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3433 - accuracy: 0.9505 - val_loss: 0.8081 - val_accuracy: 0.6923\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3278 - accuracy: 0.9539 - val_loss: 0.7933 - val_accuracy: 0.7093\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3335 - accuracy: 0.9542 - val_loss: 0.7998 - val_accuracy: 0.7014\n","Epoch 14/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3328 - accuracy: 0.9525 - val_loss: 0.8210 - val_accuracy: 0.6912\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3229 - accuracy: 0.9584 - val_loss: 0.7924 - val_accuracy: 0.7172\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3234 - accuracy: 0.9519 - val_loss: 0.7876 - val_accuracy: 0.7138\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3185 - accuracy: 0.9593 - val_loss: 0.8177 - val_accuracy: 0.7093\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3205 - accuracy: 0.9561 - val_loss: 0.7973 - val_accuracy: 0.7421\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3119 - accuracy: 0.9624 - val_loss: 0.8178 - val_accuracy: 0.7353\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3133 - accuracy: 0.9601 - val_loss: 0.8419 - val_accuracy: 0.7353\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3223 - accuracy: 0.9601 - val_loss: 0.8044 - val_accuracy: 0.7647\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3089 - accuracy: 0.9624 - val_loss: 0.8043 - val_accuracy: 0.7726\n","Epoch 23/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3079 - accuracy: 0.9618 - val_loss: 0.8206 - val_accuracy: 0.7760\n","Epoch 24/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3079 - accuracy: 0.9646 - val_loss: 0.8076 - val_accuracy: 0.7862\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3080 - accuracy: 0.9610 - val_loss: 0.8285 - val_accuracy: 0.8020\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3125 - accuracy: 0.9584 - val_loss: 0.8317 - val_accuracy: 0.7975\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3105 - accuracy: 0.9612 - val_loss: 0.8088 - val_accuracy: 0.8066\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2986 - accuracy: 0.9660 - val_loss: 0.8056 - val_accuracy: 0.8111\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3063 - accuracy: 0.9584 - val_loss: 0.8222 - val_accuracy: 0.8122\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3025 - accuracy: 0.9666 - val_loss: 0.8202 - val_accuracy: 0.8179\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2944 - accuracy: 0.9677 - val_loss: 0.8499 - val_accuracy: 0.8190\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3069 - accuracy: 0.9626 - val_loss: 0.8353 - val_accuracy: 0.8179\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2997 - accuracy: 0.9643 - val_loss: 0.8417 - val_accuracy: 0.8088\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2937 - accuracy: 0.9677 - val_loss: 0.8425 - val_accuracy: 0.8179\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2999 - accuracy: 0.9652 - val_loss: 0.8629 - val_accuracy: 0.8190\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2966 - accuracy: 0.9686 - val_loss: 0.8596 - val_accuracy: 0.8224\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2877 - accuracy: 0.9709 - val_loss: 0.8548 - val_accuracy: 0.8201\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2937 - accuracy: 0.9686 - val_loss: 0.8920 - val_accuracy: 0.8111\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2905 - accuracy: 0.9689 - val_loss: 0.9162 - val_accuracy: 0.8100\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3013 - accuracy: 0.9626 - val_loss: 0.8776 - val_accuracy: 0.8145\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2906 - accuracy: 0.9700 - val_loss: 0.8878 - val_accuracy: 0.8111\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2906 - accuracy: 0.9666 - val_loss: 0.8812 - val_accuracy: 0.8179\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2828 - accuracy: 0.9683 - val_loss: 0.8807 - val_accuracy: 0.8201\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2862 - accuracy: 0.9706 - val_loss: 0.8869 - val_accuracy: 0.8054\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2935 - accuracy: 0.9632 - val_loss: 0.8982 - val_accuracy: 0.8066\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2777 - accuracy: 0.9762 - val_loss: 0.8893 - val_accuracy: 0.8156\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2823 - accuracy: 0.9740 - val_loss: 0.8772 - val_accuracy: 0.8201\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2782 - accuracy: 0.9714 - val_loss: 0.8946 - val_accuracy: 0.8213\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2887 - accuracy: 0.9658 - val_loss: 0.8928 - val_accuracy: 0.8066\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2791 - accuracy: 0.9728 - val_loss: 0.9093 - val_accuracy: 0.8133\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2783 - accuracy: 0.9726 - val_loss: 0.9025 - val_accuracy: 0.8133\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2721 - accuracy: 0.9748 - val_loss: 0.9302 - val_accuracy: 0.8122\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2784 - accuracy: 0.9743 - val_loss: 0.9145 - val_accuracy: 0.8167\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2712 - accuracy: 0.9765 - val_loss: 0.9184 - val_accuracy: 0.8167\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2681 - accuracy: 0.9776 - val_loss: 0.9264 - val_accuracy: 0.8201\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2684 - accuracy: 0.9740 - val_loss: 0.9355 - val_accuracy: 0.8100\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2767 - accuracy: 0.9714 - val_loss: 0.9217 - val_accuracy: 0.8167\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2680 - accuracy: 0.9782 - val_loss: 0.9400 - val_accuracy: 0.8179\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2732 - accuracy: 0.9731 - val_loss: 0.9121 - val_accuracy: 0.8145\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2690 - accuracy: 0.9751 - val_loss: 0.9344 - val_accuracy: 0.7998\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2732 - accuracy: 0.9700 - val_loss: 0.9277 - val_accuracy: 0.8100\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2693 - accuracy: 0.9745 - val_loss: 0.9424 - val_accuracy: 0.8088\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2691 - accuracy: 0.9740 - val_loss: 0.9389 - val_accuracy: 0.8009\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2615 - accuracy: 0.9788 - val_loss: 0.9358 - val_accuracy: 0.8111\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2591 - accuracy: 0.9762 - val_loss: 0.9366 - val_accuracy: 0.8190\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2663 - accuracy: 0.9785 - val_loss: 1.0178 - val_accuracy: 0.7986\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2787 - accuracy: 0.9660 - val_loss: 1.0462 - val_accuracy: 0.7941\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2667 - accuracy: 0.9720 - val_loss: 0.9434 - val_accuracy: 0.8100\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2604 - accuracy: 0.9765 - val_loss: 0.9364 - val_accuracy: 0.8088\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2628 - accuracy: 0.9757 - val_loss: 0.9323 - val_accuracy: 0.8088\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2656 - accuracy: 0.9751 - val_loss: 0.9537 - val_accuracy: 0.8066\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2606 - accuracy: 0.9748 - val_loss: 0.9854 - val_accuracy: 0.8066\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2755 - accuracy: 0.9689 - val_loss: 0.9681 - val_accuracy: 0.8167\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2664 - accuracy: 0.9745 - val_loss: 0.9513 - val_accuracy: 0.8100\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2618 - accuracy: 0.9762 - val_loss: 0.9606 - val_accuracy: 0.8043\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2652 - accuracy: 0.9703 - val_loss: 0.9581 - val_accuracy: 0.8145\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2669 - accuracy: 0.9703 - val_loss: 0.9877 - val_accuracy: 0.8122\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2632 - accuracy: 0.9754 - val_loss: 0.9725 - val_accuracy: 0.8100\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2495 - accuracy: 0.9799 - val_loss: 0.9780 - val_accuracy: 0.8100\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2721 - accuracy: 0.9660 - val_loss: 1.0302 - val_accuracy: 0.7964\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2550 - accuracy: 0.9774 - val_loss: 0.9632 - val_accuracy: 0.8100\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2490 - accuracy: 0.9793 - val_loss: 0.9691 - val_accuracy: 0.8054\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2618 - accuracy: 0.9765 - val_loss: 1.0400 - val_accuracy: 0.7975\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2579 - accuracy: 0.9768 - val_loss: 1.0280 - val_accuracy: 0.8054\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2535 - accuracy: 0.9771 - val_loss: 0.9583 - val_accuracy: 0.8066\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2417 - accuracy: 0.9842 - val_loss: 0.9629 - val_accuracy: 0.7975\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2493 - accuracy: 0.9793 - val_loss: 0.9631 - val_accuracy: 0.8066\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2497 - accuracy: 0.9774 - val_loss: 0.9702 - val_accuracy: 0.8122\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2471 - accuracy: 0.9816 - val_loss: 1.0063 - val_accuracy: 0.8032\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2485 - accuracy: 0.9791 - val_loss: 0.9922 - val_accuracy: 0.8066\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2571 - accuracy: 0.9785 - val_loss: 1.0049 - val_accuracy: 0.8066\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2392 - accuracy: 0.9861 - val_loss: 1.0040 - val_accuracy: 0.8032\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2411 - accuracy: 0.9833 - val_loss: 1.0448 - val_accuracy: 0.8009\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2506 - accuracy: 0.9751 - val_loss: 1.0773 - val_accuracy: 0.8020\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2463 - accuracy: 0.9782 - val_loss: 1.0329 - val_accuracy: 0.7964\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2380 - accuracy: 0.9850 - val_loss: 1.0104 - val_accuracy: 0.8088\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2443 - accuracy: 0.9813 - val_loss: 1.0300 - val_accuracy: 0.7975\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2391 - accuracy: 0.9842 - val_loss: 1.0937 - val_accuracy: 0.7941\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2574 - accuracy: 0.9731 - val_loss: 1.0640 - val_accuracy: 0.7998\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2540 - accuracy: 0.9737 - val_loss: 1.0282 - val_accuracy: 0.7998\n","{'loss': [0.3960891366004944, 0.38789644837379456, 0.3602806627750397, 0.3577297031879425, 0.3513059914112091, 0.34195083379745483, 0.34979182481765747, 0.34768906235694885, 0.34017354249954224, 0.3357314169406891, 0.34329211711883545, 0.3277871906757355, 0.3335125148296356, 0.3327719569206238, 0.32289040088653564, 0.323413610458374, 0.31845131516456604, 0.32050952315330505, 0.31190750002861023, 0.31326091289520264, 0.3223120868206024, 0.3088720142841339, 0.30785346031188965, 0.30789390206336975, 0.30801355838775635, 0.31249240040779114, 0.31052282452583313, 0.2986495792865753, 0.30632132291793823, 0.30248376727104187, 0.2944418489933014, 0.30688804388046265, 0.29967060685157776, 0.2937326729297638, 0.29986000061035156, 0.2966252267360687, 0.2876810133457184, 0.29373499751091003, 0.29045769572257996, 0.30125048756599426, 0.2905580401420593, 0.2906127870082855, 0.2828467786312103, 0.28618261218070984, 0.2934909164905548, 0.27766522765159607, 0.2823324203491211, 0.2782188951969147, 0.2886989712715149, 0.2791159152984619, 0.27828603982925415, 0.2721117436885834, 0.278433233499527, 0.27115094661712646, 0.26810458302497864, 0.2684047520160675, 0.276719868183136, 0.26799729466438293, 0.2731824219226837, 0.26895377039909363, 0.2731866240501404, 0.26933300495147705, 0.2691173553466797, 0.26154184341430664, 0.2591269612312317, 0.26633909344673157, 0.2786893844604492, 0.266737699508667, 0.26042553782463074, 0.2628313899040222, 0.2655690014362335, 0.26057347655296326, 0.2755306661128998, 0.26635485887527466, 0.26181259751319885, 0.2651970088481903, 0.26693448424339294, 0.2632131576538086, 0.24953192472457886, 0.2721138894557953, 0.25496572256088257, 0.2489505559206009, 0.26180723309516907, 0.2579260766506195, 0.2534829378128052, 0.24173147976398468, 0.2492617517709732, 0.2496800422668457, 0.2470797300338745, 0.24846042692661285, 0.2570702135562897, 0.23921260237693787, 0.24105046689510345, 0.25063008069992065, 0.24626164138317108, 0.23798243701457977, 0.24425292015075684, 0.2391001582145691, 0.25743600726127625, 0.2539634108543396], 'accuracy': [0.9269949197769165, 0.9301075339317322, 0.945104718208313, 0.947085440158844, 0.9496321678161621, 0.9521788358688354, 0.9490662217140198, 0.9445387721061707, 0.9535936713218689, 0.9535936713218689, 0.9504810571670532, 0.9538766145706177, 0.9541596174240112, 0.9524617791175842, 0.9584040641784668, 0.9518958926200867, 0.9592529535293579, 0.9561403393745422, 0.9623655676841736, 0.960101842880249, 0.960101842880249, 0.9623655676841736, 0.961799681186676, 0.9646292924880981, 0.9609507918357849, 0.9584040641784668, 0.9612337350845337, 0.9660441279411316, 0.9584040641784668, 0.9666100740432739, 0.9677419066429138, 0.9626485705375671, 0.9643463492393494, 0.9677419066429138, 0.9651952385902405, 0.9685908555984497, 0.9708545804023743, 0.9685908555984497, 0.9688737988471985, 0.9626485705375671, 0.9700056314468384, 0.9666100740432739, 0.9683078527450562, 0.9705715775489807, 0.9632145166397095, 0.9762309193611145, 0.9739671945571899, 0.9714204668998718, 0.9657611846923828, 0.9728353023529053, 0.9725523591041565, 0.974816083908081, 0.9742501378059387, 0.9765138626098633, 0.977645754814148, 0.9739671945571899, 0.9714204668998718, 0.9782116413116455, 0.9731183052062988, 0.9750990271568298, 0.9700056314468384, 0.9745330810546875, 0.9739671945571899, 0.9787775874137878, 0.9762309193611145, 0.9784946441650391, 0.9660441279411316, 0.9719864130020142, 0.9765138626098633, 0.9756649732589722, 0.9750990271568298, 0.974816083908081, 0.9688737988471985, 0.9745330810546875, 0.9762309193611145, 0.9702886343002319, 0.9702886343002319, 0.9753820300102234, 0.9799094796180725, 0.9660441279411316, 0.9773627519607544, 0.9793435335159302, 0.9765138626098633, 0.9767968058586121, 0.9770798087120056, 0.9841539263725281, 0.9793435335159302, 0.9773627519607544, 0.9816072583198547, 0.9790605306625366, 0.9784946441650391, 0.9861347079277039, 0.983305037021637, 0.9750990271568298, 0.9782116413116455, 0.9850028157234192, 0.9813242554664612, 0.9841539263725281, 0.9731183052062988, 0.9736841917037964], 'val_loss': [0.8839249610900879, 0.8818755745887756, 0.8739539384841919, 0.8639713525772095, 0.8559436202049255, 0.8493533134460449, 0.84088134765625, 0.8292062282562256, 0.8194966912269592, 0.818996250629425, 0.8080979585647583, 0.793308436870575, 0.7997874021530151, 0.8209622502326965, 0.7924280762672424, 0.7875800728797913, 0.8177210092544556, 0.797298014163971, 0.8178186416625977, 0.8419276475906372, 0.8044137358665466, 0.8042895197868347, 0.8206384181976318, 0.8075799942016602, 0.8284521102905273, 0.8317463994026184, 0.8088489174842834, 0.805640697479248, 0.8221933841705322, 0.8201715350151062, 0.8498822450637817, 0.8352997899055481, 0.8417181372642517, 0.8425467610359192, 0.862922191619873, 0.8596203923225403, 0.8547577261924744, 0.8920382261276245, 0.9162423610687256, 0.8776330947875977, 0.8878353238105774, 0.8812023997306824, 0.8807389736175537, 0.8868827819824219, 0.8981964588165283, 0.889308512210846, 0.8771712183952332, 0.894615650177002, 0.892774760723114, 0.9092972874641418, 0.9025187492370605, 0.9302230477333069, 0.9144628643989563, 0.9183543920516968, 0.9263660311698914, 0.9355275630950928, 0.9217066168785095, 0.9399701952934265, 0.9121120572090149, 0.9344229102134705, 0.927661120891571, 0.9424290657043457, 0.938869059085846, 0.9357998967170715, 0.9366285800933838, 1.0178313255310059, 1.0461972951889038, 0.9433885216712952, 0.9364093542098999, 0.9322516918182373, 0.9536721706390381, 0.9854161143302917, 0.9680638313293457, 0.9513060450553894, 0.9606122970581055, 0.9581437706947327, 0.987663745880127, 0.9725213646888733, 0.9779784083366394, 1.0302408933639526, 0.9631770253181458, 0.9691106677055359, 1.0399785041809082, 1.0280126333236694, 0.9582856297492981, 0.9629419445991516, 0.9630984663963318, 0.9701687693595886, 1.00630784034729, 0.9921678304672241, 1.0049402713775635, 1.004008412361145, 1.0448375940322876, 1.0772907733917236, 1.0328912734985352, 1.010410189628601, 1.0299720764160156, 1.093719482421875, 1.0640181303024292, 1.028220295906067], 'val_accuracy': [0.6176470518112183, 0.5961538553237915, 0.6244344115257263, 0.6493212580680847, 0.6742081642150879, 0.679864227771759, 0.6832579374313354, 0.6843891143798828, 0.6990950107574463, 0.692307710647583, 0.692307710647583, 0.709276020526886, 0.7013574838638306, 0.6911764740943909, 0.7171945571899414, 0.7138009071350098, 0.709276020526886, 0.7420814633369446, 0.7352941036224365, 0.7352941036224365, 0.7647058963775635, 0.7726244330406189, 0.7760180830955505, 0.7861990928649902, 0.8020362257957458, 0.7975113391876221, 0.8065611124038696, 0.8110859990119934, 0.8122171759605408, 0.8178732991218567, 0.8190045356750488, 0.8178732991218567, 0.8088235259056091, 0.8178732991218567, 0.8190045356750488, 0.8223981857299805, 0.820135772228241, 0.8110859990119934, 0.8099547624588013, 0.814479649066925, 0.8110859990119934, 0.8178732991218567, 0.820135772228241, 0.8054298758506775, 0.8065611124038696, 0.8156108856201172, 0.820135772228241, 0.8212669491767883, 0.8065611124038696, 0.8133484125137329, 0.8133484125137329, 0.8122171759605408, 0.8167420625686646, 0.8167420625686646, 0.820135772228241, 0.8099547624588013, 0.8167420625686646, 0.8178732991218567, 0.814479649066925, 0.7997737526893616, 0.8099547624588013, 0.8088235259056091, 0.8009049892425537, 0.8110859990119934, 0.8190045356750488, 0.7986425161361694, 0.7941176295280457, 0.8099547624588013, 0.8088235259056091, 0.8088235259056091, 0.8065611124038696, 0.8065611124038696, 0.8167420625686646, 0.8099547624588013, 0.8042986392974854, 0.814479649066925, 0.8122171759605408, 0.8099547624588013, 0.8099547624588013, 0.7963801026344299, 0.8099547624588013, 0.8054298758506775, 0.7975113391876221, 0.8054298758506775, 0.8065611124038696, 0.7975113391876221, 0.8065611124038696, 0.8122171759605408, 0.8031674027442932, 0.8065611124038696, 0.8065611124038696, 0.8031674027442932, 0.8009049892425537, 0.8020362257957458, 0.7963801026344299, 0.8088235259056091, 0.7975113391876221, 0.7941176295280457, 0.7997737526893616, 0.7997737526893616]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5317 - accuracy: 0.8758"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 48ms/step - loss: 0.5249 - accuracy: 0.8780 - val_loss: 0.8790 - val_accuracy: 0.6395\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4387 - accuracy: 0.9134 - val_loss: 0.8732 - val_accuracy: 0.6353\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3925 - accuracy: 0.9357 - val_loss: 0.8671 - val_accuracy: 0.6395\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3832 - accuracy: 0.9344 - val_loss: 0.8581 - val_accuracy: 0.6560\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3778 - accuracy: 0.9364 - val_loss: 0.8521 - val_accuracy: 0.6519\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3710 - accuracy: 0.9367 - val_loss: 0.8375 - val_accuracy: 0.6870\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3736 - accuracy: 0.9336 - val_loss: 0.8356 - val_accuracy: 0.6694\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3756 - accuracy: 0.9310 - val_loss: 0.8162 - val_accuracy: 0.7056\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3610 - accuracy: 0.9377 - val_loss: 0.8274 - val_accuracy: 0.6674\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.9432 - val_loss: 0.8059 - val_accuracy: 0.6880\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3594 - accuracy: 0.9416 - val_loss: 0.7955 - val_accuracy: 0.6952\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3452 - accuracy: 0.9514 - val_loss: 0.7867 - val_accuracy: 0.7066\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3496 - accuracy: 0.9470 - val_loss: 0.7874 - val_accuracy: 0.7118\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3469 - accuracy: 0.9483 - val_loss: 0.7894 - val_accuracy: 0.7252\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3472 - accuracy: 0.9468 - val_loss: 0.8305 - val_accuracy: 0.6963\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3417 - accuracy: 0.9504 - val_loss: 0.8045 - val_accuracy: 0.7376\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3392 - accuracy: 0.9514 - val_loss: 0.8242 - val_accuracy: 0.7324\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3387 - accuracy: 0.9522 - val_loss: 0.8098 - val_accuracy: 0.7521\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3456 - accuracy: 0.9429 - val_loss: 0.8205 - val_accuracy: 0.7552\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3323 - accuracy: 0.9530 - val_loss: 0.8136 - val_accuracy: 0.7707\n","Epoch 21/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3418 - accuracy: 0.9465 - val_loss: 0.8342 - val_accuracy: 0.7748\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3318 - accuracy: 0.9537 - val_loss: 0.8363 - val_accuracy: 0.7676\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3279 - accuracy: 0.9527 - val_loss: 0.8280 - val_accuracy: 0.7831\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3351 - accuracy: 0.9519 - val_loss: 0.8048 - val_accuracy: 0.7893\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3319 - accuracy: 0.9509 - val_loss: 0.8344 - val_accuracy: 0.7903\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3233 - accuracy: 0.9579 - val_loss: 0.8471 - val_accuracy: 0.7913\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3274 - accuracy: 0.9506 - val_loss: 0.8676 - val_accuracy: 0.8037\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3199 - accuracy: 0.9605 - val_loss: 0.8630 - val_accuracy: 0.7986\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3321 - accuracy: 0.9486 - val_loss: 0.8927 - val_accuracy: 0.7882\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3180 - accuracy: 0.9574 - val_loss: 0.8799 - val_accuracy: 0.7903\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3178 - accuracy: 0.9571 - val_loss: 0.9025 - val_accuracy: 0.7924\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3181 - accuracy: 0.9558 - val_loss: 0.9407 - val_accuracy: 0.7862\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3214 - accuracy: 0.9545 - val_loss: 0.9174 - val_accuracy: 0.7810\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3251 - accuracy: 0.9532 - val_loss: 0.9866 - val_accuracy: 0.7820\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3197 - accuracy: 0.9558 - val_loss: 0.9134 - val_accuracy: 0.7955\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3086 - accuracy: 0.9594 - val_loss: 0.9208 - val_accuracy: 0.7975\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3050 - accuracy: 0.9641 - val_loss: 0.9254 - val_accuracy: 0.7893\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3058 - accuracy: 0.9566 - val_loss: 0.9586 - val_accuracy: 0.7944\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3281 - accuracy: 0.9426 - val_loss: 0.9823 - val_accuracy: 0.7696\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3141 - accuracy: 0.9581 - val_loss: 0.9371 - val_accuracy: 0.7841\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3109 - accuracy: 0.9589 - val_loss: 0.9545 - val_accuracy: 0.7800\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3092 - accuracy: 0.9605 - val_loss: 0.9971 - val_accuracy: 0.7738\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3178 - accuracy: 0.9568 - val_loss: 0.9296 - val_accuracy: 0.7872\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3128 - accuracy: 0.9563 - val_loss: 0.9473 - val_accuracy: 0.7882\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3068 - accuracy: 0.9592 - val_loss: 0.9441 - val_accuracy: 0.7800\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3030 - accuracy: 0.9646 - val_loss: 0.9426 - val_accuracy: 0.7882\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2976 - accuracy: 0.9633 - val_loss: 1.0176 - val_accuracy: 0.7748\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3040 - accuracy: 0.9584 - val_loss: 1.0300 - val_accuracy: 0.7707\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3035 - accuracy: 0.9597 - val_loss: 0.9707 - val_accuracy: 0.7841\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3095 - accuracy: 0.9530 - val_loss: 0.9675 - val_accuracy: 0.7882\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2995 - accuracy: 0.9654 - val_loss: 0.9993 - val_accuracy: 0.7676\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3080 - accuracy: 0.9545 - val_loss: 0.9481 - val_accuracy: 0.7851\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3108 - accuracy: 0.9568 - val_loss: 1.0385 - val_accuracy: 0.7676\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2904 - accuracy: 0.9661 - val_loss: 0.9601 - val_accuracy: 0.7841\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2886 - accuracy: 0.9667 - val_loss: 0.9669 - val_accuracy: 0.7872\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2961 - accuracy: 0.9599 - val_loss: 0.9740 - val_accuracy: 0.7810\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2917 - accuracy: 0.9625 - val_loss: 0.9752 - val_accuracy: 0.7820\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2948 - accuracy: 0.9607 - val_loss: 1.0112 - val_accuracy: 0.7779\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3014 - accuracy: 0.9568 - val_loss: 1.0142 - val_accuracy: 0.7779\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2890 - accuracy: 0.9672 - val_loss: 1.0968 - val_accuracy: 0.7583\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3020 - accuracy: 0.9584 - val_loss: 0.9955 - val_accuracy: 0.7820\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2854 - accuracy: 0.9659 - val_loss: 0.9767 - val_accuracy: 0.7851\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2835 - accuracy: 0.9677 - val_loss: 1.0118 - val_accuracy: 0.7727\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2856 - accuracy: 0.9672 - val_loss: 0.9956 - val_accuracy: 0.7872\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2916 - accuracy: 0.9636 - val_loss: 0.9969 - val_accuracy: 0.7779\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2823 - accuracy: 0.9680 - val_loss: 1.0210 - val_accuracy: 0.7800\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2912 - accuracy: 0.9643 - val_loss: 1.0178 - val_accuracy: 0.7810\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2764 - accuracy: 0.9698 - val_loss: 1.0556 - val_accuracy: 0.7707\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2840 - accuracy: 0.9680 - val_loss: 1.1274 - val_accuracy: 0.7645\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3009 - accuracy: 0.9558 - val_loss: 1.0320 - val_accuracy: 0.7758\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2781 - accuracy: 0.9687 - val_loss: 1.1200 - val_accuracy: 0.7717\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2905 - accuracy: 0.9594 - val_loss: 1.0700 - val_accuracy: 0.7655\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2754 - accuracy: 0.9718 - val_loss: 1.0316 - val_accuracy: 0.7769\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2747 - accuracy: 0.9698 - val_loss: 1.0705 - val_accuracy: 0.7645\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2799 - accuracy: 0.9690 - val_loss: 1.0411 - val_accuracy: 0.7727\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2743 - accuracy: 0.9693 - val_loss: 1.0408 - val_accuracy: 0.7738\n","Epoch 77/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2769 - accuracy: 0.9669 - val_loss: 1.0739 - val_accuracy: 0.7686\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2801 - accuracy: 0.9659 - val_loss: 1.0503 - val_accuracy: 0.7727\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2707 - accuracy: 0.9721 - val_loss: 1.1069 - val_accuracy: 0.7696\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2807 - accuracy: 0.9656 - val_loss: 1.0430 - val_accuracy: 0.7779\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2721 - accuracy: 0.9724 - val_loss: 1.0645 - val_accuracy: 0.7758\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2692 - accuracy: 0.9760 - val_loss: 1.0652 - val_accuracy: 0.7717\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2726 - accuracy: 0.9703 - val_loss: 1.0983 - val_accuracy: 0.7665\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2733 - accuracy: 0.9690 - val_loss: 1.0584 - val_accuracy: 0.7738\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2646 - accuracy: 0.9747 - val_loss: 1.0817 - val_accuracy: 0.7696\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2657 - accuracy: 0.9744 - val_loss: 1.0736 - val_accuracy: 0.7717\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2700 - accuracy: 0.9674 - val_loss: 1.0644 - val_accuracy: 0.7614\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2697 - accuracy: 0.9677 - val_loss: 1.0469 - val_accuracy: 0.7696\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2715 - accuracy: 0.9661 - val_loss: 1.0838 - val_accuracy: 0.7769\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2631 - accuracy: 0.9739 - val_loss: 1.0851 - val_accuracy: 0.7748\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2648 - accuracy: 0.9713 - val_loss: 1.0965 - val_accuracy: 0.7738\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2627 - accuracy: 0.9734 - val_loss: 1.0735 - val_accuracy: 0.7789\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2657 - accuracy: 0.9724 - val_loss: 1.0954 - val_accuracy: 0.7748\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2655 - accuracy: 0.9744 - val_loss: 1.1017 - val_accuracy: 0.7686\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2620 - accuracy: 0.9744 - val_loss: 1.1061 - val_accuracy: 0.7738\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2576 - accuracy: 0.9760 - val_loss: 1.0898 - val_accuracy: 0.7779\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2686 - accuracy: 0.9654 - val_loss: 1.2152 - val_accuracy: 0.7645\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2915 - accuracy: 0.9579 - val_loss: 1.1160 - val_accuracy: 0.7748\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2647 - accuracy: 0.9718 - val_loss: 1.0909 - val_accuracy: 0.7717\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2608 - accuracy: 0.9755 - val_loss: 1.1255 - val_accuracy: 0.7572\n","{'loss': [0.5248891115188599, 0.4387266933917999, 0.3925108015537262, 0.38322147727012634, 0.3778465986251831, 0.37104013562202454, 0.3736354112625122, 0.3756261467933655, 0.36096492409706116, 0.3545759916305542, 0.35935378074645996, 0.3451600670814514, 0.34961026906967163, 0.34693244099617004, 0.34717151522636414, 0.341736376285553, 0.33915191888809204, 0.33871906995773315, 0.34562820196151733, 0.33232632279396057, 0.3417724370956421, 0.3318480849266052, 0.3278971314430237, 0.33513039350509644, 0.33189260959625244, 0.32328036427497864, 0.32741430401802063, 0.31988710165023804, 0.3320786654949188, 0.31795817613601685, 0.31782862544059753, 0.3180624842643738, 0.32135286927223206, 0.32508912682533264, 0.31967678666114807, 0.30863985419273376, 0.3050052225589752, 0.30579960346221924, 0.3281053602695465, 0.3140981197357178, 0.3109003007411957, 0.3092127740383148, 0.3178310692310333, 0.3128143548965454, 0.3067733347415924, 0.3029618263244629, 0.2976209223270416, 0.3040427565574646, 0.3035098612308502, 0.3094765841960907, 0.2995349168777466, 0.30797716975212097, 0.310833603143692, 0.2903977334499359, 0.28856387734413147, 0.2960577607154846, 0.2917080521583557, 0.2947752773761749, 0.3014085590839386, 0.2889869511127472, 0.3019764721393585, 0.2853638231754303, 0.28353479504585266, 0.28557077050209045, 0.2916300892829895, 0.28234970569610596, 0.291235089302063, 0.27641698718070984, 0.28401902318000793, 0.3009312152862549, 0.2780894935131073, 0.2904696464538574, 0.275438129901886, 0.27473747730255127, 0.27990368008613586, 0.27425417304039, 0.2768614590167999, 0.28010961413383484, 0.2706918716430664, 0.28069669008255005, 0.27213239669799805, 0.26922670006752014, 0.2726409435272217, 0.27332860231399536, 0.26460880041122437, 0.2657264173030853, 0.27001991868019104, 0.2697422206401825, 0.2714647352695465, 0.2631155252456665, 0.2648370862007141, 0.262667715549469, 0.26574599742889404, 0.2654951214790344, 0.2620425224304199, 0.25762221217155457, 0.26856887340545654, 0.2915123701095581, 0.2647239565849304, 0.26075848937034607], 'accuracy': [0.8780362010002136, 0.9134367108345032, 0.9356589317321777, 0.9343669414520264, 0.9364340901374817, 0.9366925358772278, 0.9335917234420776, 0.9310077428817749, 0.9377260804176331, 0.9431524276733398, 0.9416020512580872, 0.9514212012290955, 0.947028398513794, 0.9483203887939453, 0.9467700123786926, 0.9503875970840454, 0.9514212012290955, 0.9521963596343994, 0.9428940415382385, 0.9529715776443481, 0.9465116262435913, 0.9537467956542969, 0.9527131915092468, 0.9519379734992981, 0.950904369354248, 0.9578811526298523, 0.9506459832191467, 0.960465133190155, 0.9485788345336914, 0.9573643207550049, 0.9571059346199036, 0.9558139443397522, 0.9545219540596008, 0.9532299637794495, 0.9558139443397522, 0.959431529045105, 0.964082658290863, 0.9565891623497009, 0.9426356554031372, 0.9581395387649536, 0.9589147567749023, 0.960465133190155, 0.9568475484848022, 0.9563307762145996, 0.9591731429100037, 0.9645994901657104, 0.9633074998855591, 0.9583979249000549, 0.9596899151802063, 0.9529715776443481, 0.9653746485710144, 0.9545219540596008, 0.9568475484848022, 0.9661498665809631, 0.9666666388511658, 0.9599483013153076, 0.9625322818756104, 0.9607235193252563, 0.9568475484848022, 0.9671834707260132, 0.9583979249000549, 0.9658914804458618, 0.9677002429962158, 0.9671834707260132, 0.9635658860206604, 0.9679586291313171, 0.9643411040306091, 0.9697674512863159, 0.9679586291313171, 0.9558139443397522, 0.9687338471412659, 0.959431529045105, 0.9718345999717712, 0.9697674512863159, 0.9689922332763672, 0.9692506194114685, 0.9669250845909119, 0.9658914804458618, 0.9720930457115173, 0.9656330943107605, 0.9723514318466187, 0.9759690165519714, 0.9702842235565186, 0.9689922332763672, 0.9746770262718201, 0.974418580532074, 0.9674418568611145, 0.9677002429962158, 0.9661498665809631, 0.9739018082618713, 0.9713178277015686, 0.9733850359916687, 0.9723514318466187, 0.974418580532074, 0.974418580532074, 0.9759690165519714, 0.9653746485710144, 0.9578811526298523, 0.9718345999717712, 0.975452184677124], 'val_loss': [0.8790449500083923, 0.8732210397720337, 0.8671048879623413, 0.858117401599884, 0.8521040081977844, 0.837481677532196, 0.8355749845504761, 0.8161826133728027, 0.8274068832397461, 0.8059258460998535, 0.795488715171814, 0.7866963744163513, 0.7874240875244141, 0.7893862724304199, 0.8304547667503357, 0.80451500415802, 0.824170708656311, 0.8097540736198425, 0.8205087184906006, 0.8136169910430908, 0.8341594338417053, 0.8362793922424316, 0.8280433416366577, 0.8048193454742432, 0.8343695402145386, 0.8471422791481018, 0.8675551414489746, 0.8629506826400757, 0.89274662733078, 0.8798709511756897, 0.9024980068206787, 0.9407287240028381, 0.917403519153595, 0.9865682721138, 0.9134233593940735, 0.9207854866981506, 0.9254187941551208, 0.958613395690918, 0.9822628498077393, 0.9370550513267517, 0.9544678330421448, 0.9971280097961426, 0.9296073317527771, 0.947289764881134, 0.9441224932670593, 0.9426196217536926, 1.017569661140442, 1.0299690961837769, 0.9706987738609314, 0.9675461053848267, 0.9993143677711487, 0.9480960965156555, 1.0385236740112305, 0.9600822329521179, 0.9668521881103516, 0.9740268588066101, 0.9751895070075989, 1.0111743211746216, 1.0141990184783936, 1.0968101024627686, 0.9955347180366516, 0.9766799807548523, 1.0118125677108765, 0.9956054091453552, 0.9968799352645874, 1.0209987163543701, 1.0178236961364746, 1.0556241273880005, 1.127394676208496, 1.0320087671279907, 1.1199901103973389, 1.0699633359909058, 1.0316325426101685, 1.0704938173294067, 1.041147232055664, 1.0408164262771606, 1.073919653892517, 1.0503274202346802, 1.1069488525390625, 1.0430011749267578, 1.0645360946655273, 1.0652488470077515, 1.0982671976089478, 1.0583690404891968, 1.0817193984985352, 1.073617696762085, 1.0643746852874756, 1.046888828277588, 1.083757758140564, 1.085139274597168, 1.0965113639831543, 1.0735470056533813, 1.09540855884552, 1.1017303466796875, 1.1061103343963623, 1.0898404121398926, 1.215222716331482, 1.115981101989746, 1.0909397602081299, 1.1255420446395874], 'val_accuracy': [0.6394628286361694, 0.6353305578231812, 0.6394628286361694, 0.6559917330741882, 0.6518595218658447, 0.6869834661483765, 0.6694214940071106, 0.7055785059928894, 0.6673553586006165, 0.6880165338516235, 0.6952479481697083, 0.7066115736961365, 0.711776852607727, 0.7252066135406494, 0.6962810158729553, 0.7376033067703247, 0.7324380278587341, 0.7520661354064941, 0.7551652789115906, 0.7706611752510071, 0.7747933864593506, 0.7675619721412659, 0.7830578684806824, 0.78925621509552, 0.7902892827987671, 0.7913222908973694, 0.8037189841270447, 0.7985537052154541, 0.788223147392273, 0.7902892827987671, 0.7923553586006165, 0.7861570119857788, 0.7809917330741882, 0.7820248007774353, 0.7954545617103577, 0.797520637512207, 0.78925621509552, 0.7944214940071106, 0.76962810754776, 0.7840909361839294, 0.7799586653709412, 0.7737603187561035, 0.7871900796890259, 0.788223147392273, 0.7799586653709412, 0.788223147392273, 0.7747933864593506, 0.7706611752510071, 0.7840909361839294, 0.788223147392273, 0.7675619721412659, 0.7851239442825317, 0.7675619721412659, 0.7840909361839294, 0.7871900796890259, 0.7809917330741882, 0.7820248007774353, 0.7778925895690918, 0.7778925895690918, 0.7582644820213318, 0.7820248007774353, 0.7851239442825317, 0.7727272510528564, 0.7871900796890259, 0.7778925895690918, 0.7799586653709412, 0.7809917330741882, 0.7706611752510071, 0.7644628286361694, 0.7758264541625977, 0.7716942429542542, 0.7654958963394165, 0.7768595218658447, 0.7644628286361694, 0.7727272510528564, 0.7737603187561035, 0.7685950398445129, 0.7727272510528564, 0.76962810754776, 0.7778925895690918, 0.7758264541625977, 0.7716942429542542, 0.7665289044380188, 0.7737603187561035, 0.76962810754776, 0.7716942429542542, 0.7613636255264282, 0.76962810754776, 0.7768595218658447, 0.7747933864593506, 0.7737603187561035, 0.7789255976676941, 0.7747933864593506, 0.7685950398445129, 0.7737603187561035, 0.7778925895690918, 0.7644628286361694, 0.7747933864593506, 0.7716942429542542, 0.7572314143180847]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.3333 - accuracy: 0.9480"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 9s 52ms/step - loss: 0.3377 - accuracy: 0.9456 - val_loss: 0.8507 - val_accuracy: 0.6034\n","Epoch 2/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3063 - accuracy: 0.9518 - val_loss: 0.8496 - val_accuracy: 0.5851\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2842 - accuracy: 0.9652 - val_loss: 0.8372 - val_accuracy: 0.6185\n","Epoch 4/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2726 - accuracy: 0.9717 - val_loss: 0.8245 - val_accuracy: 0.6573\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2751 - accuracy: 0.9696 - val_loss: 0.8194 - val_accuracy: 0.6336\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2790 - accuracy: 0.9661 - val_loss: 0.8093 - val_accuracy: 0.6638\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2744 - accuracy: 0.9696 - val_loss: 0.7972 - val_accuracy: 0.7026\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2788 - accuracy: 0.9634 - val_loss: 0.7960 - val_accuracy: 0.6864\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2694 - accuracy: 0.9701 - val_loss: 0.7843 - val_accuracy: 0.7047\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2611 - accuracy: 0.9723 - val_loss: 0.7895 - val_accuracy: 0.6821\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2681 - accuracy: 0.9696 - val_loss: 0.7796 - val_accuracy: 0.6950\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2682 - accuracy: 0.9685 - val_loss: 0.7652 - val_accuracy: 0.7166\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2566 - accuracy: 0.9758 - val_loss: 0.7877 - val_accuracy: 0.7047\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2660 - accuracy: 0.9688 - val_loss: 0.7711 - val_accuracy: 0.7263\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2574 - accuracy: 0.9731 - val_loss: 0.7983 - val_accuracy: 0.7177\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2665 - accuracy: 0.9731 - val_loss: 0.7681 - val_accuracy: 0.7284\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2605 - accuracy: 0.9704 - val_loss: 0.7976 - val_accuracy: 0.7274\n","Epoch 18/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2633 - accuracy: 0.9728 - val_loss: 0.7887 - val_accuracy: 0.7500\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2515 - accuracy: 0.9779 - val_loss: 0.7671 - val_accuracy: 0.7737\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2605 - accuracy: 0.9720 - val_loss: 0.7979 - val_accuracy: 0.7737\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2559 - accuracy: 0.9749 - val_loss: 0.7966 - val_accuracy: 0.7856\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2491 - accuracy: 0.9787 - val_loss: 0.7833 - val_accuracy: 0.7985\n","Epoch 23/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2529 - accuracy: 0.9725 - val_loss: 0.7829 - val_accuracy: 0.8125\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2591 - accuracy: 0.9706 - val_loss: 0.7477 - val_accuracy: 0.8254\n","Epoch 25/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2556 - accuracy: 0.9723 - val_loss: 0.7413 - val_accuracy: 0.8427\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2467 - accuracy: 0.9768 - val_loss: 0.7334 - val_accuracy: 0.8567\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2498 - accuracy: 0.9747 - val_loss: 0.7633 - val_accuracy: 0.8405\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2550 - accuracy: 0.9733 - val_loss: 0.7481 - val_accuracy: 0.8427\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2420 - accuracy: 0.9801 - val_loss: 0.7446 - val_accuracy: 0.8513\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2556 - accuracy: 0.9749 - val_loss: 0.7594 - val_accuracy: 0.8470\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2490 - accuracy: 0.9747 - val_loss: 0.7641 - val_accuracy: 0.8502\n","Epoch 32/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2404 - accuracy: 0.9776 - val_loss: 0.7484 - val_accuracy: 0.8588\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2474 - accuracy: 0.9774 - val_loss: 0.7574 - val_accuracy: 0.8491\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2400 - accuracy: 0.9782 - val_loss: 0.7677 - val_accuracy: 0.8513\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2464 - accuracy: 0.9774 - val_loss: 0.7632 - val_accuracy: 0.8481\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2384 - accuracy: 0.9795 - val_loss: 0.7759 - val_accuracy: 0.8502\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2465 - accuracy: 0.9790 - val_loss: 0.7714 - val_accuracy: 0.8578\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2568 - accuracy: 0.9696 - val_loss: 0.8293 - val_accuracy: 0.8394\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2634 - accuracy: 0.9682 - val_loss: 0.7700 - val_accuracy: 0.8513\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2388 - accuracy: 0.9790 - val_loss: 0.7770 - val_accuracy: 0.8470\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2355 - accuracy: 0.9784 - val_loss: 0.7709 - val_accuracy: 0.8513\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2315 - accuracy: 0.9817 - val_loss: 0.8002 - val_accuracy: 0.8394\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2475 - accuracy: 0.9747 - val_loss: 0.7963 - val_accuracy: 0.8384\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2417 - accuracy: 0.9768 - val_loss: 0.8560 - val_accuracy: 0.8351\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2333 - accuracy: 0.9811 - val_loss: 0.7912 - val_accuracy: 0.8438\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2368 - accuracy: 0.9774 - val_loss: 0.8032 - val_accuracy: 0.8502\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2342 - accuracy: 0.9811 - val_loss: 0.8431 - val_accuracy: 0.8276\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2364 - accuracy: 0.9782 - val_loss: 0.7731 - val_accuracy: 0.8545\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2362 - accuracy: 0.9828 - val_loss: 0.8799 - val_accuracy: 0.8244\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2358 - accuracy: 0.9787 - val_loss: 0.8291 - val_accuracy: 0.8287\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2284 - accuracy: 0.9825 - val_loss: 0.8123 - val_accuracy: 0.8384\n","Epoch 52/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2273 - accuracy: 0.9852 - val_loss: 0.8026 - val_accuracy: 0.8502\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2246 - accuracy: 0.9844 - val_loss: 0.8254 - val_accuracy: 0.8373\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2313 - accuracy: 0.9779 - val_loss: 0.7998 - val_accuracy: 0.8502\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2301 - accuracy: 0.9801 - val_loss: 0.8050 - val_accuracy: 0.8416\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2230 - accuracy: 0.9836 - val_loss: 0.8204 - val_accuracy: 0.8416\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2290 - accuracy: 0.9822 - val_loss: 0.8895 - val_accuracy: 0.8276\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2264 - accuracy: 0.9822 - val_loss: 0.8099 - val_accuracy: 0.8524\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2293 - accuracy: 0.9811 - val_loss: 0.8820 - val_accuracy: 0.8276\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2497 - accuracy: 0.9698 - val_loss: 0.9259 - val_accuracy: 0.8244\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2355 - accuracy: 0.9774 - val_loss: 0.8415 - val_accuracy: 0.8405\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2295 - accuracy: 0.9806 - val_loss: 0.8379 - val_accuracy: 0.8384\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2195 - accuracy: 0.9841 - val_loss: 0.8445 - val_accuracy: 0.8341\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2249 - accuracy: 0.9806 - val_loss: 0.8022 - val_accuracy: 0.8524\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2201 - accuracy: 0.9852 - val_loss: 0.8358 - val_accuracy: 0.8351\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2134 - accuracy: 0.9892 - val_loss: 0.8310 - val_accuracy: 0.8459\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2221 - accuracy: 0.9855 - val_loss: 0.8183 - val_accuracy: 0.8491\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2183 - accuracy: 0.9844 - val_loss: 0.8657 - val_accuracy: 0.8319\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2173 - accuracy: 0.9860 - val_loss: 0.8478 - val_accuracy: 0.8427\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2172 - accuracy: 0.9857 - val_loss: 0.8456 - val_accuracy: 0.8470\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2203 - accuracy: 0.9828 - val_loss: 0.8293 - val_accuracy: 0.8513\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2145 - accuracy: 0.9860 - val_loss: 0.8579 - val_accuracy: 0.8448\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2176 - accuracy: 0.9836 - val_loss: 0.8605 - val_accuracy: 0.8427\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2154 - accuracy: 0.9868 - val_loss: 0.8554 - val_accuracy: 0.8438\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2254 - accuracy: 0.9825 - val_loss: 0.9694 - val_accuracy: 0.8168\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2292 - accuracy: 0.9803 - val_loss: 0.8453 - val_accuracy: 0.8578\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2217 - accuracy: 0.9801 - val_loss: 0.9137 - val_accuracy: 0.8330\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2248 - accuracy: 0.9790 - val_loss: 0.8438 - val_accuracy: 0.8405\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2142 - accuracy: 0.9852 - val_loss: 0.8499 - val_accuracy: 0.8394\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2178 - accuracy: 0.9833 - val_loss: 0.8684 - val_accuracy: 0.8384\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2182 - accuracy: 0.9860 - val_loss: 0.9319 - val_accuracy: 0.8200\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2166 - accuracy: 0.9836 - val_loss: 0.8551 - val_accuracy: 0.8405\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2148 - accuracy: 0.9849 - val_loss: 0.9108 - val_accuracy: 0.8276\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2189 - accuracy: 0.9811 - val_loss: 0.8719 - val_accuracy: 0.8438\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2174 - accuracy: 0.9844 - val_loss: 0.9502 - val_accuracy: 0.8244\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2188 - accuracy: 0.9811 - val_loss: 0.8782 - val_accuracy: 0.8276\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2097 - accuracy: 0.9879 - val_loss: 0.8896 - val_accuracy: 0.8362\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2108 - accuracy: 0.9863 - val_loss: 0.8613 - val_accuracy: 0.8470\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2182 - accuracy: 0.9809 - val_loss: 0.8874 - val_accuracy: 0.8394\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2281 - accuracy: 0.9766 - val_loss: 0.8726 - val_accuracy: 0.8405\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2082 - accuracy: 0.9868 - val_loss: 0.8649 - val_accuracy: 0.8330\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2088 - accuracy: 0.9890 - val_loss: 0.8629 - val_accuracy: 0.8470\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2068 - accuracy: 0.9871 - val_loss: 0.8572 - val_accuracy: 0.8502\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2065 - accuracy: 0.9863 - val_loss: 0.8982 - val_accuracy: 0.8330\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2063 - accuracy: 0.9868 - val_loss: 0.8990 - val_accuracy: 0.8308\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2098 - accuracy: 0.9857 - val_loss: 0.8889 - val_accuracy: 0.8448\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2082 - accuracy: 0.9860 - val_loss: 0.9931 - val_accuracy: 0.8222\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2108 - accuracy: 0.9860 - val_loss: 0.8948 - val_accuracy: 0.8438\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2023 - accuracy: 0.9860 - val_loss: 0.9104 - val_accuracy: 0.8341\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2084 - accuracy: 0.9857 - val_loss: 0.9053 - val_accuracy: 0.8297\n","{'loss': [0.3376827836036682, 0.3062802255153656, 0.2841910719871521, 0.27262210845947266, 0.2751119136810303, 0.2789962887763977, 0.2744311988353729, 0.2788121700286865, 0.2694310247898102, 0.2610500156879425, 0.268064945936203, 0.26818376779556274, 0.2566063702106476, 0.26600944995880127, 0.2574350833892822, 0.2664785087108612, 0.26045721769332886, 0.2632890045642853, 0.2515203654766083, 0.2605000436306, 0.25593388080596924, 0.24913451075553894, 0.25290170311927795, 0.2591318190097809, 0.2556135952472687, 0.24665866792201996, 0.24984948337078094, 0.2549864649772644, 0.24204017221927643, 0.2556380331516266, 0.24902430176734924, 0.2403615564107895, 0.24743910133838654, 0.24000245332717896, 0.24639476835727692, 0.23839986324310303, 0.24651984870433807, 0.25683823227882385, 0.26340004801750183, 0.23879379034042358, 0.2355332225561142, 0.23147739470005035, 0.24752232432365417, 0.2417372763156891, 0.23328644037246704, 0.23676547408103943, 0.23424415290355682, 0.2364044487476349, 0.23624609410762787, 0.23581969738006592, 0.22835077345371246, 0.22734440863132477, 0.22455337643623352, 0.23134411871433258, 0.23008142411708832, 0.22302596271038055, 0.22897222638130188, 0.22639207541942596, 0.22931404411792755, 0.2497093379497528, 0.23554019629955292, 0.22953097522258759, 0.21950949728488922, 0.22492769360542297, 0.22006294131278992, 0.21340113878250122, 0.22206808626651764, 0.21828940510749817, 0.21731185913085938, 0.21718671917915344, 0.22025364637374878, 0.21448004245758057, 0.217635378241539, 0.21541115641593933, 0.22542084753513336, 0.22920140624046326, 0.22168193757534027, 0.224756121635437, 0.21418455243110657, 0.21780893206596375, 0.2181689292192459, 0.21663513779640198, 0.21478599309921265, 0.21893340349197388, 0.21744979918003082, 0.21882596611976624, 0.2096717655658722, 0.21079973876476288, 0.21823623776435852, 0.22810888290405273, 0.2082088589668274, 0.2088191956281662, 0.2067946344614029, 0.20651856064796448, 0.20633910596370697, 0.2098076045513153, 0.20823051035404205, 0.21078334748744965, 0.20227403938770294, 0.20836658775806427], 'accuracy': [0.9455819129943848, 0.951777994632721, 0.9652478694915771, 0.9717133641242981, 0.9695581793785095, 0.9660560488700867, 0.9695581793785095, 0.9633620977401733, 0.970097005367279, 0.9722521305084229, 0.9695581793785095, 0.9684805870056152, 0.9757543206214905, 0.96875, 0.9730603694915771, 0.9730603694915771, 0.970366358757019, 0.9727909564971924, 0.977909505367279, 0.9719827771186829, 0.974946141242981, 0.9787176847457886, 0.9725215435028076, 0.9706357717514038, 0.9722521305084229, 0.9768319129943848, 0.9746767282485962, 0.9733297228813171, 0.9800646305084229, 0.974946141242981, 0.9746767282485962, 0.9776400923728943, 0.9773706793785095, 0.978178858757019, 0.9773706793785095, 0.9795258641242981, 0.9789870977401733, 0.9695581793785095, 0.9682112336158752, 0.9789870977401733, 0.9784482717514038, 0.9816810488700867, 0.9746767282485962, 0.9768319129943848, 0.9811422228813171, 0.9773706793785095, 0.9811422228813171, 0.978178858757019, 0.982758641242981, 0.9787176847457886, 0.9824892282485962, 0.9851831793785095, 0.984375, 0.977909505367279, 0.9800646305084229, 0.9835668206214905, 0.9822198152542114, 0.9822198152542114, 0.9811422228813171, 0.9698275923728943, 0.9773706793785095, 0.9806034564971924, 0.9841055870056152, 0.9806034564971924, 0.9851831793785095, 0.9892241358757019, 0.9854525923728943, 0.984375, 0.985991358757019, 0.985722005367279, 0.982758641242981, 0.985991358757019, 0.9835668206214905, 0.9867995977401733, 0.9824892282485962, 0.9803340435028076, 0.9800646305084229, 0.9789870977401733, 0.9851831793785095, 0.9832974076271057, 0.985991358757019, 0.9835668206214905, 0.9849137663841248, 0.9811422228813171, 0.984375, 0.9811422228813171, 0.9878771305084229, 0.9862607717514038, 0.9808728694915771, 0.9765625, 0.9867995977401733, 0.9889547228813171, 0.9870689511299133, 0.9862607717514038, 0.9867995977401733, 0.985722005367279, 0.985991358757019, 0.985991358757019, 0.985991358757019, 0.985722005367279], 'val_loss': [0.8506938219070435, 0.8495640754699707, 0.8371925354003906, 0.8245060443878174, 0.8194242119789124, 0.8093377947807312, 0.7972111701965332, 0.7959601283073425, 0.7842991352081299, 0.7894920706748962, 0.7796416878700256, 0.765191912651062, 0.7877350449562073, 0.7711466550827026, 0.7983168959617615, 0.7681189179420471, 0.7975839972496033, 0.7887135148048401, 0.7670979499816895, 0.7978555560112, 0.796576976776123, 0.7833009958267212, 0.7828604578971863, 0.7477011680603027, 0.7412921786308289, 0.7334234118461609, 0.7632826566696167, 0.7481255531311035, 0.7445530891418457, 0.7593905329704285, 0.7640960812568665, 0.7483939528465271, 0.7574100494384766, 0.7677448987960815, 0.7632206678390503, 0.7758569121360779, 0.7713508009910583, 0.8292508125305176, 0.7699770927429199, 0.7770052552223206, 0.7708529829978943, 0.8001952767372131, 0.7963016033172607, 0.8559993505477905, 0.7912316918373108, 0.8031960725784302, 0.8430543541908264, 0.7730885148048401, 0.8798570036888123, 0.8290914297103882, 0.8123195171356201, 0.802635908126831, 0.8253925442695618, 0.7997658848762512, 0.80501788854599, 0.8203502893447876, 0.8895182609558105, 0.8098793625831604, 0.8820063471794128, 0.9259157776832581, 0.8414598107337952, 0.8378576040267944, 0.8444803357124329, 0.8021816611289978, 0.8357662558555603, 0.8310220241546631, 0.8183054327964783, 0.8657461404800415, 0.8477581739425659, 0.8455796241760254, 0.8292991518974304, 0.8579075336456299, 0.8604989051818848, 0.8553566932678223, 0.9694067239761353, 0.8452778458595276, 0.913694441318512, 0.8437846899032593, 0.8499217629432678, 0.8684031963348389, 0.9319167733192444, 0.8550578951835632, 0.910834014415741, 0.8719274401664734, 0.9502021074295044, 0.8782404065132141, 0.8895671963691711, 0.8613428473472595, 0.8873664736747742, 0.8726045489311218, 0.8648979663848877, 0.8628620505332947, 0.8571619987487793, 0.8982084393501282, 0.8989522457122803, 0.8888555765151978, 0.9931272864341736, 0.8948047757148743, 0.9103683233261108, 0.9053356647491455], 'val_accuracy': [0.6034482717514038, 0.5851293206214905, 0.618534505367279, 0.6573275923728943, 0.6336206793785095, 0.6637930870056152, 0.7025862336158752, 0.6864224076271057, 0.704741358757019, 0.6821120977401733, 0.6950430870056152, 0.7165948152542114, 0.704741358757019, 0.7262930870056152, 0.7176724076271057, 0.7284482717514038, 0.7273706793785095, 0.75, 0.7737069129943848, 0.7737069129943848, 0.7855603694915771, 0.798491358757019, 0.8125, 0.8254310488700867, 0.8426724076271057, 0.8566810488700867, 0.8405172228813171, 0.8426724076271057, 0.8512930870056152, 0.8469827771186829, 0.850215494632721, 0.8588362336158752, 0.8491379022598267, 0.8512930870056152, 0.8480603694915771, 0.850215494632721, 0.857758641242981, 0.8394396305084229, 0.8512930870056152, 0.8469827771186829, 0.8512930870056152, 0.8394396305084229, 0.8383620977401733, 0.8351293206214905, 0.84375, 0.850215494632721, 0.8275862336158752, 0.8545258641242981, 0.8243534564971924, 0.8286637663841248, 0.8383620977401733, 0.850215494632721, 0.837284505367279, 0.850215494632721, 0.8415948152542114, 0.8415948152542114, 0.8275862336158752, 0.8523706793785095, 0.8275862336158752, 0.8243534564971924, 0.8405172228813171, 0.8383620977401733, 0.8340517282485962, 0.8523706793785095, 0.8351293206214905, 0.8459051847457886, 0.8491379022598267, 0.8318965435028076, 0.8426724076271057, 0.8469827771186829, 0.8512930870056152, 0.8448275923728943, 0.8426724076271057, 0.84375, 0.8168103694915771, 0.857758641242981, 0.8329741358757019, 0.8405172228813171, 0.8394396305084229, 0.8383620977401733, 0.8200430870056152, 0.8405172228813171, 0.8275862336158752, 0.84375, 0.8243534564971924, 0.8275862336158752, 0.8362069129943848, 0.8469827771186829, 0.8394396305084229, 0.8405172228813171, 0.8329741358757019, 0.8469827771186829, 0.850215494632721, 0.8329741358757019, 0.8308189511299133, 0.8448275923728943, 0.8221982717514038, 0.84375, 0.8340517282485962, 0.829741358757019]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3155 - accuracy: 0.9516"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 74ms/step - loss: 0.3139 - accuracy: 0.9522 - val_loss: 0.8573 - val_accuracy: 0.5543\n","Epoch 2/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3245 - accuracy: 0.9457 - val_loss: 0.8368 - val_accuracy: 0.6346\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2797 - accuracy: 0.9680 - val_loss: 0.8313 - val_accuracy: 0.6369\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2758 - accuracy: 0.9677 - val_loss: 0.8211 - val_accuracy: 0.6731\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2713 - accuracy: 0.9643 - val_loss: 0.8190 - val_accuracy: 0.6437\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2713 - accuracy: 0.9689 - val_loss: 0.8032 - val_accuracy: 0.6889\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2728 - accuracy: 0.9660 - val_loss: 0.8083 - val_accuracy: 0.6471\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2830 - accuracy: 0.9621 - val_loss: 0.7811 - val_accuracy: 0.7059\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2570 - accuracy: 0.9726 - val_loss: 0.7741 - val_accuracy: 0.7025\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2649 - accuracy: 0.9720 - val_loss: 0.7798 - val_accuracy: 0.6991\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2665 - accuracy: 0.9703 - val_loss: 0.7745 - val_accuracy: 0.7025\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2892 - accuracy: 0.9581 - val_loss: 0.7714 - val_accuracy: 0.7070\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2696 - accuracy: 0.9692 - val_loss: 0.7524 - val_accuracy: 0.7285\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2632 - accuracy: 0.9720 - val_loss: 0.7434 - val_accuracy: 0.7251\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2586 - accuracy: 0.9717 - val_loss: 0.7464 - val_accuracy: 0.7229\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2670 - accuracy: 0.9672 - val_loss: 0.7610 - val_accuracy: 0.7387\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2525 - accuracy: 0.9740 - val_loss: 0.7875 - val_accuracy: 0.7308\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2486 - accuracy: 0.9771 - val_loss: 0.8156 - val_accuracy: 0.7319\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2670 - accuracy: 0.9700 - val_loss: 0.7698 - val_accuracy: 0.7738\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2578 - accuracy: 0.9740 - val_loss: 0.7583 - val_accuracy: 0.7873\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2464 - accuracy: 0.9813 - val_loss: 0.7401 - val_accuracy: 0.7975\n","Epoch 22/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2503 - accuracy: 0.9757 - val_loss: 0.7631 - val_accuracy: 0.8088\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2616 - accuracy: 0.9709 - val_loss: 0.7674 - val_accuracy: 0.8100\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2504 - accuracy: 0.9788 - val_loss: 0.7328 - val_accuracy: 0.8258\n","Epoch 25/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2507 - accuracy: 0.9745 - val_loss: 0.7393 - val_accuracy: 0.8281\n","Epoch 26/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2551 - accuracy: 0.9731 - val_loss: 0.7628 - val_accuracy: 0.8303\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2469 - accuracy: 0.9765 - val_loss: 0.7043 - val_accuracy: 0.8450\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2530 - accuracy: 0.9734 - val_loss: 0.6860 - val_accuracy: 0.8563\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2571 - accuracy: 0.9723 - val_loss: 0.7045 - val_accuracy: 0.8360\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2491 - accuracy: 0.9737 - val_loss: 0.7490 - val_accuracy: 0.8495\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2490 - accuracy: 0.9762 - val_loss: 0.7417 - val_accuracy: 0.8552\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2471 - accuracy: 0.9771 - val_loss: 0.7178 - val_accuracy: 0.8394\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2358 - accuracy: 0.9842 - val_loss: 0.7124 - val_accuracy: 0.8563\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2364 - accuracy: 0.9788 - val_loss: 0.7655 - val_accuracy: 0.8518\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2355 - accuracy: 0.9833 - val_loss: 0.7353 - val_accuracy: 0.8507\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2430 - accuracy: 0.9762 - val_loss: 0.7719 - val_accuracy: 0.8405\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2573 - accuracy: 0.9697 - val_loss: 0.7640 - val_accuracy: 0.8507\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2489 - accuracy: 0.9768 - val_loss: 0.7451 - val_accuracy: 0.8484\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2421 - accuracy: 0.9785 - val_loss: 0.7512 - val_accuracy: 0.8484\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2449 - accuracy: 0.9774 - val_loss: 0.7466 - val_accuracy: 0.8473\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2369 - accuracy: 0.9793 - val_loss: 0.7571 - val_accuracy: 0.8541\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2424 - accuracy: 0.9754 - val_loss: 0.7495 - val_accuracy: 0.8552\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2405 - accuracy: 0.9779 - val_loss: 0.7730 - val_accuracy: 0.8450\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2351 - accuracy: 0.9791 - val_loss: 0.8281 - val_accuracy: 0.8382\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2332 - accuracy: 0.9819 - val_loss: 0.7614 - val_accuracy: 0.8552\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2391 - accuracy: 0.9788 - val_loss: 0.7872 - val_accuracy: 0.8337\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2449 - accuracy: 0.9757 - val_loss: 0.7880 - val_accuracy: 0.8575\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2351 - accuracy: 0.9774 - val_loss: 0.8219 - val_accuracy: 0.8405\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2335 - accuracy: 0.9805 - val_loss: 0.8077 - val_accuracy: 0.8462\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2311 - accuracy: 0.9808 - val_loss: 0.8452 - val_accuracy: 0.8428\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2368 - accuracy: 0.9768 - val_loss: 0.7847 - val_accuracy: 0.8428\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2315 - accuracy: 0.9819 - val_loss: 0.7863 - val_accuracy: 0.8382\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2266 - accuracy: 0.9805 - val_loss: 0.7966 - val_accuracy: 0.8405\n","Epoch 54/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2279 - accuracy: 0.9816 - val_loss: 0.7983 - val_accuracy: 0.8416\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2315 - accuracy: 0.9802 - val_loss: 0.8194 - val_accuracy: 0.8507\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2354 - accuracy: 0.9791 - val_loss: 0.7932 - val_accuracy: 0.8484\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2293 - accuracy: 0.9788 - val_loss: 0.7886 - val_accuracy: 0.8495\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2269 - accuracy: 0.9833 - val_loss: 0.8023 - val_accuracy: 0.8450\n","Epoch 59/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2271 - accuracy: 0.9833 - val_loss: 0.8220 - val_accuracy: 0.8439\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2302 - accuracy: 0.9793 - val_loss: 0.8115 - val_accuracy: 0.8292\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2222 - accuracy: 0.9836 - val_loss: 0.8032 - val_accuracy: 0.8428\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2274 - accuracy: 0.9805 - val_loss: 0.8410 - val_accuracy: 0.8462\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2241 - accuracy: 0.9816 - val_loss: 0.8068 - val_accuracy: 0.8405\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2225 - accuracy: 0.9827 - val_loss: 0.8116 - val_accuracy: 0.8428\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2302 - accuracy: 0.9776 - val_loss: 0.8259 - val_accuracy: 0.8348\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2279 - accuracy: 0.9799 - val_loss: 0.8264 - val_accuracy: 0.8382\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2243 - accuracy: 0.9825 - val_loss: 0.8224 - val_accuracy: 0.8337\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2195 - accuracy: 0.9859 - val_loss: 0.8712 - val_accuracy: 0.8348\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2293 - accuracy: 0.9785 - val_loss: 0.8572 - val_accuracy: 0.8314\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2212 - accuracy: 0.9819 - val_loss: 0.8541 - val_accuracy: 0.8314\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2260 - accuracy: 0.9796 - val_loss: 0.8433 - val_accuracy: 0.8394\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2163 - accuracy: 0.9844 - val_loss: 0.8247 - val_accuracy: 0.8303\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2155 - accuracy: 0.9867 - val_loss: 0.8326 - val_accuracy: 0.8394\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2288 - accuracy: 0.9776 - val_loss: 0.9441 - val_accuracy: 0.8258\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2264 - accuracy: 0.9793 - val_loss: 0.8608 - val_accuracy: 0.8292\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2261 - accuracy: 0.9774 - val_loss: 0.8532 - val_accuracy: 0.8326\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2193 - accuracy: 0.9853 - val_loss: 0.8135 - val_accuracy: 0.8360\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2231 - accuracy: 0.9802 - val_loss: 0.8451 - val_accuracy: 0.8405\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2151 - accuracy: 0.9844 - val_loss: 0.8369 - val_accuracy: 0.8382\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2147 - accuracy: 0.9850 - val_loss: 0.8718 - val_accuracy: 0.8473\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2155 - accuracy: 0.9850 - val_loss: 0.8915 - val_accuracy: 0.8360\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2176 - accuracy: 0.9816 - val_loss: 0.8387 - val_accuracy: 0.8337\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2209 - accuracy: 0.9816 - val_loss: 0.8526 - val_accuracy: 0.8360\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2131 - accuracy: 0.9859 - val_loss: 0.9071 - val_accuracy: 0.8201\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2295 - accuracy: 0.9759 - val_loss: 0.8635 - val_accuracy: 0.8348\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2191 - accuracy: 0.9802 - val_loss: 0.8731 - val_accuracy: 0.8371\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2227 - accuracy: 0.9799 - val_loss: 0.8505 - val_accuracy: 0.8337\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2184 - accuracy: 0.9836 - val_loss: 0.8606 - val_accuracy: 0.8371\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2117 - accuracy: 0.9836 - val_loss: 0.8769 - val_accuracy: 0.8382\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2147 - accuracy: 0.9847 - val_loss: 0.8382 - val_accuracy: 0.8348\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2172 - accuracy: 0.9802 - val_loss: 0.8276 - val_accuracy: 0.8394\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2149 - accuracy: 0.9836 - val_loss: 0.9121 - val_accuracy: 0.8371\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2117 - accuracy: 0.9850 - val_loss: 0.8442 - val_accuracy: 0.8337\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2074 - accuracy: 0.9873 - val_loss: 0.8532 - val_accuracy: 0.8348\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2046 - accuracy: 0.9878 - val_loss: 0.8584 - val_accuracy: 0.8371\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2036 - accuracy: 0.9878 - val_loss: 0.8501 - val_accuracy: 0.8394\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2051 - accuracy: 0.9873 - val_loss: 0.8774 - val_accuracy: 0.8462\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2001 - accuracy: 0.9884 - val_loss: 0.9059 - val_accuracy: 0.8405\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2114 - accuracy: 0.9853 - val_loss: 0.8932 - val_accuracy: 0.8224\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2321 - accuracy: 0.9762 - val_loss: 0.8292 - val_accuracy: 0.8314\n","{'loss': [0.3138883411884308, 0.32452529668807983, 0.27965396642684937, 0.27584704756736755, 0.2713036835193634, 0.27128443121910095, 0.272754967212677, 0.28296998143196106, 0.25697776675224304, 0.26493561267852783, 0.26653504371643066, 0.2891518175601959, 0.26962175965309143, 0.26316124200820923, 0.25856319069862366, 0.2670140862464905, 0.25247761607170105, 0.24856255948543549, 0.26703745126724243, 0.25782835483551025, 0.24641568958759308, 0.25025030970573425, 0.2615676820278168, 0.250357985496521, 0.2507019340991974, 0.2550792098045349, 0.24685247242450714, 0.2530093789100647, 0.2570609152317047, 0.24912293255329132, 0.24898761510849, 0.24705560505390167, 0.2357693761587143, 0.23640653491020203, 0.23549900949001312, 0.24302034080028534, 0.2572788894176483, 0.24890698492527008, 0.24211883544921875, 0.2448827177286148, 0.23689526319503784, 0.24237249791622162, 0.24046237766742706, 0.23513124883174896, 0.23319415748119354, 0.23906207084655762, 0.2449422925710678, 0.23507356643676758, 0.23353806138038635, 0.23108288645744324, 0.23676638305187225, 0.23145203292369843, 0.22663459181785583, 0.22786040604114532, 0.2315213531255722, 0.2353595346212387, 0.22932757437229156, 0.22687406837940216, 0.22714832425117493, 0.23021845519542694, 0.22224073112010956, 0.2273728847503662, 0.22411972284317017, 0.22253088653087616, 0.23016557097434998, 0.22786813974380493, 0.2243412435054779, 0.21952544152736664, 0.2293470799922943, 0.22119683027267456, 0.2260192632675171, 0.21634702384471893, 0.21548296511173248, 0.22881250083446503, 0.2263772189617157, 0.22606442868709564, 0.21929281949996948, 0.22308771312236786, 0.21514874696731567, 0.21465909481048584, 0.21554185450077057, 0.2175845056772232, 0.22093422710895538, 0.213091179728508, 0.22951756417751312, 0.21910235285758972, 0.22272150218486786, 0.21841101348400116, 0.21170347929000854, 0.2146780639886856, 0.21722351014614105, 0.21494249999523163, 0.2117014080286026, 0.20735128223896027, 0.2046320140361786, 0.2035772055387497, 0.205060675740242, 0.2001015841960907, 0.21136745810508728, 0.2320677638053894], 'accuracy': [0.9521788358688354, 0.9456706047058105, 0.9680249094963074, 0.9677419066429138, 0.9643463492393494, 0.9688737988471985, 0.9660441279411316, 0.9620826244354248, 0.9725523591041565, 0.9719864130020142, 0.9702886343002319, 0.958121120929718, 0.9691567420959473, 0.9719864130020142, 0.9717034697532654, 0.9671760201454163, 0.9739671945571899, 0.9770798087120056, 0.9700056314468384, 0.9739671945571899, 0.9813242554664612, 0.9756649732589722, 0.9708545804023743, 0.9787775874137878, 0.9745330810546875, 0.9731183052062988, 0.9765138626098633, 0.9734012484550476, 0.9722693562507629, 0.9736841917037964, 0.9762309193611145, 0.9770798087120056, 0.9841539263725281, 0.9787775874137878, 0.983305037021637, 0.9762309193611145, 0.9697226881980896, 0.9767968058586121, 0.9784946441650391, 0.9773627519607544, 0.9793435335159302, 0.9753820300102234, 0.9779286980628967, 0.9790605306625366, 0.9818902015686035, 0.9787775874137878, 0.9756649732589722, 0.9773627519607544, 0.9804753661155701, 0.9807583689689636, 0.9767968058586121, 0.9818902015686035, 0.9804753661155701, 0.9816072583198547, 0.9801924228668213, 0.9790605306625366, 0.9787775874137878, 0.983305037021637, 0.983305037021637, 0.9793435335159302, 0.9835879802703857, 0.9804753661155701, 0.9816072583198547, 0.9827390909194946, 0.977645754814148, 0.9799094796180725, 0.9824561476707458, 0.9858517050743103, 0.9784946441650391, 0.9818902015686035, 0.979626476764679, 0.9844368696212769, 0.9867005944252014, 0.977645754814148, 0.9793435335159302, 0.9773627519607544, 0.9852858185768127, 0.9801924228668213, 0.9844368696212769, 0.9850028157234192, 0.9850028157234192, 0.9816072583198547, 0.9816072583198547, 0.9858517050743103, 0.975947916507721, 0.9801924228668213, 0.9799094796180725, 0.9835879802703857, 0.9835879802703857, 0.9847198724746704, 0.9801924228668213, 0.9835879802703857, 0.9850028157234192, 0.9872665405273438, 0.9878324866294861, 0.9878324866294861, 0.9872665405273438, 0.9883984327316284, 0.9852858185768127, 0.9762309193611145], 'val_loss': [0.8573299646377563, 0.8367587924003601, 0.8313032984733582, 0.8211145997047424, 0.8190128207206726, 0.8031814098358154, 0.8083413243293762, 0.7810888290405273, 0.7740840911865234, 0.7798287272453308, 0.7744531631469727, 0.7713844776153564, 0.7523824572563171, 0.7433560490608215, 0.7463903427124023, 0.7610477805137634, 0.7875443696975708, 0.8155532479286194, 0.7698033452033997, 0.7582924962043762, 0.7400581240653992, 0.7631021738052368, 0.7674015164375305, 0.7328158617019653, 0.7392675876617432, 0.762776792049408, 0.7042700052261353, 0.6859751343727112, 0.7045201659202576, 0.7489845752716064, 0.7416524291038513, 0.7177509069442749, 0.7123529314994812, 0.7654574513435364, 0.7353267073631287, 0.7718611359596252, 0.7639822959899902, 0.745130181312561, 0.751220703125, 0.7465898990631104, 0.7571162581443787, 0.749546229839325, 0.7730017900466919, 0.8280745148658752, 0.7614222168922424, 0.7872427105903625, 0.7880375981330872, 0.8219494223594666, 0.8076861500740051, 0.8452171683311462, 0.7847369313240051, 0.786334216594696, 0.7966135740280151, 0.7983058094978333, 0.8193647861480713, 0.7931637167930603, 0.7886004447937012, 0.8022714257240295, 0.8220205903053284, 0.811469316482544, 0.8031566739082336, 0.8410379886627197, 0.8067694902420044, 0.8115935325622559, 0.8258664011955261, 0.8264493346214294, 0.8224347829818726, 0.87122642993927, 0.8572121858596802, 0.8541106581687927, 0.8433323502540588, 0.8246803283691406, 0.8326056003570557, 0.9440734386444092, 0.8608395457267761, 0.8531680703163147, 0.8134515285491943, 0.8450539708137512, 0.8369046449661255, 0.8718065619468689, 0.8914663791656494, 0.8386991620063782, 0.8526294827461243, 0.9070619344711304, 0.8634634017944336, 0.873056948184967, 0.8505052924156189, 0.8605524301528931, 0.8769495487213135, 0.8382486701011658, 0.8275560736656189, 0.9120704531669617, 0.8441505432128906, 0.8532491326332092, 0.8583808541297913, 0.8500924706459045, 0.8773917555809021, 0.9058890342712402, 0.8931509256362915, 0.829245388507843], 'val_accuracy': [0.5542986392974854, 0.6346153616905212, 0.6368778347969055, 0.6730769276618958, 0.6436651349067688, 0.6889140009880066, 0.6470588445663452, 0.7058823704719543, 0.7024886608123779, 0.6990950107574463, 0.7024886608123779, 0.7070135474205017, 0.7285068035125732, 0.7251130938529968, 0.7228506803512573, 0.7386877536773682, 0.7307692170143127, 0.7319004535675049, 0.773755669593811, 0.7873303294181824, 0.7975113391876221, 0.8088235259056091, 0.8099547624588013, 0.8257918357849121, 0.8280543088912964, 0.8303167223930359, 0.8450226187705994, 0.8563348650932312, 0.8359728455543518, 0.8495475053787231, 0.8552036285400391, 0.8393664956092834, 0.8563348650932312, 0.8518099784851074, 0.8506787419319153, 0.8404977321624756, 0.8506787419319153, 0.848416268825531, 0.848416268825531, 0.8472850918769836, 0.8540723919868469, 0.8552036285400391, 0.8450226187705994, 0.8382353186607361, 0.8552036285400391, 0.8337104320526123, 0.8574660420417786, 0.8404977321624756, 0.8461538553237915, 0.8427602052688599, 0.8427602052688599, 0.8382353186607361, 0.8404977321624756, 0.8416289687156677, 0.8506787419319153, 0.848416268825531, 0.8495475053787231, 0.8450226187705994, 0.8438913822174072, 0.8291855454444885, 0.8427602052688599, 0.8461538553237915, 0.8404977321624756, 0.8427602052688599, 0.8348416090011597, 0.8382353186607361, 0.8337104320526123, 0.8348416090011597, 0.831447958946228, 0.831447958946228, 0.8393664956092834, 0.8303167223930359, 0.8393664956092834, 0.8257918357849121, 0.8291855454444885, 0.8325791954994202, 0.8359728455543518, 0.8404977321624756, 0.8382353186607361, 0.8472850918769836, 0.8359728455543518, 0.8337104320526123, 0.8359728455543518, 0.820135772228241, 0.8348416090011597, 0.837104082107544, 0.8337104320526123, 0.837104082107544, 0.8382353186607361, 0.8348416090011597, 0.8393664956092834, 0.837104082107544, 0.8337104320526123, 0.8348416090011597, 0.837104082107544, 0.8393664956092834, 0.8461538553237915, 0.8404977321624756, 0.8223981857299805, 0.831447958946228]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3482 - accuracy: 0.9422"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 49ms/step - loss: 0.3436 - accuracy: 0.9426 - val_loss: 0.8451 - val_accuracy: 0.6064\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3334 - accuracy: 0.9465 - val_loss: 0.8324 - val_accuracy: 0.6405\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3114 - accuracy: 0.9525 - val_loss: 0.8311 - val_accuracy: 0.6198\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3077 - accuracy: 0.9504 - val_loss: 0.8096 - val_accuracy: 0.6880\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3038 - accuracy: 0.9478 - val_loss: 0.8085 - val_accuracy: 0.6498\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2934 - accuracy: 0.9589 - val_loss: 0.7936 - val_accuracy: 0.6870\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3055 - accuracy: 0.9540 - val_loss: 0.7896 - val_accuracy: 0.6756\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2865 - accuracy: 0.9589 - val_loss: 0.7784 - val_accuracy: 0.6901\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2796 - accuracy: 0.9664 - val_loss: 0.7716 - val_accuracy: 0.6880\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2796 - accuracy: 0.9651 - val_loss: 0.7615 - val_accuracy: 0.6983\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2817 - accuracy: 0.9620 - val_loss: 0.7630 - val_accuracy: 0.6973\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2805 - accuracy: 0.9625 - val_loss: 0.7519 - val_accuracy: 0.7159\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2805 - accuracy: 0.9638 - val_loss: 0.7470 - val_accuracy: 0.7242\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2821 - accuracy: 0.9579 - val_loss: 0.7538 - val_accuracy: 0.7376\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2727 - accuracy: 0.9669 - val_loss: 0.7659 - val_accuracy: 0.7386\n","Epoch 16/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.2641 - accuracy: 0.9713 - val_loss: 0.7728 - val_accuracy: 0.7541\n","Epoch 17/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2701 - accuracy: 0.9651 - val_loss: 0.7867 - val_accuracy: 0.7562\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2776 - accuracy: 0.9605 - val_loss: 0.7993 - val_accuracy: 0.7676\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2774 - accuracy: 0.9651 - val_loss: 0.7799 - val_accuracy: 0.7800\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2682 - accuracy: 0.9716 - val_loss: 0.7868 - val_accuracy: 0.7944\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2668 - accuracy: 0.9695 - val_loss: 0.8014 - val_accuracy: 0.7965\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2707 - accuracy: 0.9630 - val_loss: 0.7904 - val_accuracy: 0.8110\n","Epoch 23/100\n","31/31 [==============================] - 3s 90ms/step - loss: 0.2706 - accuracy: 0.9633 - val_loss: 0.7747 - val_accuracy: 0.8140\n","Epoch 24/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2607 - accuracy: 0.9700 - val_loss: 0.7679 - val_accuracy: 0.8202\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2845 - accuracy: 0.9566 - val_loss: 0.8460 - val_accuracy: 0.8099\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2650 - accuracy: 0.9698 - val_loss: 0.7756 - val_accuracy: 0.8223\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2609 - accuracy: 0.9674 - val_loss: 0.8244 - val_accuracy: 0.8233\n","Epoch 28/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2719 - accuracy: 0.9643 - val_loss: 0.7933 - val_accuracy: 0.8306\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2604 - accuracy: 0.9726 - val_loss: 0.8233 - val_accuracy: 0.8264\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2580 - accuracy: 0.9724 - val_loss: 0.8003 - val_accuracy: 0.8306\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2636 - accuracy: 0.9682 - val_loss: 0.8384 - val_accuracy: 0.8316\n","Epoch 32/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2591 - accuracy: 0.9682 - val_loss: 0.8057 - val_accuracy: 0.8399\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2603 - accuracy: 0.9726 - val_loss: 0.8650 - val_accuracy: 0.8171\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2582 - accuracy: 0.9744 - val_loss: 0.8440 - val_accuracy: 0.8306\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2575 - accuracy: 0.9708 - val_loss: 0.8329 - val_accuracy: 0.8233\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2653 - accuracy: 0.9643 - val_loss: 0.8346 - val_accuracy: 0.8357\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2550 - accuracy: 0.9708 - val_loss: 0.8368 - val_accuracy: 0.8316\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2592 - accuracy: 0.9685 - val_loss: 0.8425 - val_accuracy: 0.8110\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2539 - accuracy: 0.9726 - val_loss: 0.8393 - val_accuracy: 0.8337\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2498 - accuracy: 0.9739 - val_loss: 0.8921 - val_accuracy: 0.8254\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2483 - accuracy: 0.9744 - val_loss: 0.8377 - val_accuracy: 0.8306\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2600 - accuracy: 0.9690 - val_loss: 0.8570 - val_accuracy: 0.8244\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2569 - accuracy: 0.9716 - val_loss: 0.8296 - val_accuracy: 0.8399\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2518 - accuracy: 0.9703 - val_loss: 0.9027 - val_accuracy: 0.8202\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2532 - accuracy: 0.9726 - val_loss: 0.8618 - val_accuracy: 0.8295\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2512 - accuracy: 0.9713 - val_loss: 0.8961 - val_accuracy: 0.8182\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2522 - accuracy: 0.9721 - val_loss: 0.9309 - val_accuracy: 0.8182\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 0.9661 - val_loss: 0.8594 - val_accuracy: 0.8264\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2478 - accuracy: 0.9752 - val_loss: 0.8843 - val_accuracy: 0.8213\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2466 - accuracy: 0.9729 - val_loss: 0.8822 - val_accuracy: 0.8275\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2431 - accuracy: 0.9752 - val_loss: 0.8850 - val_accuracy: 0.8306\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.9744 - val_loss: 0.8721 - val_accuracy: 0.8213\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2408 - accuracy: 0.9762 - val_loss: 0.8854 - val_accuracy: 0.8130\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2487 - accuracy: 0.9700 - val_loss: 0.8684 - val_accuracy: 0.8295\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2564 - accuracy: 0.9703 - val_loss: 0.9266 - val_accuracy: 0.8099\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2658 - accuracy: 0.9646 - val_loss: 0.8814 - val_accuracy: 0.8202\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2436 - accuracy: 0.9765 - val_loss: 0.8642 - val_accuracy: 0.8244\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2425 - accuracy: 0.9739 - val_loss: 0.9027 - val_accuracy: 0.8089\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2478 - accuracy: 0.9716 - val_loss: 0.9375 - val_accuracy: 0.7913\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2465 - accuracy: 0.9690 - val_loss: 0.9200 - val_accuracy: 0.8130\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2559 - accuracy: 0.9659 - val_loss: 0.8686 - val_accuracy: 0.8264\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2374 - accuracy: 0.9775 - val_loss: 0.8599 - val_accuracy: 0.8213\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2367 - accuracy: 0.9765 - val_loss: 0.9138 - val_accuracy: 0.8192\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2438 - accuracy: 0.9724 - val_loss: 0.8797 - val_accuracy: 0.8202\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2348 - accuracy: 0.9773 - val_loss: 0.8750 - val_accuracy: 0.8275\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2394 - accuracy: 0.9752 - val_loss: 0.9556 - val_accuracy: 0.8089\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2379 - accuracy: 0.9770 - val_loss: 0.9169 - val_accuracy: 0.8151\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2337 - accuracy: 0.9780 - val_loss: 0.9661 - val_accuracy: 0.7975\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2366 - accuracy: 0.9773 - val_loss: 0.8964 - val_accuracy: 0.8254\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2376 - accuracy: 0.9775 - val_loss: 0.8993 - val_accuracy: 0.8130\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2332 - accuracy: 0.9778 - val_loss: 0.8992 - val_accuracy: 0.8264\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2324 - accuracy: 0.9775 - val_loss: 0.9201 - val_accuracy: 0.8202\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2479 - accuracy: 0.9687 - val_loss: 0.9954 - val_accuracy: 0.8140\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2309 - accuracy: 0.9773 - val_loss: 0.9150 - val_accuracy: 0.8202\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2239 - accuracy: 0.9827 - val_loss: 0.9209 - val_accuracy: 0.8110\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2276 - accuracy: 0.9778 - val_loss: 0.9079 - val_accuracy: 0.8254\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2380 - accuracy: 0.9752 - val_loss: 0.9325 - val_accuracy: 0.8171\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2329 - accuracy: 0.9783 - val_loss: 0.9871 - val_accuracy: 0.8068\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2260 - accuracy: 0.9804 - val_loss: 0.9715 - val_accuracy: 0.8130\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2357 - accuracy: 0.9744 - val_loss: 0.9953 - val_accuracy: 0.8017\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2285 - accuracy: 0.9762 - val_loss: 0.9066 - val_accuracy: 0.8264\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2303 - accuracy: 0.9780 - val_loss: 0.9337 - val_accuracy: 0.8223\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2278 - accuracy: 0.9796 - val_loss: 0.9479 - val_accuracy: 0.8182\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2232 - accuracy: 0.9780 - val_loss: 0.9221 - val_accuracy: 0.8171\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2253 - accuracy: 0.9786 - val_loss: 0.9418 - val_accuracy: 0.8233\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2324 - accuracy: 0.9760 - val_loss: 1.0782 - val_accuracy: 0.7862\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2335 - accuracy: 0.9752 - val_loss: 0.9480 - val_accuracy: 0.8130\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2269 - accuracy: 0.9767 - val_loss: 0.9616 - val_accuracy: 0.8151\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2345 - accuracy: 0.9742 - val_loss: 0.9492 - val_accuracy: 0.8089\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2230 - accuracy: 0.9804 - val_loss: 0.9382 - val_accuracy: 0.8182\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2267 - accuracy: 0.9786 - val_loss: 1.1203 - val_accuracy: 0.7975\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2315 - accuracy: 0.9729 - val_loss: 0.9348 - val_accuracy: 0.8130\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2243 - accuracy: 0.9783 - val_loss: 0.9291 - val_accuracy: 0.8202\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2228 - accuracy: 0.9804 - val_loss: 0.9700 - val_accuracy: 0.8171\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2369 - accuracy: 0.9705 - val_loss: 0.9482 - val_accuracy: 0.8120\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2355 - accuracy: 0.9703 - val_loss: 0.9449 - val_accuracy: 0.8202\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2229 - accuracy: 0.9788 - val_loss: 0.9897 - val_accuracy: 0.7924\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2265 - accuracy: 0.9773 - val_loss: 0.9758 - val_accuracy: 0.8099\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2380 - accuracy: 0.9695 - val_loss: 1.0185 - val_accuracy: 0.7965\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2324 - accuracy: 0.9729 - val_loss: 0.9998 - val_accuracy: 0.8037\n","{'loss': [0.34357157349586487, 0.33338749408721924, 0.3113701343536377, 0.3076651692390442, 0.3037756681442261, 0.29337507486343384, 0.3055134117603302, 0.28653016686439514, 0.27960944175720215, 0.27962425351142883, 0.2816713750362396, 0.2805385887622833, 0.2805235981941223, 0.282103955745697, 0.2726541757583618, 0.2641426622867584, 0.27010032534599304, 0.2775958478450775, 0.2773624062538147, 0.26818081736564636, 0.2668082118034363, 0.27072787284851074, 0.2706000804901123, 0.26065394282341003, 0.2844831943511963, 0.26500919461250305, 0.26088419556617737, 0.2719147205352783, 0.26035985350608826, 0.258024662733078, 0.2636488378047943, 0.2590814530849457, 0.26027533411979675, 0.2581852972507477, 0.25749126076698303, 0.26531779766082764, 0.2550453245639801, 0.25920385122299194, 0.25386568903923035, 0.24979564547538757, 0.2482619285583496, 0.25997912883758545, 0.2568681240081787, 0.2517509162425995, 0.25317540764808655, 0.2511919140815735, 0.2521876394748688, 0.25890055298805237, 0.24778030812740326, 0.24660135805606842, 0.2430892437696457, 0.2455432415008545, 0.24084770679473877, 0.248740091919899, 0.256355345249176, 0.2657884657382965, 0.24361619353294373, 0.24245543777942657, 0.24782973527908325, 0.2465459406375885, 0.2559323012828827, 0.23740975558757782, 0.23669810593128204, 0.24382540583610535, 0.23479685187339783, 0.2393573820590973, 0.2379036545753479, 0.2337174266576767, 0.236572727560997, 0.23755289614200592, 0.23322775959968567, 0.23243878781795502, 0.24793145060539246, 0.2308817356824875, 0.22392530739307404, 0.22763819992542267, 0.23797887563705444, 0.2329057902097702, 0.22597919404506683, 0.23570111393928528, 0.22848765552043915, 0.23032167553901672, 0.22776468098163605, 0.22317402064800262, 0.22533199191093445, 0.23239190876483917, 0.2334636002779007, 0.22691725194454193, 0.23447473347187042, 0.22299236059188843, 0.2266523540019989, 0.2315404862165451, 0.22425635159015656, 0.22284339368343353, 0.2368759959936142, 0.23547695577144623, 0.22289662063121796, 0.22646553814411163, 0.2380417436361313, 0.23244330286979675], 'accuracy': [0.9426356554031372, 0.9465116262435913, 0.9524548053741455, 0.9503875970840454, 0.9478036165237427, 0.9589147567749023, 0.9540051817893982, 0.9589147567749023, 0.9664082527160645, 0.9651162624359131, 0.9620155096054077, 0.9625322818756104, 0.9638242721557617, 0.9578811526298523, 0.9669250845909119, 0.9713178277015686, 0.9651162624359131, 0.960465133190155, 0.9651162624359131, 0.9715762138366699, 0.9695090651512146, 0.9630491137504578, 0.9633074998855591, 0.9700258374214172, 0.9565891623497009, 0.9697674512863159, 0.9674418568611145, 0.9643411040306091, 0.97260981798172, 0.9723514318466187, 0.9682170748710632, 0.9682170748710632, 0.97260981798172, 0.974418580532074, 0.970801055431366, 0.9643411040306091, 0.970801055431366, 0.9684754610061646, 0.97260981798172, 0.9739018082618713, 0.974418580532074, 0.9689922332763672, 0.9715762138366699, 0.9702842235565186, 0.97260981798172, 0.9713178277015686, 0.9720930457115173, 0.9661498665809631, 0.9751937985420227, 0.9728682041168213, 0.9751937985420227, 0.974418580532074, 0.9762274026870728, 0.9700258374214172, 0.9702842235565186, 0.9645994901657104, 0.9764857888221741, 0.9739018082618713, 0.9715762138366699, 0.9689922332763672, 0.9658914804458618, 0.9775193929672241, 0.9764857888221741, 0.9723514318466187, 0.9772610068321228, 0.9751937985420227, 0.9770025610923767, 0.9780361652374268, 0.9772610068321228, 0.9775193929672241, 0.9777777791023254, 0.9775193929672241, 0.9687338471412659, 0.9772610068321228, 0.9826873540878296, 0.9777777791023254, 0.9751937985420227, 0.9782945513725281, 0.9803617596626282, 0.974418580532074, 0.9762274026870728, 0.9780361652374268, 0.9795865416526794, 0.9780361652374268, 0.9785529971122742, 0.9759690165519714, 0.9751937985420227, 0.9767441749572754, 0.9741601943969727, 0.9803617596626282, 0.9785529971122742, 0.9728682041168213, 0.9782945513725281, 0.9803617596626282, 0.9705426096916199, 0.9702842235565186, 0.9788113832473755, 0.9772610068321228, 0.9695090651512146, 0.9728682041168213], 'val_loss': [0.8451069593429565, 0.8324254751205444, 0.8310952186584473, 0.8096256256103516, 0.8084642887115479, 0.793644368648529, 0.7896217107772827, 0.7784459590911865, 0.7715545892715454, 0.7615447044372559, 0.7630130648612976, 0.7518876194953918, 0.7469800114631653, 0.7537804841995239, 0.7658683657646179, 0.7727784514427185, 0.7866784334182739, 0.7992833852767944, 0.7798641324043274, 0.786824643611908, 0.8013894557952881, 0.7904457449913025, 0.77474045753479, 0.767945408821106, 0.8460128307342529, 0.7755752205848694, 0.8244315981864929, 0.7932639718055725, 0.8232719302177429, 0.8002979159355164, 0.8383986949920654, 0.805682361125946, 0.8649699091911316, 0.8439546227455139, 0.8329356908798218, 0.8345546126365662, 0.8368271589279175, 0.8425478935241699, 0.8393307328224182, 0.8920890688896179, 0.8376800417900085, 0.8569740056991577, 0.8295513987541199, 0.9027361869812012, 0.8617833852767944, 0.8961190581321716, 0.9309306740760803, 0.8594347834587097, 0.884335994720459, 0.882229208946228, 0.8850216865539551, 0.8720600605010986, 0.8854393362998962, 0.8684209585189819, 0.9265965223312378, 0.8813552260398865, 0.8641676306724548, 0.9026999473571777, 0.9374610781669617, 0.9200491905212402, 0.8686063289642334, 0.8598847389221191, 0.9137555956840515, 0.8797363042831421, 0.8749974370002747, 0.955575704574585, 0.9168843626976013, 0.9661228656768799, 0.8963738083839417, 0.899322509765625, 0.899176299571991, 0.9200863838195801, 0.9954226613044739, 0.9149911999702454, 0.9209217429161072, 0.9078698754310608, 0.9325072765350342, 0.9870663285255432, 0.971534252166748, 0.9952643513679504, 0.9065991640090942, 0.9336977601051331, 0.9478847980499268, 0.9220633506774902, 0.9417963027954102, 1.0781617164611816, 0.9479974508285522, 0.9616265892982483, 0.9491563439369202, 0.9381608963012695, 1.120262861251831, 0.9348288178443909, 0.9291074275970459, 0.9699835777282715, 0.9482083320617676, 0.9449012875556946, 0.9896687865257263, 0.9757654666900635, 1.0185202360153198, 0.9997565150260925], 'val_accuracy': [0.6064049601554871, 0.6404958963394165, 0.6198347210884094, 0.6880165338516235, 0.6497933864593506, 0.6869834661483765, 0.6756198406219482, 0.6900826692581177, 0.6880165338516235, 0.6983470916748047, 0.6973140239715576, 0.7159090638160706, 0.7241735458374023, 0.7376033067703247, 0.7386363744735718, 0.7541322112083435, 0.7561983466148376, 0.7675619721412659, 0.7799586653709412, 0.7944214940071106, 0.7964876294136047, 0.8109503984451294, 0.8140496015548706, 0.8202479481697083, 0.8099173307418823, 0.8223140239715576, 0.8233470916748047, 0.8305785059928894, 0.8264462947845459, 0.8305785059928894, 0.8316115736961365, 0.8398760557174683, 0.817148745059967, 0.8305785059928894, 0.8233470916748047, 0.83574378490448, 0.8316115736961365, 0.8109503984451294, 0.8336777091026306, 0.8254132270812988, 0.8305785059928894, 0.8243801593780518, 0.8398760557174683, 0.8202479481697083, 0.8295454382896423, 0.8181818127632141, 0.8181818127632141, 0.8264462947845459, 0.8212810158729553, 0.827479362487793, 0.8305785059928894, 0.8212810158729553, 0.8130165338516235, 0.8295454382896423, 0.8099173307418823, 0.8202479481697083, 0.8243801593780518, 0.80888432264328, 0.7913222908973694, 0.8130165338516235, 0.8264462947845459, 0.8212810158729553, 0.8192148804664612, 0.8202479481697083, 0.827479362487793, 0.80888432264328, 0.8150826692581177, 0.797520637512207, 0.8254132270812988, 0.8130165338516235, 0.8264462947845459, 0.8202479481697083, 0.8140496015548706, 0.8202479481697083, 0.8109503984451294, 0.8254132270812988, 0.817148745059967, 0.8068181872367859, 0.8130165338516235, 0.8016529083251953, 0.8264462947845459, 0.8223140239715576, 0.8181818127632141, 0.817148745059967, 0.8233470916748047, 0.7861570119857788, 0.8130165338516235, 0.8150826692581177, 0.80888432264328, 0.8181818127632141, 0.797520637512207, 0.8130165338516235, 0.8202479481697083, 0.817148745059967, 0.8119834661483765, 0.8202479481697083, 0.7923553586006165, 0.8099173307418823, 0.7964876294136047, 0.8037189841270447]}\n","32/32 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"id":"A8i39KxW7FI0","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717502560260,"user_tz":-360,"elapsed":9,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"79f4ce77-8dc6-478d-c941-f374d86e4893"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.552764   0.567452  0.443886  0.498120     0.443886     0.661642   \n","1        1  0.561441   0.566009  0.526836  0.545721     0.526836     0.596045   \n","2        2  0.558233   0.615079  0.311245  0.413333     0.311245     0.805221   \n","3        0  0.649079   0.643087  0.670017  0.656276     0.670017     0.628141   \n","4        1  0.641949   0.619217  0.737288  0.673114     0.737288     0.546610   \n","5        2  0.666667   0.685268  0.616466  0.649049     0.616466     0.716867   \n","6        0  0.714405   0.706452  0.733668  0.719803     0.733668     0.695142   \n","7        1  0.747175   0.733957  0.775424  0.754121     0.775424     0.718927   \n","8        2  0.762048   0.772443  0.742972  0.757421     0.742972     0.781124   \n","9        0  0.759631   0.765411  0.748744  0.756986     0.748744     0.770519   \n","10       1  0.783192   0.757381  0.833333  0.793544     0.833333     0.733051   \n","11       2  0.804217   0.835920  0.757028  0.794521     0.757028     0.851406   \n","12       0  0.801508   0.802013  0.800670  0.801341     0.800670     0.802345   \n","13       1  0.814972   0.779449  0.878531  0.826029     0.878531     0.751412   \n","14       2  0.840361   0.849485  0.827309  0.838250     0.827309     0.853414   \n","\n","       Kappa  \n","0   0.105528  \n","1   0.122881  \n","2   0.116466  \n","3   0.298157  \n","4   0.283898  \n","5   0.333333  \n","6   0.428811  \n","7   0.494350  \n","8   0.524096  \n","9   0.519263  \n","10  0.566384  \n","11  0.608434  \n","12  0.603015  \n","13  0.629944  \n","14  0.680723  "],"text/html":["\n","  <div id=\"df-8f55ede2-f4ff-45ed-98f9-32d764b1015f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.552764</td>\n","      <td>0.567452</td>\n","      <td>0.443886</td>\n","      <td>0.498120</td>\n","      <td>0.443886</td>\n","      <td>0.661642</td>\n","      <td>0.105528</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.561441</td>\n","      <td>0.566009</td>\n","      <td>0.526836</td>\n","      <td>0.545721</td>\n","      <td>0.526836</td>\n","      <td>0.596045</td>\n","      <td>0.122881</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.558233</td>\n","      <td>0.615079</td>\n","      <td>0.311245</td>\n","      <td>0.413333</td>\n","      <td>0.311245</td>\n","      <td>0.805221</td>\n","      <td>0.116466</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.649079</td>\n","      <td>0.643087</td>\n","      <td>0.670017</td>\n","      <td>0.656276</td>\n","      <td>0.670017</td>\n","      <td>0.628141</td>\n","      <td>0.298157</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.641949</td>\n","      <td>0.619217</td>\n","      <td>0.737288</td>\n","      <td>0.673114</td>\n","      <td>0.737288</td>\n","      <td>0.546610</td>\n","      <td>0.283898</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.666667</td>\n","      <td>0.685268</td>\n","      <td>0.616466</td>\n","      <td>0.649049</td>\n","      <td>0.616466</td>\n","      <td>0.716867</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.714405</td>\n","      <td>0.706452</td>\n","      <td>0.733668</td>\n","      <td>0.719803</td>\n","      <td>0.733668</td>\n","      <td>0.695142</td>\n","      <td>0.428811</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.747175</td>\n","      <td>0.733957</td>\n","      <td>0.775424</td>\n","      <td>0.754121</td>\n","      <td>0.775424</td>\n","      <td>0.718927</td>\n","      <td>0.494350</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.762048</td>\n","      <td>0.772443</td>\n","      <td>0.742972</td>\n","      <td>0.757421</td>\n","      <td>0.742972</td>\n","      <td>0.781124</td>\n","      <td>0.524096</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.759631</td>\n","      <td>0.765411</td>\n","      <td>0.748744</td>\n","      <td>0.756986</td>\n","      <td>0.748744</td>\n","      <td>0.770519</td>\n","      <td>0.519263</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.783192</td>\n","      <td>0.757381</td>\n","      <td>0.833333</td>\n","      <td>0.793544</td>\n","      <td>0.833333</td>\n","      <td>0.733051</td>\n","      <td>0.566384</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.804217</td>\n","      <td>0.835920</td>\n","      <td>0.757028</td>\n","      <td>0.794521</td>\n","      <td>0.757028</td>\n","      <td>0.851406</td>\n","      <td>0.608434</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.801508</td>\n","      <td>0.802013</td>\n","      <td>0.800670</td>\n","      <td>0.801341</td>\n","      <td>0.800670</td>\n","      <td>0.802345</td>\n","      <td>0.603015</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.814972</td>\n","      <td>0.779449</td>\n","      <td>0.878531</td>\n","      <td>0.826029</td>\n","      <td>0.878531</td>\n","      <td>0.751412</td>\n","      <td>0.629944</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.840361</td>\n","      <td>0.849485</td>\n","      <td>0.827309</td>\n","      <td>0.838250</td>\n","      <td>0.827309</td>\n","      <td>0.853414</td>\n","      <td>0.680723</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f55ede2-f4ff-45ed-98f9-32d764b1015f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8f55ede2-f4ff-45ed-98f9-32d764b1015f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8f55ede2-f4ff-45ed-98f9-32d764b1015f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6633d3ba-9476-4503-ad7a-12f6f98f4abc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6633d3ba-9476-4503-ad7a-12f6f98f4abc')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6633d3ba-9476-4503-ad7a-12f6f98f4abc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09900827457201854,\n        \"min\": 0.5527638190954773,\n        \"max\": 0.8403614457831325,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7596314907872697,\n          0.8042168674698795,\n          0.5527638190954773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09321199048093225,\n        \"min\": 0.5660091047040972,\n        \"max\": 0.8494845360824742,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7654109589041096,\n          0.835920177383592,\n          0.5674518201284796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15712739071357845,\n        \"min\": 0.3112449799196787,\n        \"max\": 0.8785310734463276,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7487437185929648,\n          0.7570281124497992,\n          0.4438860971524288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1267025610076172,\n        \"min\": 0.41333333333333333,\n        \"max\": 0.8382502543234994,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7569856054191363,\n          0.7945205479452054,\n          0.4981203007518797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15712739071357845,\n        \"min\": 0.3112449799196787,\n        \"max\": 0.8785310734463276,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7487437185929648,\n          0.7570281124497992,\n          0.4438860971524288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09008832015759059,\n        \"min\": 0.5466101694915254,\n        \"max\": 0.8534136546184738,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7705192629815746,\n          0.8514056224899599,\n          0.661641541038526\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19801654914403705,\n        \"min\": 0.10552763819095479,\n        \"max\": 0.6807228915662651,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5192629815745393,\n          0.608433734939759,\n          0.10552763819095479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_GRU/Delta_time_GRU.csv', index = False)"],"metadata":{"id":"zLQa6Czv7HE2","executionInfo":{"status":"ok","timestamp":1717502560261,"user_tz":-360,"elapsed":7,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RwfhDu7O9Myk"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}