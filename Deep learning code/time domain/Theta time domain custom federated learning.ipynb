{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Mbfw8uvdftFM"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INiFJfLjgOkx"},"outputs":[],"source":["\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYo2Uq77gQSH"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g66575_xgVzz"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28370,"status":"ok","timestamp":1717435754082,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"f61ab1d2-74cd-4eb9-e804-6635f1153ec5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNy9eOGMf2qO"},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time domain /RAW/Theta_time.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"70-nAHdJJ5HQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvjC2xCQNHLP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717435878515,"user_tz":-360,"elapsed":12,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"e17c9e64-6fc6-4f01-8be7-f9003e7faca7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_callback = ModelCheckpoint(\n","                f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Theta/CNN_LSTM/best_model_{run_name}.h5',\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Theta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[\n","\n","              , csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","executionInfo":{"status":"ok","timestamp":1717437056214,"user_tz":-360,"elapsed":1177706,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"8e0bee61-2504-428d-f6e7-ef20d0deeeee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5046"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 31s 153ms/step - loss: 0.6929 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6927 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6925 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6921 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.6918 - accuracy: 0.5038 - val_loss: 0.6930 - val_accuracy: 0.4881\n","Epoch 6/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6915 - accuracy: 0.5038 - val_loss: 0.6929 - val_accuracy: 0.6142\n","Epoch 7/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6910 - accuracy: 0.5038 - val_loss: 0.6929 - val_accuracy: 0.5453\n","Epoch 8/100\n","29/29 [==============================] - 1s 51ms/step - loss: 0.6899 - accuracy: 0.5040 - val_loss: 0.6928 - val_accuracy: 0.5302\n","Epoch 9/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.6886 - accuracy: 0.5084 - val_loss: 0.6927 - val_accuracy: 0.5194\n","Epoch 10/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6865 - accuracy: 0.5383 - val_loss: 0.6925 - val_accuracy: 0.5194\n","Epoch 11/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.6838 - accuracy: 0.5461 - val_loss: 0.6925 - val_accuracy: 0.5162\n","Epoch 12/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6794 - accuracy: 0.5876 - val_loss: 0.6910 - val_accuracy: 0.5302\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6730 - accuracy: 0.6078 - val_loss: 0.6911 - val_accuracy: 0.5226\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6651 - accuracy: 0.6247 - val_loss: 0.6879 - val_accuracy: 0.5356\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6550 - accuracy: 0.6387 - val_loss: 0.6872 - val_accuracy: 0.5334\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6457 - accuracy: 0.6420 - val_loss: 0.6853 - val_accuracy: 0.5356\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6374 - accuracy: 0.6536 - val_loss: 0.6873 - val_accuracy: 0.5345\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6335 - accuracy: 0.6495 - val_loss: 0.6769 - val_accuracy: 0.5679\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6227 - accuracy: 0.6630 - val_loss: 0.6761 - val_accuracy: 0.5754\n","Epoch 20/100\n","29/29 [==============================] - 2s 61ms/step - loss: 0.6202 - accuracy: 0.6573 - val_loss: 0.6579 - val_accuracy: 0.6218\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6194 - accuracy: 0.6668 - val_loss: 0.6412 - val_accuracy: 0.6498\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6214 - accuracy: 0.6557 - val_loss: 0.6474 - val_accuracy: 0.6325\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6168 - accuracy: 0.6665 - val_loss: 0.6221 - val_accuracy: 0.6627\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6116 - accuracy: 0.6681 - val_loss: 0.6259 - val_accuracy: 0.6595\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6112 - accuracy: 0.6748 - val_loss: 0.6208 - val_accuracy: 0.6616\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6128 - accuracy: 0.6624 - val_loss: 0.6136 - val_accuracy: 0.6659\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6101 - accuracy: 0.6724 - val_loss: 0.6121 - val_accuracy: 0.6724\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6127 - accuracy: 0.6649 - val_loss: 0.6136 - val_accuracy: 0.6681\n","Epoch 29/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6126 - accuracy: 0.6695 - val_loss: 0.6118 - val_accuracy: 0.6767\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6106 - accuracy: 0.6665 - val_loss: 0.6125 - val_accuracy: 0.6724\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6087 - accuracy: 0.6684 - val_loss: 0.6176 - val_accuracy: 0.6627\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6066 - accuracy: 0.6697 - val_loss: 0.6108 - val_accuracy: 0.6746\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6095 - accuracy: 0.6689 - val_loss: 0.6111 - val_accuracy: 0.6735\n","Epoch 34/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6051 - accuracy: 0.6746 - val_loss: 0.6110 - val_accuracy: 0.6778\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6047 - accuracy: 0.6797 - val_loss: 0.6107 - val_accuracy: 0.6724\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6071 - accuracy: 0.6732 - val_loss: 0.6331 - val_accuracy: 0.6552\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6085 - accuracy: 0.6740 - val_loss: 0.6130 - val_accuracy: 0.6649\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6067 - accuracy: 0.6754 - val_loss: 0.6133 - val_accuracy: 0.6670\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6031 - accuracy: 0.6751 - val_loss: 0.6180 - val_accuracy: 0.6627\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6028 - accuracy: 0.6789 - val_loss: 0.6211 - val_accuracy: 0.6638\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6031 - accuracy: 0.6781 - val_loss: 0.6114 - val_accuracy: 0.6713\n","Epoch 42/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6017 - accuracy: 0.6756 - val_loss: 0.6095 - val_accuracy: 0.6800\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6010 - accuracy: 0.6781 - val_loss: 0.6190 - val_accuracy: 0.6649\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5987 - accuracy: 0.6818 - val_loss: 0.6247 - val_accuracy: 0.6638\n","Epoch 45/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6008 - accuracy: 0.6786 - val_loss: 0.6319 - val_accuracy: 0.6649\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5995 - accuracy: 0.6816 - val_loss: 0.6099 - val_accuracy: 0.6724\n","Epoch 47/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6023 - accuracy: 0.6837 - val_loss: 0.6240 - val_accuracy: 0.6649\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6010 - accuracy: 0.6781 - val_loss: 0.6168 - val_accuracy: 0.6713\n","Epoch 49/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5985 - accuracy: 0.6843 - val_loss: 0.6112 - val_accuracy: 0.6659\n","Epoch 50/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5977 - accuracy: 0.6848 - val_loss: 0.6114 - val_accuracy: 0.6703\n","Epoch 51/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5960 - accuracy: 0.6835 - val_loss: 0.6102 - val_accuracy: 0.6735\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5985 - accuracy: 0.6802 - val_loss: 0.6202 - val_accuracy: 0.6746\n","Epoch 53/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5936 - accuracy: 0.6907 - val_loss: 0.6089 - val_accuracy: 0.6767\n","Epoch 54/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5964 - accuracy: 0.6870 - val_loss: 0.6136 - val_accuracy: 0.6713\n","Epoch 55/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5938 - accuracy: 0.6886 - val_loss: 0.6161 - val_accuracy: 0.6789\n","Epoch 56/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5967 - accuracy: 0.6818 - val_loss: 0.6087 - val_accuracy: 0.6778\n","Epoch 57/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5971 - accuracy: 0.6862 - val_loss: 0.6145 - val_accuracy: 0.6756\n","Epoch 58/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5923 - accuracy: 0.6821 - val_loss: 0.6079 - val_accuracy: 0.6778\n","Epoch 59/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.5957 - accuracy: 0.6907 - val_loss: 0.6106 - val_accuracy: 0.6767\n","Epoch 60/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5928 - accuracy: 0.6872 - val_loss: 0.6088 - val_accuracy: 0.6789\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5946 - accuracy: 0.6805 - val_loss: 0.6087 - val_accuracy: 0.6778\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5902 - accuracy: 0.6891 - val_loss: 0.6078 - val_accuracy: 0.6767\n","Epoch 63/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5899 - accuracy: 0.6937 - val_loss: 0.6121 - val_accuracy: 0.6778\n","Epoch 64/100\n","29/29 [==============================] - 2s 80ms/step - loss: 0.5906 - accuracy: 0.6910 - val_loss: 0.6100 - val_accuracy: 0.6821\n","Epoch 65/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5888 - accuracy: 0.6894 - val_loss: 0.6123 - val_accuracy: 0.6767\n","Epoch 66/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5891 - accuracy: 0.6880 - val_loss: 0.6174 - val_accuracy: 0.6724\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5923 - accuracy: 0.6886 - val_loss: 0.6080 - val_accuracy: 0.6746\n","Epoch 68/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5871 - accuracy: 0.6915 - val_loss: 0.6106 - val_accuracy: 0.6789\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5876 - accuracy: 0.6945 - val_loss: 0.6109 - val_accuracy: 0.6810\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5873 - accuracy: 0.6934 - val_loss: 0.6094 - val_accuracy: 0.6821\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5875 - accuracy: 0.6923 - val_loss: 0.6120 - val_accuracy: 0.6778\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5870 - accuracy: 0.6932 - val_loss: 0.6174 - val_accuracy: 0.6778\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5866 - accuracy: 0.6940 - val_loss: 0.6082 - val_accuracy: 0.6800\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5840 - accuracy: 0.6975 - val_loss: 0.6081 - val_accuracy: 0.6843\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5820 - accuracy: 0.6975 - val_loss: 0.6177 - val_accuracy: 0.6767\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5807 - accuracy: 0.6999 - val_loss: 0.6151 - val_accuracy: 0.6778\n","Epoch 77/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5818 - accuracy: 0.6967 - val_loss: 0.6071 - val_accuracy: 0.6853\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5826 - accuracy: 0.6910 - val_loss: 0.6154 - val_accuracy: 0.6756\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5802 - accuracy: 0.7002 - val_loss: 0.6082 - val_accuracy: 0.6843\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5835 - accuracy: 0.6988 - val_loss: 0.6099 - val_accuracy: 0.6810\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5808 - accuracy: 0.7002 - val_loss: 0.6079 - val_accuracy: 0.6821\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5777 - accuracy: 0.7047 - val_loss: 0.6328 - val_accuracy: 0.6649\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5803 - accuracy: 0.6988 - val_loss: 0.6177 - val_accuracy: 0.6778\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5798 - accuracy: 0.7012 - val_loss: 0.6103 - val_accuracy: 0.6800\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5793 - accuracy: 0.6934 - val_loss: 0.6155 - val_accuracy: 0.6789\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5806 - accuracy: 0.6980 - val_loss: 0.6107 - val_accuracy: 0.6843\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5766 - accuracy: 0.7004 - val_loss: 0.6170 - val_accuracy: 0.6789\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5749 - accuracy: 0.7034 - val_loss: 0.6088 - val_accuracy: 0.6832\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5732 - accuracy: 0.7012 - val_loss: 0.6071 - val_accuracy: 0.6843\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5744 - accuracy: 0.6999 - val_loss: 0.6086 - val_accuracy: 0.6821\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5710 - accuracy: 0.7042 - val_loss: 0.6112 - val_accuracy: 0.6821\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5747 - accuracy: 0.7096 - val_loss: 0.6180 - val_accuracy: 0.6789\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5735 - accuracy: 0.7074 - val_loss: 0.6087 - val_accuracy: 0.6810\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5716 - accuracy: 0.7053 - val_loss: 0.6107 - val_accuracy: 0.6853\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5707 - accuracy: 0.7045 - val_loss: 0.6154 - val_accuracy: 0.6789\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5702 - accuracy: 0.7120 - val_loss: 0.6116 - val_accuracy: 0.6800\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5688 - accuracy: 0.7069 - val_loss: 0.6179 - val_accuracy: 0.6832\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5689 - accuracy: 0.7093 - val_loss: 0.6087 - val_accuracy: 0.6843\n","Epoch 99/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5645 - accuracy: 0.7117 - val_loss: 0.6084 - val_accuracy: 0.6886\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5641 - accuracy: 0.7080 - val_loss: 0.6105 - val_accuracy: 0.6886\n","{'loss': [0.6928589344024658, 0.6927424073219299, 0.6924976706504822, 0.6921146512031555, 0.6918211579322815, 0.691535234451294, 0.69097900390625, 0.6898776292800903, 0.6886202096939087, 0.6865494847297668, 0.6838240623474121, 0.6793587803840637, 0.6729837656021118, 0.665112316608429, 0.6550317406654358, 0.6457281708717346, 0.6374295949935913, 0.6335167288780212, 0.622715175151825, 0.6201673746109009, 0.619382381439209, 0.6213952302932739, 0.6168302297592163, 0.6115825772285461, 0.611157238483429, 0.612811803817749, 0.6100568175315857, 0.6126678586006165, 0.6126302480697632, 0.6105888485908508, 0.6086942553520203, 0.6065531373023987, 0.609451413154602, 0.6050560474395752, 0.6047370433807373, 0.607094943523407, 0.6085174083709717, 0.6067041754722595, 0.6030554175376892, 0.6027677059173584, 0.6031429171562195, 0.6017117500305176, 0.6010483503341675, 0.5987337231636047, 0.6008411049842834, 0.5994803309440613, 0.602254331111908, 0.6009565591812134, 0.5984570980072021, 0.5976510047912598, 0.5960190296173096, 0.5985426902770996, 0.5936291217803955, 0.5964056253433228, 0.5937560796737671, 0.5966559052467346, 0.597105085849762, 0.5923067331314087, 0.5956644415855408, 0.5928041934967041, 0.5945771932601929, 0.5901574492454529, 0.5899459719657898, 0.5905910730361938, 0.5888397693634033, 0.5890545845031738, 0.5922948122024536, 0.5870724320411682, 0.5875942707061768, 0.587326169013977, 0.5874738097190857, 0.5870122313499451, 0.5865514278411865, 0.5840043425559998, 0.5820057988166809, 0.5806989073753357, 0.581809937953949, 0.5826170444488525, 0.5801677703857422, 0.5835086107254028, 0.5808029174804688, 0.5777027010917664, 0.5802516937255859, 0.5797696113586426, 0.5793107151985168, 0.5805862545967102, 0.576560378074646, 0.5748952627182007, 0.5731570720672607, 0.5744258165359497, 0.5709609985351562, 0.5746943354606628, 0.5734957456588745, 0.5715599656105042, 0.5706587433815002, 0.5701586604118347, 0.5687776803970337, 0.5688960552215576, 0.5645343065261841, 0.564146101474762], 'accuracy': [0.5045797228813171, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5040409564971924, 0.5083512663841248, 0.5382543206214905, 0.5460668206214905, 0.587553858757019, 0.607758641242981, 0.6247305870056152, 0.6387392282485962, 0.641972005367279, 0.6535560488700867, 0.6495150923728943, 0.6629849076271057, 0.6573275923728943, 0.6667564511299133, 0.6557112336158752, 0.6664870977401733, 0.6681034564971924, 0.6748383641242981, 0.662446141242981, 0.6724137663841248, 0.6648706793785095, 0.6694504022598267, 0.6664870977401733, 0.6683728694915771, 0.6697198152542114, 0.6689116358757019, 0.6745689511299133, 0.6796875, 0.673222005367279, 0.6740301847457886, 0.6753771305084229, 0.6751077771186829, 0.6788793206214905, 0.678071141242981, 0.6756465435028076, 0.678071141242981, 0.6818426847457886, 0.6786099076271057, 0.6815732717514038, 0.6837284564971924, 0.678071141242981, 0.6842672228813171, 0.6848060488700867, 0.6834590435028076, 0.6802262663841248, 0.6907327771186829, 0.6869612336158752, 0.6885775923728943, 0.6818426847457886, 0.686152994632721, 0.6821120977401733, 0.6907327771186829, 0.6872305870056152, 0.6804956793785095, 0.689116358757019, 0.693696141242981, 0.6910021305084229, 0.6893857717514038, 0.6880387663841248, 0.6885775923728943, 0.6915409564971924, 0.6945043206214905, 0.6934267282485962, 0.6923491358757019, 0.6931573152542114, 0.693965494632721, 0.6974676847457886, 0.6974676847457886, 0.6998922228813171, 0.696659505367279, 0.6910021305084229, 0.7001616358757019, 0.6988146305084229, 0.7001616358757019, 0.704741358757019, 0.6988146305084229, 0.7012392282485962, 0.6934267282485962, 0.6980064511299133, 0.7004310488700867, 0.7033944129943848, 0.7012392282485962, 0.6998922228813171, 0.7042025923728943, 0.709590494632721, 0.7074353694915771, 0.7052801847457886, 0.704472005367279, 0.7120150923728943, 0.7068965435028076, 0.709321141242981, 0.7117456793785095, 0.7079741358757019], 'val_loss': [0.693146288394928, 0.6931399703025818, 0.6931197643280029, 0.6930785179138184, 0.6930161714553833, 0.6929370164871216, 0.6928951740264893, 0.6927778124809265, 0.6927210092544556, 0.692541778087616, 0.6924726963043213, 0.6910152435302734, 0.6911174654960632, 0.6878918409347534, 0.6872302889823914, 0.6852595210075378, 0.6872801780700684, 0.6769239902496338, 0.6760964393615723, 0.6579170823097229, 0.6411834359169006, 0.6474371552467346, 0.6221026182174683, 0.6258560419082642, 0.6207633018493652, 0.6136399507522583, 0.6121167540550232, 0.6135828495025635, 0.6118333339691162, 0.612512469291687, 0.6175509095191956, 0.6108340620994568, 0.6111020445823669, 0.6110076904296875, 0.6106882691383362, 0.6330951452255249, 0.612995982170105, 0.6133479475975037, 0.618005096912384, 0.6211183667182922, 0.6113640069961548, 0.609540581703186, 0.6190291047096252, 0.6247063875198364, 0.6319263577461243, 0.6099441647529602, 0.6240314245223999, 0.6168417930603027, 0.6112024784088135, 0.6113554835319519, 0.6102477312088013, 0.6201643943786621, 0.6089485287666321, 0.613596498966217, 0.6160549521446228, 0.6086984276771545, 0.6145159006118774, 0.6079190373420715, 0.6105536222457886, 0.6087850332260132, 0.6086996793746948, 0.6077825427055359, 0.6121494174003601, 0.610039472579956, 0.6122575402259827, 0.6173998117446899, 0.6080158352851868, 0.610624372959137, 0.6109058260917664, 0.6094261407852173, 0.6119939684867859, 0.61736661195755, 0.6081669330596924, 0.6081061959266663, 0.6176770329475403, 0.6151458024978638, 0.6070936918258667, 0.6154289245605469, 0.6082103252410889, 0.6098937392234802, 0.6078665256500244, 0.6327791810035706, 0.6176593899726868, 0.6102963089942932, 0.6155213713645935, 0.6106688380241394, 0.6169793605804443, 0.6088232398033142, 0.6071160435676575, 0.6086012721061707, 0.6112309098243713, 0.6180252432823181, 0.608654260635376, 0.6106588244438171, 0.6153705716133118, 0.6116198897361755, 0.6179119348526001, 0.6086902022361755, 0.6083977222442627, 0.6105028390884399], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4881465435028076, 0.6142241358757019, 0.545258641242981, 0.5301724076271057, 0.5193965435028076, 0.5193965435028076, 0.5161637663841248, 0.5301724076271057, 0.5226293206214905, 0.5355603694915771, 0.5334051847457886, 0.5355603694915771, 0.5344827771186829, 0.5678879022598267, 0.5754310488700867, 0.6217672228813171, 0.649784505367279, 0.6325430870056152, 0.662715494632721, 0.6594827771186829, 0.6616379022598267, 0.6659482717514038, 0.6724137663841248, 0.6681034564971924, 0.6767241358757019, 0.6724137663841248, 0.662715494632721, 0.6745689511299133, 0.673491358757019, 0.6778017282485962, 0.6724137663841248, 0.6551724076271057, 0.6648706793785095, 0.6670258641242981, 0.662715494632721, 0.6637930870056152, 0.6713362336158752, 0.6799569129943848, 0.6648706793785095, 0.6637930870056152, 0.6648706793785095, 0.6724137663841248, 0.6648706793785095, 0.6713362336158752, 0.6659482717514038, 0.670258641242981, 0.673491358757019, 0.6745689511299133, 0.6767241358757019, 0.6713362336158752, 0.6788793206214905, 0.6778017282485962, 0.6756465435028076, 0.6778017282485962, 0.6767241358757019, 0.6788793206214905, 0.6778017282485962, 0.6767241358757019, 0.6778017282485962, 0.6821120977401733, 0.6767241358757019, 0.6724137663841248, 0.6745689511299133, 0.6788793206214905, 0.681034505367279, 0.6821120977401733, 0.6778017282485962, 0.6778017282485962, 0.6799569129943848, 0.6842672228813171, 0.6767241358757019, 0.6778017282485962, 0.6853448152542114, 0.6756465435028076, 0.6842672228813171, 0.681034505367279, 0.6821120977401733, 0.6648706793785095, 0.6778017282485962, 0.6799569129943848, 0.6788793206214905, 0.6842672228813171, 0.6788793206214905, 0.6831896305084229, 0.6842672228813171, 0.6821120977401733, 0.6821120977401733, 0.6788793206214905, 0.681034505367279, 0.6853448152542114, 0.6788793206214905, 0.6799569129943848, 0.6831896305084229, 0.6842672228813171, 0.6885775923728943, 0.6885775923728943]}\n","38/38 [==============================] - 2s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.4989"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 79ms/step - loss: 0.6930 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6927 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6922 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5622\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6919 - accuracy: 0.5011 - val_loss: 0.6930 - val_accuracy: 0.6131\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.5011 - val_loss: 0.6930 - val_accuracy: 0.5373\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6907 - accuracy: 0.5025 - val_loss: 0.6930 - val_accuracy: 0.5045\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6902 - accuracy: 0.5062 - val_loss: 0.6930 - val_accuracy: 0.5045\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6888 - accuracy: 0.5116 - val_loss: 0.6928 - val_accuracy: 0.5079\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6872 - accuracy: 0.5385 - val_loss: 0.6930 - val_accuracy: 0.5045\n","Epoch 11/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6842 - accuracy: 0.5549 - val_loss: 0.6929 - val_accuracy: 0.5057\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6812 - accuracy: 0.5770 - val_loss: 0.6927 - val_accuracy: 0.5079\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6762 - accuracy: 0.6152 - val_loss: 0.6927 - val_accuracy: 0.5068\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6709 - accuracy: 0.6143 - val_loss: 0.6921 - val_accuracy: 0.5113\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6641 - accuracy: 0.6353 - val_loss: 0.6940 - val_accuracy: 0.5079\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6551 - accuracy: 0.6423 - val_loss: 0.6859 - val_accuracy: 0.5509\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6486 - accuracy: 0.6353 - val_loss: 0.6764 - val_accuracy: 0.5916\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6422 - accuracy: 0.6463 - val_loss: 0.6786 - val_accuracy: 0.5679\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6352 - accuracy: 0.6471 - val_loss: 0.6719 - val_accuracy: 0.5803\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6324 - accuracy: 0.6466 - val_loss: 0.6825 - val_accuracy: 0.5622\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6293 - accuracy: 0.6534 - val_loss: 0.6632 - val_accuracy: 0.5973\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6256 - accuracy: 0.6528 - val_loss: 0.6593 - val_accuracy: 0.6075\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6207 - accuracy: 0.6607 - val_loss: 0.6552 - val_accuracy: 0.6188\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6244 - accuracy: 0.6539 - val_loss: 0.6417 - val_accuracy: 0.6437\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6207 - accuracy: 0.6593 - val_loss: 0.6417 - val_accuracy: 0.6425\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6198 - accuracy: 0.6514 - val_loss: 0.6407 - val_accuracy: 0.6403\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6158 - accuracy: 0.6686 - val_loss: 0.6415 - val_accuracy: 0.6380\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6218 - accuracy: 0.6531 - val_loss: 0.6247 - val_accuracy: 0.6674\n","Epoch 29/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6185 - accuracy: 0.6607 - val_loss: 0.6308 - val_accuracy: 0.6697\n","Epoch 30/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6149 - accuracy: 0.6672 - val_loss: 0.6240 - val_accuracy: 0.6719\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6160 - accuracy: 0.6610 - val_loss: 0.6330 - val_accuracy: 0.6595\n","Epoch 32/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6197 - accuracy: 0.6531 - val_loss: 0.6259 - val_accuracy: 0.6787\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6147 - accuracy: 0.6627 - val_loss: 0.6243 - val_accuracy: 0.6584\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6110 - accuracy: 0.6675 - val_loss: 0.6238 - val_accuracy: 0.6776\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6137 - accuracy: 0.6624 - val_loss: 0.6236 - val_accuracy: 0.6776\n","Epoch 36/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6110 - accuracy: 0.6672 - val_loss: 0.6234 - val_accuracy: 0.6765\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6127 - accuracy: 0.6706 - val_loss: 0.6257 - val_accuracy: 0.6538\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6117 - accuracy: 0.6636 - val_loss: 0.6331 - val_accuracy: 0.6391\n","Epoch 39/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6107 - accuracy: 0.6655 - val_loss: 0.6273 - val_accuracy: 0.6810\n","Epoch 40/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6106 - accuracy: 0.6675 - val_loss: 0.6223 - val_accuracy: 0.6742\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6112 - accuracy: 0.6672 - val_loss: 0.6251 - val_accuracy: 0.6505\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6114 - accuracy: 0.6616 - val_loss: 0.6222 - val_accuracy: 0.6787\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6079 - accuracy: 0.6653 - val_loss: 0.6224 - val_accuracy: 0.6810\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6063 - accuracy: 0.6715 - val_loss: 0.6262 - val_accuracy: 0.6787\n","Epoch 45/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6086 - accuracy: 0.6720 - val_loss: 0.6237 - val_accuracy: 0.6844\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6083 - accuracy: 0.6669 - val_loss: 0.6223 - val_accuracy: 0.6686\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6084 - accuracy: 0.6706 - val_loss: 0.6220 - val_accuracy: 0.6833\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6070 - accuracy: 0.6718 - val_loss: 0.6214 - val_accuracy: 0.6742\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6067 - accuracy: 0.6726 - val_loss: 0.6271 - val_accuracy: 0.6471\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6063 - accuracy: 0.6709 - val_loss: 0.6216 - val_accuracy: 0.6731\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6078 - accuracy: 0.6749 - val_loss: 0.6199 - val_accuracy: 0.6844\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6083 - accuracy: 0.6746 - val_loss: 0.6240 - val_accuracy: 0.6527\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6049 - accuracy: 0.6732 - val_loss: 0.6250 - val_accuracy: 0.6516\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6028 - accuracy: 0.6715 - val_loss: 0.6200 - val_accuracy: 0.6765\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6051 - accuracy: 0.6729 - val_loss: 0.6210 - val_accuracy: 0.6821\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6018 - accuracy: 0.6783 - val_loss: 0.6193 - val_accuracy: 0.6787\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6018 - accuracy: 0.6754 - val_loss: 0.6208 - val_accuracy: 0.6742\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6017 - accuracy: 0.6788 - val_loss: 0.6193 - val_accuracy: 0.6765\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6038 - accuracy: 0.6726 - val_loss: 0.6202 - val_accuracy: 0.6799\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6030 - accuracy: 0.6749 - val_loss: 0.6190 - val_accuracy: 0.6787\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6027 - accuracy: 0.6746 - val_loss: 0.6224 - val_accuracy: 0.6663\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6003 - accuracy: 0.6777 - val_loss: 0.6198 - val_accuracy: 0.6742\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6008 - accuracy: 0.6777 - val_loss: 0.6206 - val_accuracy: 0.6674\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6018 - accuracy: 0.6783 - val_loss: 0.6184 - val_accuracy: 0.6821\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5971 - accuracy: 0.6853 - val_loss: 0.6195 - val_accuracy: 0.6776\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5980 - accuracy: 0.6822 - val_loss: 0.6237 - val_accuracy: 0.6799\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5970 - accuracy: 0.6797 - val_loss: 0.6236 - val_accuracy: 0.6663\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5984 - accuracy: 0.6783 - val_loss: 0.6189 - val_accuracy: 0.6799\n","Epoch 69/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5981 - accuracy: 0.6851 - val_loss: 0.6233 - val_accuracy: 0.6708\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5974 - accuracy: 0.6853 - val_loss: 0.6194 - val_accuracy: 0.6719\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5944 - accuracy: 0.6845 - val_loss: 0.6272 - val_accuracy: 0.6640\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5957 - accuracy: 0.6819 - val_loss: 0.6214 - val_accuracy: 0.6719\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5965 - accuracy: 0.6885 - val_loss: 0.6208 - val_accuracy: 0.6742\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5989 - accuracy: 0.6791 - val_loss: 0.6183 - val_accuracy: 0.6810\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5941 - accuracy: 0.6831 - val_loss: 0.6297 - val_accuracy: 0.6618\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5951 - accuracy: 0.6836 - val_loss: 0.6225 - val_accuracy: 0.6708\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5943 - accuracy: 0.6783 - val_loss: 0.6186 - val_accuracy: 0.6787\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5920 - accuracy: 0.6839 - val_loss: 0.6192 - val_accuracy: 0.6753\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5905 - accuracy: 0.6887 - val_loss: 0.6185 - val_accuracy: 0.6776\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5916 - accuracy: 0.6950 - val_loss: 0.6199 - val_accuracy: 0.6821\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5929 - accuracy: 0.6851 - val_loss: 0.6214 - val_accuracy: 0.6776\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5911 - accuracy: 0.6938 - val_loss: 0.6184 - val_accuracy: 0.6821\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5918 - accuracy: 0.6910 - val_loss: 0.6180 - val_accuracy: 0.6833\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5892 - accuracy: 0.6924 - val_loss: 0.6210 - val_accuracy: 0.6742\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5909 - accuracy: 0.6839 - val_loss: 0.6191 - val_accuracy: 0.6765\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5876 - accuracy: 0.6947 - val_loss: 0.6190 - val_accuracy: 0.6787\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5865 - accuracy: 0.6896 - val_loss: 0.6180 - val_accuracy: 0.6833\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5880 - accuracy: 0.6919 - val_loss: 0.6199 - val_accuracy: 0.6821\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5856 - accuracy: 0.6952 - val_loss: 0.6192 - val_accuracy: 0.6821\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5886 - accuracy: 0.6947 - val_loss: 0.6178 - val_accuracy: 0.6765\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5879 - accuracy: 0.6969 - val_loss: 0.6170 - val_accuracy: 0.6821\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5810 - accuracy: 0.6986 - val_loss: 0.6174 - val_accuracy: 0.6787\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5828 - accuracy: 0.6986 - val_loss: 0.6201 - val_accuracy: 0.6753\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5856 - accuracy: 0.6938 - val_loss: 0.6238 - val_accuracy: 0.6753\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5841 - accuracy: 0.6899 - val_loss: 0.6181 - val_accuracy: 0.6833\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5821 - accuracy: 0.6967 - val_loss: 0.6171 - val_accuracy: 0.6844\n","Epoch 97/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5821 - accuracy: 0.6961 - val_loss: 0.6231 - val_accuracy: 0.6753\n","Epoch 98/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5872 - accuracy: 0.6876 - val_loss: 0.6174 - val_accuracy: 0.6821\n","Epoch 99/100\n","28/28 [==============================] - 1s 47ms/step - loss: 0.5830 - accuracy: 0.6952 - val_loss: 0.6189 - val_accuracy: 0.6810\n","Epoch 100/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.5780 - accuracy: 0.7018 - val_loss: 0.6212 - val_accuracy: 0.6708\n","{'loss': [0.6929727792739868, 0.6927419304847717, 0.6925442814826965, 0.6921916007995605, 0.6919070482254028, 0.6915292143821716, 0.6907286643981934, 0.6902498006820679, 0.6888433694839478, 0.6871703267097473, 0.6842284798622131, 0.681189239025116, 0.6762052774429321, 0.6709079742431641, 0.6640844941139221, 0.6550734639167786, 0.6486436724662781, 0.6421858668327332, 0.6352449059486389, 0.6324000954627991, 0.6293167471885681, 0.6256228685379028, 0.6207101941108704, 0.624416708946228, 0.6207137703895569, 0.6197556853294373, 0.6157504916191101, 0.6218400597572327, 0.6185334920883179, 0.614881157875061, 0.6160026788711548, 0.6196876764297485, 0.6147365570068359, 0.610982358455658, 0.6136817932128906, 0.6110088229179382, 0.6127421259880066, 0.611733078956604, 0.6106966733932495, 0.6105902194976807, 0.6111786961555481, 0.6113545894622803, 0.6079193949699402, 0.6063187122344971, 0.6086181998252869, 0.6082525849342346, 0.6083790063858032, 0.6070080399513245, 0.6067355275154114, 0.6063379049301147, 0.6078484654426575, 0.6083177924156189, 0.6049135327339172, 0.6028321981430054, 0.6050528287887573, 0.6018219590187073, 0.6017661094665527, 0.6017041802406311, 0.6037694811820984, 0.6029621362686157, 0.6027202606201172, 0.6002943515777588, 0.6007817387580872, 0.601844847202301, 0.5970972180366516, 0.5980088114738464, 0.5969544053077698, 0.5984007120132446, 0.5981020927429199, 0.5973603129386902, 0.5944198966026306, 0.5957167148590088, 0.596467137336731, 0.5989206433296204, 0.5941212773323059, 0.5951077938079834, 0.5942543148994446, 0.5920217633247375, 0.5905288457870483, 0.5915897488594055, 0.5928716659545898, 0.5910956859588623, 0.5918105244636536, 0.5891563892364502, 0.5909438133239746, 0.5875813961029053, 0.5865437984466553, 0.5879926085472107, 0.5856217741966248, 0.5885571241378784, 0.5878868103027344, 0.5809798240661621, 0.582759439945221, 0.5855587720870972, 0.584141194820404, 0.5821284651756287, 0.5821138620376587, 0.5871664881706238, 0.5829970836639404, 0.5780134201049805], 'accuracy': [0.4988681375980377, 0.5011318325996399, 0.5011318325996399, 0.5011318325996399, 0.5011318325996399, 0.5011318325996399, 0.5025466680526733, 0.5062252283096313, 0.5116015672683716, 0.5384833216667175, 0.554895281791687, 0.5769665837287903, 0.615166962146759, 0.6143180727958679, 0.6352574825286865, 0.6423316597938538, 0.6352574825286865, 0.6462931632995605, 0.6471420526504517, 0.6465761065483093, 0.653367280960083, 0.6528013348579407, 0.660724401473999, 0.6539332270622253, 0.6593095660209656, 0.651386559009552, 0.6686474084854126, 0.6530843377113342, 0.660724401473999, 0.6672325730323792, 0.6610073447227478, 0.6530843377113342, 0.66270512342453, 0.6675155758857727, 0.6624221801757812, 0.6672325730323792, 0.6706281900405884, 0.6635540723800659, 0.6655347943305969, 0.6675155758857727, 0.6672325730323792, 0.6615732908248901, 0.6652518510818481, 0.6714770793914795, 0.6720430254936218, 0.6669496297836304, 0.6706281900405884, 0.6717600226402283, 0.6726089119911194, 0.6709111332893372, 0.674872636795044, 0.6745896935462952, 0.6731748580932617, 0.6714770793914795, 0.6728919148445129, 0.6782682538032532, 0.6754385828971863, 0.6788341999053955, 0.6726089119911194, 0.674872636795044, 0.6745896935462952, 0.6777023077011108, 0.6777023077011108, 0.6782682538032532, 0.6853423714637756, 0.68222975730896, 0.6796830892562866, 0.6782682538032532, 0.6850594282150269, 0.6853423714637756, 0.6844934821128845, 0.6819468140602112, 0.6884549856185913, 0.6791171431541443, 0.6830786466598511, 0.6836445927619934, 0.6782682538032532, 0.6839275360107422, 0.6887379884719849, 0.6949632167816162, 0.6850594282150269, 0.6938313245773315, 0.6910017132759094, 0.6924165487289429, 0.6839275360107422, 0.6946802735328674, 0.689586877822876, 0.6918506026268005, 0.695246160030365, 0.6946802735328674, 0.696943998336792, 0.6986417770385742, 0.6986417770385742, 0.6938313245773315, 0.6898698210716248, 0.6966609954833984, 0.6960950493812561, 0.6876060962677002, 0.695246160030365, 0.7017543911933899], 'val_loss': [0.693138062953949, 0.6931191682815552, 0.6930928826332092, 0.693062424659729, 0.6930087804794312, 0.6929675340652466, 0.6929775476455688, 0.6929727792739868, 0.692791759967804, 0.693030595779419, 0.6928725242614746, 0.6926678419113159, 0.6927151679992676, 0.6920922994613647, 0.6939728856086731, 0.6859217286109924, 0.6764366626739502, 0.6786352396011353, 0.6718538999557495, 0.6824967861175537, 0.6631796360015869, 0.6593405604362488, 0.6552401781082153, 0.6416600942611694, 0.6417192220687866, 0.6407490968704224, 0.6414845585823059, 0.6246938705444336, 0.6308400630950928, 0.6240391731262207, 0.632961094379425, 0.6258829832077026, 0.6243095993995667, 0.6238413453102112, 0.6236060857772827, 0.6234161853790283, 0.6257293224334717, 0.6331118941307068, 0.6272766590118408, 0.6223270893096924, 0.6251185536384583, 0.6222448348999023, 0.6223697662353516, 0.6261877417564392, 0.6236823797225952, 0.6223154664039612, 0.6220024824142456, 0.6214491724967957, 0.6270855069160461, 0.6215762495994568, 0.619861364364624, 0.6240242719650269, 0.6249867677688599, 0.6199759840965271, 0.6210169792175293, 0.6193063855171204, 0.6207871437072754, 0.6193182468414307, 0.620171844959259, 0.6190345883369446, 0.6223697066307068, 0.6198089122772217, 0.6206329464912415, 0.6183903813362122, 0.6195069551467896, 0.623727023601532, 0.623628556728363, 0.6189108490943909, 0.623262345790863, 0.6194208860397339, 0.6272186040878296, 0.6214054822921753, 0.6208350658416748, 0.6182742118835449, 0.6296886205673218, 0.6225094199180603, 0.6185872554779053, 0.6191515326499939, 0.6184809803962708, 0.6198578476905823, 0.6214019656181335, 0.6184015870094299, 0.6179717779159546, 0.6209542751312256, 0.6191070675849915, 0.6189946532249451, 0.6180137395858765, 0.6199089288711548, 0.619154155254364, 0.6177718043327332, 0.6170397400856018, 0.6174498796463013, 0.6200953722000122, 0.6238307952880859, 0.6180717945098877, 0.617060124874115, 0.623148500919342, 0.6174429059028625, 0.618914008140564, 0.6212142109870911], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5622171759605408, 0.6131221652030945, 0.5373303294181824, 0.5045248866081238, 0.5045248866081238, 0.5079185366630554, 0.5045248866081238, 0.5056561231613159, 0.5079185366630554, 0.5067873597145081, 0.5113122463226318, 0.5079185366630554, 0.5509049892425537, 0.5916289687156677, 0.5678732991218567, 0.5803167223930359, 0.5622171759605408, 0.5972850918769836, 0.6074660420417786, 0.6187782883644104, 0.6436651349067688, 0.6425339579582214, 0.6402714848518372, 0.6380090713500977, 0.6674208045005798, 0.6696832776069641, 0.6719456911087036, 0.6595022678375244, 0.6787330508232117, 0.6583710312843323, 0.6776018142700195, 0.6776018142700195, 0.6764705777168274, 0.6538461446762085, 0.639140248298645, 0.6809954643249512, 0.6742081642150879, 0.6504524946212769, 0.6787330508232117, 0.6809954643249512, 0.6787330508232117, 0.6843891143798828, 0.668552041053772, 0.6832579374313354, 0.6742081642150879, 0.6470588445663452, 0.6730769276618958, 0.6843891143798828, 0.6527149081230164, 0.651583731174469, 0.6764705777168274, 0.6821267008781433, 0.6787330508232117, 0.6742081642150879, 0.6764705777168274, 0.679864227771759, 0.6787330508232117, 0.6662895679473877, 0.6742081642150879, 0.6674208045005798, 0.6821267008781433, 0.6776018142700195, 0.679864227771759, 0.6662895679473877, 0.679864227771759, 0.6708144545555115, 0.6719456911087036, 0.6640271544456482, 0.6719456911087036, 0.6742081642150879, 0.6809954643249512, 0.6617646813392639, 0.6708144545555115, 0.6787330508232117, 0.6753393411636353, 0.6776018142700195, 0.6821267008781433, 0.6776018142700195, 0.6821267008781433, 0.6832579374313354, 0.6742081642150879, 0.6764705777168274, 0.6787330508232117, 0.6832579374313354, 0.6821267008781433, 0.6821267008781433, 0.6764705777168274, 0.6821267008781433, 0.6787330508232117, 0.6753393411636353, 0.6753393411636353, 0.6832579374313354, 0.6843891143798828, 0.6753393411636353, 0.6821267008781433, 0.6809954643249512, 0.6708144545555115]}\n","45/45 [==============================] - 2s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5044"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 65ms/step - loss: 0.6930 - accuracy: 0.5044 - val_loss: 0.6931 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6926 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6924 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6920 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6914 - accuracy: 0.5036 - val_loss: 0.6930 - val_accuracy: 0.5826\n","Epoch 6/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.6906 - accuracy: 0.5036 - val_loss: 0.6928 - val_accuracy: 0.6147\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6898 - accuracy: 0.5039 - val_loss: 0.6927 - val_accuracy: 0.5403\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6882 - accuracy: 0.5070 - val_loss: 0.6926 - val_accuracy: 0.5186\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6854 - accuracy: 0.5470 - val_loss: 0.6923 - val_accuracy: 0.5207\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6816 - accuracy: 0.5641 - val_loss: 0.6925 - val_accuracy: 0.5176\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6781 - accuracy: 0.6036 - val_loss: 0.6913 - val_accuracy: 0.5258\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6706 - accuracy: 0.6305 - val_loss: 0.6912 - val_accuracy: 0.5227\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6620 - accuracy: 0.6421 - val_loss: 0.6883 - val_accuracy: 0.5475\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6540 - accuracy: 0.6447 - val_loss: 0.6837 - val_accuracy: 0.5682\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6427 - accuracy: 0.6553 - val_loss: 0.6827 - val_accuracy: 0.5640\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6356 - accuracy: 0.6574 - val_loss: 0.6878 - val_accuracy: 0.5434\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6293 - accuracy: 0.6638 - val_loss: 0.6598 - val_accuracy: 0.6116\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6235 - accuracy: 0.6579 - val_loss: 0.6654 - val_accuracy: 0.5950\n","Epoch 19/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.6187 - accuracy: 0.6703 - val_loss: 0.6513 - val_accuracy: 0.6167\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6161 - accuracy: 0.6685 - val_loss: 0.6680 - val_accuracy: 0.5971\n","Epoch 21/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6129 - accuracy: 0.6698 - val_loss: 0.6427 - val_accuracy: 0.6384\n","Epoch 22/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6126 - accuracy: 0.6685 - val_loss: 0.6334 - val_accuracy: 0.6529\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6116 - accuracy: 0.6680 - val_loss: 0.6433 - val_accuracy: 0.6395\n","Epoch 24/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6124 - accuracy: 0.6651 - val_loss: 0.6294 - val_accuracy: 0.6426\n","Epoch 25/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.6079 - accuracy: 0.6718 - val_loss: 0.6325 - val_accuracy: 0.6457\n","Epoch 26/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6122 - accuracy: 0.6721 - val_loss: 0.6300 - val_accuracy: 0.6457\n","Epoch 27/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6071 - accuracy: 0.6783 - val_loss: 0.6305 - val_accuracy: 0.6446\n","Epoch 28/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6040 - accuracy: 0.6762 - val_loss: 0.6319 - val_accuracy: 0.6446\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6050 - accuracy: 0.6736 - val_loss: 0.6411 - val_accuracy: 0.6343\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6046 - accuracy: 0.6755 - val_loss: 0.6373 - val_accuracy: 0.6405\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6069 - accuracy: 0.6708 - val_loss: 0.6319 - val_accuracy: 0.6446\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6017 - accuracy: 0.6819 - val_loss: 0.6442 - val_accuracy: 0.6312\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6036 - accuracy: 0.6752 - val_loss: 0.6323 - val_accuracy: 0.6498\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6058 - accuracy: 0.6742 - val_loss: 0.6380 - val_accuracy: 0.6426\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6021 - accuracy: 0.6804 - val_loss: 0.6348 - val_accuracy: 0.6395\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5983 - accuracy: 0.6806 - val_loss: 0.6383 - val_accuracy: 0.6415\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5986 - accuracy: 0.6814 - val_loss: 0.6347 - val_accuracy: 0.6384\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5969 - accuracy: 0.6850 - val_loss: 0.6433 - val_accuracy: 0.6322\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6014 - accuracy: 0.6793 - val_loss: 0.6494 - val_accuracy: 0.6364\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5972 - accuracy: 0.6829 - val_loss: 0.6336 - val_accuracy: 0.6436\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5988 - accuracy: 0.6817 - val_loss: 0.6480 - val_accuracy: 0.6384\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6029 - accuracy: 0.6780 - val_loss: 0.6461 - val_accuracy: 0.6374\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5970 - accuracy: 0.6850 - val_loss: 0.6317 - val_accuracy: 0.6477\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5972 - accuracy: 0.6824 - val_loss: 0.6469 - val_accuracy: 0.6374\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5969 - accuracy: 0.6817 - val_loss: 0.6398 - val_accuracy: 0.6343\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5945 - accuracy: 0.6884 - val_loss: 0.6361 - val_accuracy: 0.6415\n","Epoch 47/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5924 - accuracy: 0.6935 - val_loss: 0.6336 - val_accuracy: 0.6405\n","Epoch 48/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.5952 - accuracy: 0.6850 - val_loss: 0.6409 - val_accuracy: 0.6322\n","Epoch 49/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5938 - accuracy: 0.6829 - val_loss: 0.6346 - val_accuracy: 0.6374\n","Epoch 50/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5929 - accuracy: 0.6840 - val_loss: 0.6333 - val_accuracy: 0.6415\n","Epoch 51/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5962 - accuracy: 0.6806 - val_loss: 0.6321 - val_accuracy: 0.6384\n","Epoch 52/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.5960 - accuracy: 0.6848 - val_loss: 0.6366 - val_accuracy: 0.6436\n","Epoch 53/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5907 - accuracy: 0.6881 - val_loss: 0.6370 - val_accuracy: 0.6415\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5916 - accuracy: 0.6889 - val_loss: 0.6326 - val_accuracy: 0.6353\n","Epoch 55/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5894 - accuracy: 0.6842 - val_loss: 0.6324 - val_accuracy: 0.6415\n","Epoch 56/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5902 - accuracy: 0.6948 - val_loss: 0.6357 - val_accuracy: 0.6374\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5892 - accuracy: 0.6915 - val_loss: 0.6317 - val_accuracy: 0.6405\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5927 - accuracy: 0.6891 - val_loss: 0.6376 - val_accuracy: 0.6405\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5893 - accuracy: 0.6850 - val_loss: 0.6330 - val_accuracy: 0.6353\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5891 - accuracy: 0.6866 - val_loss: 0.6363 - val_accuracy: 0.6374\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5924 - accuracy: 0.6863 - val_loss: 0.6353 - val_accuracy: 0.6384\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5900 - accuracy: 0.6935 - val_loss: 0.6486 - val_accuracy: 0.6405\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5875 - accuracy: 0.6966 - val_loss: 0.6328 - val_accuracy: 0.6405\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5868 - accuracy: 0.6915 - val_loss: 0.6372 - val_accuracy: 0.6395\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5879 - accuracy: 0.6866 - val_loss: 0.6330 - val_accuracy: 0.6457\n","Epoch 66/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5908 - accuracy: 0.6853 - val_loss: 0.6354 - val_accuracy: 0.6384\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5843 - accuracy: 0.6974 - val_loss: 0.6357 - val_accuracy: 0.6374\n","Epoch 68/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5866 - accuracy: 0.6915 - val_loss: 0.6342 - val_accuracy: 0.6519\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5852 - accuracy: 0.6966 - val_loss: 0.6349 - val_accuracy: 0.6322\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5864 - accuracy: 0.6946 - val_loss: 0.6415 - val_accuracy: 0.6343\n","Epoch 71/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5857 - accuracy: 0.6915 - val_loss: 0.6315 - val_accuracy: 0.6446\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5832 - accuracy: 0.6930 - val_loss: 0.6433 - val_accuracy: 0.6343\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5828 - accuracy: 0.6987 - val_loss: 0.6472 - val_accuracy: 0.6384\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5858 - accuracy: 0.6917 - val_loss: 0.6335 - val_accuracy: 0.6343\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5829 - accuracy: 0.6961 - val_loss: 0.6319 - val_accuracy: 0.6436\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5817 - accuracy: 0.6959 - val_loss: 0.6328 - val_accuracy: 0.6426\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5839 - accuracy: 0.6933 - val_loss: 0.6330 - val_accuracy: 0.6436\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5812 - accuracy: 0.7013 - val_loss: 0.6335 - val_accuracy: 0.6415\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5789 - accuracy: 0.7026 - val_loss: 0.6365 - val_accuracy: 0.6322\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5797 - accuracy: 0.6941 - val_loss: 0.6361 - val_accuracy: 0.6384\n","Epoch 81/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5793 - accuracy: 0.6974 - val_loss: 0.6359 - val_accuracy: 0.6415\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5771 - accuracy: 0.7016 - val_loss: 0.6382 - val_accuracy: 0.6343\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5775 - accuracy: 0.7008 - val_loss: 0.6362 - val_accuracy: 0.6384\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5782 - accuracy: 0.6979 - val_loss: 0.6375 - val_accuracy: 0.6364\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5775 - accuracy: 0.6995 - val_loss: 0.6326 - val_accuracy: 0.6498\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5804 - accuracy: 0.6977 - val_loss: 0.6522 - val_accuracy: 0.6395\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5772 - accuracy: 0.7016 - val_loss: 0.6356 - val_accuracy: 0.6395\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5762 - accuracy: 0.7065 - val_loss: 0.6341 - val_accuracy: 0.6457\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5743 - accuracy: 0.7072 - val_loss: 0.6344 - val_accuracy: 0.6467\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5740 - accuracy: 0.7098 - val_loss: 0.6446 - val_accuracy: 0.6343\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5753 - accuracy: 0.7052 - val_loss: 0.6339 - val_accuracy: 0.6508\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5720 - accuracy: 0.7044 - val_loss: 0.6338 - val_accuracy: 0.6508\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5743 - accuracy: 0.6992 - val_loss: 0.6357 - val_accuracy: 0.6415\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5721 - accuracy: 0.7083 - val_loss: 0.6364 - val_accuracy: 0.6384\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5709 - accuracy: 0.7075 - val_loss: 0.6361 - val_accuracy: 0.6508\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5681 - accuracy: 0.7132 - val_loss: 0.6361 - val_accuracy: 0.6436\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5698 - accuracy: 0.7049 - val_loss: 0.6344 - val_accuracy: 0.6457\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5733 - accuracy: 0.7090 - val_loss: 0.6512 - val_accuracy: 0.6333\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5691 - accuracy: 0.7134 - val_loss: 0.6352 - val_accuracy: 0.6446\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5673 - accuracy: 0.7137 - val_loss: 0.6398 - val_accuracy: 0.6415\n","{'loss': [0.6929684281349182, 0.6926340460777283, 0.6923569440841675, 0.6920156478881836, 0.691376268863678, 0.6906408071517944, 0.689793050289154, 0.6882369518280029, 0.6854497790336609, 0.6815840005874634, 0.6781087517738342, 0.6706218123435974, 0.661961555480957, 0.6539715528488159, 0.6427143812179565, 0.6355817317962646, 0.6293200850486755, 0.6234890818595886, 0.6186991333961487, 0.6160907745361328, 0.6128746867179871, 0.612622857093811, 0.6116431951522827, 0.6124129295349121, 0.6078519821166992, 0.6121639609336853, 0.6071072816848755, 0.6039758920669556, 0.6049726605415344, 0.6046207547187805, 0.6069110035896301, 0.6017310619354248, 0.6035827994346619, 0.6058485507965088, 0.6021379232406616, 0.598320484161377, 0.5986374020576477, 0.5969268083572388, 0.6014419198036194, 0.5971786975860596, 0.5988235473632812, 0.602947473526001, 0.5969856381416321, 0.5971786379814148, 0.5969302654266357, 0.5945188999176025, 0.5923943519592285, 0.5951817631721497, 0.5937522649765015, 0.5928676724433899, 0.5961589813232422, 0.5959915518760681, 0.5907147526741028, 0.5915549397468567, 0.5894425511360168, 0.5901727676391602, 0.5891732573509216, 0.5927246809005737, 0.589331865310669, 0.5891143679618835, 0.5924162864685059, 0.5899624228477478, 0.5874675512313843, 0.586841881275177, 0.5878809690475464, 0.5908450484275818, 0.5843287706375122, 0.5866426825523376, 0.5852437019348145, 0.5863645672798157, 0.5857192277908325, 0.5832185745239258, 0.582805335521698, 0.5858250260353088, 0.5829088687896729, 0.581713080406189, 0.5839080810546875, 0.5812480449676514, 0.5788728594779968, 0.579720675945282, 0.5792859792709351, 0.577093243598938, 0.5774840712547302, 0.5782367587089539, 0.5775428414344788, 0.5803853273391724, 0.5772443413734436, 0.5761874914169312, 0.5742641687393188, 0.5739659667015076, 0.5752642154693604, 0.5719520449638367, 0.5743369460105896, 0.5721399188041687, 0.5709252953529358, 0.5680862665176392, 0.5697983503341675, 0.5732582807540894, 0.5690551996231079, 0.567284345626831], 'accuracy': [0.5043927431106567, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5038759708404541, 0.5069767236709595, 0.5470284223556519, 0.564082682132721, 0.6036175489425659, 0.6304909586906433, 0.6421188712120056, 0.6447028517723083, 0.6552971601486206, 0.6573643684387207, 0.6638242602348328, 0.6578811407089233, 0.6702842116355896, 0.6684754490852356, 0.669767439365387, 0.6684754490852356, 0.667958676815033, 0.6651162505149841, 0.6718346476554871, 0.6720930337905884, 0.6782945990562439, 0.6762273907661438, 0.6736434102058411, 0.6754521727561951, 0.670801043510437, 0.6819121241569519, 0.6751937866210938, 0.6741601824760437, 0.6803617477416992, 0.6806201338768005, 0.6813953518867493, 0.685012936592102, 0.6793281435966492, 0.682945728302002, 0.6816537380218506, 0.6780361533164978, 0.685012936592102, 0.6824289560317993, 0.6816537380218506, 0.6883720755577087, 0.6935400366783142, 0.685012936592102, 0.682945728302002, 0.683979332447052, 0.6806201338768005, 0.6847545504570007, 0.6881136894226074, 0.6888889074325562, 0.6842377185821533, 0.6948320269584656, 0.6914728879928589, 0.6891472935676575, 0.685012936592102, 0.6865633130073547, 0.6863049268722534, 0.6935400366783142, 0.6966408491134644, 0.6914728879928589, 0.6865633130073547, 0.6852713227272034, 0.6974160075187683, 0.6914728879928589, 0.6966408491134644, 0.6945736408233643, 0.6914728879928589, 0.6930232644081116, 0.6987079977989197, 0.6917312741279602, 0.6961240172386169, 0.6958656311035156, 0.6932816505432129, 0.7012919783592224, 0.7025839686393738, 0.6940568685531616, 0.6974160075187683, 0.7015503644943237, 0.7007752060890198, 0.6979328393936157, 0.6994832158088684, 0.6976743936538696, 0.7015503644943237, 0.7064599394798279, 0.7072351574897766, 0.7098191380500793, 0.7051679491996765, 0.7043927907943726, 0.6992248296737671, 0.7082687616348267, 0.7074935436248779, 0.713178277015686, 0.7049095630645752, 0.7090439200401306, 0.7134366631507874, 0.7136951088905334], 'val_loss': [0.6931472420692444, 0.6931318044662476, 0.6931019425392151, 0.6930508613586426, 0.6929581761360168, 0.6928381323814392, 0.6927239298820496, 0.6926360130310059, 0.6923413276672363, 0.6924666166305542, 0.6913478374481201, 0.691240131855011, 0.6883477568626404, 0.6837079524993896, 0.682695746421814, 0.687769889831543, 0.6598040461540222, 0.6654009222984314, 0.6512866616249084, 0.6680497527122498, 0.6426979303359985, 0.6333970427513123, 0.6432799696922302, 0.6294034719467163, 0.6325082778930664, 0.6299972534179688, 0.6304623484611511, 0.6319297552108765, 0.6410825848579407, 0.6373282670974731, 0.6318537592887878, 0.6441881060600281, 0.6323225498199463, 0.6380404829978943, 0.6348042488098145, 0.6382875442504883, 0.6347001194953918, 0.6432595252990723, 0.6493914723396301, 0.6336480975151062, 0.6480022668838501, 0.6460634469985962, 0.6316590309143066, 0.6469196081161499, 0.6398307085037231, 0.6360580921173096, 0.6335663199424744, 0.6408794522285461, 0.6345946192741394, 0.633251965045929, 0.6321171522140503, 0.6365971565246582, 0.6370007395744324, 0.6326009631156921, 0.6323650479316711, 0.6357393860816956, 0.6317077279090881, 0.6376088857650757, 0.6329807639122009, 0.6362721920013428, 0.6353216767311096, 0.6485701203346252, 0.6327855587005615, 0.6372187733650208, 0.632988691329956, 0.6354495882987976, 0.6357185244560242, 0.634181797504425, 0.6349425315856934, 0.6415414214134216, 0.6314526796340942, 0.6432952880859375, 0.647171139717102, 0.6335281133651733, 0.6319025754928589, 0.6328201293945312, 0.6329688429832458, 0.633452296257019, 0.6364783644676208, 0.6360899806022644, 0.6358821392059326, 0.6381833553314209, 0.6362445950508118, 0.6374664902687073, 0.6326124668121338, 0.6522336602210999, 0.635613739490509, 0.6340506672859192, 0.6344144940376282, 0.6445961594581604, 0.6339365243911743, 0.6338347792625427, 0.6357370018959045, 0.6363921165466309, 0.6360805034637451, 0.6361052989959717, 0.6343528032302856, 0.6511995196342468, 0.6351638436317444, 0.6398374438285828], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5826446413993835, 0.6146694421768188, 0.5402892827987671, 0.5185950398445129, 0.5206611752510071, 0.5175619721412659, 0.5258264541625977, 0.5227272510528564, 0.547520637512207, 0.5681818127632141, 0.5640496015548706, 0.5433884263038635, 0.6115702390670776, 0.5950413346290588, 0.6167355179786682, 0.5971074104309082, 0.6384297609329224, 0.6528925895690918, 0.6394628286361694, 0.6425619721412659, 0.6456611752510071, 0.6456611752510071, 0.64462810754776, 0.64462810754776, 0.6342975497245789, 0.6404958963394165, 0.64462810754776, 0.6311983466148376, 0.6497933864593506, 0.6425619721412659, 0.6394628286361694, 0.6415289044380188, 0.6384297609329224, 0.6322314143180847, 0.6363636255264282, 0.6435950398445129, 0.6384297609329224, 0.6373966932296753, 0.6477272510528564, 0.6373966932296753, 0.6342975497245789, 0.6415289044380188, 0.6404958963394165, 0.6322314143180847, 0.6373966932296753, 0.6415289044380188, 0.6384297609329224, 0.6435950398445129, 0.6415289044380188, 0.6353305578231812, 0.6415289044380188, 0.6373966932296753, 0.6404958963394165, 0.6404958963394165, 0.6353305578231812, 0.6373966932296753, 0.6384297609329224, 0.6404958963394165, 0.6404958963394165, 0.6394628286361694, 0.6456611752510071, 0.6384297609329224, 0.6373966932296753, 0.6518595218658447, 0.6322314143180847, 0.6342975497245789, 0.64462810754776, 0.6342975497245789, 0.6384297609329224, 0.6342975497245789, 0.6435950398445129, 0.6425619721412659, 0.6435950398445129, 0.6415289044380188, 0.6322314143180847, 0.6384297609329224, 0.6415289044380188, 0.6342975497245789, 0.6384297609329224, 0.6363636255264282, 0.6497933864593506, 0.6394628286361694, 0.6394628286361694, 0.6456611752510071, 0.6466942429542542, 0.6342975497245789, 0.6508264541625977, 0.6508264541625977, 0.6415289044380188, 0.6384297609329224, 0.6508264541625977, 0.6435950398445129, 0.6456611752510071, 0.6332644820213318, 0.64462810754776, 0.6415289044380188]}\n","32/32 [==============================] - 1s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 8s 52ms/step - loss: 0.5961 - accuracy: 0.6837 - val_loss: 0.6888 - val_accuracy: 0.5259\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 13ms/step - loss: 0.5932 - accuracy: 0.6848 - val_loss: 0.6879 - val_accuracy: 0.5248\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5888 - accuracy: 0.6934 - val_loss: 0.6875 - val_accuracy: 0.5183\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5893 - accuracy: 0.6894 - val_loss: 0.6869 - val_accuracy: 0.5216\n","Epoch 5/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5846 - accuracy: 0.6878 - val_loss: 0.6877 - val_accuracy: 0.5172\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5852 - accuracy: 0.6948 - val_loss: 0.6862 - val_accuracy: 0.5205\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5851 - accuracy: 0.6996 - val_loss: 0.6884 - val_accuracy: 0.5172\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5866 - accuracy: 0.6907 - val_loss: 0.6873 - val_accuracy: 0.5194\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.6956 - val_loss: 0.6872 - val_accuracy: 0.5205\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5838 - accuracy: 0.6915 - val_loss: 0.6884 - val_accuracy: 0.5205\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5818 - accuracy: 0.6926 - val_loss: 0.6870 - val_accuracy: 0.5248\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5838 - accuracy: 0.6967 - val_loss: 0.6875 - val_accuracy: 0.5259\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5771 - accuracy: 0.6999 - val_loss: 0.6861 - val_accuracy: 0.5280\n","Epoch 14/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.5794 - accuracy: 0.6991 - val_loss: 0.6840 - val_accuracy: 0.5356\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5743 - accuracy: 0.7053 - val_loss: 0.6906 - val_accuracy: 0.5312\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5759 - accuracy: 0.6961 - val_loss: 0.6735 - val_accuracy: 0.5582\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5741 - accuracy: 0.7012 - val_loss: 0.6929 - val_accuracy: 0.5463\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5722 - accuracy: 0.7064 - val_loss: 0.6810 - val_accuracy: 0.5614\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5732 - accuracy: 0.7015 - val_loss: 0.6765 - val_accuracy: 0.5776\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5714 - accuracy: 0.7055 - val_loss: 0.6448 - val_accuracy: 0.6358\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5713 - accuracy: 0.7034 - val_loss: 0.6287 - val_accuracy: 0.6530\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5727 - accuracy: 0.7023 - val_loss: 0.6388 - val_accuracy: 0.6422\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5681 - accuracy: 0.7055 - val_loss: 0.6208 - val_accuracy: 0.6692\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5688 - accuracy: 0.7026 - val_loss: 0.5990 - val_accuracy: 0.6875\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5656 - accuracy: 0.7126 - val_loss: 0.6007 - val_accuracy: 0.6907\n","Epoch 26/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5687 - accuracy: 0.7107 - val_loss: 0.5934 - val_accuracy: 0.7026\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5635 - accuracy: 0.7085 - val_loss: 0.5930 - val_accuracy: 0.6994\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5660 - accuracy: 0.7091 - val_loss: 0.5952 - val_accuracy: 0.6972\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5654 - accuracy: 0.7150 - val_loss: 0.5949 - val_accuracy: 0.6961\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5627 - accuracy: 0.7134 - val_loss: 0.5955 - val_accuracy: 0.6994\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5627 - accuracy: 0.7131 - val_loss: 0.5961 - val_accuracy: 0.6961\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5592 - accuracy: 0.7123 - val_loss: 0.5969 - val_accuracy: 0.6983\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5617 - accuracy: 0.7115 - val_loss: 0.5958 - val_accuracy: 0.7004\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5584 - accuracy: 0.7206 - val_loss: 0.5951 - val_accuracy: 0.6972\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5579 - accuracy: 0.7142 - val_loss: 0.5956 - val_accuracy: 0.6929\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5568 - accuracy: 0.7142 - val_loss: 0.5961 - val_accuracy: 0.6940\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5516 - accuracy: 0.7193 - val_loss: 0.5978 - val_accuracy: 0.6950\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5532 - accuracy: 0.7206 - val_loss: 0.6006 - val_accuracy: 0.6940\n","Epoch 39/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.5541 - accuracy: 0.7295 - val_loss: 0.6043 - val_accuracy: 0.6907\n","Epoch 40/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5528 - accuracy: 0.7188 - val_loss: 0.6014 - val_accuracy: 0.6929\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5573 - accuracy: 0.7171 - val_loss: 0.5987 - val_accuracy: 0.6950\n","Epoch 42/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5467 - accuracy: 0.7228 - val_loss: 0.6207 - val_accuracy: 0.6789\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5525 - accuracy: 0.7179 - val_loss: 0.5963 - val_accuracy: 0.6972\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5472 - accuracy: 0.7282 - val_loss: 0.5980 - val_accuracy: 0.6994\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5416 - accuracy: 0.7336 - val_loss: 0.5991 - val_accuracy: 0.6972\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5428 - accuracy: 0.7325 - val_loss: 0.6038 - val_accuracy: 0.6983\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5437 - accuracy: 0.7298 - val_loss: 0.5984 - val_accuracy: 0.6961\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5451 - accuracy: 0.7212 - val_loss: 0.5990 - val_accuracy: 0.7004\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5355 - accuracy: 0.7379 - val_loss: 0.6017 - val_accuracy: 0.6961\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5424 - accuracy: 0.7274 - val_loss: 0.5989 - val_accuracy: 0.6972\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5386 - accuracy: 0.7309 - val_loss: 0.6012 - val_accuracy: 0.6940\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5361 - accuracy: 0.7398 - val_loss: 0.6039 - val_accuracy: 0.6961\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5341 - accuracy: 0.7408 - val_loss: 0.6046 - val_accuracy: 0.7004\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5365 - accuracy: 0.7309 - val_loss: 0.6063 - val_accuracy: 0.7004\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5291 - accuracy: 0.7427 - val_loss: 0.6391 - val_accuracy: 0.6649\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5306 - accuracy: 0.7419 - val_loss: 0.6009 - val_accuracy: 0.6961\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5232 - accuracy: 0.7516 - val_loss: 0.6035 - val_accuracy: 0.6972\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5262 - accuracy: 0.7387 - val_loss: 0.6047 - val_accuracy: 0.6940\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5243 - accuracy: 0.7443 - val_loss: 0.6058 - val_accuracy: 0.6929\n","Epoch 60/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5263 - accuracy: 0.7398 - val_loss: 0.6108 - val_accuracy: 0.6994\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5197 - accuracy: 0.7500 - val_loss: 0.6119 - val_accuracy: 0.6897\n","Epoch 62/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5219 - accuracy: 0.7446 - val_loss: 0.6074 - val_accuracy: 0.6907\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5130 - accuracy: 0.7516 - val_loss: 0.6128 - val_accuracy: 0.6918\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5169 - accuracy: 0.7524 - val_loss: 0.6283 - val_accuracy: 0.6929\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5160 - accuracy: 0.7565 - val_loss: 0.6105 - val_accuracy: 0.6983\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5144 - accuracy: 0.7516 - val_loss: 0.6119 - val_accuracy: 0.6918\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5133 - accuracy: 0.7495 - val_loss: 0.6292 - val_accuracy: 0.6886\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5145 - accuracy: 0.7530 - val_loss: 0.6113 - val_accuracy: 0.6886\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5089 - accuracy: 0.7584 - val_loss: 0.6330 - val_accuracy: 0.6864\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5075 - accuracy: 0.7632 - val_loss: 0.6152 - val_accuracy: 0.6940\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5030 - accuracy: 0.7610 - val_loss: 0.6130 - val_accuracy: 0.6940\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5091 - accuracy: 0.7513 - val_loss: 0.6285 - val_accuracy: 0.6810\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4997 - accuracy: 0.7619 - val_loss: 0.6201 - val_accuracy: 0.6994\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5015 - accuracy: 0.7592 - val_loss: 0.6182 - val_accuracy: 0.6918\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5000 - accuracy: 0.7654 - val_loss: 0.6342 - val_accuracy: 0.6789\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5000 - accuracy: 0.7672 - val_loss: 0.6190 - val_accuracy: 0.6950\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4944 - accuracy: 0.7691 - val_loss: 0.6357 - val_accuracy: 0.6821\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4970 - accuracy: 0.7691 - val_loss: 0.6267 - val_accuracy: 0.6886\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4927 - accuracy: 0.7621 - val_loss: 0.6473 - val_accuracy: 0.6864\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4940 - accuracy: 0.7629 - val_loss: 0.6288 - val_accuracy: 0.6821\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4942 - accuracy: 0.7689 - val_loss: 0.6249 - val_accuracy: 0.6918\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4874 - accuracy: 0.7753 - val_loss: 0.6388 - val_accuracy: 0.6821\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4926 - accuracy: 0.7721 - val_loss: 0.6297 - val_accuracy: 0.6886\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4798 - accuracy: 0.7802 - val_loss: 0.6710 - val_accuracy: 0.6692\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4919 - accuracy: 0.7686 - val_loss: 0.6274 - val_accuracy: 0.6918\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4817 - accuracy: 0.7764 - val_loss: 0.6298 - val_accuracy: 0.6853\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4825 - accuracy: 0.7767 - val_loss: 0.6288 - val_accuracy: 0.6929\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4769 - accuracy: 0.7815 - val_loss: 0.6331 - val_accuracy: 0.6918\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4775 - accuracy: 0.7777 - val_loss: 0.6342 - val_accuracy: 0.6843\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4767 - accuracy: 0.7775 - val_loss: 0.6363 - val_accuracy: 0.6832\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4807 - accuracy: 0.7780 - val_loss: 0.6459 - val_accuracy: 0.6875\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4694 - accuracy: 0.7864 - val_loss: 0.6370 - val_accuracy: 0.6864\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4654 - accuracy: 0.7966 - val_loss: 0.6441 - val_accuracy: 0.6810\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4669 - accuracy: 0.7861 - val_loss: 0.6529 - val_accuracy: 0.6843\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4656 - accuracy: 0.7888 - val_loss: 0.6429 - val_accuracy: 0.6853\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4635 - accuracy: 0.7909 - val_loss: 0.6520 - val_accuracy: 0.6832\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4674 - accuracy: 0.7848 - val_loss: 0.6582 - val_accuracy: 0.6778\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4573 - accuracy: 0.7928 - val_loss: 0.6455 - val_accuracy: 0.6886\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4635 - accuracy: 0.7858 - val_loss: 0.6857 - val_accuracy: 0.6659\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4605 - accuracy: 0.7950 - val_loss: 0.6480 - val_accuracy: 0.6886\n","{'loss': [0.5961390137672424, 0.5931988954544067, 0.5887994170188904, 0.5892986059188843, 0.5845711827278137, 0.5851552486419678, 0.5851306319236755, 0.5866273641586304, 0.5814347267150879, 0.583831787109375, 0.5818366408348083, 0.58382248878479, 0.5771158933639526, 0.5794416069984436, 0.5743048191070557, 0.5758944749832153, 0.5740504860877991, 0.5721831321716309, 0.5731850266456604, 0.5714040398597717, 0.5713309645652771, 0.5727423429489136, 0.5681336522102356, 0.5687679052352905, 0.5655999183654785, 0.568689227104187, 0.5634929537773132, 0.5660080313682556, 0.5653570890426636, 0.56269770860672, 0.5627385377883911, 0.5592359900474548, 0.5616937279701233, 0.5583888292312622, 0.5578815937042236, 0.5567729473114014, 0.5515536665916443, 0.5531942844390869, 0.5540852546691895, 0.552767813205719, 0.5572890043258667, 0.5466875433921814, 0.5524547696113586, 0.5471544861793518, 0.5416136384010315, 0.5428069233894348, 0.5436866879463196, 0.5451154112815857, 0.5355271100997925, 0.5423811674118042, 0.5386444330215454, 0.5360761284828186, 0.5340836644172668, 0.536513090133667, 0.5290841460227966, 0.530623197555542, 0.5232299566268921, 0.5262457132339478, 0.5242762565612793, 0.5263353586196899, 0.5197485089302063, 0.5219449400901794, 0.5129891633987427, 0.516855001449585, 0.5160252451896667, 0.5144209265708923, 0.5133218765258789, 0.5144640803337097, 0.5089151859283447, 0.5074636936187744, 0.5030090808868408, 0.5091325044631958, 0.49965450167655945, 0.5015356540679932, 0.499979704618454, 0.49996814131736755, 0.49443721771240234, 0.49701863527297974, 0.4927370250225067, 0.49399638175964355, 0.4942159056663513, 0.4874146282672882, 0.4926208257675171, 0.47982195019721985, 0.4919480085372925, 0.4817154109477997, 0.4825400710105896, 0.4768720269203186, 0.47753533720970154, 0.47672149538993835, 0.48073697090148926, 0.46942412853240967, 0.46541011333465576, 0.4668876826763153, 0.465636670589447, 0.4635111689567566, 0.46744826436042786, 0.457297146320343, 0.46351152658462524, 0.46045437455177307], 'accuracy': [0.6837284564971924, 0.6848060488700867, 0.6934267282485962, 0.6893857717514038, 0.6877694129943848, 0.6947737336158752, 0.6996228694915771, 0.6907327771186829, 0.6955819129943848, 0.6915409564971924, 0.6926185488700867, 0.696659505367279, 0.6998922228813171, 0.6990840435028076, 0.7052801847457886, 0.6961206793785095, 0.7012392282485962, 0.7063577771186829, 0.701508641242981, 0.7055495977401733, 0.7033944129943848, 0.7023168206214905, 0.7055495977401733, 0.7025862336158752, 0.712553858757019, 0.7106680870056152, 0.7085129022598267, 0.7090517282485962, 0.7149784564971924, 0.7133620977401733, 0.7130926847457886, 0.712284505367279, 0.7114762663841248, 0.7206357717514038, 0.7141702771186829, 0.7141702771186829, 0.7192887663841248, 0.7206357717514038, 0.7295258641242981, 0.71875, 0.717133641242981, 0.7227909564971924, 0.7179418206214905, 0.728178858757019, 0.7335668206214905, 0.7324892282485962, 0.7297952771186829, 0.7211745977401733, 0.7378771305084229, 0.7273706793785095, 0.7308728694915771, 0.7397629022598267, 0.740840494632721, 0.7308728694915771, 0.7427262663841248, 0.7419180870056152, 0.751616358757019, 0.7386853694915771, 0.7443426847457886, 0.7397629022598267, 0.75, 0.7446120977401733, 0.751616358757019, 0.7524245977401733, 0.756465494632721, 0.751616358757019, 0.7494612336158752, 0.7529633641242981, 0.7583512663841248, 0.7632004022598267, 0.7610452771186829, 0.751347005367279, 0.7618534564971924, 0.759159505367279, 0.7653555870056152, 0.767241358757019, 0.7691271305084229, 0.7691271305084229, 0.7621228694915771, 0.7629310488700867, 0.7688577771186829, 0.7753232717514038, 0.772090494632721, 0.7801724076271057, 0.7685883641242981, 0.7764008641242981, 0.7766702771186829, 0.7815194129943848, 0.7777478694915771, 0.7774784564971924, 0.7780172228813171, 0.7863685488700867, 0.7966055870056152, 0.7860991358757019, 0.7887930870056152, 0.7909482717514038, 0.7847521305084229, 0.7928340435028076, 0.7858297228813171, 0.7949892282485962], 'val_loss': [0.6888143420219421, 0.6879158616065979, 0.6875216960906982, 0.6869279742240906, 0.6876750588417053, 0.6861509680747986, 0.6884192824363708, 0.687333881855011, 0.6872012615203857, 0.6883760690689087, 0.6870337128639221, 0.6875463128089905, 0.6861151456832886, 0.6840006113052368, 0.6906177997589111, 0.6735206246376038, 0.6929499506950378, 0.6809592247009277, 0.6764943599700928, 0.6447741389274597, 0.6286608576774597, 0.6388029456138611, 0.6207932829856873, 0.599036455154419, 0.6007218956947327, 0.5933614373207092, 0.593024730682373, 0.5951638221740723, 0.5948638319969177, 0.5954523682594299, 0.5961288213729858, 0.5968607068061829, 0.5957527160644531, 0.5950503945350647, 0.5956336259841919, 0.596109926700592, 0.5977919101715088, 0.6005846858024597, 0.6043444275856018, 0.6014177799224854, 0.598659336566925, 0.6207028031349182, 0.5963378548622131, 0.5980415344238281, 0.599100649356842, 0.6038245558738708, 0.5984228849411011, 0.5989698171615601, 0.6016660332679749, 0.5988859534263611, 0.6012338399887085, 0.6039226055145264, 0.6046147346496582, 0.6062617897987366, 0.6390694379806519, 0.6009337902069092, 0.603508472442627, 0.6047120094299316, 0.6057578325271606, 0.6107844710350037, 0.6118875741958618, 0.6073867082595825, 0.6127775311470032, 0.6283241510391235, 0.6105002164840698, 0.6119332313537598, 0.6291709542274475, 0.6113336682319641, 0.6329748034477234, 0.6151689887046814, 0.6129755973815918, 0.628510594367981, 0.620109498500824, 0.6181792616844177, 0.6342191100120544, 0.6189835667610168, 0.6356735229492188, 0.6266971230506897, 0.647307276725769, 0.6288188695907593, 0.6248764395713806, 0.6387972235679626, 0.6296932101249695, 0.6710028648376465, 0.6274024844169617, 0.6298289895057678, 0.6288233399391174, 0.6330599784851074, 0.6341982483863831, 0.6362525820732117, 0.6459053158760071, 0.636987030506134, 0.6440670490264893, 0.6529194116592407, 0.6428730487823486, 0.6520299315452576, 0.6581639051437378, 0.6454770565032959, 0.6856837868690491, 0.6480127573013306], 'val_accuracy': [0.5258620977401733, 0.524784505367279, 0.5183189511299133, 0.5215517282485962, 0.517241358757019, 0.5204741358757019, 0.517241358757019, 0.5193965435028076, 0.5204741358757019, 0.5204741358757019, 0.524784505367279, 0.5258620977401733, 0.5280172228813171, 0.5355603694915771, 0.53125, 0.5581896305084229, 0.5463362336158752, 0.5614224076271057, 0.5775862336158752, 0.6357758641242981, 0.6530172228813171, 0.642241358757019, 0.6691810488700867, 0.6875, 0.6907327771186829, 0.7025862336158752, 0.6993534564971924, 0.6971982717514038, 0.6961206793785095, 0.6993534564971924, 0.6961206793785095, 0.6982758641242981, 0.7004310488700867, 0.6971982717514038, 0.6928879022598267, 0.693965494632721, 0.6950430870056152, 0.693965494632721, 0.6907327771186829, 0.6928879022598267, 0.6950430870056152, 0.6788793206214905, 0.6971982717514038, 0.6993534564971924, 0.6971982717514038, 0.6982758641242981, 0.6961206793785095, 0.7004310488700867, 0.6961206793785095, 0.6971982717514038, 0.693965494632721, 0.6961206793785095, 0.7004310488700867, 0.7004310488700867, 0.6648706793785095, 0.6961206793785095, 0.6971982717514038, 0.693965494632721, 0.6928879022598267, 0.6993534564971924, 0.6896551847457886, 0.6907327771186829, 0.6918103694915771, 0.6928879022598267, 0.6982758641242981, 0.6918103694915771, 0.6885775923728943, 0.6885775923728943, 0.6864224076271057, 0.693965494632721, 0.693965494632721, 0.681034505367279, 0.6993534564971924, 0.6918103694915771, 0.6788793206214905, 0.6950430870056152, 0.6821120977401733, 0.6885775923728943, 0.6864224076271057, 0.6821120977401733, 0.6918103694915771, 0.6821120977401733, 0.6885775923728943, 0.6691810488700867, 0.6918103694915771, 0.6853448152542114, 0.6928879022598267, 0.6918103694915771, 0.6842672228813171, 0.6831896305084229, 0.6875, 0.6864224076271057, 0.681034505367279, 0.6842672228813171, 0.6853448152542114, 0.6831896305084229, 0.6778017282485962, 0.6885775923728943, 0.6659482717514038, 0.6885775923728943]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.6043 - accuracy: 0.6787"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 55ms/step - loss: 0.6023 - accuracy: 0.6811 - val_loss: 0.6895 - val_accuracy: 0.5192\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5969 - accuracy: 0.6828 - val_loss: 0.6884 - val_accuracy: 0.5238\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5965 - accuracy: 0.6828 - val_loss: 0.6895 - val_accuracy: 0.5068\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5953 - accuracy: 0.6839 - val_loss: 0.6898 - val_accuracy: 0.5068\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5920 - accuracy: 0.6885 - val_loss: 0.6915 - val_accuracy: 0.5057\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5952 - accuracy: 0.6882 - val_loss: 0.6894 - val_accuracy: 0.5079\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5910 - accuracy: 0.6873 - val_loss: 0.6898 - val_accuracy: 0.5079\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5884 - accuracy: 0.6919 - val_loss: 0.6925 - val_accuracy: 0.5068\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5920 - accuracy: 0.6851 - val_loss: 0.6923 - val_accuracy: 0.5068\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5913 - accuracy: 0.6845 - val_loss: 0.6955 - val_accuracy: 0.5068\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5894 - accuracy: 0.6916 - val_loss: 0.6964 - val_accuracy: 0.5079\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5877 - accuracy: 0.6938 - val_loss: 0.6962 - val_accuracy: 0.5090\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5864 - accuracy: 0.6947 - val_loss: 0.6936 - val_accuracy: 0.5113\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5864 - accuracy: 0.6919 - val_loss: 0.6992 - val_accuracy: 0.5124\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5848 - accuracy: 0.6972 - val_loss: 0.6984 - val_accuracy: 0.5192\n","Epoch 16/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5846 - accuracy: 0.6958 - val_loss: 0.6902 - val_accuracy: 0.5396\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5830 - accuracy: 0.6984 - val_loss: 0.6961 - val_accuracy: 0.5373\n","Epoch 18/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5823 - accuracy: 0.6933 - val_loss: 0.6735 - val_accuracy: 0.5747\n","Epoch 19/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5817 - accuracy: 0.6961 - val_loss: 0.7121 - val_accuracy: 0.5396\n","Epoch 20/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5825 - accuracy: 0.6964 - val_loss: 0.6648 - val_accuracy: 0.5860\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5780 - accuracy: 0.6989 - val_loss: 0.6654 - val_accuracy: 0.5905\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5758 - accuracy: 0.7037 - val_loss: 0.6363 - val_accuracy: 0.6335\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5766 - accuracy: 0.6995 - val_loss: 0.6432 - val_accuracy: 0.6210\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5718 - accuracy: 0.7088 - val_loss: 0.6614 - val_accuracy: 0.6120\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5745 - accuracy: 0.7035 - val_loss: 0.6274 - val_accuracy: 0.6606\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5729 - accuracy: 0.7063 - val_loss: 0.6035 - val_accuracy: 0.6912\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5751 - accuracy: 0.7037 - val_loss: 0.6056 - val_accuracy: 0.6889\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5736 - accuracy: 0.7040 - val_loss: 0.6054 - val_accuracy: 0.6923\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5733 - accuracy: 0.7068 - val_loss: 0.6205 - val_accuracy: 0.6787\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5779 - accuracy: 0.7020 - val_loss: 0.6022 - val_accuracy: 0.6900\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5755 - accuracy: 0.7012 - val_loss: 0.6002 - val_accuracy: 0.6878\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5687 - accuracy: 0.7100 - val_loss: 0.6046 - val_accuracy: 0.6867\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5718 - accuracy: 0.7049 - val_loss: 0.6021 - val_accuracy: 0.6900\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5702 - accuracy: 0.7094 - val_loss: 0.6014 - val_accuracy: 0.6889\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5637 - accuracy: 0.7139 - val_loss: 0.6007 - val_accuracy: 0.6912\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5648 - accuracy: 0.7139 - val_loss: 0.6042 - val_accuracy: 0.6889\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5676 - accuracy: 0.7122 - val_loss: 0.6026 - val_accuracy: 0.6855\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5628 - accuracy: 0.7168 - val_loss: 0.6003 - val_accuracy: 0.6923\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5677 - accuracy: 0.7108 - val_loss: 0.6089 - val_accuracy: 0.6878\n","Epoch 40/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5577 - accuracy: 0.7182 - val_loss: 0.6024 - val_accuracy: 0.6934\n","Epoch 41/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5646 - accuracy: 0.7122 - val_loss: 0.6002 - val_accuracy: 0.6946\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5656 - accuracy: 0.7080 - val_loss: 0.6017 - val_accuracy: 0.6900\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5572 - accuracy: 0.7204 - val_loss: 0.6017 - val_accuracy: 0.6923\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5595 - accuracy: 0.7204 - val_loss: 0.6052 - val_accuracy: 0.6833\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5587 - accuracy: 0.7193 - val_loss: 0.6085 - val_accuracy: 0.6878\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5585 - accuracy: 0.7196 - val_loss: 0.6084 - val_accuracy: 0.6923\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5561 - accuracy: 0.7250 - val_loss: 0.6015 - val_accuracy: 0.6946\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5523 - accuracy: 0.7258 - val_loss: 0.6036 - val_accuracy: 0.6900\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5515 - accuracy: 0.7315 - val_loss: 0.6074 - val_accuracy: 0.6912\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5487 - accuracy: 0.7258 - val_loss: 0.6013 - val_accuracy: 0.6889\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5441 - accuracy: 0.7374 - val_loss: 0.6048 - val_accuracy: 0.6912\n","Epoch 52/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5443 - accuracy: 0.7320 - val_loss: 0.6031 - val_accuracy: 0.6968\n","Epoch 53/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5473 - accuracy: 0.7301 - val_loss: 0.6015 - val_accuracy: 0.7014\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5412 - accuracy: 0.7397 - val_loss: 0.6030 - val_accuracy: 0.6991\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5438 - accuracy: 0.7329 - val_loss: 0.6050 - val_accuracy: 0.6889\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5480 - accuracy: 0.7258 - val_loss: 0.6077 - val_accuracy: 0.6900\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5379 - accuracy: 0.7363 - val_loss: 0.6131 - val_accuracy: 0.6900\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5423 - accuracy: 0.7368 - val_loss: 0.6051 - val_accuracy: 0.6889\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5351 - accuracy: 0.7374 - val_loss: 0.6051 - val_accuracy: 0.6957\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5317 - accuracy: 0.7436 - val_loss: 0.6069 - val_accuracy: 0.6991\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5321 - accuracy: 0.7445 - val_loss: 0.6128 - val_accuracy: 0.6844\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5340 - accuracy: 0.7436 - val_loss: 0.6211 - val_accuracy: 0.6742\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5353 - accuracy: 0.7374 - val_loss: 0.6170 - val_accuracy: 0.6810\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5318 - accuracy: 0.7402 - val_loss: 0.6099 - val_accuracy: 0.6934\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5273 - accuracy: 0.7470 - val_loss: 0.6129 - val_accuracy: 0.6900\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5304 - accuracy: 0.7459 - val_loss: 0.6134 - val_accuracy: 0.6923\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5226 - accuracy: 0.7516 - val_loss: 0.6097 - val_accuracy: 0.6934\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5285 - accuracy: 0.7400 - val_loss: 0.6183 - val_accuracy: 0.6844\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5220 - accuracy: 0.7439 - val_loss: 0.6124 - val_accuracy: 0.6934\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5186 - accuracy: 0.7535 - val_loss: 0.6119 - val_accuracy: 0.6946\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5220 - accuracy: 0.7496 - val_loss: 0.6165 - val_accuracy: 0.6855\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5150 - accuracy: 0.7558 - val_loss: 0.6126 - val_accuracy: 0.6867\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5154 - accuracy: 0.7550 - val_loss: 0.6150 - val_accuracy: 0.6878\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5257 - accuracy: 0.7431 - val_loss: 0.6161 - val_accuracy: 0.6912\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5137 - accuracy: 0.7555 - val_loss: 0.6155 - val_accuracy: 0.6889\n","Epoch 76/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5116 - accuracy: 0.7637 - val_loss: 0.6132 - val_accuracy: 0.6968\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5061 - accuracy: 0.7572 - val_loss: 0.6257 - val_accuracy: 0.6833\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5081 - accuracy: 0.7547 - val_loss: 0.6147 - val_accuracy: 0.6957\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5023 - accuracy: 0.7615 - val_loss: 0.6206 - val_accuracy: 0.6855\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5087 - accuracy: 0.7533 - val_loss: 0.6158 - val_accuracy: 0.6867\n","Epoch 81/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5030 - accuracy: 0.7640 - val_loss: 0.6190 - val_accuracy: 0.6968\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5009 - accuracy: 0.7646 - val_loss: 0.6308 - val_accuracy: 0.6934\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5168 - accuracy: 0.7470 - val_loss: 0.6188 - val_accuracy: 0.6844\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5083 - accuracy: 0.7569 - val_loss: 0.6424 - val_accuracy: 0.6731\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4933 - accuracy: 0.7728 - val_loss: 0.6203 - val_accuracy: 0.6957\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5036 - accuracy: 0.7640 - val_loss: 0.6273 - val_accuracy: 0.6912\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4972 - accuracy: 0.7674 - val_loss: 0.6552 - val_accuracy: 0.6538\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4917 - accuracy: 0.7722 - val_loss: 0.6225 - val_accuracy: 0.6934\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4892 - accuracy: 0.7733 - val_loss: 0.6395 - val_accuracy: 0.6731\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4862 - accuracy: 0.7714 - val_loss: 0.6245 - val_accuracy: 0.6957\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4868 - accuracy: 0.7745 - val_loss: 0.6445 - val_accuracy: 0.6742\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4849 - accuracy: 0.7725 - val_loss: 0.6314 - val_accuracy: 0.6855\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4792 - accuracy: 0.7824 - val_loss: 0.6328 - val_accuracy: 0.6968\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4779 - accuracy: 0.7827 - val_loss: 0.6331 - val_accuracy: 0.6968\n","Epoch 95/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4788 - accuracy: 0.7813 - val_loss: 0.6384 - val_accuracy: 0.6753\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4798 - accuracy: 0.7813 - val_loss: 0.6384 - val_accuracy: 0.6946\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4687 - accuracy: 0.7883 - val_loss: 0.6573 - val_accuracy: 0.6719\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4766 - accuracy: 0.7818 - val_loss: 0.6376 - val_accuracy: 0.6946\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4988 - accuracy: 0.7575 - val_loss: 0.6298 - val_accuracy: 0.6957\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4744 - accuracy: 0.7779 - val_loss: 0.6412 - val_accuracy: 0.6708\n","{'loss': [0.6022844910621643, 0.5968689322471619, 0.5965140461921692, 0.5953479409217834, 0.5920419692993164, 0.59520423412323, 0.5910215377807617, 0.5883961319923401, 0.5920458436012268, 0.5912562012672424, 0.5893778800964355, 0.5877069234848022, 0.5864435434341431, 0.5864241123199463, 0.5848094820976257, 0.5845986008644104, 0.5829970240592957, 0.5822593569755554, 0.5817168951034546, 0.5825344324111938, 0.5780373811721802, 0.5758168697357178, 0.5765660405158997, 0.571789026260376, 0.5745437741279602, 0.5729267001152039, 0.5750872492790222, 0.5735921859741211, 0.573349118232727, 0.5779056549072266, 0.5755444765090942, 0.5686768293380737, 0.5718219876289368, 0.5701566934585571, 0.563673198223114, 0.5648448467254639, 0.5676237940788269, 0.5628074407577515, 0.5676748156547546, 0.5576610565185547, 0.5645580887794495, 0.5656384825706482, 0.5572189092636108, 0.5595168471336365, 0.5587478876113892, 0.5585373640060425, 0.5561411380767822, 0.552312433719635, 0.5515117645263672, 0.5486574769020081, 0.5440542697906494, 0.5442987680435181, 0.54734206199646, 0.5411973595619202, 0.5438359975814819, 0.5479798316955566, 0.5379250049591064, 0.5423161387443542, 0.5350853204727173, 0.531658947467804, 0.5320807695388794, 0.5339905619621277, 0.5353003740310669, 0.5318387150764465, 0.5272709131240845, 0.5303517580032349, 0.5225508213043213, 0.5285364985466003, 0.5220499038696289, 0.5186238884925842, 0.5220211744308472, 0.5150414705276489, 0.5153896808624268, 0.5257450342178345, 0.513696014881134, 0.5115842223167419, 0.5061105489730835, 0.5081261396408081, 0.5022541880607605, 0.5086545944213867, 0.503020703792572, 0.5009358525276184, 0.516787588596344, 0.5083261132240295, 0.49332568049430847, 0.5036165118217468, 0.49722278118133545, 0.49172794818878174, 0.4891693890094757, 0.48621466755867004, 0.4867704212665558, 0.48493334650993347, 0.47921982407569885, 0.4779101312160492, 0.4787817597389221, 0.47976285219192505, 0.4686729609966278, 0.4765925109386444, 0.49882104992866516, 0.4744269847869873], 'accuracy': [0.6810979247093201, 0.6827957034111023, 0.6827957034111023, 0.6839275360107422, 0.6884549856185913, 0.6881720423698425, 0.6873231530189514, 0.6918506026268005, 0.6850594282150269, 0.6844934821128845, 0.691567599773407, 0.6938313245773315, 0.6946802735328674, 0.6918506026268005, 0.6972269415855408, 0.6958121061325073, 0.6983587741851807, 0.693265438079834, 0.6960950493812561, 0.6963780522346497, 0.698924720287323, 0.7037351727485657, 0.6994906663894653, 0.7088285088539124, 0.7034521698951721, 0.706281840801239, 0.7037351727485657, 0.7040181159973145, 0.7068477869033813, 0.7020373344421387, 0.7011884450912476, 0.709960401058197, 0.7048670053482056, 0.7093944549560547, 0.7139219045639038, 0.7139219045639038, 0.7122241258621216, 0.7167515754699707, 0.7108092904090881, 0.7181664109230042, 0.7122241258621216, 0.7079796195030212, 0.7204301357269287, 0.7204301357269287, 0.719298243522644, 0.7195811867713928, 0.7249575257301331, 0.725806474685669, 0.731465756893158, 0.725806474685669, 0.7374080419540405, 0.7320317029953003, 0.7300509214401245, 0.7396717667579651, 0.7328805923461914, 0.725806474685669, 0.7362761497497559, 0.7368420958518982, 0.7374080419540405, 0.7436332702636719, 0.744482159614563, 0.7436332702636719, 0.7374080419540405, 0.7402377128601074, 0.7470288872718811, 0.7458969950675964, 0.7515563368797302, 0.7399547100067139, 0.7439162135124207, 0.7535370588302612, 0.7495755553245544, 0.7558007836341858, 0.7549518942832947, 0.7430673241615295, 0.755517840385437, 0.7637238502502441, 0.7572156190872192, 0.7546689510345459, 0.7614601254463196, 0.7532541155815125, 0.7640067934989929, 0.7645727396011353, 0.7470288872718811, 0.7569326758384705, 0.7727787494659424, 0.7640067934989929, 0.7674023509025574, 0.7722128033638, 0.7733446359634399, 0.7713639140129089, 0.7744765281677246, 0.7724957466125488, 0.7823995351791382, 0.7826825380325317, 0.7812677025794983, 0.7812677025794983, 0.7883418202400208, 0.7818335890769958, 0.757498562335968, 0.7778720855712891], 'val_loss': [0.6894840002059937, 0.6884099841117859, 0.689530611038208, 0.6898009777069092, 0.6914593577384949, 0.6894264221191406, 0.6898226737976074, 0.6924927234649658, 0.6922592520713806, 0.695462167263031, 0.6963863968849182, 0.696197509765625, 0.693587064743042, 0.6992264986038208, 0.69841468334198, 0.6902452707290649, 0.6961198449134827, 0.6734985113143921, 0.712057888507843, 0.6647815108299255, 0.6653774380683899, 0.6362547278404236, 0.6431504487991333, 0.6614235043525696, 0.62740159034729, 0.6034848093986511, 0.6056267023086548, 0.6053990721702576, 0.6205352544784546, 0.6022014617919922, 0.6002220511436462, 0.6046193838119507, 0.6021205186843872, 0.6014349460601807, 0.6007006168365479, 0.604191780090332, 0.6026024222373962, 0.6002916693687439, 0.6088770627975464, 0.6023592948913574, 0.6002109050750732, 0.6016845703125, 0.6017146706581116, 0.6052389740943909, 0.6084733605384827, 0.608350396156311, 0.6015169024467468, 0.603560209274292, 0.6073600649833679, 0.6013270020484924, 0.604826033115387, 0.6030747890472412, 0.6014943718910217, 0.6029751896858215, 0.6050352454185486, 0.6076748371124268, 0.6131128072738647, 0.6050874590873718, 0.605056881904602, 0.60691237449646, 0.612794816493988, 0.6210961937904358, 0.6170485019683838, 0.6099194884300232, 0.6129199862480164, 0.6133983731269836, 0.6096962690353394, 0.6183345913887024, 0.6123899817466736, 0.6119204163551331, 0.6165239810943604, 0.6125820875167847, 0.6149976253509521, 0.6161110997200012, 0.6155010461807251, 0.6131680607795715, 0.6257120370864868, 0.614716112613678, 0.6206499934196472, 0.6157801747322083, 0.6189906597137451, 0.6308198571205139, 0.6187970042228699, 0.6424251198768616, 0.6203317046165466, 0.6273229122161865, 0.6552224159240723, 0.6224656105041504, 0.6395044326782227, 0.624505341053009, 0.6444880962371826, 0.6313689947128296, 0.6327732801437378, 0.6331376433372498, 0.6384090781211853, 0.6384036540985107, 0.6572602391242981, 0.6376435160636902, 0.6298182010650635, 0.6412440538406372], 'val_accuracy': [0.5192307829856873, 0.523755669593811, 0.5067873597145081, 0.5067873597145081, 0.5056561231613159, 0.5079185366630554, 0.5079185366630554, 0.5067873597145081, 0.5067873597145081, 0.5067873597145081, 0.5079185366630554, 0.5090497732162476, 0.5113122463226318, 0.5124434232711792, 0.5192307829856873, 0.5395927429199219, 0.5373303294181824, 0.5746606588363647, 0.5395927429199219, 0.5859728455543518, 0.5904977321624756, 0.6334841847419739, 0.6210407018661499, 0.6119909286499023, 0.6606335043907166, 0.6911764740943909, 0.6889140009880066, 0.692307710647583, 0.6787330508232117, 0.6900452375411987, 0.6877828240394592, 0.6866515874862671, 0.6900452375411987, 0.6889140009880066, 0.6911764740943909, 0.6889140009880066, 0.685520350933075, 0.692307710647583, 0.6877828240394592, 0.6934388875961304, 0.6945701241493225, 0.6900452375411987, 0.692307710647583, 0.6832579374313354, 0.6877828240394592, 0.692307710647583, 0.6945701241493225, 0.6900452375411987, 0.6911764740943909, 0.6889140009880066, 0.6911764740943909, 0.6968325972557068, 0.7013574838638306, 0.6990950107574463, 0.6889140009880066, 0.6900452375411987, 0.6900452375411987, 0.6889140009880066, 0.6957013607025146, 0.6990950107574463, 0.6843891143798828, 0.6742081642150879, 0.6809954643249512, 0.6934388875961304, 0.6900452375411987, 0.692307710647583, 0.6934388875961304, 0.6843891143798828, 0.6934388875961304, 0.6945701241493225, 0.685520350933075, 0.6866515874862671, 0.6877828240394592, 0.6911764740943909, 0.6889140009880066, 0.6968325972557068, 0.6832579374313354, 0.6957013607025146, 0.685520350933075, 0.6866515874862671, 0.6968325972557068, 0.6934388875961304, 0.6843891143798828, 0.6730769276618958, 0.6957013607025146, 0.6911764740943909, 0.6538461446762085, 0.6934388875961304, 0.6730769276618958, 0.6957013607025146, 0.6742081642150879, 0.685520350933075, 0.6968325972557068, 0.6968325972557068, 0.6753393411636353, 0.6945701241493225, 0.6719456911087036, 0.6945701241493225, 0.6957013607025146, 0.6708144545555115]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.5923 - accuracy: 0.6883"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 55ms/step - loss: 0.5929 - accuracy: 0.6889 - val_loss: 0.6888 - val_accuracy: 0.5320\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5883 - accuracy: 0.6917 - val_loss: 0.6881 - val_accuracy: 0.5248\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5881 - accuracy: 0.6953 - val_loss: 0.6872 - val_accuracy: 0.5269\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5841 - accuracy: 0.6941 - val_loss: 0.6875 - val_accuracy: 0.5186\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5812 - accuracy: 0.6956 - val_loss: 0.6870 - val_accuracy: 0.5238\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5815 - accuracy: 0.7003 - val_loss: 0.6877 - val_accuracy: 0.5186\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5793 - accuracy: 0.7041 - val_loss: 0.6890 - val_accuracy: 0.5176\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5810 - accuracy: 0.6961 - val_loss: 0.6914 - val_accuracy: 0.5176\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5771 - accuracy: 0.7018 - val_loss: 0.6884 - val_accuracy: 0.5227\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5771 - accuracy: 0.7016 - val_loss: 0.6886 - val_accuracy: 0.5258\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5784 - accuracy: 0.7018 - val_loss: 0.6892 - val_accuracy: 0.5279\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5757 - accuracy: 0.7093 - val_loss: 0.6979 - val_accuracy: 0.5227\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5752 - accuracy: 0.7003 - val_loss: 0.6905 - val_accuracy: 0.5320\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5812 - accuracy: 0.6959 - val_loss: 0.6797 - val_accuracy: 0.5599\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5743 - accuracy: 0.7023 - val_loss: 0.6912 - val_accuracy: 0.5486\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5723 - accuracy: 0.7075 - val_loss: 0.6843 - val_accuracy: 0.5692\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5705 - accuracy: 0.7075 - val_loss: 0.7111 - val_accuracy: 0.5558\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5759 - accuracy: 0.7044 - val_loss: 0.6675 - val_accuracy: 0.5971\n","Epoch 19/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5726 - accuracy: 0.7098 - val_loss: 0.6576 - val_accuracy: 0.6136\n","Epoch 20/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.5723 - accuracy: 0.7016 - val_loss: 0.6619 - val_accuracy: 0.6157\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5681 - accuracy: 0.7101 - val_loss: 0.6486 - val_accuracy: 0.6281\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5729 - accuracy: 0.7018 - val_loss: 0.6336 - val_accuracy: 0.6519\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5692 - accuracy: 0.7142 - val_loss: 0.6200 - val_accuracy: 0.6715\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5658 - accuracy: 0.7124 - val_loss: 0.6128 - val_accuracy: 0.6705\n","Epoch 25/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.5648 - accuracy: 0.7137 - val_loss: 0.6220 - val_accuracy: 0.6725\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5701 - accuracy: 0.7116 - val_loss: 0.6147 - val_accuracy: 0.6756\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5638 - accuracy: 0.7171 - val_loss: 0.6205 - val_accuracy: 0.6674\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5640 - accuracy: 0.7140 - val_loss: 0.6217 - val_accuracy: 0.6581\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5638 - accuracy: 0.7109 - val_loss: 0.6203 - val_accuracy: 0.6684\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5605 - accuracy: 0.7191 - val_loss: 0.6178 - val_accuracy: 0.6663\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5592 - accuracy: 0.7202 - val_loss: 0.6204 - val_accuracy: 0.6725\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5615 - accuracy: 0.7158 - val_loss: 0.6183 - val_accuracy: 0.6643\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5596 - accuracy: 0.7194 - val_loss: 0.6220 - val_accuracy: 0.6612\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5557 - accuracy: 0.7222 - val_loss: 0.6182 - val_accuracy: 0.6653\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5557 - accuracy: 0.7217 - val_loss: 0.6209 - val_accuracy: 0.6622\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5574 - accuracy: 0.7165 - val_loss: 0.6212 - val_accuracy: 0.6674\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5556 - accuracy: 0.7227 - val_loss: 0.6204 - val_accuracy: 0.6746\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5579 - accuracy: 0.7176 - val_loss: 0.6203 - val_accuracy: 0.6674\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5463 - accuracy: 0.7310 - val_loss: 0.6225 - val_accuracy: 0.6674\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5537 - accuracy: 0.7269 - val_loss: 0.6249 - val_accuracy: 0.6663\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5517 - accuracy: 0.7269 - val_loss: 0.6333 - val_accuracy: 0.6570\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5508 - accuracy: 0.7313 - val_loss: 0.6221 - val_accuracy: 0.6674\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5480 - accuracy: 0.7323 - val_loss: 0.6230 - val_accuracy: 0.6674\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5500 - accuracy: 0.7333 - val_loss: 0.6210 - val_accuracy: 0.6632\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5461 - accuracy: 0.7297 - val_loss: 0.6222 - val_accuracy: 0.6643\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5471 - accuracy: 0.7302 - val_loss: 0.6221 - val_accuracy: 0.6663\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5436 - accuracy: 0.7302 - val_loss: 0.6259 - val_accuracy: 0.6736\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5434 - accuracy: 0.7274 - val_loss: 0.6245 - val_accuracy: 0.6643\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5403 - accuracy: 0.7349 - val_loss: 0.6245 - val_accuracy: 0.6694\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5373 - accuracy: 0.7388 - val_loss: 0.6254 - val_accuracy: 0.6643\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5400 - accuracy: 0.7370 - val_loss: 0.6252 - val_accuracy: 0.6663\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5367 - accuracy: 0.7364 - val_loss: 0.6368 - val_accuracy: 0.6612\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5368 - accuracy: 0.7351 - val_loss: 0.6283 - val_accuracy: 0.6643\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5371 - accuracy: 0.7457 - val_loss: 0.6314 - val_accuracy: 0.6663\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5313 - accuracy: 0.7416 - val_loss: 0.6325 - val_accuracy: 0.6694\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5396 - accuracy: 0.7320 - val_loss: 0.6267 - val_accuracy: 0.6715\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5317 - accuracy: 0.7408 - val_loss: 0.6283 - val_accuracy: 0.6674\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5277 - accuracy: 0.7408 - val_loss: 0.6347 - val_accuracy: 0.6746\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5270 - accuracy: 0.7478 - val_loss: 0.6349 - val_accuracy: 0.6756\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5260 - accuracy: 0.7468 - val_loss: 0.6305 - val_accuracy: 0.6643\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5256 - accuracy: 0.7473 - val_loss: 0.6469 - val_accuracy: 0.6632\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5250 - accuracy: 0.7509 - val_loss: 0.6363 - val_accuracy: 0.6725\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5199 - accuracy: 0.7499 - val_loss: 0.6377 - val_accuracy: 0.6736\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5162 - accuracy: 0.7610 - val_loss: 0.6344 - val_accuracy: 0.6725\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5174 - accuracy: 0.7439 - val_loss: 0.6358 - val_accuracy: 0.6674\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5188 - accuracy: 0.7545 - val_loss: 0.6399 - val_accuracy: 0.6756\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5122 - accuracy: 0.7525 - val_loss: 0.6335 - val_accuracy: 0.6663\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 0.7530 - val_loss: 0.6384 - val_accuracy: 0.6643\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5181 - accuracy: 0.7514 - val_loss: 0.6370 - val_accuracy: 0.6684\n","Epoch 70/100\n","31/31 [==============================] - 2s 61ms/step - loss: 0.5088 - accuracy: 0.7597 - val_loss: 0.6453 - val_accuracy: 0.6767\n","Epoch 71/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5124 - accuracy: 0.7571 - val_loss: 0.6479 - val_accuracy: 0.6694\n","Epoch 72/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5096 - accuracy: 0.7594 - val_loss: 0.6417 - val_accuracy: 0.6653\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5113 - accuracy: 0.7636 - val_loss: 0.6397 - val_accuracy: 0.6674\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5155 - accuracy: 0.7499 - val_loss: 0.6525 - val_accuracy: 0.6715\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5189 - accuracy: 0.7470 - val_loss: 0.6403 - val_accuracy: 0.6643\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5012 - accuracy: 0.7659 - val_loss: 0.6463 - val_accuracy: 0.6767\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4997 - accuracy: 0.7695 - val_loss: 0.6615 - val_accuracy: 0.6694\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4956 - accuracy: 0.7711 - val_loss: 0.6471 - val_accuracy: 0.6674\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4931 - accuracy: 0.7674 - val_loss: 0.6500 - val_accuracy: 0.6736\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4965 - accuracy: 0.7669 - val_loss: 0.6565 - val_accuracy: 0.6601\n","Epoch 81/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4927 - accuracy: 0.7693 - val_loss: 0.6582 - val_accuracy: 0.6808\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4909 - accuracy: 0.7739 - val_loss: 0.6563 - val_accuracy: 0.6550\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4875 - accuracy: 0.7734 - val_loss: 0.6680 - val_accuracy: 0.6756\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4888 - accuracy: 0.7780 - val_loss: 0.6548 - val_accuracy: 0.6674\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4888 - accuracy: 0.7796 - val_loss: 0.6577 - val_accuracy: 0.6715\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4869 - accuracy: 0.7806 - val_loss: 0.6913 - val_accuracy: 0.6457\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4862 - accuracy: 0.7757 - val_loss: 0.6585 - val_accuracy: 0.6715\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4825 - accuracy: 0.7806 - val_loss: 0.6591 - val_accuracy: 0.6694\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4789 - accuracy: 0.7817 - val_loss: 0.6764 - val_accuracy: 0.6591\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4834 - accuracy: 0.7788 - val_loss: 0.6714 - val_accuracy: 0.6529\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4800 - accuracy: 0.7829 - val_loss: 0.6872 - val_accuracy: 0.6488\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4799 - accuracy: 0.7811 - val_loss: 0.6617 - val_accuracy: 0.6767\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4846 - accuracy: 0.7775 - val_loss: 0.6619 - val_accuracy: 0.6591\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4755 - accuracy: 0.7842 - val_loss: 0.6667 - val_accuracy: 0.6653\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4740 - accuracy: 0.7786 - val_loss: 0.6684 - val_accuracy: 0.6705\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4702 - accuracy: 0.7858 - val_loss: 0.6713 - val_accuracy: 0.6601\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4666 - accuracy: 0.7922 - val_loss: 0.6728 - val_accuracy: 0.6601\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4640 - accuracy: 0.7915 - val_loss: 0.6779 - val_accuracy: 0.6736\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4630 - accuracy: 0.7886 - val_loss: 0.6888 - val_accuracy: 0.6581\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4701 - accuracy: 0.7907 - val_loss: 0.6969 - val_accuracy: 0.6477\n","{'loss': [0.5928665399551392, 0.5882647037506104, 0.5881224274635315, 0.5840862989425659, 0.5811573266983032, 0.5815221071243286, 0.579322874546051, 0.5810061097145081, 0.5771116018295288, 0.5771458745002747, 0.5784363150596619, 0.5757092833518982, 0.5751788020133972, 0.5811764001846313, 0.5742736458778381, 0.5722581148147583, 0.570536732673645, 0.5758978724479675, 0.572594404220581, 0.5722709894180298, 0.568131685256958, 0.5728989243507385, 0.5692059397697449, 0.5658488273620605, 0.564803421497345, 0.5701124668121338, 0.5638440847396851, 0.5639609098434448, 0.5637964606285095, 0.560458779335022, 0.5592133402824402, 0.5615115761756897, 0.5596262812614441, 0.5556506514549255, 0.5557276010513306, 0.5574201941490173, 0.5555592179298401, 0.5579416751861572, 0.546271026134491, 0.5537477135658264, 0.551679790019989, 0.5507587790489197, 0.5480250120162964, 0.549994170665741, 0.5461495518684387, 0.5470832586288452, 0.5436315536499023, 0.5434202551841736, 0.540338397026062, 0.537299394607544, 0.5399793386459351, 0.5366900563240051, 0.5367909073829651, 0.5370610952377319, 0.5312532186508179, 0.5395880937576294, 0.5316637754440308, 0.5276750922203064, 0.5270332098007202, 0.5260448455810547, 0.5256301760673523, 0.5250318050384521, 0.5199141502380371, 0.5161646008491516, 0.5173749923706055, 0.5188007354736328, 0.5122458934783936, 0.5125078558921814, 0.5181328654289246, 0.5087988376617432, 0.5123887658119202, 0.5096297860145569, 0.5112977623939514, 0.5155146718025208, 0.5189083218574524, 0.5012001395225525, 0.4996548593044281, 0.4955739378929138, 0.49311187863349915, 0.49648964405059814, 0.492707759141922, 0.4909246265888214, 0.4875219464302063, 0.4887915253639221, 0.48882821202278137, 0.4868641793727875, 0.4861730933189392, 0.48251500725746155, 0.4789244532585144, 0.4834267497062683, 0.4799974262714386, 0.4799495041370392, 0.48463645577430725, 0.47548553347587585, 0.47395944595336914, 0.470162957906723, 0.4665699899196625, 0.46397167444229126, 0.4629862308502197, 0.47011488676071167], 'accuracy': [0.6888889074325562, 0.6917312741279602, 0.695348858833313, 0.6940568685531616, 0.6956072449684143, 0.7002583742141724, 0.7041343450546265, 0.6961240172386169, 0.7018088102340698, 0.7015503644943237, 0.7018088102340698, 0.7093023061752319, 0.7002583742141724, 0.6958656311035156, 0.7023255825042725, 0.7074935436248779, 0.7074935436248779, 0.7043927907943726, 0.7098191380500793, 0.7015503644943237, 0.7100775241851807, 0.7018088102340698, 0.7142118811607361, 0.7124031186103821, 0.7136951088905334, 0.7116279006004333, 0.7170542478561401, 0.7139534950256348, 0.7108527421951294, 0.7191214561462402, 0.7201550602912903, 0.7157622575759888, 0.7193798422813416, 0.7222222089767456, 0.721705436706543, 0.7165374755859375, 0.722739040851593, 0.7175710797309875, 0.7310077548027039, 0.7268733978271484, 0.7268733978271484, 0.7312661409378052, 0.7322997450828552, 0.7333333492279053, 0.7297157645225525, 0.7302325367927551, 0.7302325367927551, 0.7273901700973511, 0.734883725643158, 0.7387596964836121, 0.7369509339332581, 0.7364341020584106, 0.7351421117782593, 0.7457364201545715, 0.7416020631790161, 0.7320413589477539, 0.7408268451690674, 0.7408268451690674, 0.7478036284446716, 0.7467700242996216, 0.7472867965698242, 0.750904381275177, 0.749870777130127, 0.7609819173812866, 0.7439276576042175, 0.7545219659805298, 0.7524547576904297, 0.7529715895652771, 0.7514212131500244, 0.7596899271011353, 0.7571059465408325, 0.7594315409660339, 0.7635658979415894, 0.749870777130127, 0.7470284104347229, 0.7658914923667908, 0.7695090174674988, 0.7710594534873962, 0.7674418687820435, 0.766925036907196, 0.7692506313323975, 0.7739018201828003, 0.7733849883079529, 0.7780361771583557, 0.7795865535736084, 0.7806201577186584, 0.7757105827331543, 0.7806201577186584, 0.7816537618637085, 0.7788113951683044, 0.7829457521438599, 0.7811369299888611, 0.7775194048881531, 0.7842377424240112, 0.7785529494285583, 0.7857881188392639, 0.7922480702400208, 0.791472852230072, 0.788630485534668, 0.7906976938247681], 'val_loss': [0.6888129711151123, 0.6880643963813782, 0.6872346997261047, 0.687492847442627, 0.6869608759880066, 0.6877087950706482, 0.6890272498130798, 0.6913713812828064, 0.688389778137207, 0.6885506510734558, 0.6891711950302124, 0.6978554725646973, 0.6904790997505188, 0.6796649098396301, 0.6912181973457336, 0.6842981576919556, 0.7110865712165833, 0.6674944162368774, 0.6576057076454163, 0.661888837814331, 0.6486306190490723, 0.6335809230804443, 0.6200319528579712, 0.6127912998199463, 0.6219748258590698, 0.6146950125694275, 0.6204958558082581, 0.6216567754745483, 0.6202965378761292, 0.6177788376808167, 0.6203696131706238, 0.618324339389801, 0.6220213770866394, 0.618187665939331, 0.6208619475364685, 0.6212013363838196, 0.6203926801681519, 0.6202710866928101, 0.6224783658981323, 0.6249184012413025, 0.6333330869674683, 0.6221390962600708, 0.6229786276817322, 0.621028482913971, 0.6222384572029114, 0.6220549941062927, 0.625878095626831, 0.624537467956543, 0.6245371103286743, 0.625355064868927, 0.6251998543739319, 0.6368088722229004, 0.6283348202705383, 0.6313556432723999, 0.632474958896637, 0.6266516447067261, 0.6282935738563538, 0.6346977949142456, 0.6348512768745422, 0.6305199861526489, 0.6468982696533203, 0.6363058090209961, 0.6376982927322388, 0.6343994736671448, 0.6357628703117371, 0.639874279499054, 0.6334950923919678, 0.6383749842643738, 0.6370338797569275, 0.6453166007995605, 0.6478726863861084, 0.6416727900505066, 0.639710545539856, 0.6524658203125, 0.6402534246444702, 0.6462716460227966, 0.6615203619003296, 0.6471015214920044, 0.6499805450439453, 0.6565181016921997, 0.6582332253456116, 0.6562893986701965, 0.6679531335830688, 0.6547656655311584, 0.657724916934967, 0.69134122133255, 0.6584904789924622, 0.6591150164604187, 0.676430344581604, 0.6713678240776062, 0.687157154083252, 0.6616699695587158, 0.6618682146072388, 0.6666887998580933, 0.6683530211448669, 0.6712526679039001, 0.6728240847587585, 0.6779062747955322, 0.6888312101364136, 0.6968560814857483], 'val_accuracy': [0.5320248007774353, 0.5247933864593506, 0.5268595218658447, 0.5185950398445129, 0.5237603187561035, 0.5185950398445129, 0.5175619721412659, 0.5175619721412659, 0.5227272510528564, 0.5258264541625977, 0.5278925895690918, 0.5227272510528564, 0.5320248007774353, 0.5599173307418823, 0.5485537052154541, 0.5692148804664612, 0.5557851195335388, 0.5971074104309082, 0.6136363744735718, 0.6157024502754211, 0.6280992031097412, 0.6518595218658447, 0.6714876294136047, 0.6704545617103577, 0.672520637512207, 0.6756198406219482, 0.6673553586006165, 0.6580578684806824, 0.6683884263038635, 0.6663222908973694, 0.672520637512207, 0.66425621509552, 0.6611570119857788, 0.6652892827987671, 0.6621900796890259, 0.6673553586006165, 0.6745867729187012, 0.6673553586006165, 0.6673553586006165, 0.6663222908973694, 0.6570248007774353, 0.6673553586006165, 0.6673553586006165, 0.663223147392273, 0.66425621509552, 0.6663222908973694, 0.6735537052154541, 0.66425621509552, 0.6694214940071106, 0.66425621509552, 0.6663222908973694, 0.6611570119857788, 0.66425621509552, 0.6663222908973694, 0.6694214940071106, 0.6714876294136047, 0.6673553586006165, 0.6745867729187012, 0.6756198406219482, 0.66425621509552, 0.663223147392273, 0.672520637512207, 0.6735537052154541, 0.672520637512207, 0.6673553586006165, 0.6756198406219482, 0.6663222908973694, 0.66425621509552, 0.6683884263038635, 0.6766529083251953, 0.6694214940071106, 0.6652892827987671, 0.6673553586006165, 0.6714876294136047, 0.66425621509552, 0.6766529083251953, 0.6694214940071106, 0.6673553586006165, 0.6735537052154541, 0.6601239442825317, 0.6807851195335388, 0.6549586653709412, 0.6756198406219482, 0.6673553586006165, 0.6714876294136047, 0.6456611752510071, 0.6714876294136047, 0.6694214940071106, 0.6590909361839294, 0.6528925895690918, 0.6487603187561035, 0.6766529083251953, 0.6590909361839294, 0.6652892827987671, 0.6704545617103577, 0.6601239442825317, 0.6601239442825317, 0.6735537052154541, 0.6580578684806824, 0.6477272510528564]}\n","32/32 [==============================] - 2s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 7s 54ms/step - loss: 0.5123 - accuracy: 0.7562 - val_loss: 0.6893 - val_accuracy: 0.4849\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4994 - accuracy: 0.7627 - val_loss: 0.6863 - val_accuracy: 0.4914\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5072 - accuracy: 0.7570 - val_loss: 0.6831 - val_accuracy: 0.5797\n","Epoch 4/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4948 - accuracy: 0.7697 - val_loss: 0.6803 - val_accuracy: 0.6703\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4887 - accuracy: 0.7699 - val_loss: 0.6781 - val_accuracy: 0.6800\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4874 - accuracy: 0.7724 - val_loss: 0.6767 - val_accuracy: 0.6078\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4905 - accuracy: 0.7705 - val_loss: 0.6729 - val_accuracy: 0.6422\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4865 - accuracy: 0.7718 - val_loss: 0.6720 - val_accuracy: 0.6013\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4883 - accuracy: 0.7707 - val_loss: 0.6693 - val_accuracy: 0.5959\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4872 - accuracy: 0.7683 - val_loss: 0.6689 - val_accuracy: 0.5776\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4764 - accuracy: 0.7745 - val_loss: 0.6708 - val_accuracy: 0.5603\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.6673 - val_accuracy: 0.5711\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4795 - accuracy: 0.7767 - val_loss: 0.6644 - val_accuracy: 0.5819\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4810 - accuracy: 0.7777 - val_loss: 0.6715 - val_accuracy: 0.5690\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4719 - accuracy: 0.7856 - val_loss: 0.6577 - val_accuracy: 0.6034\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4719 - accuracy: 0.7815 - val_loss: 0.6649 - val_accuracy: 0.5970\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4696 - accuracy: 0.7818 - val_loss: 0.6505 - val_accuracy: 0.6110\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4645 - accuracy: 0.7880 - val_loss: 0.6766 - val_accuracy: 0.6013\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4647 - accuracy: 0.7791 - val_loss: 0.6447 - val_accuracy: 0.6401\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4597 - accuracy: 0.7874 - val_loss: 0.6443 - val_accuracy: 0.6466\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4625 - accuracy: 0.7829 - val_loss: 0.6359 - val_accuracy: 0.6606\n","Epoch 22/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4659 - accuracy: 0.7866 - val_loss: 0.5918 - val_accuracy: 0.7004\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4580 - accuracy: 0.7899 - val_loss: 0.6093 - val_accuracy: 0.6994\n","Epoch 24/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4566 - accuracy: 0.7934 - val_loss: 0.5836 - val_accuracy: 0.7144\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4533 - accuracy: 0.7912 - val_loss: 0.5954 - val_accuracy: 0.7123\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4596 - accuracy: 0.7893 - val_loss: 0.6128 - val_accuracy: 0.7123\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4541 - accuracy: 0.7901 - val_loss: 0.5837 - val_accuracy: 0.7155\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4696 - accuracy: 0.7783 - val_loss: 0.5937 - val_accuracy: 0.7123\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4641 - accuracy: 0.7891 - val_loss: 0.5850 - val_accuracy: 0.7144\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4501 - accuracy: 0.7961 - val_loss: 0.5892 - val_accuracy: 0.7177\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4491 - accuracy: 0.7969 - val_loss: 0.5935 - val_accuracy: 0.7123\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4395 - accuracy: 0.8025 - val_loss: 0.6012 - val_accuracy: 0.7134\n","Epoch 33/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4441 - accuracy: 0.7958 - val_loss: 0.6017 - val_accuracy: 0.7209\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4427 - accuracy: 0.8020 - val_loss: 0.6096 - val_accuracy: 0.7134\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4418 - accuracy: 0.7985 - val_loss: 0.6080 - val_accuracy: 0.7198\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4341 - accuracy: 0.8047 - val_loss: 0.6095 - val_accuracy: 0.7101\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4353 - accuracy: 0.8074 - val_loss: 0.6161 - val_accuracy: 0.7166\n","Epoch 38/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.4354 - accuracy: 0.8020 - val_loss: 0.6105 - val_accuracy: 0.7231\n","Epoch 39/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4312 - accuracy: 0.8082 - val_loss: 0.6515 - val_accuracy: 0.6907\n","Epoch 40/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4293 - accuracy: 0.8106 - val_loss: 0.6162 - val_accuracy: 0.7101\n","Epoch 41/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4319 - accuracy: 0.8090 - val_loss: 0.6469 - val_accuracy: 0.7069\n","Epoch 42/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4426 - accuracy: 0.7980 - val_loss: 0.6134 - val_accuracy: 0.7080\n","Epoch 43/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4295 - accuracy: 0.8090 - val_loss: 0.6190 - val_accuracy: 0.7155\n","Epoch 44/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4293 - accuracy: 0.8093 - val_loss: 0.6259 - val_accuracy: 0.7004\n","Epoch 45/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4201 - accuracy: 0.8163 - val_loss: 0.6189 - val_accuracy: 0.7166\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4164 - accuracy: 0.8173 - val_loss: 0.6495 - val_accuracy: 0.6972\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4185 - accuracy: 0.8176 - val_loss: 0.6262 - val_accuracy: 0.7144\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4117 - accuracy: 0.8235 - val_loss: 0.6292 - val_accuracy: 0.7177\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4212 - accuracy: 0.8125 - val_loss: 0.6253 - val_accuracy: 0.7188\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4203 - accuracy: 0.8071 - val_loss: 0.6244 - val_accuracy: 0.7101\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4122 - accuracy: 0.8187 - val_loss: 0.6299 - val_accuracy: 0.7091\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4059 - accuracy: 0.8238 - val_loss: 0.6323 - val_accuracy: 0.7091\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4047 - accuracy: 0.8241 - val_loss: 0.6427 - val_accuracy: 0.7112\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4097 - accuracy: 0.8246 - val_loss: 0.6392 - val_accuracy: 0.7123\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4056 - accuracy: 0.8192 - val_loss: 0.6353 - val_accuracy: 0.7123\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4151 - accuracy: 0.8165 - val_loss: 0.6684 - val_accuracy: 0.6843\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4029 - accuracy: 0.8206 - val_loss: 0.6378 - val_accuracy: 0.7091\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3961 - accuracy: 0.8311 - val_loss: 0.6368 - val_accuracy: 0.7047\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3977 - accuracy: 0.8295 - val_loss: 0.6404 - val_accuracy: 0.6994\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3951 - accuracy: 0.8311 - val_loss: 0.6766 - val_accuracy: 0.6832\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3946 - accuracy: 0.8297 - val_loss: 0.6415 - val_accuracy: 0.7015\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4197 - accuracy: 0.8106 - val_loss: 0.6459 - val_accuracy: 0.7188\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4051 - accuracy: 0.8203 - val_loss: 0.6700 - val_accuracy: 0.7058\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3974 - accuracy: 0.8254 - val_loss: 0.6435 - val_accuracy: 0.7123\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3836 - accuracy: 0.8373 - val_loss: 0.6722 - val_accuracy: 0.6929\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3995 - accuracy: 0.8265 - val_loss: 0.6575 - val_accuracy: 0.7091\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.8370 - val_loss: 0.6501 - val_accuracy: 0.6972\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3797 - accuracy: 0.8438 - val_loss: 0.6599 - val_accuracy: 0.7091\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3794 - accuracy: 0.8305 - val_loss: 0.6592 - val_accuracy: 0.7069\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3839 - accuracy: 0.8349 - val_loss: 0.6681 - val_accuracy: 0.6972\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3779 - accuracy: 0.8376 - val_loss: 0.7213 - val_accuracy: 0.6756\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3942 - accuracy: 0.8257 - val_loss: 0.6699 - val_accuracy: 0.6994\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3717 - accuracy: 0.8419 - val_loss: 0.6661 - val_accuracy: 0.7144\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3686 - accuracy: 0.8443 - val_loss: 0.6684 - val_accuracy: 0.6961\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3681 - accuracy: 0.8456 - val_loss: 0.6734 - val_accuracy: 0.6940\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3710 - accuracy: 0.8408 - val_loss: 0.6833 - val_accuracy: 0.6864\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3693 - accuracy: 0.8464 - val_loss: 0.6748 - val_accuracy: 0.7026\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3726 - accuracy: 0.8365 - val_loss: 0.6820 - val_accuracy: 0.7101\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3847 - accuracy: 0.8297 - val_loss: 0.6681 - val_accuracy: 0.7037\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3734 - accuracy: 0.8386 - val_loss: 0.6730 - val_accuracy: 0.7080\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3816 - accuracy: 0.8300 - val_loss: 0.6774 - val_accuracy: 0.6929\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3541 - accuracy: 0.8572 - val_loss: 0.6857 - val_accuracy: 0.6929\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3630 - accuracy: 0.8456 - val_loss: 0.7190 - val_accuracy: 0.6778\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3523 - accuracy: 0.8516 - val_loss: 0.6882 - val_accuracy: 0.6929\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3531 - accuracy: 0.8534 - val_loss: 0.6867 - val_accuracy: 0.6961\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3499 - accuracy: 0.8621 - val_loss: 0.6928 - val_accuracy: 0.6918\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3511 - accuracy: 0.8518 - val_loss: 0.6863 - val_accuracy: 0.6983\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3446 - accuracy: 0.8610 - val_loss: 0.7334 - val_accuracy: 0.6821\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3418 - accuracy: 0.8548 - val_loss: 0.7617 - val_accuracy: 0.6627\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3546 - accuracy: 0.8537 - val_loss: 0.7082 - val_accuracy: 0.6832\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3447 - accuracy: 0.8580 - val_loss: 0.7214 - val_accuracy: 0.7091\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3503 - accuracy: 0.8521 - val_loss: 0.6942 - val_accuracy: 0.6897\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3387 - accuracy: 0.8578 - val_loss: 0.7017 - val_accuracy: 0.6994\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3404 - accuracy: 0.8596 - val_loss: 0.7024 - val_accuracy: 0.7004\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3431 - accuracy: 0.8521 - val_loss: 0.7396 - val_accuracy: 0.6778\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3516 - accuracy: 0.8489 - val_loss: 0.7510 - val_accuracy: 0.6756\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3395 - accuracy: 0.8610 - val_loss: 0.7113 - val_accuracy: 0.6961\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3337 - accuracy: 0.8626 - val_loss: 0.7172 - val_accuracy: 0.6897\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3279 - accuracy: 0.8634 - val_loss: 0.7224 - val_accuracy: 0.6821\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3375 - accuracy: 0.8559 - val_loss: 0.7171 - val_accuracy: 0.7026\n","{'loss': [0.5123080611228943, 0.4994189143180847, 0.5071784257888794, 0.4947819411754608, 0.48869869112968445, 0.48738226294517517, 0.49051612615585327, 0.4864940047264099, 0.48831871151924133, 0.4871898591518402, 0.4764159023761749, 0.4719509780406952, 0.4795140027999878, 0.48104313015937805, 0.4719310402870178, 0.47192350029945374, 0.4695519506931305, 0.46445998549461365, 0.46471789479255676, 0.45970237255096436, 0.46249890327453613, 0.4659373164176941, 0.458046019077301, 0.4566424489021301, 0.4532656967639923, 0.4595574140548706, 0.4541438817977905, 0.46964317560195923, 0.46411994099617004, 0.45008471608161926, 0.4490804076194763, 0.43948981165885925, 0.44413673877716064, 0.44267529249191284, 0.44180792570114136, 0.4340530037879944, 0.43528109788894653, 0.43535909056663513, 0.4312154948711395, 0.42933714389801025, 0.4318714737892151, 0.44258585572242737, 0.4294620156288147, 0.42926961183547974, 0.4200999140739441, 0.4164237082004547, 0.41847896575927734, 0.4117276072502136, 0.4212167263031006, 0.42032092809677124, 0.41215160489082336, 0.4058675169944763, 0.40466511249542236, 0.40969592332839966, 0.40563341975212097, 0.41506335139274597, 0.4028669595718384, 0.39613935351371765, 0.39766258001327515, 0.3951041102409363, 0.3945534825325012, 0.419744074344635, 0.40510326623916626, 0.3973689675331116, 0.38362881541252136, 0.39945557713508606, 0.3907226026058197, 0.37966179847717285, 0.3794040381908417, 0.38391250371932983, 0.37791603803634644, 0.39424699544906616, 0.37172725796699524, 0.368638813495636, 0.3681105673313141, 0.37097230553627014, 0.36929911375045776, 0.37263935804367065, 0.38474971055984497, 0.37336599826812744, 0.3816067576408386, 0.35414475202560425, 0.36300942301750183, 0.35226213932037354, 0.3530530333518982, 0.34992948174476624, 0.3510934114456177, 0.3445867598056793, 0.3418194651603699, 0.3546164035797119, 0.3446634113788605, 0.35032910108566284, 0.33873116970062256, 0.34044596552848816, 0.3430851697921753, 0.35164159536361694, 0.3395221531391144, 0.3336823582649231, 0.3278837203979492, 0.337538480758667], 'accuracy': [0.756196141242981, 0.7626616358757019, 0.7570043206214905, 0.7696659564971924, 0.7699353694915771, 0.7723599076271057, 0.7704741358757019, 0.771821141242981, 0.7707435488700867, 0.7683189511299133, 0.7745150923728943, 0.7820581793785095, 0.7766702771186829, 0.7777478694915771, 0.7855603694915771, 0.7815194129943848, 0.7817887663841248, 0.7879849076271057, 0.7790948152542114, 0.787446141242981, 0.782866358757019, 0.7866379022598267, 0.7898706793785095, 0.7933728694915771, 0.7912176847457886, 0.7893319129943848, 0.7901400923728943, 0.7782866358757019, 0.7890625, 0.7960668206214905, 0.796875, 0.8025323152542114, 0.7957974076271057, 0.8019935488700867, 0.798491358757019, 0.8046875, 0.8073814511299133, 0.8019935488700867, 0.8081896305084229, 0.8106142282485962, 0.8089978694915771, 0.7979525923728943, 0.8089978694915771, 0.8092672228813171, 0.8162715435028076, 0.8173491358757019, 0.8176185488700867, 0.8235452771186829, 0.8125, 0.8071120977401733, 0.818696141242981, 0.8238146305084229, 0.8240840435028076, 0.8246228694915771, 0.8192349076271057, 0.8165409564971924, 0.8205819129943848, 0.8310883641242981, 0.829472005367279, 0.8310883641242981, 0.829741358757019, 0.8106142282485962, 0.8203125, 0.8254310488700867, 0.837284505367279, 0.826508641242981, 0.8370150923728943, 0.84375, 0.8305495977401733, 0.8348599076271057, 0.837553858757019, 0.8257004022598267, 0.8418642282485962, 0.8442887663841248, 0.8456357717514038, 0.8407866358757019, 0.8464439511299133, 0.8364762663841248, 0.829741358757019, 0.8386314511299133, 0.8300107717514038, 0.8572198152542114, 0.8456357717514038, 0.8515625, 0.8534482717514038, 0.8620689511299133, 0.8518319129943848, 0.860991358757019, 0.8547952771186829, 0.8537176847457886, 0.858027994632721, 0.8521012663841248, 0.857758641242981, 0.8596444129943848, 0.8521012663841248, 0.8488685488700867, 0.860991358757019, 0.8626077771186829, 0.8634159564971924, 0.8558728694915771], 'val_loss': [0.6893087029457092, 0.6863475441932678, 0.683127224445343, 0.6803072690963745, 0.6781281232833862, 0.6766785979270935, 0.6729363203048706, 0.6719682812690735, 0.6692508459091187, 0.6689350605010986, 0.6707779169082642, 0.6673417091369629, 0.664447546005249, 0.6715153455734253, 0.6577358841896057, 0.6649276614189148, 0.6504517197608948, 0.6765802502632141, 0.6447234153747559, 0.6443192958831787, 0.635856568813324, 0.5918460488319397, 0.6092689037322998, 0.5835838317871094, 0.5953606367111206, 0.61283278465271, 0.5837191343307495, 0.593712568283081, 0.5849780440330505, 0.5891658663749695, 0.5934510827064514, 0.6012474298477173, 0.6016694903373718, 0.6095925569534302, 0.6079763770103455, 0.6095173358917236, 0.6161462664604187, 0.6104733943939209, 0.6515275835990906, 0.6161651611328125, 0.6469073295593262, 0.6134304404258728, 0.6190227270126343, 0.6258658170700073, 0.6188843250274658, 0.6494699120521545, 0.6261683106422424, 0.6291561722755432, 0.6252985596656799, 0.6244138479232788, 0.6298955678939819, 0.6322805285453796, 0.642733633518219, 0.6391512751579285, 0.6353048086166382, 0.6683557629585266, 0.6378385424613953, 0.636762797832489, 0.6404070854187012, 0.6766332983970642, 0.6415050625801086, 0.645857572555542, 0.6699712872505188, 0.6435166597366333, 0.6722149848937988, 0.6575480699539185, 0.6501108407974243, 0.6598748564720154, 0.6591936945915222, 0.6681492328643799, 0.7213229537010193, 0.6698673963546753, 0.6661092638969421, 0.6684479713439941, 0.6733927130699158, 0.6832520961761475, 0.6747979521751404, 0.6819722652435303, 0.6681071519851685, 0.6730431914329529, 0.6774011254310608, 0.685703694820404, 0.7190054059028625, 0.6882190108299255, 0.686735987663269, 0.6928115487098694, 0.6862956881523132, 0.7334379553794861, 0.7616778612136841, 0.7081738710403442, 0.7213864922523499, 0.6941739916801453, 0.7016635537147522, 0.7023868560791016, 0.7396032214164734, 0.750970184803009, 0.7112647294998169, 0.717227578163147, 0.7224265933036804, 0.7171224355697632], 'val_accuracy': [0.48491379618644714, 0.4913793206214905, 0.579741358757019, 0.670258641242981, 0.6799569129943848, 0.607758641242981, 0.642241358757019, 0.6012930870056152, 0.5959051847457886, 0.5775862336158752, 0.5603448152542114, 0.5711206793785095, 0.5818965435028076, 0.568965494632721, 0.6034482717514038, 0.5969827771186829, 0.610991358757019, 0.6012930870056152, 0.6400862336158752, 0.6465517282485962, 0.6605603694915771, 0.7004310488700867, 0.6993534564971924, 0.7144396305084229, 0.712284505367279, 0.712284505367279, 0.7155172228813171, 0.712284505367279, 0.7144396305084229, 0.7176724076271057, 0.712284505367279, 0.7133620977401733, 0.7209051847457886, 0.7133620977401733, 0.7198275923728943, 0.7101293206214905, 0.7165948152542114, 0.7230603694915771, 0.6907327771186829, 0.7101293206214905, 0.7068965435028076, 0.7079741358757019, 0.7155172228813171, 0.7004310488700867, 0.7165948152542114, 0.6971982717514038, 0.7144396305084229, 0.7176724076271057, 0.71875, 0.7101293206214905, 0.7090517282485962, 0.7090517282485962, 0.7112069129943848, 0.712284505367279, 0.712284505367279, 0.6842672228813171, 0.7090517282485962, 0.704741358757019, 0.6993534564971924, 0.6831896305084229, 0.701508641242981, 0.71875, 0.7058189511299133, 0.712284505367279, 0.6928879022598267, 0.7090517282485962, 0.6971982717514038, 0.7090517282485962, 0.7068965435028076, 0.6971982717514038, 0.6756465435028076, 0.6993534564971924, 0.7144396305084229, 0.6961206793785095, 0.693965494632721, 0.6864224076271057, 0.7025862336158752, 0.7101293206214905, 0.7036637663841248, 0.7079741358757019, 0.6928879022598267, 0.6928879022598267, 0.6778017282485962, 0.6928879022598267, 0.6961206793785095, 0.6918103694915771, 0.6982758641242981, 0.6821120977401733, 0.662715494632721, 0.6831896305084229, 0.7090517282485962, 0.6896551847457886, 0.6993534564971924, 0.7004310488700867, 0.6778017282485962, 0.6756465435028076, 0.6961206793785095, 0.6896551847457886, 0.6821120977401733, 0.7025862336158752]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.5255 - accuracy: 0.7431"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 57ms/step - loss: 0.5250 - accuracy: 0.7445 - val_loss: 0.6875 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5105 - accuracy: 0.7538 - val_loss: 0.6853 - val_accuracy: 0.5068\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5048 - accuracy: 0.7541 - val_loss: 0.6826 - val_accuracy: 0.5882\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5120 - accuracy: 0.7564 - val_loss: 0.6807 - val_accuracy: 0.6572\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4956 - accuracy: 0.7637 - val_loss: 0.6787 - val_accuracy: 0.6787\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4997 - accuracy: 0.7680 - val_loss: 0.6780 - val_accuracy: 0.6210\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4951 - accuracy: 0.7629 - val_loss: 0.6750 - val_accuracy: 0.6267\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4910 - accuracy: 0.7666 - val_loss: 0.6739 - val_accuracy: 0.5950\n","Epoch 9/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4965 - accuracy: 0.7606 - val_loss: 0.6744 - val_accuracy: 0.5701\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4946 - accuracy: 0.7683 - val_loss: 0.6786 - val_accuracy: 0.5385\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4997 - accuracy: 0.7629 - val_loss: 0.6798 - val_accuracy: 0.5328\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4870 - accuracy: 0.7799 - val_loss: 0.6695 - val_accuracy: 0.5713\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.6680 - val_accuracy: 0.5735\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4908 - accuracy: 0.7685 - val_loss: 0.6724 - val_accuracy: 0.5645\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4870 - accuracy: 0.7708 - val_loss: 0.6981 - val_accuracy: 0.5317\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4832 - accuracy: 0.7711 - val_loss: 0.6896 - val_accuracy: 0.5486\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4874 - accuracy: 0.7708 - val_loss: 0.6702 - val_accuracy: 0.5848\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4771 - accuracy: 0.7773 - val_loss: 0.6798 - val_accuracy: 0.5848\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4724 - accuracy: 0.7881 - val_loss: 0.6619 - val_accuracy: 0.6086\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4741 - accuracy: 0.7847 - val_loss: 0.6353 - val_accuracy: 0.6493\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4766 - accuracy: 0.7767 - val_loss: 0.6930 - val_accuracy: 0.6041\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4633 - accuracy: 0.7906 - val_loss: 0.6362 - val_accuracy: 0.6482\n","Epoch 23/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4656 - accuracy: 0.7881 - val_loss: 0.6420 - val_accuracy: 0.6459\n","Epoch 24/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4590 - accuracy: 0.7926 - val_loss: 0.6212 - val_accuracy: 0.6708\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4641 - accuracy: 0.7864 - val_loss: 0.6475 - val_accuracy: 0.6572\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4749 - accuracy: 0.7756 - val_loss: 0.6439 - val_accuracy: 0.6640\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4700 - accuracy: 0.7804 - val_loss: 0.5820 - val_accuracy: 0.7014\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4597 - accuracy: 0.7906 - val_loss: 0.5884 - val_accuracy: 0.7002\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4596 - accuracy: 0.7937 - val_loss: 0.5806 - val_accuracy: 0.7059\n","Epoch 30/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4593 - accuracy: 0.7858 - val_loss: 0.5808 - val_accuracy: 0.7115\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4551 - accuracy: 0.7980 - val_loss: 0.5994 - val_accuracy: 0.7002\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4492 - accuracy: 0.8039 - val_loss: 0.5799 - val_accuracy: 0.7195\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4603 - accuracy: 0.7821 - val_loss: 0.5811 - val_accuracy: 0.7183\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4560 - accuracy: 0.7932 - val_loss: 0.5784 - val_accuracy: 0.7161\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4542 - accuracy: 0.7963 - val_loss: 0.5816 - val_accuracy: 0.7229\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4424 - accuracy: 0.8076 - val_loss: 0.5862 - val_accuracy: 0.7036\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4430 - accuracy: 0.7982 - val_loss: 0.5845 - val_accuracy: 0.7206\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4442 - accuracy: 0.7977 - val_loss: 0.5939 - val_accuracy: 0.7183\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4395 - accuracy: 0.7994 - val_loss: 0.5883 - val_accuracy: 0.7036\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4481 - accuracy: 0.7883 - val_loss: 0.6115 - val_accuracy: 0.6968\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4370 - accuracy: 0.8042 - val_loss: 0.5931 - val_accuracy: 0.7217\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4369 - accuracy: 0.7991 - val_loss: 0.5955 - val_accuracy: 0.6957\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4341 - accuracy: 0.8098 - val_loss: 0.6002 - val_accuracy: 0.7048\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4414 - accuracy: 0.7949 - val_loss: 0.6170 - val_accuracy: 0.6889\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.6029 - val_accuracy: 0.7002\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4368 - accuracy: 0.8050 - val_loss: 0.6100 - val_accuracy: 0.6878\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4285 - accuracy: 0.8130 - val_loss: 0.5972 - val_accuracy: 0.7093\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4254 - accuracy: 0.8166 - val_loss: 0.5983 - val_accuracy: 0.7183\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4278 - accuracy: 0.8065 - val_loss: 0.5964 - val_accuracy: 0.7195\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4307 - accuracy: 0.8050 - val_loss: 0.5996 - val_accuracy: 0.7104\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4214 - accuracy: 0.8132 - val_loss: 0.6055 - val_accuracy: 0.7104\n","Epoch 52/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4198 - accuracy: 0.8144 - val_loss: 0.6031 - val_accuracy: 0.7161\n","Epoch 53/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4118 - accuracy: 0.8141 - val_loss: 0.6247 - val_accuracy: 0.6957\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4172 - accuracy: 0.8101 - val_loss: 0.6093 - val_accuracy: 0.7149\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4104 - accuracy: 0.8206 - val_loss: 0.6092 - val_accuracy: 0.7104\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4145 - accuracy: 0.8200 - val_loss: 0.6146 - val_accuracy: 0.6968\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4170 - accuracy: 0.8127 - val_loss: 0.6192 - val_accuracy: 0.7002\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4035 - accuracy: 0.8280 - val_loss: 0.6384 - val_accuracy: 0.6912\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4088 - accuracy: 0.8206 - val_loss: 0.6762 - val_accuracy: 0.6889\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4108 - accuracy: 0.8181 - val_loss: 0.6244 - val_accuracy: 0.7002\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4016 - accuracy: 0.8299 - val_loss: 0.6284 - val_accuracy: 0.6980\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4098 - accuracy: 0.8121 - val_loss: 0.6235 - val_accuracy: 0.7025\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4021 - accuracy: 0.8214 - val_loss: 0.6148 - val_accuracy: 0.7115\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3969 - accuracy: 0.8251 - val_loss: 0.6245 - val_accuracy: 0.7115\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3967 - accuracy: 0.8274 - val_loss: 0.6227 - val_accuracy: 0.7093\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3968 - accuracy: 0.8263 - val_loss: 0.6327 - val_accuracy: 0.7059\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3957 - accuracy: 0.8251 - val_loss: 0.6271 - val_accuracy: 0.7025\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3944 - accuracy: 0.8231 - val_loss: 0.6820 - val_accuracy: 0.6833\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3902 - accuracy: 0.8288 - val_loss: 0.6299 - val_accuracy: 0.7081\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3863 - accuracy: 0.8356 - val_loss: 0.6463 - val_accuracy: 0.6968\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3775 - accuracy: 0.8339 - val_loss: 0.6440 - val_accuracy: 0.6957\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3807 - accuracy: 0.8314 - val_loss: 0.6335 - val_accuracy: 0.6980\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3786 - accuracy: 0.8390 - val_loss: 0.6552 - val_accuracy: 0.6991\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3729 - accuracy: 0.8441 - val_loss: 0.6497 - val_accuracy: 0.6946\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3810 - accuracy: 0.8322 - val_loss: 0.6452 - val_accuracy: 0.6991\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3748 - accuracy: 0.8373 - val_loss: 0.6485 - val_accuracy: 0.6980\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.8435 - val_loss: 0.6453 - val_accuracy: 0.7036\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3663 - accuracy: 0.8401 - val_loss: 0.6546 - val_accuracy: 0.7014\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3652 - accuracy: 0.8404 - val_loss: 0.6890 - val_accuracy: 0.6934\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3753 - accuracy: 0.8331 - val_loss: 0.6578 - val_accuracy: 0.7036\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3764 - accuracy: 0.8305 - val_loss: 0.6607 - val_accuracy: 0.6934\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3665 - accuracy: 0.8435 - val_loss: 0.6667 - val_accuracy: 0.6968\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3683 - accuracy: 0.8418 - val_loss: 0.6537 - val_accuracy: 0.7002\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3624 - accuracy: 0.8472 - val_loss: 0.6754 - val_accuracy: 0.6968\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3780 - accuracy: 0.8342 - val_loss: 0.7026 - val_accuracy: 0.6686\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3726 - accuracy: 0.8396 - val_loss: 0.6763 - val_accuracy: 0.7002\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3623 - accuracy: 0.8441 - val_loss: 0.6677 - val_accuracy: 0.6980\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3562 - accuracy: 0.8447 - val_loss: 0.7385 - val_accuracy: 0.6640\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3708 - accuracy: 0.8407 - val_loss: 0.6606 - val_accuracy: 0.6923\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3589 - accuracy: 0.8472 - val_loss: 0.6911 - val_accuracy: 0.6912\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3487 - accuracy: 0.8540 - val_loss: 0.6770 - val_accuracy: 0.6912\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3563 - accuracy: 0.8514 - val_loss: 0.6887 - val_accuracy: 0.6946\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3412 - accuracy: 0.8588 - val_loss: 0.6763 - val_accuracy: 0.6991\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3395 - accuracy: 0.8616 - val_loss: 0.6765 - val_accuracy: 0.6912\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3421 - accuracy: 0.8557 - val_loss: 0.6829 - val_accuracy: 0.7014\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.8325 - val_loss: 0.6757 - val_accuracy: 0.7002\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3393 - accuracy: 0.8563 - val_loss: 0.6814 - val_accuracy: 0.6991\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3285 - accuracy: 0.8642 - val_loss: 0.7009 - val_accuracy: 0.6923\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3319 - accuracy: 0.8642 - val_loss: 0.7082 - val_accuracy: 0.6968\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3366 - accuracy: 0.8551 - val_loss: 0.7164 - val_accuracy: 0.6912\n","{'loss': [0.5250287055969238, 0.5104503631591797, 0.5047896504402161, 0.5120124816894531, 0.49557849764823914, 0.49971768260002136, 0.4951222240924835, 0.4910174310207367, 0.496537983417511, 0.4945933520793915, 0.49968579411506653, 0.4870454967021942, 0.4897540509700775, 0.49082717299461365, 0.4870295226573944, 0.483228862285614, 0.48736563324928284, 0.4771133363246918, 0.4723830819129944, 0.47412174940109253, 0.47662249207496643, 0.4633041024208069, 0.46563494205474854, 0.4590252935886383, 0.46405884623527527, 0.4748896360397339, 0.47003573179244995, 0.4596807360649109, 0.45963141322135925, 0.45932960510253906, 0.45514440536499023, 0.44919219613075256, 0.4603474736213684, 0.45600175857543945, 0.4542098045349121, 0.44237908720970154, 0.44297555088996887, 0.4441588222980499, 0.4395488500595093, 0.44809672236442566, 0.436973512172699, 0.436918705701828, 0.4341115653514862, 0.44144272804260254, 0.4477297067642212, 0.43678098917007446, 0.428488165140152, 0.4253925085067749, 0.4277893602848053, 0.4306696355342865, 0.4213549494743347, 0.4198436737060547, 0.4118163287639618, 0.4171726107597351, 0.41039708256721497, 0.4145321249961853, 0.41697046160697937, 0.4035136103630066, 0.40883803367614746, 0.41080206632614136, 0.4016262888908386, 0.4098126292228699, 0.4020693898200989, 0.39685681462287903, 0.39665377140045166, 0.3968486487865448, 0.3957337737083435, 0.39442071318626404, 0.39015626907348633, 0.38625431060791016, 0.37746119499206543, 0.3806912302970886, 0.3785885274410248, 0.37285587191581726, 0.3809835910797119, 0.37478193640708923, 0.3696432411670685, 0.3662746548652649, 0.3652433454990387, 0.3752940595149994, 0.3763734698295593, 0.36647093296051025, 0.3683035373687744, 0.3623618483543396, 0.3780103325843811, 0.37264159321784973, 0.36232757568359375, 0.3561907708644867, 0.37078073620796204, 0.35889649391174316, 0.3486573398113251, 0.35631829500198364, 0.34116506576538086, 0.33953073620796204, 0.34205904603004456, 0.3754509389400482, 0.3392527401447296, 0.3284877836704254, 0.33185914158821106, 0.33657678961753845], 'accuracy': [0.744482159614563, 0.7538200616836548, 0.7541030049324036, 0.7563667297363281, 0.7637238502502441, 0.7679682970046997, 0.7628749012947083, 0.7665534615516663, 0.7606111764907837, 0.7682512998580933, 0.7628749012947083, 0.7798528671264648, 0.7707979679107666, 0.768534243106842, 0.7707979679107666, 0.7710809111595154, 0.7707979679107666, 0.7773061394691467, 0.788058876991272, 0.7846632599830627, 0.7767402529716492, 0.7906055450439453, 0.788058876991272, 0.7925863265991211, 0.786361038684845, 0.7756083607673645, 0.7804188132286072, 0.7906055450439453, 0.793718159198761, 0.7857951521873474, 0.7979626655578613, 0.8039049506187439, 0.7821165919303894, 0.7931522130966187, 0.7962648272514343, 0.8075834512710571, 0.7982456088066101, 0.7976796627044678, 0.7993775010108948, 0.7883418202400208, 0.8041878938674927, 0.7990944981575012, 0.8098471760749817, 0.7948500514030457, 0.7951329946517944, 0.8050367832183838, 0.8129597902297974, 0.8166383504867554, 0.8064516186714172, 0.8050367832183838, 0.8132427930831909, 0.8143746256828308, 0.814091682434082, 0.8101301789283752, 0.8205999135971069, 0.8200339674949646, 0.8126768469810486, 0.8279569745063782, 0.8205999135971069, 0.8180531859397888, 0.829937756061554, 0.8121109008789062, 0.821448802947998, 0.825127363204956, 0.8273910880088806, 0.826259195804596, 0.825127363204956, 0.8231465816497803, 0.8288058638572693, 0.835597038269043, 0.8338992595672607, 0.8313525915145874, 0.8389926552772522, 0.8440860509872437, 0.8322014808654785, 0.83729487657547, 0.8435201048851013, 0.8401244878768921, 0.8404074907302856, 0.8330503702163696, 0.8305037021636963, 0.8435201048851013, 0.8418223261833191, 0.8471986651420593, 0.8341822028160095, 0.8395586013793945, 0.8440860509872437, 0.8446519374847412, 0.8406904339790344, 0.8471986651420593, 0.853989839553833, 0.8514431118965149, 0.8588002324104309, 0.8616299033164978, 0.8556876182556152, 0.8324844241142273, 0.8562535643577576, 0.8641765713691711, 0.8641765713691711, 0.8551216721534729], 'val_loss': [0.6874825954437256, 0.6853305697441101, 0.682642936706543, 0.6806901693344116, 0.6787405610084534, 0.6779546737670898, 0.6749959588050842, 0.6739331483840942, 0.6744427680969238, 0.6786341667175293, 0.6798229813575745, 0.6694652438163757, 0.6680439114570618, 0.6723743081092834, 0.6980771422386169, 0.6896234154701233, 0.6702187657356262, 0.679812490940094, 0.6618975400924683, 0.6353392601013184, 0.6930384635925293, 0.6362190246582031, 0.6420129537582397, 0.6212486624717712, 0.6475138068199158, 0.6438763737678528, 0.5820492506027222, 0.5884217619895935, 0.5806179046630859, 0.5808223485946655, 0.5993698835372925, 0.5798524618148804, 0.581078827381134, 0.5783530473709106, 0.5816290378570557, 0.5861597657203674, 0.5844822525978088, 0.5938535928726196, 0.5882775783538818, 0.6114646792411804, 0.5931428074836731, 0.5955281257629395, 0.6002304553985596, 0.6169774532318115, 0.6029183864593506, 0.6100314855575562, 0.5972040891647339, 0.5982748866081238, 0.5963884592056274, 0.5996348261833191, 0.6054636240005493, 0.6031109094619751, 0.6247238516807556, 0.6093342900276184, 0.6092389225959778, 0.6146051287651062, 0.6191712617874146, 0.6383954882621765, 0.6762137413024902, 0.6243965029716492, 0.6283695697784424, 0.6235368251800537, 0.6147934794425964, 0.6244809031486511, 0.6226688027381897, 0.6326587200164795, 0.6271107792854309, 0.6819670796394348, 0.6299262642860413, 0.6462622880935669, 0.6440132856369019, 0.6335199475288391, 0.6551632285118103, 0.6497008800506592, 0.6451769471168518, 0.6485106945037842, 0.6452918648719788, 0.6546498537063599, 0.688951849937439, 0.6577943563461304, 0.6606927514076233, 0.666739284992218, 0.6536628007888794, 0.6754381656646729, 0.7026315927505493, 0.6763472557067871, 0.6677020788192749, 0.738522469997406, 0.6605817079544067, 0.6910566687583923, 0.6770166754722595, 0.6886897683143616, 0.6763309240341187, 0.6764996647834778, 0.6829137802124023, 0.6757145524024963, 0.6813836693763733, 0.7009314894676208, 0.7082331776618958, 0.7164284586906433], 'val_accuracy': [0.4954751133918762, 0.5067873597145081, 0.5882353186607361, 0.6572397947311401, 0.6787330508232117, 0.6210407018661499, 0.6266968250274658, 0.5950226187705994, 0.570135772228241, 0.5384615659713745, 0.5328054428100586, 0.5712669491767883, 0.5735294222831726, 0.564479649066925, 0.5316742062568665, 0.5486425161361694, 0.5848416090011597, 0.5848416090011597, 0.6085972785949707, 0.6493212580680847, 0.6040723919868469, 0.6481900215148926, 0.6459276080131531, 0.6708144545555115, 0.6572397947311401, 0.6640271544456482, 0.7013574838638306, 0.7002262473106384, 0.7058823704719543, 0.7115384340286255, 0.7002262473106384, 0.7194570302963257, 0.7183257937431335, 0.7160633206367493, 0.7228506803512573, 0.7036198973655701, 0.720588207244873, 0.7183257937431335, 0.7036198973655701, 0.6968325972557068, 0.7217194437980652, 0.6957013607025146, 0.7047511339187622, 0.6889140009880066, 0.7002262473106384, 0.6877828240394592, 0.709276020526886, 0.7183257937431335, 0.7194570302963257, 0.7104072570800781, 0.7104072570800781, 0.7160633206367493, 0.6957013607025146, 0.7149321436882019, 0.7104072570800781, 0.6968325972557068, 0.7002262473106384, 0.6911764740943909, 0.6889140009880066, 0.7002262473106384, 0.6979637742042542, 0.7024886608123779, 0.7115384340286255, 0.7115384340286255, 0.709276020526886, 0.7058823704719543, 0.7024886608123779, 0.6832579374313354, 0.7081447839736938, 0.6968325972557068, 0.6957013607025146, 0.6979637742042542, 0.6990950107574463, 0.6945701241493225, 0.6990950107574463, 0.6979637742042542, 0.7036198973655701, 0.7013574838638306, 0.6934388875961304, 0.7036198973655701, 0.6934388875961304, 0.6968325972557068, 0.7002262473106384, 0.6968325972557068, 0.668552041053772, 0.7002262473106384, 0.6979637742042542, 0.6640271544456482, 0.692307710647583, 0.6911764740943909, 0.6911764740943909, 0.6945701241493225, 0.6990950107574463, 0.6911764740943909, 0.7013574838638306, 0.7002262473106384, 0.6990950107574463, 0.692307710647583, 0.6968325972557068, 0.6911764740943909]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5081 - accuracy: 0.7609"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 55ms/step - loss: 0.5082 - accuracy: 0.7618 - val_loss: 0.6896 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5009 - accuracy: 0.7643 - val_loss: 0.6861 - val_accuracy: 0.4969\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5020 - accuracy: 0.7651 - val_loss: 0.6830 - val_accuracy: 0.6674\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4999 - accuracy: 0.7649 - val_loss: 0.6804 - val_accuracy: 0.6767\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4928 - accuracy: 0.7661 - val_loss: 0.6778 - val_accuracy: 0.6601\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4931 - accuracy: 0.7680 - val_loss: 0.6765 - val_accuracy: 0.5992\n","Epoch 7/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4923 - accuracy: 0.7677 - val_loss: 0.6743 - val_accuracy: 0.5950\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4858 - accuracy: 0.7724 - val_loss: 0.6735 - val_accuracy: 0.5713\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4841 - accuracy: 0.7705 - val_loss: 0.6718 - val_accuracy: 0.5682\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4827 - accuracy: 0.7757 - val_loss: 0.6691 - val_accuracy: 0.5744\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4851 - accuracy: 0.7744 - val_loss: 0.6791 - val_accuracy: 0.5527\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4841 - accuracy: 0.7708 - val_loss: 0.6768 - val_accuracy: 0.5579\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4848 - accuracy: 0.7742 - val_loss: 0.6799 - val_accuracy: 0.5620\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4791 - accuracy: 0.7780 - val_loss: 0.6921 - val_accuracy: 0.5568\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4749 - accuracy: 0.7793 - val_loss: 0.6907 - val_accuracy: 0.5713\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4851 - accuracy: 0.7711 - val_loss: 0.6762 - val_accuracy: 0.5919\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4781 - accuracy: 0.7773 - val_loss: 0.6677 - val_accuracy: 0.6157\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4777 - accuracy: 0.7811 - val_loss: 0.6917 - val_accuracy: 0.6054\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4645 - accuracy: 0.7897 - val_loss: 0.6771 - val_accuracy: 0.6240\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4703 - accuracy: 0.7850 - val_loss: 0.6351 - val_accuracy: 0.6560\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4656 - accuracy: 0.7912 - val_loss: 0.6892 - val_accuracy: 0.6343\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4689 - accuracy: 0.7959 - val_loss: 0.6214 - val_accuracy: 0.6684\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4674 - accuracy: 0.7894 - val_loss: 0.6299 - val_accuracy: 0.6684\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4632 - accuracy: 0.7915 - val_loss: 0.6623 - val_accuracy: 0.6591\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4596 - accuracy: 0.7948 - val_loss: 0.6197 - val_accuracy: 0.6767\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4676 - accuracy: 0.7817 - val_loss: 0.6510 - val_accuracy: 0.6622\n","Epoch 27/100\n","31/31 [==============================] - 2s 57ms/step - loss: 0.4888 - accuracy: 0.7682 - val_loss: 0.6157 - val_accuracy: 0.6921\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4699 - accuracy: 0.7845 - val_loss: 0.6147 - val_accuracy: 0.6901\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4566 - accuracy: 0.7972 - val_loss: 0.6339 - val_accuracy: 0.6942\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4557 - accuracy: 0.7915 - val_loss: 0.6261 - val_accuracy: 0.6911\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4496 - accuracy: 0.7961 - val_loss: 0.6345 - val_accuracy: 0.6818\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4471 - accuracy: 0.8036 - val_loss: 0.6370 - val_accuracy: 0.6880\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.7987 - val_loss: 0.6434 - val_accuracy: 0.6818\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4547 - accuracy: 0.7920 - val_loss: 0.6381 - val_accuracy: 0.6983\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4461 - accuracy: 0.7951 - val_loss: 0.6378 - val_accuracy: 0.6942\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 0.8052 - val_loss: 0.6688 - val_accuracy: 0.6818\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4502 - accuracy: 0.7979 - val_loss: 0.6453 - val_accuracy: 0.6973\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4345 - accuracy: 0.8140 - val_loss: 0.6448 - val_accuracy: 0.6942\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4364 - accuracy: 0.8096 - val_loss: 0.6442 - val_accuracy: 0.7014\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4345 - accuracy: 0.8145 - val_loss: 0.6484 - val_accuracy: 0.6983\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4277 - accuracy: 0.8114 - val_loss: 0.6660 - val_accuracy: 0.6860\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4327 - accuracy: 0.8083 - val_loss: 0.6542 - val_accuracy: 0.7045\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4327 - accuracy: 0.8062 - val_loss: 0.6589 - val_accuracy: 0.6849\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4267 - accuracy: 0.8145 - val_loss: 0.6645 - val_accuracy: 0.6870\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4358 - accuracy: 0.8075 - val_loss: 0.6910 - val_accuracy: 0.6705\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4246 - accuracy: 0.8119 - val_loss: 0.6664 - val_accuracy: 0.6818\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4269 - accuracy: 0.8062 - val_loss: 0.6578 - val_accuracy: 0.6994\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4218 - accuracy: 0.8137 - val_loss: 0.6678 - val_accuracy: 0.6880\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4204 - accuracy: 0.8160 - val_loss: 0.6616 - val_accuracy: 0.7014\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4487 - accuracy: 0.7997 - val_loss: 0.6705 - val_accuracy: 0.6767\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4195 - accuracy: 0.8057 - val_loss: 0.6613 - val_accuracy: 0.6963\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4123 - accuracy: 0.8171 - val_loss: 0.6708 - val_accuracy: 0.6932\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4118 - accuracy: 0.8222 - val_loss: 0.6683 - val_accuracy: 0.7025\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4108 - accuracy: 0.8181 - val_loss: 0.6798 - val_accuracy: 0.6860\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4134 - accuracy: 0.8173 - val_loss: 0.6786 - val_accuracy: 0.6963\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4114 - accuracy: 0.8264 - val_loss: 0.6732 - val_accuracy: 0.6963\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4175 - accuracy: 0.8134 - val_loss: 0.7018 - val_accuracy: 0.6632\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4127 - accuracy: 0.8258 - val_loss: 0.6836 - val_accuracy: 0.6860\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.6836 - val_accuracy: 0.6880\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3966 - accuracy: 0.8258 - val_loss: 0.6845 - val_accuracy: 0.6911\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4015 - accuracy: 0.8310 - val_loss: 0.7225 - val_accuracy: 0.6643\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4104 - accuracy: 0.8173 - val_loss: 0.6845 - val_accuracy: 0.6860\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4021 - accuracy: 0.8256 - val_loss: 0.6899 - val_accuracy: 0.6849\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3927 - accuracy: 0.8351 - val_loss: 0.6904 - val_accuracy: 0.6921\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4072 - accuracy: 0.8266 - val_loss: 0.7040 - val_accuracy: 0.6921\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3929 - accuracy: 0.8328 - val_loss: 0.6954 - val_accuracy: 0.6994\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4053 - accuracy: 0.8253 - val_loss: 0.7150 - val_accuracy: 0.6705\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4075 - accuracy: 0.8204 - val_loss: 0.6948 - val_accuracy: 0.6818\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3943 - accuracy: 0.8274 - val_loss: 0.6999 - val_accuracy: 0.6849\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3880 - accuracy: 0.8336 - val_loss: 0.7073 - val_accuracy: 0.6798\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3889 - accuracy: 0.8370 - val_loss: 0.7358 - val_accuracy: 0.6663\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3858 - accuracy: 0.8388 - val_loss: 0.7058 - val_accuracy: 0.6932\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3874 - accuracy: 0.8310 - val_loss: 0.7138 - val_accuracy: 0.6818\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3815 - accuracy: 0.8385 - val_loss: 0.7076 - val_accuracy: 0.6818\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3919 - accuracy: 0.8331 - val_loss: 0.7472 - val_accuracy: 0.6560\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3853 - accuracy: 0.8344 - val_loss: 0.7139 - val_accuracy: 0.6787\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3784 - accuracy: 0.8437 - val_loss: 0.7105 - val_accuracy: 0.6849\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3779 - accuracy: 0.8408 - val_loss: 0.7243 - val_accuracy: 0.6880\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3857 - accuracy: 0.8328 - val_loss: 0.7188 - val_accuracy: 0.6777\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3670 - accuracy: 0.8483 - val_loss: 0.7237 - val_accuracy: 0.6777\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3690 - accuracy: 0.8442 - val_loss: 0.7292 - val_accuracy: 0.6880\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3657 - accuracy: 0.8488 - val_loss: 0.7271 - val_accuracy: 0.6839\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3647 - accuracy: 0.8481 - val_loss: 0.7298 - val_accuracy: 0.6870\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3710 - accuracy: 0.8390 - val_loss: 0.7247 - val_accuracy: 0.6880\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3619 - accuracy: 0.8429 - val_loss: 0.7322 - val_accuracy: 0.6715\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3628 - accuracy: 0.8488 - val_loss: 0.7506 - val_accuracy: 0.6777\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.8460 - val_loss: 0.7458 - val_accuracy: 0.6756\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3746 - accuracy: 0.8367 - val_loss: 0.7961 - val_accuracy: 0.6519\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3630 - accuracy: 0.8468 - val_loss: 0.7430 - val_accuracy: 0.6911\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3614 - accuracy: 0.8483 - val_loss: 0.7369 - val_accuracy: 0.6818\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3626 - accuracy: 0.8478 - val_loss: 0.7936 - val_accuracy: 0.6550\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3615 - accuracy: 0.8478 - val_loss: 0.7414 - val_accuracy: 0.6839\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3561 - accuracy: 0.8452 - val_loss: 0.7460 - val_accuracy: 0.6829\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3415 - accuracy: 0.8607 - val_loss: 0.7445 - val_accuracy: 0.6860\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3377 - accuracy: 0.8656 - val_loss: 0.7587 - val_accuracy: 0.6798\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3406 - accuracy: 0.8607 - val_loss: 0.7548 - val_accuracy: 0.6952\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3364 - accuracy: 0.8610 - val_loss: 0.7673 - val_accuracy: 0.6829\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3497 - accuracy: 0.8494 - val_loss: 0.7556 - val_accuracy: 0.6911\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3430 - accuracy: 0.8548 - val_loss: 0.7839 - val_accuracy: 0.6694\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.8630 - val_loss: 0.7795 - val_accuracy: 0.6756\n","{'loss': [0.5081665515899658, 0.5009453892707825, 0.5019500851631165, 0.49986502528190613, 0.4927607774734497, 0.4931192398071289, 0.49232083559036255, 0.4858236312866211, 0.48409026861190796, 0.48273319005966187, 0.4851498007774353, 0.4841117858886719, 0.4848029315471649, 0.4790720045566559, 0.47485092282295227, 0.4851391613483429, 0.47807052731513977, 0.4776636064052582, 0.46450844407081604, 0.47026845812797546, 0.4656388461589813, 0.4688846170902252, 0.46740615367889404, 0.4632205367088318, 0.4595799744129181, 0.4675755202770233, 0.4887954890727997, 0.4699192941188812, 0.4565802216529846, 0.45565181970596313, 0.4495908319950104, 0.44705191254615784, 0.449478417634964, 0.454690158367157, 0.4460904896259308, 0.43795084953308105, 0.4501834809780121, 0.4345276355743408, 0.4363861680030823, 0.4344709813594818, 0.4276858866214752, 0.43272528052330017, 0.43270888924598694, 0.4267362654209137, 0.4357704818248749, 0.42461034655570984, 0.42691341042518616, 0.42182207107543945, 0.4203985631465912, 0.4486839175224304, 0.4195041358470917, 0.4123198091983795, 0.41180160641670227, 0.4108104109764099, 0.41336145997047424, 0.41135767102241516, 0.4175087809562683, 0.4127347767353058, 0.40175193548202515, 0.39663979411125183, 0.4015401303768158, 0.4104005992412567, 0.4020567834377289, 0.39265385270118713, 0.40723419189453125, 0.3929167091846466, 0.40527382493019104, 0.4074690639972687, 0.394272118806839, 0.3879665434360504, 0.3889124393463135, 0.38578078150749207, 0.38737383484840393, 0.38150840997695923, 0.3919112980365753, 0.38530316948890686, 0.3783752918243408, 0.3778620660305023, 0.3856998383998871, 0.367031067609787, 0.36898767948150635, 0.36566251516342163, 0.36473560333251953, 0.37104666233062744, 0.3618640899658203, 0.36276695132255554, 0.3652382791042328, 0.3745655417442322, 0.3629600703716278, 0.36139658093452454, 0.36261454224586487, 0.36153098940849304, 0.3561343252658844, 0.3415181636810303, 0.33773359656333923, 0.3405524492263794, 0.33643537759780884, 0.3496633470058441, 0.34299105405807495, 0.34339049458503723], 'accuracy': [0.7617571353912354, 0.7643410563468933, 0.765116274356842, 0.7648578882217407, 0.7661498785018921, 0.7679586410522461, 0.7677002549171448, 0.7723514437675476, 0.7705426216125488, 0.7757105827331543, 0.7744185924530029, 0.7708010077476501, 0.7741602063179016, 0.7780361771583557, 0.7793281674385071, 0.7710594534873962, 0.777260959148407, 0.7811369299888611, 0.789664089679718, 0.7850129008293152, 0.7912144660949707, 0.7958656549453735, 0.7894057035446167, 0.791472852230072, 0.7948320508003235, 0.7816537618637085, 0.7682170271873474, 0.7844961285591125, 0.7971576452255249, 0.791472852230072, 0.7961240410804749, 0.8036175966262817, 0.7987080216407776, 0.7919896841049194, 0.7950904369354248, 0.8051679730415344, 0.7979328036308289, 0.8139534592628479, 0.8095607161521912, 0.8144702911376953, 0.8113695383071899, 0.8082687258720398, 0.8062015771865845, 0.8144702911376953, 0.8074935674667358, 0.8118863105773926, 0.8062015771865845, 0.8136950731277466, 0.816020667552948, 0.7997416257858276, 0.8056847453117371, 0.817054271697998, 0.8222222328186035, 0.8180878758430481, 0.8173126578330994, 0.8263565897941589, 0.8134366869926453, 0.8258398175239563, 0.8263565897941589, 0.8258398175239563, 0.8310077786445618, 0.8173126578330994, 0.8255813717842102, 0.8351421356201172, 0.8266149759292603, 0.8328165411949158, 0.8253229856491089, 0.8204134106636047, 0.827390193939209, 0.8335917592048645, 0.8369508981704712, 0.8387596607208252, 0.8310077786445618, 0.8385012745857239, 0.8330749273300171, 0.8343669176101685, 0.8436692357063293, 0.8408268690109253, 0.8328165411949158, 0.8483204245567322, 0.8441860675811768, 0.8488371968269348, 0.8480620384216309, 0.8390181064605713, 0.8428940773010254, 0.8488371968269348, 0.8459948301315308, 0.8366925120353699, 0.8467700481414795, 0.8483204245567322, 0.8478035926818848, 0.8478035926818848, 0.845219612121582, 0.8607234954833984, 0.8656330704689026, 0.8607234954833984, 0.8609819412231445, 0.8493540287017822, 0.854780375957489, 0.8630490899085999], 'val_loss': [0.6895968317985535, 0.686115562915802, 0.6829808354377747, 0.6803871393203735, 0.677759051322937, 0.676506519317627, 0.6742971539497375, 0.6735126376152039, 0.6717878580093384, 0.6691063642501831, 0.6791478395462036, 0.676761269569397, 0.6798944473266602, 0.6921237707138062, 0.6906667947769165, 0.6762443780899048, 0.6677136421203613, 0.6917046904563904, 0.6771390438079834, 0.6350619792938232, 0.6891841292381287, 0.621441125869751, 0.629916250705719, 0.6622642278671265, 0.6196925044059753, 0.6510035395622253, 0.6156761646270752, 0.6146855354309082, 0.6338971257209778, 0.6260900497436523, 0.6344833374023438, 0.6369957327842712, 0.6433771252632141, 0.6381320357322693, 0.637758731842041, 0.6688202619552612, 0.6453009247779846, 0.6448055505752563, 0.6441693902015686, 0.6483871340751648, 0.6659685373306274, 0.6541704535484314, 0.6588616967201233, 0.6644583940505981, 0.6910381317138672, 0.6663708686828613, 0.6577988862991333, 0.6678138375282288, 0.6615658402442932, 0.670451819896698, 0.661250114440918, 0.6707904934883118, 0.6683436632156372, 0.6798211932182312, 0.6785693764686584, 0.6732231974601746, 0.7018053531646729, 0.6836087703704834, 0.6836472153663635, 0.684511125087738, 0.7225102782249451, 0.6845430135726929, 0.6899192929267883, 0.690384566783905, 0.7040468454360962, 0.6954484581947327, 0.7150360345840454, 0.694789707660675, 0.6998654007911682, 0.7073290348052979, 0.7357988357543945, 0.7057523727416992, 0.7137832045555115, 0.707614004611969, 0.7471752166748047, 0.7139026522636414, 0.7105382680892944, 0.7242512106895447, 0.7188063859939575, 0.723661482334137, 0.7292008996009827, 0.7270606756210327, 0.7298374176025391, 0.7246763110160828, 0.7322024703025818, 0.7506005167961121, 0.7457632422447205, 0.7961074709892273, 0.7429516911506653, 0.7368786334991455, 0.7935840487480164, 0.7414449453353882, 0.7459568381309509, 0.7444977760314941, 0.75872403383255, 0.7547827363014221, 0.7672639489173889, 0.7555570006370544, 0.7839446067810059, 0.7795376181602478], 'val_accuracy': [0.48553720116615295, 0.4969008266925812, 0.6673553586006165, 0.6766529083251953, 0.6601239442825317, 0.5991735458374023, 0.5950413346290588, 0.5712810158729553, 0.5681818127632141, 0.5743801593780518, 0.5526859760284424, 0.557851254940033, 0.5619834661483765, 0.5568181872367859, 0.5712810158729553, 0.5919421315193176, 0.6157024502754211, 0.60537189245224, 0.6239669322967529, 0.6559917330741882, 0.6342975497245789, 0.6683884263038635, 0.6683884263038635, 0.6590909361839294, 0.6766529083251953, 0.6621900796890259, 0.692148745059967, 0.6900826692581177, 0.6942148804664612, 0.69111567735672, 0.6818181872367859, 0.6880165338516235, 0.6818181872367859, 0.6983470916748047, 0.6942148804664612, 0.6818181872367859, 0.6973140239715576, 0.6942148804664612, 0.7014462947845459, 0.6983470916748047, 0.6859503984451294, 0.7045454382896423, 0.6849173307418823, 0.6869834661483765, 0.6704545617103577, 0.6818181872367859, 0.6993801593780518, 0.6880165338516235, 0.7014462947845459, 0.6766529083251953, 0.6962810158729553, 0.6931818127632141, 0.702479362487793, 0.6859503984451294, 0.6962810158729553, 0.6962810158729553, 0.663223147392273, 0.6859503984451294, 0.6880165338516235, 0.69111567735672, 0.66425621509552, 0.6859503984451294, 0.6849173307418823, 0.692148745059967, 0.692148745059967, 0.6993801593780518, 0.6704545617103577, 0.6818181872367859, 0.6849173307418823, 0.6797520518302917, 0.6663222908973694, 0.6931818127632141, 0.6818181872367859, 0.6818181872367859, 0.6559917330741882, 0.6787189841270447, 0.6849173307418823, 0.6880165338516235, 0.6776859760284424, 0.6776859760284424, 0.6880165338516235, 0.68388432264328, 0.6869834661483765, 0.6880165338516235, 0.6714876294136047, 0.6776859760284424, 0.6756198406219482, 0.6518595218658447, 0.69111567735672, 0.6818181872367859, 0.6549586653709412, 0.68388432264328, 0.682851254940033, 0.6859503984451294, 0.6797520518302917, 0.6952479481697083, 0.682851254940033, 0.69111567735672, 0.6694214940071106, 0.6756198406219482]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.4092 - accuracy: 0.8225"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 56ms/step - loss: 0.4085 - accuracy: 0.8209 - val_loss: 0.6990 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3962 - accuracy: 0.8252 - val_loss: 0.6940 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3938 - accuracy: 0.8284 - val_loss: 0.6863 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3811 - accuracy: 0.8343 - val_loss: 0.6792 - val_accuracy: 0.5259\n","Epoch 5/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3816 - accuracy: 0.8386 - val_loss: 0.6725 - val_accuracy: 0.6412\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3816 - accuracy: 0.8429 - val_loss: 0.6678 - val_accuracy: 0.6584\n","Epoch 7/100\n","29/29 [==============================] - 1s 16ms/step - loss: 0.3756 - accuracy: 0.8346 - val_loss: 0.6662 - val_accuracy: 0.6358\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3860 - accuracy: 0.8327 - val_loss: 0.6657 - val_accuracy: 0.6034\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3715 - accuracy: 0.8424 - val_loss: 0.6597 - val_accuracy: 0.6142\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3798 - accuracy: 0.8370 - val_loss: 0.6571 - val_accuracy: 0.6078\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3793 - accuracy: 0.8316 - val_loss: 0.6520 - val_accuracy: 0.6185\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3606 - accuracy: 0.8491 - val_loss: 0.6667 - val_accuracy: 0.5916\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3636 - accuracy: 0.8443 - val_loss: 0.6797 - val_accuracy: 0.5830\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3569 - accuracy: 0.8456 - val_loss: 0.6877 - val_accuracy: 0.5797\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3665 - accuracy: 0.8373 - val_loss: 0.7081 - val_accuracy: 0.5765\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.8386 - val_loss: 0.6927 - val_accuracy: 0.5916\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3549 - accuracy: 0.8540 - val_loss: 0.7327 - val_accuracy: 0.5808\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3601 - accuracy: 0.8489 - val_loss: 0.7520 - val_accuracy: 0.5851\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.8534 - val_loss: 0.7099 - val_accuracy: 0.6131\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3471 - accuracy: 0.8570 - val_loss: 0.7038 - val_accuracy: 0.6401\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3493 - accuracy: 0.8521 - val_loss: 0.7259 - val_accuracy: 0.6401\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3472 - accuracy: 0.8508 - val_loss: 0.6328 - val_accuracy: 0.6886\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3399 - accuracy: 0.8634 - val_loss: 0.6190 - val_accuracy: 0.7037\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3521 - accuracy: 0.8483 - val_loss: 0.6793 - val_accuracy: 0.6907\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3378 - accuracy: 0.8580 - val_loss: 0.6536 - val_accuracy: 0.7058\n","Epoch 26/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3365 - accuracy: 0.8621 - val_loss: 0.6341 - val_accuracy: 0.7112\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3310 - accuracy: 0.8656 - val_loss: 0.6199 - val_accuracy: 0.7209\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3263 - accuracy: 0.8575 - val_loss: 0.5947 - val_accuracy: 0.7435\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3362 - accuracy: 0.8602 - val_loss: 0.6070 - val_accuracy: 0.7403\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3468 - accuracy: 0.8508 - val_loss: 0.6074 - val_accuracy: 0.7371\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3270 - accuracy: 0.8658 - val_loss: 0.6074 - val_accuracy: 0.7457\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3272 - accuracy: 0.8691 - val_loss: 0.6281 - val_accuracy: 0.7317\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3290 - accuracy: 0.8656 - val_loss: 0.6182 - val_accuracy: 0.7360\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3190 - accuracy: 0.8680 - val_loss: 0.6173 - val_accuracy: 0.7360\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3168 - accuracy: 0.8688 - val_loss: 0.6221 - val_accuracy: 0.7403\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3352 - accuracy: 0.8578 - val_loss: 0.6339 - val_accuracy: 0.7446\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3168 - accuracy: 0.8715 - val_loss: 0.6257 - val_accuracy: 0.7349\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3267 - accuracy: 0.8626 - val_loss: 0.6462 - val_accuracy: 0.7338\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3180 - accuracy: 0.8712 - val_loss: 0.6296 - val_accuracy: 0.7403\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.8691 - val_loss: 0.6444 - val_accuracy: 0.7274\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3168 - accuracy: 0.8702 - val_loss: 0.6377 - val_accuracy: 0.7349\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3152 - accuracy: 0.8696 - val_loss: 0.6437 - val_accuracy: 0.7284\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3306 - accuracy: 0.8613 - val_loss: 0.6299 - val_accuracy: 0.7392\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3083 - accuracy: 0.8747 - val_loss: 0.6624 - val_accuracy: 0.7220\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3117 - accuracy: 0.8675 - val_loss: 0.7250 - val_accuracy: 0.6918\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3010 - accuracy: 0.8766 - val_loss: 0.6460 - val_accuracy: 0.7328\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3128 - accuracy: 0.8739 - val_loss: 0.6647 - val_accuracy: 0.7263\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3168 - accuracy: 0.8610 - val_loss: 0.6687 - val_accuracy: 0.7274\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3112 - accuracy: 0.8702 - val_loss: 0.6615 - val_accuracy: 0.7317\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2929 - accuracy: 0.8788 - val_loss: 0.6539 - val_accuracy: 0.7338\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2977 - accuracy: 0.8745 - val_loss: 0.6876 - val_accuracy: 0.7241\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2873 - accuracy: 0.8828 - val_loss: 0.6611 - val_accuracy: 0.7317\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2852 - accuracy: 0.8895 - val_loss: 0.6856 - val_accuracy: 0.7231\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2983 - accuracy: 0.8782 - val_loss: 0.6618 - val_accuracy: 0.7306\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2842 - accuracy: 0.8850 - val_loss: 0.7381 - val_accuracy: 0.6972\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2905 - accuracy: 0.8815 - val_loss: 0.6847 - val_accuracy: 0.7284\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2839 - accuracy: 0.8855 - val_loss: 0.6725 - val_accuracy: 0.7317\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2873 - accuracy: 0.8855 - val_loss: 0.6691 - val_accuracy: 0.7284\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2864 - accuracy: 0.8831 - val_loss: 0.7764 - val_accuracy: 0.6886\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2884 - accuracy: 0.8812 - val_loss: 0.6782 - val_accuracy: 0.7252\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2849 - accuracy: 0.8834 - val_loss: 0.6790 - val_accuracy: 0.7241\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2715 - accuracy: 0.8914 - val_loss: 0.6786 - val_accuracy: 0.7349\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2705 - accuracy: 0.8976 - val_loss: 0.6917 - val_accuracy: 0.7241\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2883 - accuracy: 0.8798 - val_loss: 0.6889 - val_accuracy: 0.7284\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2699 - accuracy: 0.8920 - val_loss: 0.7139 - val_accuracy: 0.7101\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2764 - accuracy: 0.8890 - val_loss: 0.6921 - val_accuracy: 0.7295\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2732 - accuracy: 0.8898 - val_loss: 0.7155 - val_accuracy: 0.7188\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2676 - accuracy: 0.8960 - val_loss: 0.6952 - val_accuracy: 0.7349\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2633 - accuracy: 0.8974 - val_loss: 0.7819 - val_accuracy: 0.7004\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2761 - accuracy: 0.8882 - val_loss: 0.6971 - val_accuracy: 0.7338\n","Epoch 71/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2651 - accuracy: 0.8966 - val_loss: 0.6994 - val_accuracy: 0.7284\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2708 - accuracy: 0.8885 - val_loss: 0.7808 - val_accuracy: 0.6972\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2653 - accuracy: 0.8974 - val_loss: 0.7486 - val_accuracy: 0.7123\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2618 - accuracy: 0.8955 - val_loss: 0.7335 - val_accuracy: 0.7091\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2614 - accuracy: 0.8922 - val_loss: 0.7117 - val_accuracy: 0.7198\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2665 - accuracy: 0.8914 - val_loss: 0.7045 - val_accuracy: 0.7263\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2509 - accuracy: 0.8971 - val_loss: 0.7191 - val_accuracy: 0.7209\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2601 - accuracy: 0.8930 - val_loss: 0.7813 - val_accuracy: 0.6972\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2638 - accuracy: 0.8871 - val_loss: 0.7151 - val_accuracy: 0.7295\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2487 - accuracy: 0.9009 - val_loss: 0.8044 - val_accuracy: 0.6853\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2595 - accuracy: 0.8984 - val_loss: 0.7829 - val_accuracy: 0.6983\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2695 - accuracy: 0.8904 - val_loss: 0.7166 - val_accuracy: 0.7284\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2401 - accuracy: 0.9044 - val_loss: 0.7250 - val_accuracy: 0.7177\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2432 - accuracy: 0.9054 - val_loss: 0.7300 - val_accuracy: 0.7241\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2477 - accuracy: 0.9036 - val_loss: 0.7631 - val_accuracy: 0.7047\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2484 - accuracy: 0.9052 - val_loss: 0.7683 - val_accuracy: 0.7058\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2415 - accuracy: 0.9054 - val_loss: 0.7362 - val_accuracy: 0.7155\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2356 - accuracy: 0.9057 - val_loss: 0.7348 - val_accuracy: 0.7209\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2314 - accuracy: 0.9127 - val_loss: 0.7519 - val_accuracy: 0.7144\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2479 - accuracy: 0.9001 - val_loss: 0.8406 - val_accuracy: 0.6929\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2379 - accuracy: 0.9062 - val_loss: 0.7600 - val_accuracy: 0.7220\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2303 - accuracy: 0.9076 - val_loss: 0.7556 - val_accuracy: 0.7241\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2282 - accuracy: 0.9138 - val_loss: 0.7783 - val_accuracy: 0.7188\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2185 - accuracy: 0.9116 - val_loss: 0.7707 - val_accuracy: 0.7155\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2311 - accuracy: 0.9100 - val_loss: 0.7803 - val_accuracy: 0.7166\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2209 - accuracy: 0.9154 - val_loss: 0.7674 - val_accuracy: 0.7220\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2330 - accuracy: 0.9030 - val_loss: 0.7791 - val_accuracy: 0.7155\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2238 - accuracy: 0.9079 - val_loss: 0.7815 - val_accuracy: 0.7188\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2255 - accuracy: 0.9100 - val_loss: 0.7708 - val_accuracy: 0.7155\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2250 - accuracy: 0.9100 - val_loss: 0.7972 - val_accuracy: 0.7037\n","{'loss': [0.40851184725761414, 0.39621028304100037, 0.39384543895721436, 0.38114920258522034, 0.38159653544425964, 0.38164883852005005, 0.37556296586990356, 0.38601770997047424, 0.37151631712913513, 0.37979406118392944, 0.3793143630027771, 0.3605518043041229, 0.3636054992675781, 0.3569321930408478, 0.3665069341659546, 0.3671083152294159, 0.3549445569515228, 0.360068142414093, 0.35512587428092957, 0.3471303880214691, 0.3493032455444336, 0.347237229347229, 0.3398907780647278, 0.3521466851234436, 0.33779025077819824, 0.3365335762500763, 0.3310282826423645, 0.32628604769706726, 0.33621320128440857, 0.3468422591686249, 0.32704201340675354, 0.3271659314632416, 0.32903990149497986, 0.3189757764339447, 0.3167940080165863, 0.33522945642471313, 0.3168047070503235, 0.32665035128593445, 0.31802740693092346, 0.31767016649246216, 0.3167972266674042, 0.3151989281177521, 0.33056312799453735, 0.3083080053329468, 0.31166404485702515, 0.3009699881076813, 0.3127562701702118, 0.31676071882247925, 0.31123897433280945, 0.29294848442077637, 0.29769593477249146, 0.287287175655365, 0.2851526737213135, 0.29834210872650146, 0.2841564118862152, 0.2904907464981079, 0.2839150130748749, 0.2872622013092041, 0.28642725944519043, 0.2883533537387848, 0.28486403822898865, 0.27149125933647156, 0.27054697275161743, 0.2882990539073944, 0.26986369490623474, 0.2763628363609314, 0.27324068546295166, 0.26755473017692566, 0.2632701098918915, 0.2760617434978485, 0.26513850688934326, 0.27083587646484375, 0.2653005123138428, 0.26181429624557495, 0.2613815367221832, 0.2665264308452606, 0.2509118914604187, 0.2601238191127777, 0.2638203203678131, 0.24873888492584229, 0.2595180869102478, 0.2694757580757141, 0.24012736976146698, 0.24320916831493378, 0.2476731836795807, 0.24840117990970612, 0.24145932495594025, 0.23557880520820618, 0.23135031759738922, 0.24785056710243225, 0.23785357177257538, 0.2303345501422882, 0.22821107506752014, 0.21848508715629578, 0.23110514879226685, 0.22089925408363342, 0.23300330340862274, 0.2238471359014511, 0.2254616767168045, 0.2250339537858963], 'accuracy': [0.8208512663841248, 0.8251616358757019, 0.8283944129943848, 0.834321141242981, 0.8386314511299133, 0.8429418206214905, 0.834590494632721, 0.8327047228813171, 0.842402994632721, 0.8370150923728943, 0.8316271305084229, 0.8491379022598267, 0.8442887663841248, 0.8456357717514038, 0.837284505367279, 0.8386314511299133, 0.8539870977401733, 0.8488685488700867, 0.8534482717514038, 0.8569504022598267, 0.8521012663841248, 0.8507543206214905, 0.8634159564971924, 0.8483297228813171, 0.858027994632721, 0.8620689511299133, 0.865571141242981, 0.8574892282485962, 0.8601831793785095, 0.8507543206214905, 0.865840494632721, 0.8690732717514038, 0.865571141242981, 0.8679956793785095, 0.868803858757019, 0.857758641242981, 0.8714978694915771, 0.8626077771186829, 0.8712284564971924, 0.8690732717514038, 0.8701508641242981, 0.8696120977401733, 0.8612607717514038, 0.8747305870056152, 0.8674569129943848, 0.876616358757019, 0.8739224076271057, 0.860991358757019, 0.8701508641242981, 0.8787715435028076, 0.8744612336158752, 0.8828125, 0.8895474076271057, 0.8782327771186829, 0.8849676847457886, 0.881465494632721, 0.8855064511299133, 0.8855064511299133, 0.8830819129943848, 0.881196141242981, 0.8833512663841248, 0.8914331793785095, 0.8976293206214905, 0.8798491358757019, 0.891972005367279, 0.889008641242981, 0.8898168206214905, 0.8960129022598267, 0.8973599076271057, 0.8882004022598267, 0.8965517282485962, 0.8884698152542114, 0.8973599076271057, 0.8954741358757019, 0.892241358757019, 0.8914331793785095, 0.897090494632721, 0.8930495977401733, 0.8871228694915771, 0.9008620977401733, 0.8984375, 0.8903555870056152, 0.9043642282485962, 0.9054418206214905, 0.9035560488700867, 0.9051724076271057, 0.9054418206214905, 0.9057112336158752, 0.912715494632721, 0.900053858757019, 0.90625, 0.907597005367279, 0.9137930870056152, 0.9116379022598267, 0.9100215435028076, 0.915409505367279, 0.9030172228813171, 0.907866358757019, 0.9100215435028076, 0.9100215435028076], 'val_loss': [0.6990014314651489, 0.694028377532959, 0.6862627863883972, 0.679223895072937, 0.672493577003479, 0.6677860617637634, 0.6661784052848816, 0.6657001376152039, 0.6597388982772827, 0.6570910811424255, 0.6520188450813293, 0.6667022705078125, 0.679710328578949, 0.687705934047699, 0.7080821394920349, 0.6927363276481628, 0.7326645851135254, 0.7519816160202026, 0.7099367380142212, 0.7038167119026184, 0.7259481549263, 0.6327598690986633, 0.6190376281738281, 0.679308295249939, 0.6535735130310059, 0.6341355443000793, 0.619877278804779, 0.5947256684303284, 0.6069638729095459, 0.6074045300483704, 0.6073896884918213, 0.6280784010887146, 0.6181944608688354, 0.6172804236412048, 0.6220603585243225, 0.6338868141174316, 0.6257398128509521, 0.6461645364761353, 0.6295952200889587, 0.6443714499473572, 0.6376760601997375, 0.6436913013458252, 0.6298574209213257, 0.6624347567558289, 0.7249869704246521, 0.645969033241272, 0.66468346118927, 0.6687451004981995, 0.6614719033241272, 0.6539262533187866, 0.6876016855239868, 0.6611328125, 0.6856303215026855, 0.6617664098739624, 0.7380568385124207, 0.6846693158149719, 0.6724603176116943, 0.6690753698348999, 0.77638179063797, 0.6781619787216187, 0.6790307760238647, 0.6785556674003601, 0.6917139291763306, 0.6888523697853088, 0.7138919234275818, 0.6920871138572693, 0.7154983878135681, 0.6951543092727661, 0.7819350957870483, 0.6971045732498169, 0.6994286179542542, 0.7807853817939758, 0.7486002445220947, 0.7335218787193298, 0.711692750453949, 0.7045338749885559, 0.7190919518470764, 0.7812843322753906, 0.715124249458313, 0.8043923377990723, 0.7828897833824158, 0.7165578603744507, 0.7249583601951599, 0.730040967464447, 0.7631097435951233, 0.768309473991394, 0.7362454533576965, 0.7347697615623474, 0.7518775463104248, 0.8405917882919312, 0.7599511742591858, 0.7555958032608032, 0.7782689332962036, 0.7706810235977173, 0.7803160548210144, 0.7674087882041931, 0.7791151404380798, 0.7814890742301941, 0.7708075046539307, 0.7971743941307068], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.5258620977401733, 0.6411637663841248, 0.6584051847457886, 0.6357758641242981, 0.6034482717514038, 0.6142241358757019, 0.607758641242981, 0.618534505367279, 0.5915948152542114, 0.5829741358757019, 0.579741358757019, 0.576508641242981, 0.5915948152542114, 0.5808189511299133, 0.5851293206214905, 0.6131465435028076, 0.6400862336158752, 0.6400862336158752, 0.6885775923728943, 0.7036637663841248, 0.6907327771186829, 0.7058189511299133, 0.7112069129943848, 0.7209051847457886, 0.743534505367279, 0.7403017282485962, 0.7370689511299133, 0.7456896305084229, 0.7316810488700867, 0.735991358757019, 0.735991358757019, 0.7403017282485962, 0.7446120977401733, 0.7349137663841248, 0.7338362336158752, 0.7403017282485962, 0.7273706793785095, 0.7349137663841248, 0.7284482717514038, 0.7392241358757019, 0.7219827771186829, 0.6918103694915771, 0.732758641242981, 0.7262930870056152, 0.7273706793785095, 0.7316810488700867, 0.7338362336158752, 0.7241379022598267, 0.7316810488700867, 0.7230603694915771, 0.7306034564971924, 0.6971982717514038, 0.7284482717514038, 0.7316810488700867, 0.7284482717514038, 0.6885775923728943, 0.725215494632721, 0.7241379022598267, 0.7349137663841248, 0.7241379022598267, 0.7284482717514038, 0.7101293206214905, 0.7295258641242981, 0.71875, 0.7349137663841248, 0.7004310488700867, 0.7338362336158752, 0.7284482717514038, 0.6971982717514038, 0.712284505367279, 0.7090517282485962, 0.7198275923728943, 0.7262930870056152, 0.7209051847457886, 0.6971982717514038, 0.7295258641242981, 0.6853448152542114, 0.6982758641242981, 0.7284482717514038, 0.7176724076271057, 0.7241379022598267, 0.704741358757019, 0.7058189511299133, 0.7155172228813171, 0.7209051847457886, 0.7144396305084229, 0.6928879022598267, 0.7219827771186829, 0.7241379022598267, 0.71875, 0.7155172228813171, 0.7165948152542114, 0.7219827771186829, 0.7155172228813171, 0.71875, 0.7155172228813171, 0.7036637663841248]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.8138"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 62ms/step - loss: 0.4224 - accuracy: 0.8138 - val_loss: 0.6958 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3965 - accuracy: 0.8316 - val_loss: 0.6918 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3927 - accuracy: 0.8297 - val_loss: 0.6856 - val_accuracy: 0.5000\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3938 - accuracy: 0.8268 - val_loss: 0.6798 - val_accuracy: 0.5204\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3920 - accuracy: 0.8282 - val_loss: 0.6735 - val_accuracy: 0.6244\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3990 - accuracy: 0.8175 - val_loss: 0.6701 - val_accuracy: 0.6538\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3948 - accuracy: 0.8280 - val_loss: 0.6656 - val_accuracy: 0.6606\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3807 - accuracy: 0.8311 - val_loss: 0.6635 - val_accuracy: 0.6471\n","Epoch 9/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3784 - accuracy: 0.8367 - val_loss: 0.6659 - val_accuracy: 0.6086\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3885 - accuracy: 0.8248 - val_loss: 0.6643 - val_accuracy: 0.6097\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3801 - accuracy: 0.8328 - val_loss: 0.6623 - val_accuracy: 0.6097\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3814 - accuracy: 0.8398 - val_loss: 0.6722 - val_accuracy: 0.5826\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3774 - accuracy: 0.8373 - val_loss: 0.6671 - val_accuracy: 0.5962\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3682 - accuracy: 0.8376 - val_loss: 0.6611 - val_accuracy: 0.6075\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3715 - accuracy: 0.8421 - val_loss: 0.6665 - val_accuracy: 0.5995\n","Epoch 16/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3688 - accuracy: 0.8396 - val_loss: 0.6894 - val_accuracy: 0.5928\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3575 - accuracy: 0.8463 - val_loss: 0.6916 - val_accuracy: 0.6029\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3901 - accuracy: 0.8263 - val_loss: 0.6660 - val_accuracy: 0.6301\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.8407 - val_loss: 0.6845 - val_accuracy: 0.6278\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3519 - accuracy: 0.8571 - val_loss: 0.6462 - val_accuracy: 0.6629\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3647 - accuracy: 0.8461 - val_loss: 0.7159 - val_accuracy: 0.6312\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3561 - accuracy: 0.8427 - val_loss: 0.6861 - val_accuracy: 0.6640\n","Epoch 23/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3600 - accuracy: 0.8463 - val_loss: 0.6382 - val_accuracy: 0.6821\n","Epoch 24/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3420 - accuracy: 0.8531 - val_loss: 0.6040 - val_accuracy: 0.7104\n","Epoch 25/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3451 - accuracy: 0.8475 - val_loss: 0.5840 - val_accuracy: 0.7274\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3362 - accuracy: 0.8602 - val_loss: 0.6501 - val_accuracy: 0.7025\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3490 - accuracy: 0.8438 - val_loss: 0.5907 - val_accuracy: 0.7308\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3513 - accuracy: 0.8523 - val_loss: 0.5708 - val_accuracy: 0.7296\n","Epoch 29/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3391 - accuracy: 0.8551 - val_loss: 0.5621 - val_accuracy: 0.7330\n","Epoch 30/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3470 - accuracy: 0.8540 - val_loss: 0.5731 - val_accuracy: 0.7353\n","Epoch 31/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3371 - accuracy: 0.8565 - val_loss: 0.5651 - val_accuracy: 0.7443\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3412 - accuracy: 0.8616 - val_loss: 0.5723 - val_accuracy: 0.7387\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3266 - accuracy: 0.8599 - val_loss: 0.5802 - val_accuracy: 0.7398\n","Epoch 34/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3303 - accuracy: 0.8580 - val_loss: 0.5878 - val_accuracy: 0.7466\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3278 - accuracy: 0.8645 - val_loss: 0.5950 - val_accuracy: 0.7353\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3286 - accuracy: 0.8602 - val_loss: 0.5885 - val_accuracy: 0.7398\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3255 - accuracy: 0.8580 - val_loss: 0.5834 - val_accuracy: 0.7466\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3182 - accuracy: 0.8633 - val_loss: 0.6032 - val_accuracy: 0.7319\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3155 - accuracy: 0.8707 - val_loss: 0.6075 - val_accuracy: 0.7319\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3117 - accuracy: 0.8664 - val_loss: 0.6069 - val_accuracy: 0.7353\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3199 - accuracy: 0.8696 - val_loss: 0.6033 - val_accuracy: 0.7466\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3216 - accuracy: 0.8670 - val_loss: 0.6070 - val_accuracy: 0.7443\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3189 - accuracy: 0.8633 - val_loss: 0.6048 - val_accuracy: 0.7398\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3093 - accuracy: 0.8755 - val_loss: 0.6239 - val_accuracy: 0.7319\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3068 - accuracy: 0.8749 - val_loss: 0.6142 - val_accuracy: 0.7285\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3086 - accuracy: 0.8735 - val_loss: 0.6199 - val_accuracy: 0.7410\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3049 - accuracy: 0.8772 - val_loss: 0.6149 - val_accuracy: 0.7466\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3043 - accuracy: 0.8744 - val_loss: 0.6460 - val_accuracy: 0.7274\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3045 - accuracy: 0.8749 - val_loss: 0.6624 - val_accuracy: 0.7206\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3040 - accuracy: 0.8735 - val_loss: 0.6218 - val_accuracy: 0.7466\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2962 - accuracy: 0.8727 - val_loss: 0.6501 - val_accuracy: 0.7229\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2945 - accuracy: 0.8780 - val_loss: 0.6237 - val_accuracy: 0.7432\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3014 - accuracy: 0.8713 - val_loss: 0.6296 - val_accuracy: 0.7308\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2865 - accuracy: 0.8871 - val_loss: 0.6545 - val_accuracy: 0.7217\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2991 - accuracy: 0.8718 - val_loss: 0.6841 - val_accuracy: 0.7138\n","Epoch 56/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3151 - accuracy: 0.8613 - val_loss: 0.6271 - val_accuracy: 0.7443\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2926 - accuracy: 0.8758 - val_loss: 0.6437 - val_accuracy: 0.7330\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2905 - accuracy: 0.8741 - val_loss: 0.6206 - val_accuracy: 0.7466\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2838 - accuracy: 0.8820 - val_loss: 0.7136 - val_accuracy: 0.7149\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2929 - accuracy: 0.8769 - val_loss: 0.6551 - val_accuracy: 0.7285\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2886 - accuracy: 0.8758 - val_loss: 0.6604 - val_accuracy: 0.7353\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2716 - accuracy: 0.8896 - val_loss: 0.6453 - val_accuracy: 0.7262\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2814 - accuracy: 0.8857 - val_loss: 0.6507 - val_accuracy: 0.7353\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2844 - accuracy: 0.8746 - val_loss: 0.6482 - val_accuracy: 0.7421\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2773 - accuracy: 0.8905 - val_loss: 0.6632 - val_accuracy: 0.7330\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2660 - accuracy: 0.8930 - val_loss: 0.6656 - val_accuracy: 0.7308\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2653 - accuracy: 0.8908 - val_loss: 0.6684 - val_accuracy: 0.7240\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2810 - accuracy: 0.8809 - val_loss: 0.6574 - val_accuracy: 0.7398\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 0.8735 - val_loss: 0.7082 - val_accuracy: 0.7104\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2701 - accuracy: 0.8877 - val_loss: 0.6517 - val_accuracy: 0.7330\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2597 - accuracy: 0.8984 - val_loss: 0.6571 - val_accuracy: 0.7387\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2648 - accuracy: 0.8936 - val_loss: 0.6857 - val_accuracy: 0.7308\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2601 - accuracy: 0.8953 - val_loss: 0.6780 - val_accuracy: 0.7319\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2705 - accuracy: 0.8831 - val_loss: 0.6859 - val_accuracy: 0.7342\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2566 - accuracy: 0.8973 - val_loss: 0.6710 - val_accuracy: 0.7387\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2525 - accuracy: 0.8956 - val_loss: 0.7086 - val_accuracy: 0.7138\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2743 - accuracy: 0.8820 - val_loss: 0.6923 - val_accuracy: 0.7285\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2483 - accuracy: 0.9024 - val_loss: 0.6784 - val_accuracy: 0.7251\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2466 - accuracy: 0.8970 - val_loss: 0.7065 - val_accuracy: 0.7172\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2624 - accuracy: 0.8885 - val_loss: 0.6819 - val_accuracy: 0.7376\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2400 - accuracy: 0.9027 - val_loss: 0.6997 - val_accuracy: 0.7229\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2589 - accuracy: 0.8902 - val_loss: 0.6903 - val_accuracy: 0.7398\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2488 - accuracy: 0.8998 - val_loss: 0.7140 - val_accuracy: 0.7217\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2431 - accuracy: 0.9004 - val_loss: 0.7004 - val_accuracy: 0.7342\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2404 - accuracy: 0.9007 - val_loss: 0.6945 - val_accuracy: 0.7364\n","Epoch 86/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2391 - accuracy: 0.9001 - val_loss: 0.6967 - val_accuracy: 0.7410\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2494 - accuracy: 0.9001 - val_loss: 0.7547 - val_accuracy: 0.7025\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2618 - accuracy: 0.8936 - val_loss: 0.7115 - val_accuracy: 0.7206\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2417 - accuracy: 0.9004 - val_loss: 0.7696 - val_accuracy: 0.7070\n","Epoch 90/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2410 - accuracy: 0.9052 - val_loss: 0.7378 - val_accuracy: 0.7127\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2409 - accuracy: 0.8970 - val_loss: 0.7069 - val_accuracy: 0.7410\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2320 - accuracy: 0.9029 - val_loss: 0.7320 - val_accuracy: 0.7308\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2251 - accuracy: 0.9095 - val_loss: 0.7239 - val_accuracy: 0.7308\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2232 - accuracy: 0.9109 - val_loss: 0.7188 - val_accuracy: 0.7319\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2258 - accuracy: 0.9080 - val_loss: 0.7309 - val_accuracy: 0.7251\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2278 - accuracy: 0.9066 - val_loss: 0.7264 - val_accuracy: 0.7195\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2161 - accuracy: 0.9134 - val_loss: 0.7331 - val_accuracy: 0.7353\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2172 - accuracy: 0.9165 - val_loss: 0.7321 - val_accuracy: 0.7376\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2187 - accuracy: 0.9151 - val_loss: 0.7661 - val_accuracy: 0.7251\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2275 - accuracy: 0.9109 - val_loss: 0.7317 - val_accuracy: 0.7443\n","{'loss': [0.4224206209182739, 0.3964539170265198, 0.3926898241043091, 0.39380329847335815, 0.3920295536518097, 0.39897090196609497, 0.3948236405849457, 0.38066452741622925, 0.3784143030643463, 0.3885466158390045, 0.38006845116615295, 0.3814294636249542, 0.37735408544540405, 0.3682081699371338, 0.3714792728424072, 0.36884310841560364, 0.3574700355529785, 0.3900679349899292, 0.3637579679489136, 0.35185593366622925, 0.36472129821777344, 0.35614562034606934, 0.35996875166893005, 0.34200987219810486, 0.3450845777988434, 0.33620837330818176, 0.34899815917015076, 0.3513343036174774, 0.3391369879245758, 0.3469755947589874, 0.337089478969574, 0.34118083119392395, 0.3266492486000061, 0.33027026057243347, 0.32778000831604004, 0.3286255896091461, 0.3255424201488495, 0.3182367980480194, 0.31549227237701416, 0.31165266036987305, 0.31988897919654846, 0.32162654399871826, 0.3188749849796295, 0.30928418040275574, 0.30679085850715637, 0.30864739418029785, 0.304882287979126, 0.3042695224285126, 0.30451151728630066, 0.30398374795913696, 0.29622021317481995, 0.29452139139175415, 0.3013954758644104, 0.28649383783340454, 0.2990624010562897, 0.3150777518749237, 0.29257112741470337, 0.29047325253486633, 0.2838258147239685, 0.2928605377674103, 0.2885535955429077, 0.2715735137462616, 0.2813939154148102, 0.2843901216983795, 0.2772517502307892, 0.26595592498779297, 0.265257865190506, 0.2809978127479553, 0.29698076844215393, 0.27005302906036377, 0.25972360372543335, 0.26481229066848755, 0.2601108253002167, 0.27052026987075806, 0.25658050179481506, 0.2525441348552704, 0.2742709517478943, 0.24825651943683624, 0.2465561032295227, 0.2623957395553589, 0.2400389313697815, 0.25893035531044006, 0.24876120686531067, 0.24305109679698944, 0.24038216471672058, 0.2391144335269928, 0.2493734210729599, 0.2617779076099396, 0.24167773127555847, 0.2409842610359192, 0.24089108407497406, 0.23198407888412476, 0.22511276602745056, 0.22321271896362305, 0.22581203281879425, 0.22780078649520874, 0.21612383425235748, 0.21719375252723694, 0.2187262922525406, 0.22753018140792847], 'accuracy': [0.8138087391853333, 0.8316355347633362, 0.8296547532081604, 0.8268251419067383, 0.8282399773597717, 0.8174872398376465, 0.8279569745063782, 0.8310695886611938, 0.8367289304733276, 0.8248443603515625, 0.8327674269676208, 0.8398415446281433, 0.83729487657547, 0.8375778198242188, 0.8421052694320679, 0.8395586013793945, 0.8463497161865234, 0.826259195804596, 0.8406904339790344, 0.8571024537086487, 0.8460667729377747, 0.8426712155342102, 0.8463497161865234, 0.8531408905982971, 0.8474816083908081, 0.8602150678634644, 0.8438030481338501, 0.852292001247406, 0.8551216721534729, 0.853989839553833, 0.8565365076065063, 0.8616299033164978, 0.8599320650100708, 0.8579513430595398, 0.8644595146179199, 0.8602150678634644, 0.8579513430595398, 0.86332768201828, 0.870684802532196, 0.8664402961730957, 0.8695529103279114, 0.867006242275238, 0.86332768201828, 0.875495195388794, 0.8749292492866516, 0.8735144138336182, 0.8771929740905762, 0.8743633031845093, 0.8749292492866516, 0.8735144138336182, 0.872665524482727, 0.8780418634414673, 0.8712506890296936, 0.8870967626571655, 0.8718166351318359, 0.8613469004631042, 0.8757781386375427, 0.8740803599357605, 0.8820033669471741, 0.8769100308418274, 0.8757781386375427, 0.8896434903144836, 0.8856819272041321, 0.8746463060379028, 0.8904923796653748, 0.8930390477180481, 0.8907753229141235, 0.8808715343475342, 0.8735144138336182, 0.8876627087593079, 0.8984153866767883, 0.8936049938201904, 0.8953027725219727, 0.8831352591514587, 0.8972835540771484, 0.8955857157707214, 0.8820033669471741, 0.9023768901824951, 0.8970005512237549, 0.888511598110199, 0.9026598930358887, 0.8902093768119812, 0.8998302221298218, 0.9003961682319641, 0.9006791114807129, 0.9001131653785706, 0.9001131653785706, 0.8936049938201904, 0.9003961682319641, 0.905206561088562, 0.8970005512237549, 0.9029428362846375, 0.9094510674476624, 0.9108659029006958, 0.9080362319946289, 0.9066213965415955, 0.9134125709533691, 0.9165251851081848, 0.9151103496551514, 0.9108659029006958], 'val_loss': [0.6957695484161377, 0.691750168800354, 0.6855500340461731, 0.6797606348991394, 0.6734967827796936, 0.6700610518455505, 0.6656315922737122, 0.6634582877159119, 0.6659197807312012, 0.6643070578575134, 0.6623015403747559, 0.6721534132957458, 0.6671248078346252, 0.6610956192016602, 0.666450023651123, 0.6893756985664368, 0.6915577054023743, 0.666007936000824, 0.6845175623893738, 0.6461950540542603, 0.715873122215271, 0.6860777139663696, 0.6382449269294739, 0.6040365099906921, 0.5839729309082031, 0.6500851511955261, 0.5907006859779358, 0.5708479881286621, 0.5620830059051514, 0.5730663537979126, 0.5650505423545837, 0.5722713470458984, 0.5801571607589722, 0.5877858400344849, 0.5949557423591614, 0.5884904265403748, 0.58344566822052, 0.6032217144966125, 0.6075409650802612, 0.6068681478500366, 0.603308379650116, 0.6069570779800415, 0.604792058467865, 0.6238583326339722, 0.6142009496688843, 0.6198577284812927, 0.6148988604545593, 0.6460181474685669, 0.6624423861503601, 0.621829628944397, 0.6501134037971497, 0.6236768960952759, 0.6295809745788574, 0.6545019149780273, 0.6841158866882324, 0.6270653009414673, 0.6436920762062073, 0.6205917000770569, 0.7136061787605286, 0.6550876498222351, 0.6603531241416931, 0.6452571749687195, 0.6506596803665161, 0.6481561660766602, 0.6632449626922607, 0.6656018495559692, 0.6683543920516968, 0.6573843955993652, 0.7082149386405945, 0.651699960231781, 0.6571083068847656, 0.6856682300567627, 0.6780080795288086, 0.6859368085861206, 0.6709549427032471, 0.7085618376731873, 0.6922721862792969, 0.6783676743507385, 0.7064683437347412, 0.681861937046051, 0.6997010707855225, 0.6902991533279419, 0.7139928936958313, 0.7003857493400574, 0.6945376992225647, 0.6967198848724365, 0.7547135353088379, 0.7114817500114441, 0.7696455717086792, 0.737789511680603, 0.706852376461029, 0.7320089340209961, 0.7239388227462769, 0.7187538146972656, 0.7309015393257141, 0.7264419198036194, 0.7330549359321594, 0.7320687174797058, 0.7661291360855103, 0.7317285537719727], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.5, 0.5203620195388794, 0.6244344115257263, 0.6538461446762085, 0.6606335043907166, 0.6470588445663452, 0.6085972785949707, 0.6097285151481628, 0.6097285151481628, 0.5825791954994202, 0.5961538553237915, 0.6074660420417786, 0.5995475053787231, 0.5927602052688599, 0.6029411554336548, 0.6300904750823975, 0.627828061580658, 0.662895917892456, 0.6312217116355896, 0.6640271544456482, 0.6821267008781433, 0.7104072570800781, 0.7273755669593811, 0.7024886608123779, 0.7307692170143127, 0.7296379804611206, 0.733031690120697, 0.7352941036224365, 0.7443438768386841, 0.7386877536773682, 0.7398189902305603, 0.7466063499450684, 0.7352941036224365, 0.7398189902305603, 0.7466063499450684, 0.7319004535675049, 0.7319004535675049, 0.7352941036224365, 0.7466063499450684, 0.7443438768386841, 0.7398189902305603, 0.7319004535675049, 0.7285068035125732, 0.7409502267837524, 0.7466063499450684, 0.7273755669593811, 0.720588207244873, 0.7466063499450684, 0.7228506803512573, 0.7432126402854919, 0.7307692170143127, 0.7217194437980652, 0.7138009071350098, 0.7443438768386841, 0.733031690120697, 0.7466063499450684, 0.7149321436882019, 0.7285068035125732, 0.7352941036224365, 0.726244330406189, 0.7352941036224365, 0.7420814633369446, 0.733031690120697, 0.7307692170143127, 0.7239819169044495, 0.7398189902305603, 0.7104072570800781, 0.733031690120697, 0.7386877536773682, 0.7307692170143127, 0.7319004535675049, 0.7341628670692444, 0.7386877536773682, 0.7138009071350098, 0.7285068035125732, 0.7251130938529968, 0.7171945571899414, 0.7375565767288208, 0.7228506803512573, 0.7398189902305603, 0.7217194437980652, 0.7341628670692444, 0.7364253401756287, 0.7409502267837524, 0.7024886608123779, 0.720588207244873, 0.7070135474205017, 0.7126696705818176, 0.7409502267837524, 0.7307692170143127, 0.7307692170143127, 0.7319004535675049, 0.7251130938529968, 0.7194570302963257, 0.7352941036224365, 0.7375565767288208, 0.7251130938529968, 0.7443438768386841]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4277 - accuracy: 0.8099"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 72ms/step - loss: 0.4269 - accuracy: 0.8106 - val_loss: 0.6986 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4250 - accuracy: 0.8111 - val_loss: 0.6947 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3948 - accuracy: 0.8351 - val_loss: 0.6854 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3897 - accuracy: 0.8313 - val_loss: 0.6779 - val_accuracy: 0.5496\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3934 - accuracy: 0.8297 - val_loss: 0.6718 - val_accuracy: 0.6488\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4005 - accuracy: 0.8261 - val_loss: 0.6676 - val_accuracy: 0.6632\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3926 - accuracy: 0.8240 - val_loss: 0.6640 - val_accuracy: 0.6498\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3868 - accuracy: 0.8315 - val_loss: 0.6618 - val_accuracy: 0.6260\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3797 - accuracy: 0.8421 - val_loss: 0.6627 - val_accuracy: 0.6043\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3761 - accuracy: 0.8416 - val_loss: 0.6680 - val_accuracy: 0.5785\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3769 - accuracy: 0.8393 - val_loss: 0.6703 - val_accuracy: 0.5754\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3779 - accuracy: 0.8354 - val_loss: 0.6652 - val_accuracy: 0.5930\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3727 - accuracy: 0.8432 - val_loss: 0.6664 - val_accuracy: 0.5981\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3834 - accuracy: 0.8320 - val_loss: 0.6938 - val_accuracy: 0.5847\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3681 - accuracy: 0.8491 - val_loss: 0.6989 - val_accuracy: 0.5899\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3655 - accuracy: 0.8403 - val_loss: 0.7221 - val_accuracy: 0.5919\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3657 - accuracy: 0.8437 - val_loss: 0.7132 - val_accuracy: 0.6064\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3737 - accuracy: 0.8439 - val_loss: 0.7217 - val_accuracy: 0.6167\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3616 - accuracy: 0.8447 - val_loss: 0.8125 - val_accuracy: 0.5950\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3650 - accuracy: 0.8416 - val_loss: 0.6872 - val_accuracy: 0.6539\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3665 - accuracy: 0.8434 - val_loss: 0.6780 - val_accuracy: 0.6632\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3597 - accuracy: 0.8550 - val_loss: 0.7056 - val_accuracy: 0.6601\n","Epoch 23/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3545 - accuracy: 0.8540 - val_loss: 0.6855 - val_accuracy: 0.6725\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3723 - accuracy: 0.8323 - val_loss: 0.7655 - val_accuracy: 0.6601\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3522 - accuracy: 0.8486 - val_loss: 0.6832 - val_accuracy: 0.6725\n","Epoch 26/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3499 - accuracy: 0.8535 - val_loss: 0.6317 - val_accuracy: 0.7169\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3469 - accuracy: 0.8553 - val_loss: 0.6882 - val_accuracy: 0.6829\n","Epoch 28/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3505 - accuracy: 0.8473 - val_loss: 0.6438 - val_accuracy: 0.7211\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3494 - accuracy: 0.8501 - val_loss: 0.6648 - val_accuracy: 0.7097\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3724 - accuracy: 0.8354 - val_loss: 0.6460 - val_accuracy: 0.7138\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3468 - accuracy: 0.8584 - val_loss: 0.6477 - val_accuracy: 0.7231\n","Epoch 32/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3325 - accuracy: 0.8625 - val_loss: 0.6554 - val_accuracy: 0.7283\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3399 - accuracy: 0.8618 - val_loss: 0.6617 - val_accuracy: 0.7221\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3278 - accuracy: 0.8615 - val_loss: 0.6683 - val_accuracy: 0.7118\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3337 - accuracy: 0.8561 - val_loss: 0.6749 - val_accuracy: 0.7138\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3387 - accuracy: 0.8576 - val_loss: 0.6735 - val_accuracy: 0.7293\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3301 - accuracy: 0.8638 - val_loss: 0.6779 - val_accuracy: 0.7242\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3321 - accuracy: 0.8612 - val_loss: 0.7031 - val_accuracy: 0.7066\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3362 - accuracy: 0.8496 - val_loss: 0.7032 - val_accuracy: 0.7087\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3331 - accuracy: 0.8654 - val_loss: 0.6806 - val_accuracy: 0.7138\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3237 - accuracy: 0.8649 - val_loss: 0.6907 - val_accuracy: 0.7169\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3213 - accuracy: 0.8661 - val_loss: 0.6962 - val_accuracy: 0.7211\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3239 - accuracy: 0.8685 - val_loss: 0.6906 - val_accuracy: 0.7138\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3203 - accuracy: 0.8661 - val_loss: 0.6964 - val_accuracy: 0.7211\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3127 - accuracy: 0.8705 - val_loss: 0.7192 - val_accuracy: 0.7035\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3309 - accuracy: 0.8602 - val_loss: 0.7020 - val_accuracy: 0.7045\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3117 - accuracy: 0.8721 - val_loss: 0.7217 - val_accuracy: 0.7035\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3377 - accuracy: 0.8574 - val_loss: 0.7248 - val_accuracy: 0.7004\n","Epoch 49/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3165 - accuracy: 0.8711 - val_loss: 0.7176 - val_accuracy: 0.7056\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3012 - accuracy: 0.8783 - val_loss: 0.7075 - val_accuracy: 0.7076\n","Epoch 51/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3139 - accuracy: 0.8713 - val_loss: 0.7090 - val_accuracy: 0.7138\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3052 - accuracy: 0.8791 - val_loss: 0.7101 - val_accuracy: 0.7169\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3032 - accuracy: 0.8773 - val_loss: 0.7276 - val_accuracy: 0.7107\n","Epoch 54/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3118 - accuracy: 0.8713 - val_loss: 0.7132 - val_accuracy: 0.7221\n","Epoch 55/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2915 - accuracy: 0.8827 - val_loss: 0.7255 - val_accuracy: 0.7118\n","Epoch 56/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2949 - accuracy: 0.8780 - val_loss: 0.7397 - val_accuracy: 0.7107\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3045 - accuracy: 0.8747 - val_loss: 0.7256 - val_accuracy: 0.7221\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2913 - accuracy: 0.8793 - val_loss: 0.7339 - val_accuracy: 0.7056\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2940 - accuracy: 0.8832 - val_loss: 0.7396 - val_accuracy: 0.7159\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2878 - accuracy: 0.8850 - val_loss: 0.8795 - val_accuracy: 0.6570\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3129 - accuracy: 0.8646 - val_loss: 0.7356 - val_accuracy: 0.7097\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.8835 - val_loss: 0.7494 - val_accuracy: 0.7004\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2847 - accuracy: 0.8850 - val_loss: 0.7484 - val_accuracy: 0.7128\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2817 - accuracy: 0.8855 - val_loss: 0.7664 - val_accuracy: 0.7076\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2790 - accuracy: 0.8860 - val_loss: 0.7617 - val_accuracy: 0.7118\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2846 - accuracy: 0.8819 - val_loss: 0.7634 - val_accuracy: 0.7025\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2880 - accuracy: 0.8822 - val_loss: 0.7738 - val_accuracy: 0.7035\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2724 - accuracy: 0.8876 - val_loss: 0.7767 - val_accuracy: 0.7004\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2794 - accuracy: 0.8858 - val_loss: 0.7591 - val_accuracy: 0.7056\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2669 - accuracy: 0.8935 - val_loss: 0.7696 - val_accuracy: 0.7128\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2695 - accuracy: 0.8860 - val_loss: 0.7675 - val_accuracy: 0.7118\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2752 - accuracy: 0.8837 - val_loss: 0.7782 - val_accuracy: 0.7128\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2714 - accuracy: 0.8922 - val_loss: 0.8074 - val_accuracy: 0.6921\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2743 - accuracy: 0.8886 - val_loss: 0.8565 - val_accuracy: 0.6777\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2925 - accuracy: 0.8713 - val_loss: 0.7733 - val_accuracy: 0.6973\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2578 - accuracy: 0.8959 - val_loss: 0.7996 - val_accuracy: 0.6963\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2670 - accuracy: 0.8910 - val_loss: 0.8134 - val_accuracy: 0.6860\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2634 - accuracy: 0.8915 - val_loss: 0.8054 - val_accuracy: 0.7035\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2604 - accuracy: 0.8953 - val_loss: 0.8617 - val_accuracy: 0.6829\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2612 - accuracy: 0.8928 - val_loss: 0.7939 - val_accuracy: 0.6952\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2529 - accuracy: 0.9008 - val_loss: 0.8724 - val_accuracy: 0.6746\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2637 - accuracy: 0.8920 - val_loss: 0.7959 - val_accuracy: 0.7004\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2703 - accuracy: 0.8884 - val_loss: 0.7884 - val_accuracy: 0.6983\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2591 - accuracy: 0.8917 - val_loss: 0.7949 - val_accuracy: 0.7097\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2497 - accuracy: 0.9013 - val_loss: 0.8034 - val_accuracy: 0.6983\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2449 - accuracy: 0.8990 - val_loss: 0.8100 - val_accuracy: 0.6994\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2504 - accuracy: 0.9023 - val_loss: 0.8173 - val_accuracy: 0.7066\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2416 - accuracy: 0.9023 - val_loss: 0.8598 - val_accuracy: 0.7014\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2509 - accuracy: 0.8969 - val_loss: 0.8503 - val_accuracy: 0.6860\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2429 - accuracy: 0.8964 - val_loss: 0.8486 - val_accuracy: 0.6901\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2564 - accuracy: 0.8959 - val_loss: 0.8734 - val_accuracy: 0.6808\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2503 - accuracy: 0.8951 - val_loss: 0.8183 - val_accuracy: 0.6952\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2304 - accuracy: 0.9101 - val_loss: 0.8326 - val_accuracy: 0.6973\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2330 - accuracy: 0.9078 - val_loss: 0.8447 - val_accuracy: 0.6952\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2356 - accuracy: 0.9031 - val_loss: 0.8516 - val_accuracy: 0.7004\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2340 - accuracy: 0.9059 - val_loss: 0.8471 - val_accuracy: 0.6911\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2365 - accuracy: 0.9057 - val_loss: 0.8496 - val_accuracy: 0.6994\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2376 - accuracy: 0.9039 - val_loss: 0.8642 - val_accuracy: 0.6942\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2212 - accuracy: 0.9096 - val_loss: 0.8543 - val_accuracy: 0.6921\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2271 - accuracy: 0.9088 - val_loss: 0.8780 - val_accuracy: 0.6890\n","{'loss': [0.42687752842903137, 0.42499178647994995, 0.39480331540107727, 0.38968342542648315, 0.39335376024246216, 0.40054696798324585, 0.3926004469394684, 0.3868008553981781, 0.37973740696907043, 0.3760700821876526, 0.3768613636493683, 0.3779364824295044, 0.37271007895469666, 0.38342154026031494, 0.3681309223175049, 0.3654690384864807, 0.36565905809402466, 0.37368646264076233, 0.3615589737892151, 0.3649616837501526, 0.3665182888507843, 0.35967379808425903, 0.35450470447540283, 0.37234973907470703, 0.35224664211273193, 0.34991341829299927, 0.34685218334198, 0.35045135021209717, 0.3494255542755127, 0.37243443727493286, 0.3467974066734314, 0.33251649141311646, 0.33991608023643494, 0.32780638337135315, 0.33366331458091736, 0.3387119770050049, 0.33014976978302, 0.33213773369789124, 0.3361953794956207, 0.3331320881843567, 0.32374075055122375, 0.32131481170654297, 0.32391825318336487, 0.32029467821121216, 0.3127293884754181, 0.3309338390827179, 0.3117120862007141, 0.3377397358417511, 0.3164878785610199, 0.30117323994636536, 0.3139101564884186, 0.30516311526298523, 0.3031638562679291, 0.3118438720703125, 0.29146644473075867, 0.2949103116989136, 0.30453866720199585, 0.2912916839122772, 0.29399579763412476, 0.2877699136734009, 0.3128783106803894, 0.28774532675743103, 0.2846510112285614, 0.2816562056541443, 0.2790113687515259, 0.284566193819046, 0.2879820764064789, 0.2724132537841797, 0.2794201672077179, 0.2669402062892914, 0.26948124170303345, 0.2752355635166168, 0.27142736315727234, 0.27429312467575073, 0.2925414741039276, 0.25783681869506836, 0.26699167490005493, 0.263388454914093, 0.26043111085891724, 0.2611887454986572, 0.2528725862503052, 0.26370927691459656, 0.2702620327472687, 0.25912415981292725, 0.24968932569026947, 0.2449321150779724, 0.2503723204135895, 0.24163100123405457, 0.25090187788009644, 0.24288615584373474, 0.25641560554504395, 0.2502715587615967, 0.2304372638463974, 0.2329741269350052, 0.2355901449918747, 0.23402613401412964, 0.23647160828113556, 0.23759016394615173, 0.22123968601226807, 0.22712793946266174], 'accuracy': [0.8105943202972412, 0.8111110925674438, 0.8351421356201172, 0.8312661647796631, 0.8297157883644104, 0.8260982036590576, 0.8240309953689575, 0.8315245509147644, 0.8421188592910767, 0.841602087020874, 0.8392764925956726, 0.8354005217552185, 0.8431524634361267, 0.832041323184967, 0.8490955829620361, 0.8403100967407227, 0.8436692357063293, 0.8439276218414307, 0.8447028398513794, 0.841602087020874, 0.843410849571228, 0.8550387620925903, 0.8540051579475403, 0.8322997689247131, 0.8485788106918335, 0.8534883856773376, 0.8552971482276917, 0.8472868204116821, 0.8501291871070862, 0.8354005217552185, 0.8583979606628418, 0.8625323176383972, 0.8617570996284485, 0.8614987134933472, 0.8560723662376404, 0.8576227426528931, 0.8638243079185486, 0.8612403273582458, 0.8496124148368835, 0.8653746843338013, 0.8648578524589539, 0.8661498427391052, 0.8684754371643066, 0.8661498427391052, 0.8705426454544067, 0.8602067232131958, 0.8720930218696594, 0.8573643565177917, 0.8710594177246094, 0.8782945871353149, 0.8713178038597107, 0.8790697455406189, 0.8772609829902649, 0.8713178038597107, 0.8826873302459717, 0.8780362010002136, 0.8746770024299622, 0.879328191280365, 0.8832041621208191, 0.8850129246711731, 0.8645994663238525, 0.8834625482559204, 0.8850129246711731, 0.8855296969413757, 0.8860465288162231, 0.8819121718406677, 0.882170557975769, 0.8875969052314758, 0.8857881426811218, 0.8935400247573853, 0.8860465288162231, 0.8837209343910217, 0.8922480344772339, 0.8886305093765259, 0.8713178038597107, 0.8958656191825867, 0.8909560441970825, 0.8914728760719299, 0.895348846912384, 0.8927648663520813, 0.9007751941680908, 0.8919896483421326, 0.8883720636367798, 0.8917312622070312, 0.9012919664382935, 0.8989664316177368, 0.9023255705833435, 0.9023255705833435, 0.8968992233276367, 0.8963824510574341, 0.8958656191825867, 0.8950904607772827, 0.9100775122642517, 0.9077519178390503, 0.9031007885932922, 0.9059431552886963, 0.905684769153595, 0.9038759469985962, 0.9095607399940491, 0.9087855219841003], 'val_loss': [0.698560357093811, 0.6946598291397095, 0.6853737235069275, 0.6778505444526672, 0.6717779636383057, 0.6675553321838379, 0.6639696955680847, 0.6618431806564331, 0.66265469789505, 0.6679858565330505, 0.6702971458435059, 0.6651667952537537, 0.666439950466156, 0.6937732100486755, 0.6989047527313232, 0.7220903635025024, 0.7131631970405579, 0.7217317819595337, 0.8125239014625549, 0.6872299313545227, 0.6780430674552917, 0.7056089043617249, 0.6854865550994873, 0.7655117511749268, 0.6831598281860352, 0.6317398548126221, 0.6881896257400513, 0.6437578797340393, 0.664790153503418, 0.6459945440292358, 0.6476749777793884, 0.6553530693054199, 0.6617449522018433, 0.6683167815208435, 0.6749335527420044, 0.6734506487846375, 0.6778813004493713, 0.7030985355377197, 0.703209400177002, 0.6806094646453857, 0.6907384991645813, 0.6961953043937683, 0.6905887126922607, 0.6964055299758911, 0.7191749215126038, 0.7020436525344849, 0.7216694355010986, 0.7247536182403564, 0.7175800800323486, 0.7074637413024902, 0.7090360522270203, 0.710119366645813, 0.7275575995445251, 0.7131730914115906, 0.7254787087440491, 0.7397286891937256, 0.7256252765655518, 0.7338583469390869, 0.7396256923675537, 0.8795145750045776, 0.7355873584747314, 0.7493911981582642, 0.7483505606651306, 0.7664270401000977, 0.761651873588562, 0.7633545994758606, 0.7737590074539185, 0.7766727209091187, 0.7591001987457275, 0.7695983648300171, 0.7674923539161682, 0.7782405614852905, 0.80735182762146, 0.8564708828926086, 0.7733168005943298, 0.799636721611023, 0.8134307861328125, 0.8054420948028564, 0.861740231513977, 0.7939063906669617, 0.8724150657653809, 0.7958574295043945, 0.7883520126342773, 0.7949081063270569, 0.8033570051193237, 0.809973955154419, 0.8172723054885864, 0.8597724437713623, 0.8502752184867859, 0.8486116528511047, 0.8734166026115417, 0.8183056116104126, 0.8326141834259033, 0.8446550369262695, 0.8515638709068298, 0.8471243381500244, 0.8495798707008362, 0.8642492294311523, 0.8542752861976624, 0.8780052065849304], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4886363744735718, 0.5495867729187012, 0.6487603187561035, 0.663223147392273, 0.6497933864593506, 0.6260330677032471, 0.6043388247489929, 0.5785123705863953, 0.5754132270812988, 0.5929751992225647, 0.5981404781341553, 0.5847107172012329, 0.5898760557174683, 0.5919421315193176, 0.6064049601554871, 0.6167355179786682, 0.5950413346290588, 0.6539255976676941, 0.663223147392273, 0.6601239442825317, 0.672520637512207, 0.6601239442825317, 0.672520637512207, 0.7169421315193176, 0.682851254940033, 0.7210744023323059, 0.7097107172012329, 0.7138429880142212, 0.7231404781341553, 0.7283057570457458, 0.7221074104309082, 0.711776852607727, 0.7138429880142212, 0.7293388247489929, 0.7241735458374023, 0.7066115736961365, 0.7086777091026306, 0.7138429880142212, 0.7169421315193176, 0.7210744023323059, 0.7138429880142212, 0.7210744023323059, 0.7035123705863953, 0.7045454382896423, 0.7035123705863953, 0.7004132270812988, 0.7055785059928894, 0.7076446413993835, 0.7138429880142212, 0.7169421315193176, 0.71074378490448, 0.7221074104309082, 0.711776852607727, 0.71074378490448, 0.7221074104309082, 0.7055785059928894, 0.7159090638160706, 0.6570248007774353, 0.7097107172012329, 0.7004132270812988, 0.7128099203109741, 0.7076446413993835, 0.711776852607727, 0.702479362487793, 0.7035123705863953, 0.7004132270812988, 0.7055785059928894, 0.7128099203109741, 0.711776852607727, 0.7128099203109741, 0.692148745059967, 0.6776859760284424, 0.6973140239715576, 0.6962810158729553, 0.6859503984451294, 0.7035123705863953, 0.682851254940033, 0.6952479481697083, 0.6745867729187012, 0.7004132270812988, 0.6983470916748047, 0.7097107172012329, 0.6983470916748047, 0.6993801593780518, 0.7066115736961365, 0.7014462947845459, 0.6859503984451294, 0.6900826692581177, 0.6807851195335388, 0.6952479481697083, 0.6973140239715576, 0.6952479481697083, 0.7004132270812988, 0.69111567735672, 0.6993801593780518, 0.6942148804664612, 0.692148745059967, 0.6890496015548706]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 8s 52ms/step - loss: 0.3300 - accuracy: 0.8572 - val_loss: 0.7041 - val_accuracy: 0.4849\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3095 - accuracy: 0.8688 - val_loss: 0.6972 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2920 - accuracy: 0.8739 - val_loss: 0.6859 - val_accuracy: 0.4903\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2801 - accuracy: 0.8798 - val_loss: 0.6766 - val_accuracy: 0.5323\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2854 - accuracy: 0.8847 - val_loss: 0.6662 - val_accuracy: 0.6390\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2789 - accuracy: 0.8863 - val_loss: 0.6617 - val_accuracy: 0.6552\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2808 - accuracy: 0.8820 - val_loss: 0.6565 - val_accuracy: 0.6562\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2681 - accuracy: 0.8955 - val_loss: 0.6616 - val_accuracy: 0.6034\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2750 - accuracy: 0.8898 - val_loss: 0.6661 - val_accuracy: 0.5905\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2632 - accuracy: 0.8920 - val_loss: 0.6700 - val_accuracy: 0.5884\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2575 - accuracy: 0.8947 - val_loss: 0.6855 - val_accuracy: 0.5765\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2563 - accuracy: 0.8998 - val_loss: 0.6895 - val_accuracy: 0.5830\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2664 - accuracy: 0.8871 - val_loss: 0.7394 - val_accuracy: 0.5614\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2559 - accuracy: 0.8947 - val_loss: 0.7484 - val_accuracy: 0.5679\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2570 - accuracy: 0.8947 - val_loss: 0.7806 - val_accuracy: 0.5700\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2473 - accuracy: 0.8995 - val_loss: 0.7807 - val_accuracy: 0.5862\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2563 - accuracy: 0.8976 - val_loss: 0.7956 - val_accuracy: 0.5991\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2551 - accuracy: 0.8982 - val_loss: 0.8795 - val_accuracy: 0.5830\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2532 - accuracy: 0.9001 - val_loss: 0.8669 - val_accuracy: 0.6024\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2435 - accuracy: 0.9011 - val_loss: 0.9250 - val_accuracy: 0.6034\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2492 - accuracy: 0.8968 - val_loss: 0.7742 - val_accuracy: 0.6476\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2382 - accuracy: 0.9041 - val_loss: 0.7197 - val_accuracy: 0.6778\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2419 - accuracy: 0.9009 - val_loss: 0.7691 - val_accuracy: 0.6789\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2399 - accuracy: 0.9057 - val_loss: 0.6938 - val_accuracy: 0.7134\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2393 - accuracy: 0.9038 - val_loss: 0.5948 - val_accuracy: 0.7478\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2431 - accuracy: 0.8992 - val_loss: 0.6629 - val_accuracy: 0.7241\n","Epoch 27/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2460 - accuracy: 0.9025 - val_loss: 0.5928 - val_accuracy: 0.7672\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2275 - accuracy: 0.9073 - val_loss: 0.6155 - val_accuracy: 0.7565\n","Epoch 29/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2334 - accuracy: 0.9038 - val_loss: 0.6021 - val_accuracy: 0.7683\n","Epoch 30/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2300 - accuracy: 0.9065 - val_loss: 0.5928 - val_accuracy: 0.7769\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2284 - accuracy: 0.9073 - val_loss: 0.6133 - val_accuracy: 0.7651\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2219 - accuracy: 0.9143 - val_loss: 0.6250 - val_accuracy: 0.7586\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2206 - accuracy: 0.9141 - val_loss: 0.6268 - val_accuracy: 0.7651\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2189 - accuracy: 0.9098 - val_loss: 0.6183 - val_accuracy: 0.7629\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2103 - accuracy: 0.9195 - val_loss: 0.6295 - val_accuracy: 0.7629\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2156 - accuracy: 0.9124 - val_loss: 0.7135 - val_accuracy: 0.7435\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2253 - accuracy: 0.9087 - val_loss: 0.6424 - val_accuracy: 0.7683\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2102 - accuracy: 0.9238 - val_loss: 0.6466 - val_accuracy: 0.7565\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2132 - accuracy: 0.9197 - val_loss: 0.6868 - val_accuracy: 0.7435\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2199 - accuracy: 0.9138 - val_loss: 0.7124 - val_accuracy: 0.7392\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2187 - accuracy: 0.9081 - val_loss: 0.7424 - val_accuracy: 0.7317\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2184 - accuracy: 0.9143 - val_loss: 0.6497 - val_accuracy: 0.7683\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2055 - accuracy: 0.9189 - val_loss: 0.6526 - val_accuracy: 0.7619\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2026 - accuracy: 0.9230 - val_loss: 0.7560 - val_accuracy: 0.7306\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2304 - accuracy: 0.9060 - val_loss: 0.6543 - val_accuracy: 0.7651\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2061 - accuracy: 0.9200 - val_loss: 0.6646 - val_accuracy: 0.7694\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2045 - accuracy: 0.9197 - val_loss: 0.6635 - val_accuracy: 0.7522\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2065 - accuracy: 0.9151 - val_loss: 0.6651 - val_accuracy: 0.7554\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2075 - accuracy: 0.9162 - val_loss: 0.6753 - val_accuracy: 0.7586\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1963 - accuracy: 0.9278 - val_loss: 0.6741 - val_accuracy: 0.7586\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1995 - accuracy: 0.9143 - val_loss: 0.6972 - val_accuracy: 0.7435\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2018 - accuracy: 0.9184 - val_loss: 0.7142 - val_accuracy: 0.7446\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2037 - accuracy: 0.9200 - val_loss: 0.6792 - val_accuracy: 0.7575\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1928 - accuracy: 0.9227 - val_loss: 0.7130 - val_accuracy: 0.7414\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1909 - accuracy: 0.9273 - val_loss: 0.6929 - val_accuracy: 0.7629\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2041 - accuracy: 0.9138 - val_loss: 0.6811 - val_accuracy: 0.7608\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1955 - accuracy: 0.9267 - val_loss: 0.6951 - val_accuracy: 0.7554\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1844 - accuracy: 0.9283 - val_loss: 0.6875 - val_accuracy: 0.7586\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1863 - accuracy: 0.9297 - val_loss: 0.7776 - val_accuracy: 0.7306\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1890 - accuracy: 0.9308 - val_loss: 0.7159 - val_accuracy: 0.7457\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1881 - accuracy: 0.9248 - val_loss: 0.7051 - val_accuracy: 0.7435\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1844 - accuracy: 0.9308 - val_loss: 0.6942 - val_accuracy: 0.7586\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1858 - accuracy: 0.9318 - val_loss: 0.6927 - val_accuracy: 0.7619\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1829 - accuracy: 0.9327 - val_loss: 0.7824 - val_accuracy: 0.7381\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1810 - accuracy: 0.9291 - val_loss: 0.7146 - val_accuracy: 0.7586\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1831 - accuracy: 0.9281 - val_loss: 0.7086 - val_accuracy: 0.7575\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1775 - accuracy: 0.9316 - val_loss: 0.7399 - val_accuracy: 0.7425\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1850 - accuracy: 0.9273 - val_loss: 0.7081 - val_accuracy: 0.7522\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1688 - accuracy: 0.9370 - val_loss: 0.7114 - val_accuracy: 0.7532\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1853 - accuracy: 0.9286 - val_loss: 0.7089 - val_accuracy: 0.7478\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1811 - accuracy: 0.9300 - val_loss: 0.7436 - val_accuracy: 0.7446\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1775 - accuracy: 0.9308 - val_loss: 0.7176 - val_accuracy: 0.7522\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1816 - accuracy: 0.9259 - val_loss: 0.7260 - val_accuracy: 0.7446\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1661 - accuracy: 0.9362 - val_loss: 0.7381 - val_accuracy: 0.7425\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1912 - accuracy: 0.9240 - val_loss: 0.7702 - val_accuracy: 0.7425\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1653 - accuracy: 0.9372 - val_loss: 0.7727 - val_accuracy: 0.7414\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1799 - accuracy: 0.9275 - val_loss: 0.7748 - val_accuracy: 0.7511\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1963 - accuracy: 0.9224 - val_loss: 0.7491 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1658 - accuracy: 0.9332 - val_loss: 0.7570 - val_accuracy: 0.7338\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1777 - accuracy: 0.9291 - val_loss: 0.7308 - val_accuracy: 0.7586\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1585 - accuracy: 0.9397 - val_loss: 0.7989 - val_accuracy: 0.7306\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1545 - accuracy: 0.9418 - val_loss: 0.7828 - val_accuracy: 0.7500\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1549 - accuracy: 0.9353 - val_loss: 0.7497 - val_accuracy: 0.7425\n","Epoch 84/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1519 - accuracy: 0.9426 - val_loss: 0.7516 - val_accuracy: 0.7522\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1538 - accuracy: 0.9378 - val_loss: 0.7557 - val_accuracy: 0.7468\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1570 - accuracy: 0.9364 - val_loss: 0.8145 - val_accuracy: 0.7425\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1720 - accuracy: 0.9300 - val_loss: 0.7706 - val_accuracy: 0.7586\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1628 - accuracy: 0.9399 - val_loss: 0.8117 - val_accuracy: 0.7360\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1507 - accuracy: 0.9415 - val_loss: 0.7583 - val_accuracy: 0.7532\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1486 - accuracy: 0.9434 - val_loss: 0.7849 - val_accuracy: 0.7500\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1597 - accuracy: 0.9367 - val_loss: 0.8249 - val_accuracy: 0.7317\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1542 - accuracy: 0.9407 - val_loss: 0.7751 - val_accuracy: 0.7532\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1767 - accuracy: 0.9232 - val_loss: 0.7636 - val_accuracy: 0.7554\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1645 - accuracy: 0.9324 - val_loss: 0.8423 - val_accuracy: 0.7231\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1533 - accuracy: 0.9407 - val_loss: 0.7645 - val_accuracy: 0.7522\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1421 - accuracy: 0.9445 - val_loss: 0.7892 - val_accuracy: 0.7414\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1419 - accuracy: 0.9467 - val_loss: 0.7987 - val_accuracy: 0.7532\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1451 - accuracy: 0.9407 - val_loss: 0.8045 - val_accuracy: 0.7435\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1744 - accuracy: 0.9259 - val_loss: 0.7918 - val_accuracy: 0.7403\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1438 - accuracy: 0.9410 - val_loss: 0.7966 - val_accuracy: 0.7446\n","{'loss': [0.32996439933776855, 0.30947768688201904, 0.2920494079589844, 0.28005918860435486, 0.2853512465953827, 0.27886122465133667, 0.28079819679260254, 0.26810529828071594, 0.2749888002872467, 0.2632043957710266, 0.2574952244758606, 0.25627562403678894, 0.2664422392845154, 0.2558847963809967, 0.2570396065711975, 0.24733969569206238, 0.2563153803348541, 0.255092054605484, 0.25323766469955444, 0.2435385286808014, 0.24922676384449005, 0.23819179832935333, 0.24188543856143951, 0.23988860845565796, 0.2393067479133606, 0.24311970174312592, 0.24600587785243988, 0.2275184690952301, 0.23344793915748596, 0.22998978197574615, 0.22838842868804932, 0.2219085991382599, 0.22062644362449646, 0.21894608438014984, 0.21026159822940826, 0.21563924849033356, 0.22530502080917358, 0.21015453338623047, 0.21320806443691254, 0.219892218708992, 0.21868161857128143, 0.21838611364364624, 0.20551921427249908, 0.20261827111244202, 0.23044301569461823, 0.2061115801334381, 0.2044510394334793, 0.20648732781410217, 0.20745082199573517, 0.19627444446086884, 0.1994515061378479, 0.20182208716869354, 0.20371145009994507, 0.19276940822601318, 0.19091454148292542, 0.20406299829483032, 0.19553332030773163, 0.184449702501297, 0.18634089827537537, 0.1889837682247162, 0.18814408779144287, 0.18437562882900238, 0.18584391474723816, 0.18293534219264984, 0.1809665560722351, 0.1831343024969101, 0.17752309143543243, 0.18495559692382812, 0.16880494356155396, 0.18532346189022064, 0.1810557097196579, 0.1774878203868866, 0.1815946251153946, 0.16605053842067719, 0.19124454259872437, 0.16526822745800018, 0.17988671362400055, 0.19630087912082672, 0.16577783226966858, 0.17769765853881836, 0.15849049389362335, 0.15449687838554382, 0.15490303933620453, 0.15194635093212128, 0.1537795513868332, 0.1570199429988861, 0.17200034856796265, 0.16279473900794983, 0.15074996650218964, 0.14859403669834137, 0.1597103625535965, 0.15421965718269348, 0.17666003108024597, 0.16452811658382416, 0.15333271026611328, 0.14206600189208984, 0.14193803071975708, 0.1451229751110077, 0.17439237236976624, 0.14379945397377014], 'accuracy': [0.8572198152542114, 0.868803858757019, 0.8739224076271057, 0.8798491358757019, 0.8846982717514038, 0.8863146305084229, 0.8820043206214905, 0.8954741358757019, 0.8898168206214905, 0.891972005367279, 0.8946659564971924, 0.899784505367279, 0.8871228694915771, 0.8946659564971924, 0.8946659564971924, 0.8995150923728943, 0.8976293206214905, 0.8981680870056152, 0.900053858757019, 0.9011314511299133, 0.896821141242981, 0.9040948152542114, 0.9008620977401733, 0.9057112336158752, 0.9038254022598267, 0.8992456793785095, 0.9024784564971924, 0.9073275923728943, 0.9038254022598267, 0.9065194129943848, 0.9073275923728943, 0.9143319129943848, 0.9140625, 0.9097521305084229, 0.9194504022598267, 0.912446141242981, 0.9086745977401733, 0.9237607717514038, 0.9197198152542114, 0.9137930870056152, 0.9081357717514038, 0.9143319129943848, 0.9189116358757019, 0.9229525923728943, 0.9059805870056152, 0.9199892282485962, 0.9197198152542114, 0.9151400923728943, 0.9162176847457886, 0.9278017282485962, 0.9143319129943848, 0.9183728694915771, 0.9199892282485962, 0.9226831793785095, 0.9272629022598267, 0.9137930870056152, 0.9267241358757019, 0.928340494632721, 0.9296875, 0.9307650923728943, 0.9248383641242981, 0.9307650923728943, 0.9318426847457886, 0.9326508641242981, 0.9291487336158752, 0.928071141242981, 0.9315732717514038, 0.9272629022598267, 0.9369612336158752, 0.9286099076271057, 0.9299569129943848, 0.9307650923728943, 0.9259159564971924, 0.936152994632721, 0.9240301847457886, 0.9372305870056152, 0.9275323152542114, 0.9224137663841248, 0.9331896305084229, 0.9291487336158752, 0.9396551847457886, 0.9418103694915771, 0.9353448152542114, 0.9426185488700867, 0.9377694129943848, 0.9364224076271057, 0.9299569129943848, 0.9399245977401733, 0.9415409564971924, 0.9434267282485962, 0.9366918206214905, 0.9407327771186829, 0.923222005367279, 0.9323814511299133, 0.9407327771186829, 0.9445043206214905, 0.946659505367279, 0.9407327771186829, 0.9259159564971924, 0.9410021305084229], 'val_loss': [0.7040941119194031, 0.6972336173057556, 0.6858552694320679, 0.6765788793563843, 0.666157603263855, 0.6617195010185242, 0.6564933061599731, 0.6616120934486389, 0.6661266684532166, 0.6699697375297546, 0.6855036020278931, 0.6894936561584473, 0.7394091486930847, 0.7484135627746582, 0.7805882692337036, 0.7806748151779175, 0.7956106066703796, 0.8795377612113953, 0.866926372051239, 0.925031304359436, 0.7741940021514893, 0.7196884155273438, 0.7690955996513367, 0.6937679052352905, 0.5948421955108643, 0.6628638505935669, 0.5928040742874146, 0.6155343651771545, 0.6021013855934143, 0.5927628874778748, 0.6133020520210266, 0.6249527335166931, 0.6268073320388794, 0.6182537078857422, 0.6294893622398376, 0.7134941816329956, 0.6424339413642883, 0.6465513110160828, 0.6868335008621216, 0.7123972177505493, 0.7423935532569885, 0.6496807336807251, 0.6525601744651794, 0.7559913992881775, 0.6543481349945068, 0.66460120677948, 0.6635185480117798, 0.665127158164978, 0.6753048300743103, 0.6740880012512207, 0.6971595883369446, 0.7142140865325928, 0.679176390171051, 0.7130032777786255, 0.6928635835647583, 0.6810994744300842, 0.6950857043266296, 0.6874687671661377, 0.7776208519935608, 0.7159168720245361, 0.7050545811653137, 0.694225549697876, 0.6926812529563904, 0.782439112663269, 0.7145833373069763, 0.7086257934570312, 0.7398605346679688, 0.7080658078193665, 0.7114040851593018, 0.708906888961792, 0.7436302304267883, 0.7176154851913452, 0.7259941101074219, 0.7380926012992859, 0.7701942324638367, 0.772722601890564, 0.7747640013694763, 0.7490646839141846, 0.7570489048957825, 0.7307739853858948, 0.7989410161972046, 0.7827627062797546, 0.7497289776802063, 0.7515735030174255, 0.7557246685028076, 0.8144587278366089, 0.7705800533294678, 0.8116830587387085, 0.7583061456680298, 0.7848535776138306, 0.8249207735061646, 0.7750955820083618, 0.763566255569458, 0.8423306941986084, 0.7644881010055542, 0.7892260551452637, 0.7987078428268433, 0.8045075535774231, 0.7918308973312378, 0.7965880632400513], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.4903017282485962, 0.5323275923728943, 0.639008641242981, 0.6551724076271057, 0.65625, 0.6034482717514038, 0.5905172228813171, 0.5883620977401733, 0.576508641242981, 0.5829741358757019, 0.5614224076271057, 0.5678879022598267, 0.5700430870056152, 0.5862069129943848, 0.5991379022598267, 0.5829741358757019, 0.6023706793785095, 0.6034482717514038, 0.6476293206214905, 0.6778017282485962, 0.6788793206214905, 0.7133620977401733, 0.7478448152542114, 0.7241379022598267, 0.767241358757019, 0.756465494632721, 0.7683189511299133, 0.7769396305084229, 0.7650862336158752, 0.7586206793785095, 0.7650862336158752, 0.7629310488700867, 0.7629310488700867, 0.743534505367279, 0.7683189511299133, 0.756465494632721, 0.743534505367279, 0.7392241358757019, 0.7316810488700867, 0.7683189511299133, 0.7618534564971924, 0.7306034564971924, 0.7650862336158752, 0.7693965435028076, 0.7521551847457886, 0.7553879022598267, 0.7586206793785095, 0.7586206793785095, 0.743534505367279, 0.7446120977401733, 0.7575430870056152, 0.7413793206214905, 0.7629310488700867, 0.7607758641242981, 0.7553879022598267, 0.7586206793785095, 0.7306034564971924, 0.7456896305084229, 0.743534505367279, 0.7586206793785095, 0.7618534564971924, 0.7381465435028076, 0.7586206793785095, 0.7575430870056152, 0.7424569129943848, 0.7521551847457886, 0.7532327771186829, 0.7478448152542114, 0.7446120977401733, 0.7521551847457886, 0.7446120977401733, 0.7424569129943848, 0.7424569129943848, 0.7413793206214905, 0.7510775923728943, 0.743534505367279, 0.7338362336158752, 0.7586206793785095, 0.7306034564971924, 0.75, 0.7424569129943848, 0.7521551847457886, 0.7467672228813171, 0.7424569129943848, 0.7586206793785095, 0.735991358757019, 0.7532327771186829, 0.75, 0.7316810488700867, 0.7532327771186829, 0.7553879022598267, 0.7230603694915771, 0.7521551847457886, 0.7413793206214905, 0.7532327771186829, 0.743534505367279, 0.7403017282485962, 0.7446120977401733]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3260 - accuracy: 0.8633"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 77ms/step - loss: 0.3271 - accuracy: 0.8616 - val_loss: 0.7001 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.2967 - accuracy: 0.8746 - val_loss: 0.6944 - val_accuracy: 0.4966\n","Epoch 3/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.2888 - accuracy: 0.8681 - val_loss: 0.6827 - val_accuracy: 0.5057\n","Epoch 4/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2998 - accuracy: 0.8710 - val_loss: 0.6732 - val_accuracy: 0.5645\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2849 - accuracy: 0.8786 - val_loss: 0.6680 - val_accuracy: 0.6425\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2679 - accuracy: 0.8871 - val_loss: 0.6644 - val_accuracy: 0.6391\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2697 - accuracy: 0.8879 - val_loss: 0.6607 - val_accuracy: 0.6391\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2676 - accuracy: 0.8857 - val_loss: 0.6622 - val_accuracy: 0.6075\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2810 - accuracy: 0.8795 - val_loss: 0.6660 - val_accuracy: 0.5973\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2660 - accuracy: 0.8899 - val_loss: 0.6636 - val_accuracy: 0.6007\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2530 - accuracy: 0.8942 - val_loss: 0.6562 - val_accuracy: 0.6120\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2680 - accuracy: 0.8879 - val_loss: 0.7019 - val_accuracy: 0.5713\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2609 - accuracy: 0.8916 - val_loss: 0.6943 - val_accuracy: 0.5882\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2610 - accuracy: 0.8922 - val_loss: 0.7022 - val_accuracy: 0.5905\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2536 - accuracy: 0.8916 - val_loss: 0.7584 - val_accuracy: 0.5758\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2551 - accuracy: 0.8978 - val_loss: 0.7549 - val_accuracy: 0.5871\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2486 - accuracy: 0.8947 - val_loss: 0.8103 - val_accuracy: 0.5848\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2371 - accuracy: 0.9027 - val_loss: 0.8652 - val_accuracy: 0.5837\n","Epoch 19/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2404 - accuracy: 0.8976 - val_loss: 0.9012 - val_accuracy: 0.5928\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2306 - accuracy: 0.9058 - val_loss: 0.9071 - val_accuracy: 0.6086\n","Epoch 21/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.2396 - accuracy: 0.8981 - val_loss: 0.7160 - val_accuracy: 0.6606\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2389 - accuracy: 0.8984 - val_loss: 0.9013 - val_accuracy: 0.6278\n","Epoch 23/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.2446 - accuracy: 0.9015 - val_loss: 0.7247 - val_accuracy: 0.6821\n","Epoch 24/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2435 - accuracy: 0.9041 - val_loss: 0.8305 - val_accuracy: 0.6618\n","Epoch 25/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.2407 - accuracy: 0.8970 - val_loss: 0.6778 - val_accuracy: 0.7183\n","Epoch 26/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2345 - accuracy: 0.9061 - val_loss: 0.7635 - val_accuracy: 0.7081\n","Epoch 27/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.2291 - accuracy: 0.9021 - val_loss: 0.6702 - val_accuracy: 0.7285\n","Epoch 28/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.2241 - accuracy: 0.9083 - val_loss: 0.5989 - val_accuracy: 0.7568\n","Epoch 29/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.2253 - accuracy: 0.9103 - val_loss: 0.5716 - val_accuracy: 0.7692\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2209 - accuracy: 0.9089 - val_loss: 0.6854 - val_accuracy: 0.7285\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2388 - accuracy: 0.8953 - val_loss: 0.6323 - val_accuracy: 0.7489\n","Epoch 32/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2393 - accuracy: 0.8942 - val_loss: 0.5636 - val_accuracy: 0.7738\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2177 - accuracy: 0.9095 - val_loss: 0.5822 - val_accuracy: 0.7726\n","Epoch 34/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2104 - accuracy: 0.9075 - val_loss: 0.5941 - val_accuracy: 0.7771\n","Epoch 35/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2173 - accuracy: 0.9086 - val_loss: 0.5793 - val_accuracy: 0.7828\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2057 - accuracy: 0.9191 - val_loss: 0.5881 - val_accuracy: 0.7805\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2344 - accuracy: 0.9032 - val_loss: 0.6203 - val_accuracy: 0.7636\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2432 - accuracy: 0.8947 - val_loss: 0.5963 - val_accuracy: 0.7726\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2204 - accuracy: 0.9114 - val_loss: 0.6523 - val_accuracy: 0.7477\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2184 - accuracy: 0.9078 - val_loss: 0.6367 - val_accuracy: 0.7636\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1967 - accuracy: 0.9208 - val_loss: 0.6067 - val_accuracy: 0.7760\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2098 - accuracy: 0.9063 - val_loss: 0.6109 - val_accuracy: 0.7771\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 0.9134 - val_loss: 0.6601 - val_accuracy: 0.7545\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2011 - accuracy: 0.9154 - val_loss: 0.6732 - val_accuracy: 0.7466\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1993 - accuracy: 0.9168 - val_loss: 0.6121 - val_accuracy: 0.7602\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1944 - accuracy: 0.9179 - val_loss: 0.6288 - val_accuracy: 0.7738\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1967 - accuracy: 0.9168 - val_loss: 0.6374 - val_accuracy: 0.7647\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1934 - accuracy: 0.9216 - val_loss: 0.6354 - val_accuracy: 0.7681\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1862 - accuracy: 0.9222 - val_loss: 0.6582 - val_accuracy: 0.7658\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1832 - accuracy: 0.9253 - val_loss: 0.6464 - val_accuracy: 0.7704\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1869 - accuracy: 0.9239 - val_loss: 0.6662 - val_accuracy: 0.7749\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1915 - accuracy: 0.9213 - val_loss: 0.6610 - val_accuracy: 0.7704\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1923 - accuracy: 0.9219 - val_loss: 0.6622 - val_accuracy: 0.7636\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1937 - accuracy: 0.9160 - val_loss: 0.6622 - val_accuracy: 0.7658\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1979 - accuracy: 0.9140 - val_loss: 0.6432 - val_accuracy: 0.7771\n","Epoch 56/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1730 - accuracy: 0.9312 - val_loss: 0.6759 - val_accuracy: 0.7500\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1908 - accuracy: 0.9239 - val_loss: 0.6701 - val_accuracy: 0.7749\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1806 - accuracy: 0.9278 - val_loss: 0.6677 - val_accuracy: 0.7658\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1880 - accuracy: 0.9179 - val_loss: 0.7650 - val_accuracy: 0.7477\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2035 - accuracy: 0.9168 - val_loss: 0.6930 - val_accuracy: 0.7511\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2053 - accuracy: 0.9140 - val_loss: 0.7089 - val_accuracy: 0.7489\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1785 - accuracy: 0.9284 - val_loss: 0.6552 - val_accuracy: 0.7749\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1840 - accuracy: 0.9244 - val_loss: 0.7351 - val_accuracy: 0.7455\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2052 - accuracy: 0.9106 - val_loss: 0.6542 - val_accuracy: 0.7783\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1705 - accuracy: 0.9321 - val_loss: 0.6745 - val_accuracy: 0.7647\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1688 - accuracy: 0.9318 - val_loss: 0.6817 - val_accuracy: 0.7568\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1661 - accuracy: 0.9321 - val_loss: 0.6729 - val_accuracy: 0.7670\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1621 - accuracy: 0.9366 - val_loss: 0.7173 - val_accuracy: 0.7590\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1680 - accuracy: 0.9307 - val_loss: 0.6951 - val_accuracy: 0.7726\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1670 - accuracy: 0.9352 - val_loss: 0.7612 - val_accuracy: 0.7410\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1790 - accuracy: 0.9290 - val_loss: 0.7254 - val_accuracy: 0.7432\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1601 - accuracy: 0.9377 - val_loss: 0.7216 - val_accuracy: 0.7568\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1594 - accuracy: 0.9392 - val_loss: 0.6965 - val_accuracy: 0.7602\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1602 - accuracy: 0.9344 - val_loss: 0.7023 - val_accuracy: 0.7738\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1657 - accuracy: 0.9293 - val_loss: 0.7136 - val_accuracy: 0.7681\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1836 - accuracy: 0.9228 - val_loss: 0.6962 - val_accuracy: 0.7681\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1553 - accuracy: 0.9426 - val_loss: 0.7186 - val_accuracy: 0.7613\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1483 - accuracy: 0.9471 - val_loss: 0.7252 - val_accuracy: 0.7636\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1516 - accuracy: 0.9428 - val_loss: 0.7311 - val_accuracy: 0.7557\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1517 - accuracy: 0.9454 - val_loss: 0.7491 - val_accuracy: 0.7568\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1593 - accuracy: 0.9358 - val_loss: 0.7420 - val_accuracy: 0.7545\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1547 - accuracy: 0.9358 - val_loss: 0.7318 - val_accuracy: 0.7523\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1443 - accuracy: 0.9414 - val_loss: 0.7434 - val_accuracy: 0.7613\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1471 - accuracy: 0.9409 - val_loss: 0.7316 - val_accuracy: 0.7557\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1516 - accuracy: 0.9386 - val_loss: 0.7695 - val_accuracy: 0.7602\n","Epoch 86/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1448 - accuracy: 0.9465 - val_loss: 0.7592 - val_accuracy: 0.7602\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1522 - accuracy: 0.9397 - val_loss: 0.8672 - val_accuracy: 0.7432\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1602 - accuracy: 0.9355 - val_loss: 0.7559 - val_accuracy: 0.7466\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1510 - accuracy: 0.9386 - val_loss: 0.7820 - val_accuracy: 0.7557\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1521 - accuracy: 0.9411 - val_loss: 0.7529 - val_accuracy: 0.7715\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1496 - accuracy: 0.9372 - val_loss: 0.8757 - val_accuracy: 0.7285\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1550 - accuracy: 0.9377 - val_loss: 0.7632 - val_accuracy: 0.7613\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1475 - accuracy: 0.9409 - val_loss: 0.8185 - val_accuracy: 0.7511\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1339 - accuracy: 0.9460 - val_loss: 0.7779 - val_accuracy: 0.7568\n","Epoch 95/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1625 - accuracy: 0.9267 - val_loss: 0.8208 - val_accuracy: 0.7489\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9372 - val_loss: 0.7835 - val_accuracy: 0.7443\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1460 - accuracy: 0.9428 - val_loss: 0.7512 - val_accuracy: 0.7523\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1422 - accuracy: 0.9479 - val_loss: 0.7718 - val_accuracy: 0.7636\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1372 - accuracy: 0.9457 - val_loss: 0.8114 - val_accuracy: 0.7443\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1336 - accuracy: 0.9477 - val_loss: 0.7748 - val_accuracy: 0.7534\n","{'loss': [0.3271363079547882, 0.2966603934764862, 0.2888418734073639, 0.2997610569000244, 0.284933865070343, 0.2679392695426941, 0.2697090208530426, 0.267633318901062, 0.28104254603385925, 0.26595693826675415, 0.2529546022415161, 0.26795247197151184, 0.2609146535396576, 0.2610093951225281, 0.2536017596721649, 0.2551248073577881, 0.24863563477993011, 0.23712407052516937, 0.24036815762519836, 0.23063601553440094, 0.23955346643924713, 0.2388661950826645, 0.244587704539299, 0.24347051978111267, 0.24074001610279083, 0.2344513088464737, 0.22910793125629425, 0.22410990297794342, 0.22525064647197723, 0.2209368795156479, 0.23884889483451843, 0.2392626851797104, 0.21768610179424286, 0.21042682230472565, 0.2173021286725998, 0.20573265850543976, 0.23439233005046844, 0.24317945539951324, 0.22043584287166595, 0.2184242606163025, 0.19672848284244537, 0.20982423424720764, 0.20317167043685913, 0.20107044279575348, 0.19929052889347076, 0.19442151486873627, 0.1967175304889679, 0.19344376027584076, 0.18615221977233887, 0.1831970363855362, 0.18692870438098907, 0.19145505130290985, 0.1922866851091385, 0.19374340772628784, 0.1979442834854126, 0.17300064861774445, 0.19075506925582886, 0.18059301376342773, 0.18801026046276093, 0.20345363020896912, 0.2053026258945465, 0.17845971882343292, 0.18402479588985443, 0.20518508553504944, 0.1705319732427597, 0.16875700652599335, 0.16607245802879333, 0.162053644657135, 0.1679593324661255, 0.16697441041469574, 0.17904439568519592, 0.16011230647563934, 0.15939120948314667, 0.16017428040504456, 0.16570553183555603, 0.1835530549287796, 0.1552884429693222, 0.14828380942344666, 0.15161949396133423, 0.1516597419977188, 0.15925991535186768, 0.15471872687339783, 0.14430826902389526, 0.14712710678577423, 0.15160652995109558, 0.14476178586483002, 0.15219803154468536, 0.16016502678394318, 0.1510370969772339, 0.1521163135766983, 0.1496000587940216, 0.15504662692546844, 0.14750982820987701, 0.13386645913124084, 0.16254055500030518, 0.15070955455303192, 0.14604829251766205, 0.14224682748317719, 0.13724757730960846, 0.13357865810394287], 'accuracy': [0.8616299033164978, 0.8746463060379028, 0.8681380748748779, 0.8709677457809448, 0.8786078095436096, 0.8870967626571655, 0.8879456520080566, 0.8856819272041321, 0.8794566988945007, 0.8899264335632324, 0.8941709399223328, 0.8879456520080566, 0.8916242122650146, 0.892190158367157, 0.8916242122650146, 0.897849440574646, 0.8947368264198303, 0.9026598930358887, 0.8975664973258972, 0.9057725071907043, 0.8981324434280396, 0.8984153866767883, 0.901528000831604, 0.9040747284889221, 0.8970005512237549, 0.9060554504394531, 0.9020939469337463, 0.9083191752433777, 0.9102999567985535, 0.90888512134552, 0.8953027725219727, 0.8941709399223328, 0.9094510674476624, 0.9074702858924866, 0.9086021780967712, 0.9190718531608582, 0.9032257795333862, 0.8947368264198303, 0.9114317893981934, 0.9077532291412354, 0.9207696914672852, 0.9063384532928467, 0.9134125709533691, 0.9153932929039001, 0.9168081283569336, 0.9179400205612183, 0.9168081283569336, 0.9216185808181763, 0.9221844673156738, 0.9252971410751343, 0.9238823056221008, 0.9213355779647827, 0.921901524066925, 0.9159592390060425, 0.9139785170555115, 0.9312393665313721, 0.9238823056221008, 0.9278438091278076, 0.9179400205612183, 0.9168081283569336, 0.9139785170555115, 0.92840975522995, 0.9244481921195984, 0.9105829000473022, 0.9320882558822632, 0.9318053126335144, 0.9320882558822632, 0.9366157054901123, 0.9306734800338745, 0.9352009296417236, 0.9289756417274475, 0.937747597694397, 0.9391624331474304, 0.9343519806861877, 0.9292586445808411, 0.9227504134178162, 0.9425579905509949, 0.947085440158844, 0.9428409934043884, 0.9453876614570618, 0.9357668161392212, 0.9357668161392212, 0.941426157951355, 0.9408602118492126, 0.9385964870452881, 0.9465195536613464, 0.9397283792495728, 0.9354838728904724, 0.9385964870452881, 0.9411431550979614, 0.9371816515922546, 0.937747597694397, 0.9408602118492126, 0.9459536075592041, 0.926711916923523, 0.9371816515922546, 0.9428409934043884, 0.9479343295097351, 0.9456706047058105, 0.9476513862609863], 'val_loss': [0.7000617384910583, 0.6943652033805847, 0.6826985478401184, 0.6731868386268616, 0.6679521799087524, 0.6644012331962585, 0.660695493221283, 0.6621854901313782, 0.6659847497940063, 0.6635794639587402, 0.6562163829803467, 0.7018699645996094, 0.6942599415779114, 0.7021592259407043, 0.7584236860275269, 0.7548864483833313, 0.8103429675102234, 0.8652195930480957, 0.9011681079864502, 0.9070723056793213, 0.716018557548523, 0.9013196229934692, 0.7246832251548767, 0.8305385112762451, 0.6778102517127991, 0.7635384798049927, 0.6702206134796143, 0.5988975167274475, 0.5716319680213928, 0.6853892207145691, 0.6323333978652954, 0.563579797744751, 0.5821657776832581, 0.594130277633667, 0.579346239566803, 0.588057279586792, 0.6202839016914368, 0.5962908267974854, 0.652256190776825, 0.6367103457450867, 0.606716513633728, 0.610934317111969, 0.6601349711418152, 0.6731700897216797, 0.6121127605438232, 0.6287655234336853, 0.6373932957649231, 0.6353534460067749, 0.6582412123680115, 0.646393358707428, 0.6661790013313293, 0.6610143184661865, 0.6622134447097778, 0.6622361540794373, 0.6431597471237183, 0.6759018898010254, 0.6700965762138367, 0.6677449345588684, 0.7650302648544312, 0.6930128335952759, 0.7089014649391174, 0.6551522016525269, 0.7350987195968628, 0.6542284488677979, 0.6745309829711914, 0.6816860437393188, 0.6728929877281189, 0.7173209190368652, 0.6951476335525513, 0.761226236820221, 0.725364089012146, 0.721571683883667, 0.6964530348777771, 0.7022765874862671, 0.7135549187660217, 0.696191132068634, 0.7185928821563721, 0.7251580953598022, 0.7310795187950134, 0.7490566968917847, 0.7420470118522644, 0.7318206429481506, 0.7434391975402832, 0.7315748333930969, 0.7695463299751282, 0.7592232823371887, 0.8671505451202393, 0.7558911442756653, 0.7819835543632507, 0.7528634667396545, 0.8757199048995972, 0.7632128596305847, 0.818474531173706, 0.7779231667518616, 0.8208181262016296, 0.7834828495979309, 0.7512394785881042, 0.7718415856361389, 0.8113971948623657, 0.7747699022293091], 'val_accuracy': [0.4954751133918762, 0.49660632014274597, 0.5056561231613159, 0.564479649066925, 0.6425339579582214, 0.639140248298645, 0.639140248298645, 0.6074660420417786, 0.5972850918769836, 0.6006787419319153, 0.6119909286499023, 0.5712669491767883, 0.5882353186607361, 0.5904977321624756, 0.5757918357849121, 0.587104082107544, 0.5848416090011597, 0.5837104320526123, 0.5927602052688599, 0.6085972785949707, 0.6606335043907166, 0.627828061580658, 0.6821267008781433, 0.6617646813392639, 0.7183257937431335, 0.7081447839736938, 0.7285068035125732, 0.7567873597145081, 0.7692307829856873, 0.7285068035125732, 0.7488687634468079, 0.773755669593811, 0.7726244330406189, 0.7771493196487427, 0.7828054428100586, 0.7805429697036743, 0.7635746598243713, 0.7726244330406189, 0.7477375268936157, 0.7635746598243713, 0.7760180830955505, 0.7771493196487427, 0.7545248866081238, 0.7466063499450684, 0.7601810097694397, 0.773755669593811, 0.7647058963775635, 0.7680995464324951, 0.7658371329307556, 0.7703620195388794, 0.7748869061470032, 0.7703620195388794, 0.7635746598243713, 0.7658371329307556, 0.7771493196487427, 0.75, 0.7748869061470032, 0.7658371329307556, 0.7477375268936157, 0.7511312365531921, 0.7488687634468079, 0.7748869061470032, 0.7454751133918762, 0.7782805562019348, 0.7647058963775635, 0.7567873597145081, 0.766968309879303, 0.7590497732162476, 0.7726244330406189, 0.7409502267837524, 0.7432126402854919, 0.7567873597145081, 0.7601810097694397, 0.773755669593811, 0.7680995464324951, 0.7680995464324951, 0.7613122463226318, 0.7635746598243713, 0.7556561231613159, 0.7567873597145081, 0.7545248866081238, 0.7522624731063843, 0.7613122463226318, 0.7556561231613159, 0.7601810097694397, 0.7601810097694397, 0.7432126402854919, 0.7466063499450684, 0.7556561231613159, 0.7714931964874268, 0.7285068035125732, 0.7613122463226318, 0.7511312365531921, 0.7567873597145081, 0.7488687634468079, 0.7443438768386841, 0.7522624731063843, 0.7635746598243713, 0.7443438768386841, 0.7533936500549316]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8463"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 65ms/step - loss: 0.3506 - accuracy: 0.8463 - val_loss: 0.7034 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3043 - accuracy: 0.8739 - val_loss: 0.6985 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2963 - accuracy: 0.8744 - val_loss: 0.6850 - val_accuracy: 0.4917\n","Epoch 4/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.2882 - accuracy: 0.8811 - val_loss: 0.6741 - val_accuracy: 0.5568\n","Epoch 5/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3011 - accuracy: 0.8731 - val_loss: 0.6648 - val_accuracy: 0.6488\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2882 - accuracy: 0.8860 - val_loss: 0.6629 - val_accuracy: 0.6322\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2888 - accuracy: 0.8804 - val_loss: 0.6582 - val_accuracy: 0.6281\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2805 - accuracy: 0.8832 - val_loss: 0.6657 - val_accuracy: 0.5930\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2914 - accuracy: 0.8747 - val_loss: 0.6632 - val_accuracy: 0.5971\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2807 - accuracy: 0.8822 - val_loss: 0.6919 - val_accuracy: 0.5579\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2742 - accuracy: 0.8809 - val_loss: 0.6870 - val_accuracy: 0.5816\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2619 - accuracy: 0.8871 - val_loss: 0.7341 - val_accuracy: 0.5589\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2732 - accuracy: 0.8809 - val_loss: 0.7481 - val_accuracy: 0.5640\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2634 - accuracy: 0.8943 - val_loss: 0.8094 - val_accuracy: 0.5537\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2722 - accuracy: 0.8824 - val_loss: 0.8322 - val_accuracy: 0.5671\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2636 - accuracy: 0.8899 - val_loss: 0.8914 - val_accuracy: 0.5682\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2657 - accuracy: 0.8904 - val_loss: 0.8735 - val_accuracy: 0.5847\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2511 - accuracy: 0.9013 - val_loss: 0.9381 - val_accuracy: 0.5837\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2533 - accuracy: 0.8997 - val_loss: 0.9356 - val_accuracy: 0.5981\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2497 - accuracy: 0.8979 - val_loss: 1.0952 - val_accuracy: 0.5816\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2730 - accuracy: 0.8879 - val_loss: 0.7643 - val_accuracy: 0.6632\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2775 - accuracy: 0.8853 - val_loss: 0.8838 - val_accuracy: 0.6426\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2548 - accuracy: 0.8961 - val_loss: 0.8270 - val_accuracy: 0.6674\n","Epoch 24/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2503 - accuracy: 0.8948 - val_loss: 0.6486 - val_accuracy: 0.7211\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2470 - accuracy: 0.9021 - val_loss: 0.6687 - val_accuracy: 0.7262\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2412 - accuracy: 0.9026 - val_loss: 0.7174 - val_accuracy: 0.7107\n","Epoch 27/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2382 - accuracy: 0.9039 - val_loss: 0.6688 - val_accuracy: 0.7397\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2484 - accuracy: 0.9000 - val_loss: 0.7011 - val_accuracy: 0.7231\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2573 - accuracy: 0.8853 - val_loss: 0.7112 - val_accuracy: 0.7262\n","Epoch 30/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.2533 - accuracy: 0.8948 - val_loss: 0.6742 - val_accuracy: 0.7459\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2424 - accuracy: 0.9057 - val_loss: 0.6752 - val_accuracy: 0.7397\n","Epoch 32/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2300 - accuracy: 0.9085 - val_loss: 0.7074 - val_accuracy: 0.7500\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2251 - accuracy: 0.9090 - val_loss: 0.7151 - val_accuracy: 0.7324\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2316 - accuracy: 0.9059 - val_loss: 0.7034 - val_accuracy: 0.7428\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2281 - accuracy: 0.9047 - val_loss: 0.7152 - val_accuracy: 0.7293\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3046 - accuracy: 0.8687 - val_loss: 0.7000 - val_accuracy: 0.7345\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2394 - accuracy: 0.9065 - val_loss: 0.6861 - val_accuracy: 0.7314\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2355 - accuracy: 0.9041 - val_loss: 0.7097 - val_accuracy: 0.7397\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2148 - accuracy: 0.9132 - val_loss: 0.6990 - val_accuracy: 0.7345\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2171 - accuracy: 0.9116 - val_loss: 0.7736 - val_accuracy: 0.7159\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2227 - accuracy: 0.9075 - val_loss: 0.7348 - val_accuracy: 0.7293\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2327 - accuracy: 0.9039 - val_loss: 0.7450 - val_accuracy: 0.7345\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2174 - accuracy: 0.9129 - val_loss: 0.7359 - val_accuracy: 0.7345\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2128 - accuracy: 0.9150 - val_loss: 0.7148 - val_accuracy: 0.7355\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2157 - accuracy: 0.9134 - val_loss: 0.7248 - val_accuracy: 0.7397\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2108 - accuracy: 0.9132 - val_loss: 0.7503 - val_accuracy: 0.7386\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2111 - accuracy: 0.9168 - val_loss: 0.7600 - val_accuracy: 0.7242\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2309 - accuracy: 0.9103 - val_loss: 0.7294 - val_accuracy: 0.7345\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2133 - accuracy: 0.9137 - val_loss: 0.7356 - val_accuracy: 0.7407\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1972 - accuracy: 0.9279 - val_loss: 0.7495 - val_accuracy: 0.7345\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2087 - accuracy: 0.9191 - val_loss: 0.7747 - val_accuracy: 0.7221\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2230 - accuracy: 0.9067 - val_loss: 0.7781 - val_accuracy: 0.7180\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2123 - accuracy: 0.9171 - val_loss: 0.7805 - val_accuracy: 0.7273\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2054 - accuracy: 0.9235 - val_loss: 0.7401 - val_accuracy: 0.7417\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2096 - accuracy: 0.9142 - val_loss: 0.7589 - val_accuracy: 0.7345\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1998 - accuracy: 0.9207 - val_loss: 0.8117 - val_accuracy: 0.7200\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2012 - accuracy: 0.9152 - val_loss: 0.7580 - val_accuracy: 0.7304\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2031 - accuracy: 0.9196 - val_loss: 0.7624 - val_accuracy: 0.7304\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1916 - accuracy: 0.9251 - val_loss: 0.7870 - val_accuracy: 0.7355\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2056 - accuracy: 0.9163 - val_loss: 0.7585 - val_accuracy: 0.7335\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1913 - accuracy: 0.9279 - val_loss: 0.7806 - val_accuracy: 0.7345\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1963 - accuracy: 0.9207 - val_loss: 0.7757 - val_accuracy: 0.7428\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1942 - accuracy: 0.9202 - val_loss: 0.8438 - val_accuracy: 0.7190\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2077 - accuracy: 0.9173 - val_loss: 0.7983 - val_accuracy: 0.7335\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1954 - accuracy: 0.9214 - val_loss: 0.7931 - val_accuracy: 0.7262\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1847 - accuracy: 0.9243 - val_loss: 0.8515 - val_accuracy: 0.7200\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1883 - accuracy: 0.9253 - val_loss: 0.8325 - val_accuracy: 0.7252\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1980 - accuracy: 0.9207 - val_loss: 0.7973 - val_accuracy: 0.7355\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1927 - accuracy: 0.9202 - val_loss: 0.7987 - val_accuracy: 0.7345\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1903 - accuracy: 0.9220 - val_loss: 0.8098 - val_accuracy: 0.7314\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1839 - accuracy: 0.9328 - val_loss: 0.8036 - val_accuracy: 0.7386\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1807 - accuracy: 0.9289 - val_loss: 0.7970 - val_accuracy: 0.7293\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1947 - accuracy: 0.9171 - val_loss: 0.7929 - val_accuracy: 0.7221\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1868 - accuracy: 0.9238 - val_loss: 0.8450 - val_accuracy: 0.7273\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1825 - accuracy: 0.9284 - val_loss: 0.8609 - val_accuracy: 0.7211\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1761 - accuracy: 0.9295 - val_loss: 0.8303 - val_accuracy: 0.7190\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1901 - accuracy: 0.9217 - val_loss: 0.8571 - val_accuracy: 0.7231\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1783 - accuracy: 0.9279 - val_loss: 0.8102 - val_accuracy: 0.7355\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1724 - accuracy: 0.9346 - val_loss: 0.8481 - val_accuracy: 0.7304\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1924 - accuracy: 0.9178 - val_loss: 0.8519 - val_accuracy: 0.7314\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1763 - accuracy: 0.9297 - val_loss: 0.8541 - val_accuracy: 0.7231\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1700 - accuracy: 0.9331 - val_loss: 0.8247 - val_accuracy: 0.7366\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1780 - accuracy: 0.9284 - val_loss: 0.8485 - val_accuracy: 0.7200\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1762 - accuracy: 0.9300 - val_loss: 0.8334 - val_accuracy: 0.7293\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1659 - accuracy: 0.9362 - val_loss: 0.8719 - val_accuracy: 0.7324\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1737 - accuracy: 0.9315 - val_loss: 0.8434 - val_accuracy: 0.7231\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1772 - accuracy: 0.9295 - val_loss: 0.9620 - val_accuracy: 0.6973\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1729 - accuracy: 0.9323 - val_loss: 0.8608 - val_accuracy: 0.7200\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1665 - accuracy: 0.9318 - val_loss: 0.8915 - val_accuracy: 0.7118\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1629 - accuracy: 0.9351 - val_loss: 0.8591 - val_accuracy: 0.7273\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1553 - accuracy: 0.9408 - val_loss: 1.0596 - val_accuracy: 0.6963\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1891 - accuracy: 0.9176 - val_loss: 0.8785 - val_accuracy: 0.7355\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1809 - accuracy: 0.9256 - val_loss: 0.8608 - val_accuracy: 0.7231\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1806 - accuracy: 0.9245 - val_loss: 0.8668 - val_accuracy: 0.7273\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1583 - accuracy: 0.9385 - val_loss: 0.9171 - val_accuracy: 0.7076\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1626 - accuracy: 0.9346 - val_loss: 0.9203 - val_accuracy: 0.7076\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1613 - accuracy: 0.9333 - val_loss: 0.9858 - val_accuracy: 0.7128\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1764 - accuracy: 0.9297 - val_loss: 0.8886 - val_accuracy: 0.7211\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1859 - accuracy: 0.9199 - val_loss: 0.8787 - val_accuracy: 0.7293\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1665 - accuracy: 0.9346 - val_loss: 0.8894 - val_accuracy: 0.7107\n","{'loss': [0.35062506794929504, 0.30427175760269165, 0.29631295800209045, 0.2881604731082916, 0.30112984776496887, 0.2882222533226013, 0.2887621819972992, 0.2804984450340271, 0.2913582921028137, 0.28065240383148193, 0.2741742730140686, 0.26194384694099426, 0.2732449173927307, 0.2633667290210724, 0.2722141742706299, 0.26361724734306335, 0.2657352685928345, 0.2511289715766907, 0.2532944679260254, 0.2497071623802185, 0.2729704976081848, 0.2775275707244873, 0.2548389136791229, 0.2502567768096924, 0.2470056414604187, 0.24117983877658844, 0.2382494956254959, 0.2484288513660431, 0.2572845220565796, 0.2532629370689392, 0.24239593744277954, 0.23002278804779053, 0.22511038184165955, 0.2316218614578247, 0.22807510197162628, 0.3045705258846283, 0.23943637311458588, 0.2355472445487976, 0.21480344235897064, 0.21706753969192505, 0.22270247340202332, 0.2326740324497223, 0.21741439402103424, 0.21280713379383087, 0.21571943163871765, 0.2108372151851654, 0.21108335256576538, 0.2308976799249649, 0.2132628858089447, 0.1972123235464096, 0.2087135910987854, 0.2229657918214798, 0.21227775514125824, 0.20535428822040558, 0.20964907109737396, 0.19984734058380127, 0.20124000310897827, 0.20312735438346863, 0.19155031442642212, 0.20561520755290985, 0.19128210842609406, 0.1963224709033966, 0.1942334771156311, 0.20767192542552948, 0.1954202502965927, 0.184674933552742, 0.1883070319890976, 0.1979852020740509, 0.1926805078983307, 0.19032955169677734, 0.18389123678207397, 0.18069615960121155, 0.19469964504241943, 0.18678897619247437, 0.18253502249717712, 0.17610648274421692, 0.1901470124721527, 0.1783417910337448, 0.17242881655693054, 0.19243654608726501, 0.17625175416469574, 0.16999441385269165, 0.1779567301273346, 0.17615877091884613, 0.1659221649169922, 0.17374280095100403, 0.1771528422832489, 0.17292648553848267, 0.1664688140153885, 0.1628684252500534, 0.15525071322917938, 0.1891442835330963, 0.1809067577123642, 0.18059185147285461, 0.15828676521778107, 0.16262821853160858, 0.1613457351922989, 0.17644096910953522, 0.18588930368423462, 0.1664564609527588], 'accuracy': [0.8462532162666321, 0.8739017844200134, 0.8744186162948608, 0.881136953830719, 0.8731266260147095, 0.8860465288162231, 0.8803617358207703, 0.8832041621208191, 0.8746770024299622, 0.882170557975769, 0.8808785676956177, 0.8870801329612732, 0.8808785676956177, 0.894315242767334, 0.8824289441108704, 0.8899224996566772, 0.8904392719268799, 0.9012919664382935, 0.8997415900230408, 0.8979328274726868, 0.8878552913665771, 0.8852713108062744, 0.896124005317688, 0.8948320150375366, 0.9020671844482422, 0.9025839567184448, 0.9038759469985962, 0.8999999761581421, 0.8852713108062744, 0.8948320150375366, 0.905684769153595, 0.908527135848999, 0.9090439081192017, 0.9059431552886963, 0.9046511650085449, 0.868733823299408, 0.9064599275588989, 0.9041343927383423, 0.9131782650947571, 0.9116278886795044, 0.907493531703949, 0.9038759469985962, 0.9129198789596558, 0.9149870872497559, 0.9134367108345032, 0.9131782650947571, 0.9167958498001099, 0.910335898399353, 0.9136950969696045, 0.9279069900512695, 0.9191214442253113, 0.906718373298645, 0.9170542359352112, 0.923514187335968, 0.9142118692398071, 0.920671820640564, 0.9152454733848572, 0.9196382164955139, 0.9250646233558655, 0.9162790775299072, 0.9279069900512695, 0.920671820640564, 0.9201550483703613, 0.9173126816749573, 0.9214470386505127, 0.9242894053459167, 0.9253230094909668, 0.920671820640564, 0.9201550483703613, 0.9219638109207153, 0.9328165650367737, 0.9289405941963196, 0.9170542359352112, 0.9237726330757141, 0.9284237623214722, 0.9294573664665222, 0.921705424785614, 0.9279069900512695, 0.9346253275871277, 0.9178294539451599, 0.9297157526016235, 0.933074951171875, 0.9284237623214722, 0.9299741387367249, 0.9361757040023804, 0.9315245747566223, 0.9294573664665222, 0.9322997331619263, 0.9317829608917236, 0.9351420998573303, 0.9408268928527832, 0.9175710678100586, 0.9255813956260681, 0.9245477914810181, 0.9385012984275818, 0.9346253275871277, 0.9333333373069763, 0.9297157526016235, 0.91989666223526, 0.9346253275871277], 'val_loss': [0.7034217119216919, 0.6984804272651672, 0.6849710941314697, 0.6740937829017639, 0.6648496389389038, 0.6629085540771484, 0.6581841707229614, 0.6657350063323975, 0.6632047891616821, 0.6918815970420837, 0.6869569420814514, 0.7341480851173401, 0.748144805431366, 0.8094156384468079, 0.832226574420929, 0.891379177570343, 0.8734673261642456, 0.9381399750709534, 0.9356358647346497, 1.0951892137527466, 0.7642838954925537, 0.8837575316429138, 0.8269761800765991, 0.648649275302887, 0.6687411665916443, 0.7174355387687683, 0.6688178181648254, 0.7010937333106995, 0.711214005947113, 0.6741664409637451, 0.6752378940582275, 0.7073550224304199, 0.7151272296905518, 0.7033941745758057, 0.7151944041252136, 0.6999862790107727, 0.6861262321472168, 0.7097137570381165, 0.6989501714706421, 0.7736153602600098, 0.7347748875617981, 0.7450117468833923, 0.7358770370483398, 0.7147818803787231, 0.7248116135597229, 0.7502683401107788, 0.7600101232528687, 0.7294495701789856, 0.7356266975402832, 0.7494646906852722, 0.774673342704773, 0.7780817747116089, 0.780479907989502, 0.7401494383811951, 0.7589011192321777, 0.8117119073867798, 0.7580158114433289, 0.7624196410179138, 0.7870144844055176, 0.7585453987121582, 0.7805743217468262, 0.77571040391922, 0.8437802195549011, 0.798313319683075, 0.7930918335914612, 0.8514630198478699, 0.8324732780456543, 0.7973368167877197, 0.7986922860145569, 0.8098414540290833, 0.8035935163497925, 0.7969679236412048, 0.7928704619407654, 0.8450067043304443, 0.8609011769294739, 0.8303160667419434, 0.857144296169281, 0.810167670249939, 0.8481318950653076, 0.851890504360199, 0.8541253209114075, 0.8246600031852722, 0.8485023379325867, 0.8333895206451416, 0.871917724609375, 0.8434467315673828, 0.9620084166526794, 0.860817551612854, 0.8914859294891357, 0.8590859770774841, 1.059594988822937, 0.8784760236740112, 0.8608417510986328, 0.8668066263198853, 0.9171401262283325, 0.9203252792358398, 0.9857730269432068, 0.8885889649391174, 0.8787307739257812, 0.8893855810165405], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4917355477809906, 0.5568181872367859, 0.6487603187561035, 0.6322314143180847, 0.6280992031097412, 0.5929751992225647, 0.5971074104309082, 0.557851254940033, 0.5816115736961365, 0.55888432264328, 0.5640496015548706, 0.5537189841270447, 0.567148745059967, 0.5681818127632141, 0.5847107172012329, 0.5836777091026306, 0.5981404781341553, 0.5816115736961365, 0.663223147392273, 0.6425619721412659, 0.6673553586006165, 0.7210744023323059, 0.7262396812438965, 0.71074378490448, 0.7396694421768188, 0.7231404781341553, 0.7262396812438965, 0.7458677887916565, 0.7396694421768188, 0.75, 0.7324380278587341, 0.7427685856819153, 0.7293388247489929, 0.7345041036605835, 0.7314049601554871, 0.7396694421768188, 0.7345041036605835, 0.7159090638160706, 0.7293388247489929, 0.7345041036605835, 0.7345041036605835, 0.7355371713638306, 0.7396694421768188, 0.7386363744735718, 0.7241735458374023, 0.7345041036605835, 0.7407024502754211, 0.7345041036605835, 0.7221074104309082, 0.7179751992225647, 0.7272727489471436, 0.7417355179786682, 0.7345041036605835, 0.7200413346290588, 0.73037189245224, 0.73037189245224, 0.7355371713638306, 0.7334710955619812, 0.7345041036605835, 0.7427685856819153, 0.7190082669258118, 0.7334710955619812, 0.7262396812438965, 0.7200413346290588, 0.7252066135406494, 0.7355371713638306, 0.7345041036605835, 0.7314049601554871, 0.7386363744735718, 0.7293388247489929, 0.7221074104309082, 0.7272727489471436, 0.7210744023323059, 0.7190082669258118, 0.7231404781341553, 0.7355371713638306, 0.73037189245224, 0.7314049601554871, 0.7231404781341553, 0.7365702390670776, 0.7200413346290588, 0.7293388247489929, 0.7324380278587341, 0.7231404781341553, 0.6973140239715576, 0.7200413346290588, 0.711776852607727, 0.7272727489471436, 0.6962810158729553, 0.7355371713638306, 0.7231404781341553, 0.7272727489471436, 0.7076446413993835, 0.7076446413993835, 0.7128099203109741, 0.7210744023323059, 0.7293388247489929, 0.71074378490448]}\n","32/32 [==============================] - 1s 4ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1717437056215,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"Ik5JoVP2NPvY","outputId":"9133d3ea-89ce-4509-ea84-1321b1012398"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.662      0.691   0.588  0.635        0.588        0.737   \n","1        1     0.691      0.700   0.669  0.684        0.669        0.713   \n","2        2     0.640      0.605   0.807  0.691        0.807        0.472   \n","3        0     0.668      0.722   0.548  0.623        0.548        0.789   \n","4        1     0.687      0.748   0.565  0.644        0.565        0.809   \n","5        2     0.628      0.592   0.819  0.687        0.819        0.436   \n","6        0     0.698      0.739   0.611  0.669        0.611        0.784   \n","7        1     0.690      0.660   0.785  0.717        0.785        0.595   \n","8        2     0.701      0.712   0.675  0.693        0.675        0.727   \n","9        0     0.713      0.694   0.762  0.726        0.762        0.663   \n","10       1     0.726      0.731   0.716  0.723        0.716        0.736   \n","11       2     0.699      0.659   0.823  0.732        0.823        0.574   \n","12       0     0.740      0.736   0.750  0.743        0.750        0.730   \n","13       1     0.740      0.725   0.774  0.749        0.774        0.706   \n","14       2     0.742      0.693   0.867  0.771        0.867        0.616   \n","\n","    Kappa  \n","0   0.325  \n","1   0.383  \n","2   0.279  \n","3   0.337  \n","4   0.374  \n","5   0.255  \n","6   0.395  \n","7   0.380  \n","8   0.402  \n","9   0.425  \n","10  0.452  \n","11  0.398  \n","12  0.481  \n","13  0.480  \n","14  0.484  "],"text/html":["\n","  <div id=\"df-a9bbbb8b-3475-45a7-ac13-7cb20cc1256f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.662</td>\n","      <td>0.691</td>\n","      <td>0.588</td>\n","      <td>0.635</td>\n","      <td>0.588</td>\n","      <td>0.737</td>\n","      <td>0.325</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.691</td>\n","      <td>0.700</td>\n","      <td>0.669</td>\n","      <td>0.684</td>\n","      <td>0.669</td>\n","      <td>0.713</td>\n","      <td>0.383</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.640</td>\n","      <td>0.605</td>\n","      <td>0.807</td>\n","      <td>0.691</td>\n","      <td>0.807</td>\n","      <td>0.472</td>\n","      <td>0.279</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.668</td>\n","      <td>0.722</td>\n","      <td>0.548</td>\n","      <td>0.623</td>\n","      <td>0.548</td>\n","      <td>0.789</td>\n","      <td>0.337</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.687</td>\n","      <td>0.748</td>\n","      <td>0.565</td>\n","      <td>0.644</td>\n","      <td>0.565</td>\n","      <td>0.809</td>\n","      <td>0.374</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.628</td>\n","      <td>0.592</td>\n","      <td>0.819</td>\n","      <td>0.687</td>\n","      <td>0.819</td>\n","      <td>0.436</td>\n","      <td>0.255</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.698</td>\n","      <td>0.739</td>\n","      <td>0.611</td>\n","      <td>0.669</td>\n","      <td>0.611</td>\n","      <td>0.784</td>\n","      <td>0.395</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.690</td>\n","      <td>0.660</td>\n","      <td>0.785</td>\n","      <td>0.717</td>\n","      <td>0.785</td>\n","      <td>0.595</td>\n","      <td>0.380</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.701</td>\n","      <td>0.712</td>\n","      <td>0.675</td>\n","      <td>0.693</td>\n","      <td>0.675</td>\n","      <td>0.727</td>\n","      <td>0.402</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.713</td>\n","      <td>0.694</td>\n","      <td>0.762</td>\n","      <td>0.726</td>\n","      <td>0.762</td>\n","      <td>0.663</td>\n","      <td>0.425</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.726</td>\n","      <td>0.731</td>\n","      <td>0.716</td>\n","      <td>0.723</td>\n","      <td>0.716</td>\n","      <td>0.736</td>\n","      <td>0.452</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.699</td>\n","      <td>0.659</td>\n","      <td>0.823</td>\n","      <td>0.732</td>\n","      <td>0.823</td>\n","      <td>0.574</td>\n","      <td>0.398</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.740</td>\n","      <td>0.736</td>\n","      <td>0.750</td>\n","      <td>0.743</td>\n","      <td>0.750</td>\n","      <td>0.730</td>\n","      <td>0.481</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.740</td>\n","      <td>0.725</td>\n","      <td>0.774</td>\n","      <td>0.749</td>\n","      <td>0.774</td>\n","      <td>0.706</td>\n","      <td>0.480</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.742</td>\n","      <td>0.693</td>\n","      <td>0.867</td>\n","      <td>0.771</td>\n","      <td>0.867</td>\n","      <td>0.616</td>\n","      <td>0.484</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9bbbb8b-3475-45a7-ac13-7cb20cc1256f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a9bbbb8b-3475-45a7-ac13-7cb20cc1256f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a9bbbb8b-3475-45a7-ac13-7cb20cc1256f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ea593dd6-6e4c-4006-9051-4fc4a32d8806\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea593dd6-6e4c-4006-9051-4fc4a32d8806')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ea593dd6-6e4c-4006-9051-4fc4a32d8806 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03488962187077575,\n        \"min\": 0.628,\n        \"max\": 0.742,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.713,\n          0.699,\n          0.662\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046975981704939995,\n        \"min\": 0.592,\n        \"max\": 0.748,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.694,\n          0.659,\n          0.691\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10241265732785369,\n        \"min\": 0.548,\n        \"max\": 0.867,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.762,\n          0.823,\n          0.588\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04359204820453687,\n        \"min\": 0.623,\n        \"max\": 0.771,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.726,\n          0.732,\n          0.635\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10241265732785369,\n        \"min\": 0.548,\n        \"max\": 0.867,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.762,\n          0.823,\n          0.588\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11243783467617414,\n        \"min\": 0.436,\n        \"max\": 0.809,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.663,\n          0.574,\n          0.737\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06995100326044548,\n        \"min\": 0.255,\n        \"max\": 0.484,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.425,\n          0.398,\n          0.325\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ncf_cMAQF6g4"},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_LSTM/Theta_time_CNN_LSTM.csv', index = False)"]},{"cell_type":"markdown","metadata":{"id":"QUuWzfMHSNmi"},"source":["# CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xrx_fxBSWGd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Theta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Theta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":858797,"status":"ok","timestamp":1717437914845,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"H1TaNdIbSfkq","outputId":"b75ae9a2-0bfe-4b1d-f137-fa4b273677ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 1.7732 - accuracy: 0.4997"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 5s 44ms/step - loss: 1.7720 - accuracy: 0.5024 - val_loss: 1.7672 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.7568 - accuracy: 0.5436 - val_loss: 1.7579 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.7410 - accuracy: 0.6013 - val_loss: 1.7486 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7272 - accuracy: 0.5975 - val_loss: 1.7390 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.7128 - accuracy: 0.6026 - val_loss: 1.7295 - val_accuracy: 0.5517\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6997 - accuracy: 0.6180 - val_loss: 1.7196 - val_accuracy: 0.6584\n","Epoch 7/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6836 - accuracy: 0.6363 - val_loss: 1.7094 - val_accuracy: 0.6552\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6674 - accuracy: 0.6476 - val_loss: 1.6986 - val_accuracy: 0.6616\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6529 - accuracy: 0.6554 - val_loss: 1.6880 - val_accuracy: 0.6153\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6374 - accuracy: 0.6552 - val_loss: 1.6773 - val_accuracy: 0.5733\n","Epoch 11/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6235 - accuracy: 0.6627 - val_loss: 1.6658 - val_accuracy: 0.5873\n","Epoch 12/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6100 - accuracy: 0.6665 - val_loss: 1.6545 - val_accuracy: 0.5862\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5968 - accuracy: 0.6646 - val_loss: 1.6422 - val_accuracy: 0.5948\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5930 - accuracy: 0.6492 - val_loss: 1.6304 - val_accuracy: 0.6110\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.5838 - accuracy: 0.6530 - val_loss: 1.6176 - val_accuracy: 0.6282\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.5659 - accuracy: 0.6781 - val_loss: 1.6025 - val_accuracy: 0.6519\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5571 - accuracy: 0.6748 - val_loss: 1.5940 - val_accuracy: 0.6369\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5456 - accuracy: 0.6770 - val_loss: 1.5798 - val_accuracy: 0.6530\n","Epoch 19/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5379 - accuracy: 0.6767 - val_loss: 1.5670 - val_accuracy: 0.6541\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5364 - accuracy: 0.6649 - val_loss: 1.5643 - val_accuracy: 0.6379\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5220 - accuracy: 0.6821 - val_loss: 1.5470 - val_accuracy: 0.6562\n","Epoch 22/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.5110 - accuracy: 0.6832 - val_loss: 1.5314 - val_accuracy: 0.6638\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5042 - accuracy: 0.6824 - val_loss: 1.5239 - val_accuracy: 0.6584\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.4986 - accuracy: 0.6727 - val_loss: 1.5139 - val_accuracy: 0.6649\n","Epoch 25/100\n","29/29 [==============================] - 1s 41ms/step - loss: 1.4867 - accuracy: 0.6851 - val_loss: 1.4995 - val_accuracy: 0.6832\n","Epoch 26/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4792 - accuracy: 0.6794 - val_loss: 1.4899 - val_accuracy: 0.6746\n","Epoch 27/100\n","29/29 [==============================] - 1s 38ms/step - loss: 1.4714 - accuracy: 0.6856 - val_loss: 1.4825 - val_accuracy: 0.6853\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.4634 - accuracy: 0.6870 - val_loss: 1.4740 - val_accuracy: 0.6724\n","Epoch 29/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4567 - accuracy: 0.6894 - val_loss: 1.4685 - val_accuracy: 0.6767\n","Epoch 30/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4476 - accuracy: 0.6921 - val_loss: 1.4618 - val_accuracy: 0.6789\n","Epoch 31/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.4449 - accuracy: 0.6802 - val_loss: 1.4544 - val_accuracy: 0.6853\n","Epoch 32/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4357 - accuracy: 0.6902 - val_loss: 1.4497 - val_accuracy: 0.6832\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4281 - accuracy: 0.6867 - val_loss: 1.4513 - val_accuracy: 0.6638\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4176 - accuracy: 0.6886 - val_loss: 1.4549 - val_accuracy: 0.6519\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4173 - accuracy: 0.6837 - val_loss: 1.4284 - val_accuracy: 0.6832\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4071 - accuracy: 0.6891 - val_loss: 1.4327 - val_accuracy: 0.6692\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4019 - accuracy: 0.6918 - val_loss: 1.4175 - val_accuracy: 0.6832\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3892 - accuracy: 0.6983 - val_loss: 1.4080 - val_accuracy: 0.6767\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3843 - accuracy: 0.6969 - val_loss: 1.4020 - val_accuracy: 0.6800\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3765 - accuracy: 0.6913 - val_loss: 1.4021 - val_accuracy: 0.6778\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3722 - accuracy: 0.6985 - val_loss: 1.3899 - val_accuracy: 0.6832\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3671 - accuracy: 0.6932 - val_loss: 1.3844 - val_accuracy: 0.6832\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3584 - accuracy: 0.7020 - val_loss: 1.3796 - val_accuracy: 0.6789\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3492 - accuracy: 0.7064 - val_loss: 1.3782 - val_accuracy: 0.6800\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3459 - accuracy: 0.6977 - val_loss: 1.3718 - val_accuracy: 0.6778\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3362 - accuracy: 0.7053 - val_loss: 1.3683 - val_accuracy: 0.6778\n","Epoch 47/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3329 - accuracy: 0.7047 - val_loss: 1.3571 - val_accuracy: 0.6832\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3257 - accuracy: 0.7039 - val_loss: 1.3495 - val_accuracy: 0.6853\n","Epoch 49/100\n","29/29 [==============================] - 2s 62ms/step - loss: 1.3195 - accuracy: 0.7053 - val_loss: 1.3446 - val_accuracy: 0.6886\n","Epoch 50/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.3098 - accuracy: 0.7112 - val_loss: 1.3476 - val_accuracy: 0.6735\n","Epoch 51/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3082 - accuracy: 0.7069 - val_loss: 1.3559 - val_accuracy: 0.6530\n","Epoch 52/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.2974 - accuracy: 0.7134 - val_loss: 1.3291 - val_accuracy: 0.6843\n","Epoch 53/100\n","29/29 [==============================] - 1s 44ms/step - loss: 1.2931 - accuracy: 0.7072 - val_loss: 1.3222 - val_accuracy: 0.6940\n","Epoch 54/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.2838 - accuracy: 0.7112 - val_loss: 1.3263 - val_accuracy: 0.6810\n","Epoch 55/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.2807 - accuracy: 0.7142 - val_loss: 1.3125 - val_accuracy: 0.6929\n","Epoch 56/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2706 - accuracy: 0.7161 - val_loss: 1.3127 - val_accuracy: 0.6778\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2654 - accuracy: 0.7171 - val_loss: 1.3023 - val_accuracy: 0.6918\n","Epoch 58/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2603 - accuracy: 0.7196 - val_loss: 1.2972 - val_accuracy: 0.6897\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2514 - accuracy: 0.7239 - val_loss: 1.2927 - val_accuracy: 0.6918\n","Epoch 60/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2471 - accuracy: 0.7258 - val_loss: 1.3001 - val_accuracy: 0.6627\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2394 - accuracy: 0.7252 - val_loss: 1.2844 - val_accuracy: 0.6886\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2370 - accuracy: 0.7193 - val_loss: 1.2809 - val_accuracy: 0.6929\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2286 - accuracy: 0.7249 - val_loss: 1.2757 - val_accuracy: 0.6821\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2250 - accuracy: 0.7217 - val_loss: 1.2812 - val_accuracy: 0.6659\n","Epoch 65/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2139 - accuracy: 0.7314 - val_loss: 1.2658 - val_accuracy: 0.6843\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2107 - accuracy: 0.7266 - val_loss: 1.2596 - val_accuracy: 0.6940\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2027 - accuracy: 0.7295 - val_loss: 1.2549 - val_accuracy: 0.6940\n","Epoch 68/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1969 - accuracy: 0.7287 - val_loss: 1.2509 - val_accuracy: 0.6940\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1897 - accuracy: 0.7320 - val_loss: 1.2472 - val_accuracy: 0.6929\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1866 - accuracy: 0.7328 - val_loss: 1.2421 - val_accuracy: 0.6907\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1789 - accuracy: 0.7346 - val_loss: 1.2421 - val_accuracy: 0.6853\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1729 - accuracy: 0.7406 - val_loss: 1.2415 - val_accuracy: 0.6724\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1681 - accuracy: 0.7338 - val_loss: 1.2286 - val_accuracy: 0.7026\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1642 - accuracy: 0.7411 - val_loss: 1.2265 - val_accuracy: 0.6886\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1542 - accuracy: 0.7416 - val_loss: 1.2264 - val_accuracy: 0.6778\n","Epoch 76/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1490 - accuracy: 0.7449 - val_loss: 1.2160 - val_accuracy: 0.7004\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1444 - accuracy: 0.7441 - val_loss: 1.2133 - val_accuracy: 0.6929\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1377 - accuracy: 0.7427 - val_loss: 1.2087 - val_accuracy: 0.7004\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1315 - accuracy: 0.7452 - val_loss: 1.2050 - val_accuracy: 0.6940\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1308 - accuracy: 0.7360 - val_loss: 1.2341 - val_accuracy: 0.6519\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1410 - accuracy: 0.7247 - val_loss: 1.1986 - val_accuracy: 0.6940\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1170 - accuracy: 0.7538 - val_loss: 1.1938 - val_accuracy: 0.6972\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1095 - accuracy: 0.7538 - val_loss: 1.1978 - val_accuracy: 0.6756\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1034 - accuracy: 0.7468 - val_loss: 1.1897 - val_accuracy: 0.6864\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0984 - accuracy: 0.7530 - val_loss: 1.1883 - val_accuracy: 0.6875\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0968 - accuracy: 0.7473 - val_loss: 1.1854 - val_accuracy: 0.6789\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0861 - accuracy: 0.7562 - val_loss: 1.1923 - val_accuracy: 0.6638\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0812 - accuracy: 0.7592 - val_loss: 1.1783 - val_accuracy: 0.6843\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0745 - accuracy: 0.7635 - val_loss: 1.1709 - val_accuracy: 0.6875\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0711 - accuracy: 0.7629 - val_loss: 1.1738 - val_accuracy: 0.6789\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0658 - accuracy: 0.7621 - val_loss: 1.1644 - val_accuracy: 0.6940\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0648 - accuracy: 0.7548 - val_loss: 1.2324 - val_accuracy: 0.6207\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0559 - accuracy: 0.7654 - val_loss: 1.1583 - val_accuracy: 0.6940\n","Epoch 94/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0503 - accuracy: 0.7629 - val_loss: 1.1673 - val_accuracy: 0.6746\n","Epoch 95/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0432 - accuracy: 0.7629 - val_loss: 1.1527 - val_accuracy: 0.6918\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0375 - accuracy: 0.7670 - val_loss: 1.1540 - val_accuracy: 0.6778\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0305 - accuracy: 0.7710 - val_loss: 1.1509 - val_accuracy: 0.6789\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0265 - accuracy: 0.7767 - val_loss: 1.1452 - val_accuracy: 0.6853\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0209 - accuracy: 0.7691 - val_loss: 1.1423 - val_accuracy: 0.6929\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0209 - accuracy: 0.7672 - val_loss: 1.1493 - val_accuracy: 0.6800\n","{'loss': [1.771967887878418, 1.7567988634109497, 1.7409858703613281, 1.727231502532959, 1.7127765417099, 1.6996800899505615, 1.6836111545562744, 1.6674294471740723, 1.6528607606887817, 1.6373586654663086, 1.6235071420669556, 1.6099824905395508, 1.5968409776687622, 1.5929529666900635, 1.583755373954773, 1.5659412145614624, 1.5571280717849731, 1.5456287860870361, 1.5378644466400146, 1.5363940000534058, 1.5220363140106201, 1.5110357999801636, 1.5041837692260742, 1.4986069202423096, 1.4866740703582764, 1.4792075157165527, 1.4714469909667969, 1.4633723497390747, 1.4566594362258911, 1.4475651979446411, 1.4448745250701904, 1.4357184171676636, 1.4280608892440796, 1.4175564050674438, 1.417345404624939, 1.4070954322814941, 1.4019144773483276, 1.3891661167144775, 1.384337067604065, 1.3764870166778564, 1.3721789121627808, 1.367112636566162, 1.3583765029907227, 1.3491811752319336, 1.3458927869796753, 1.3361910581588745, 1.3328837156295776, 1.3256895542144775, 1.3194996118545532, 1.3097862005233765, 1.3082259893417358, 1.2974437475204468, 1.2930704355239868, 1.283780574798584, 1.2806538343429565, 1.2706247568130493, 1.2654417753219604, 1.2603126764297485, 1.2514244318008423, 1.2471119165420532, 1.23944091796875, 1.237021565437317, 1.2285748720169067, 1.2249557971954346, 1.2138524055480957, 1.2107056379318237, 1.2026787996292114, 1.196885585784912, 1.1896990537643433, 1.1865508556365967, 1.1788853406906128, 1.1728527545928955, 1.1680829524993896, 1.164202332496643, 1.154241681098938, 1.1489886045455933, 1.144423484802246, 1.1376678943634033, 1.1315014362335205, 1.1308099031448364, 1.1410495042800903, 1.117016077041626, 1.109546184539795, 1.1034427881240845, 1.0984458923339844, 1.0968294143676758, 1.0860953330993652, 1.0812482833862305, 1.0745331048965454, 1.0711426734924316, 1.0657857656478882, 1.064752221107483, 1.0559154748916626, 1.0503355264663696, 1.0432214736938477, 1.0375310182571411, 1.0304878950119019, 1.026506781578064, 1.020906686782837, 1.0209308862686157], 'accuracy': [0.5024245977401733, 0.5436422228813171, 0.6012930870056152, 0.5975215435028076, 0.6026400923728943, 0.6179956793785095, 0.6363146305084229, 0.6476293206214905, 0.6554418206214905, 0.6551724076271057, 0.662715494632721, 0.6664870977401733, 0.6646012663841248, 0.6492456793785095, 0.6530172228813171, 0.678071141242981, 0.6748383641242981, 0.6769935488700867, 0.6767241358757019, 0.6648706793785095, 0.6821120977401733, 0.6831896305084229, 0.6823814511299133, 0.6726831793785095, 0.6850754022598267, 0.6794180870056152, 0.6856142282485962, 0.6869612336158752, 0.6893857717514038, 0.6920797228813171, 0.6802262663841248, 0.6901939511299133, 0.6866918206214905, 0.6885775923728943, 0.6837284564971924, 0.689116358757019, 0.6918103694915771, 0.6982758641242981, 0.696928858757019, 0.6912715435028076, 0.6985452771186829, 0.6931573152542114, 0.7020474076271057, 0.7063577771186829, 0.6977370977401733, 0.7052801847457886, 0.704741358757019, 0.7039331793785095, 0.7052801847457886, 0.7112069129943848, 0.7068965435028076, 0.7133620977401733, 0.7071659564971924, 0.7112069129943848, 0.7141702771186829, 0.7160560488700867, 0.717133641242981, 0.7195581793785095, 0.7238685488700867, 0.7257543206214905, 0.725215494632721, 0.7192887663841248, 0.724946141242981, 0.7217133641242981, 0.7314116358757019, 0.7265625, 0.7295258641242981, 0.7287176847457886, 0.7319504022598267, 0.732758641242981, 0.7346444129943848, 0.740571141242981, 0.7338362336158752, 0.7411099076271057, 0.7416487336158752, 0.7448814511299133, 0.7440732717514038, 0.7427262663841248, 0.7451508641242981, 0.735991358757019, 0.7246767282485962, 0.7537715435028076, 0.7537715435028076, 0.7467672228813171, 0.7529633641242981, 0.7473060488700867, 0.756196141242981, 0.759159505367279, 0.7634698152542114, 0.7629310488700867, 0.7621228694915771, 0.7548491358757019, 0.7653555870056152, 0.7629310488700867, 0.7629310488700867, 0.766972005367279, 0.7710129022598267, 0.7766702771186829, 0.7691271305084229, 0.767241358757019], 'val_loss': [1.7671654224395752, 1.7578600645065308, 1.7485640048980713, 1.7390400171279907, 1.7295267581939697, 1.719602346420288, 1.7093794345855713, 1.6985502243041992, 1.6880099773406982, 1.6772953271865845, 1.665786623954773, 1.6545250415802002, 1.6422433853149414, 1.6303890943527222, 1.6176068782806396, 1.6024835109710693, 1.594014048576355, 1.579791784286499, 1.5670092105865479, 1.5642704963684082, 1.5470385551452637, 1.531369686126709, 1.5238608121871948, 1.5139178037643433, 1.4994823932647705, 1.4898686408996582, 1.482483148574829, 1.4740283489227295, 1.4685132503509521, 1.4618083238601685, 1.4544334411621094, 1.4496839046478271, 1.451308250427246, 1.454898476600647, 1.4283510446548462, 1.4326618909835815, 1.417473316192627, 1.4080016613006592, 1.4019582271575928, 1.4021368026733398, 1.3898777961730957, 1.3844412565231323, 1.379632592201233, 1.3782366514205933, 1.3717552423477173, 1.3682677745819092, 1.3571150302886963, 1.349531650543213, 1.3446327447891235, 1.3476053476333618, 1.3558893203735352, 1.3291490077972412, 1.3221908807754517, 1.326281189918518, 1.312535047531128, 1.3126994371414185, 1.3022551536560059, 1.2972211837768555, 1.2927101850509644, 1.3001242876052856, 1.2844375371932983, 1.280900239944458, 1.275659203529358, 1.281165599822998, 1.2657545804977417, 1.2595645189285278, 1.2549116611480713, 1.2508643865585327, 1.2472416162490845, 1.242130994796753, 1.242081642150879, 1.2415239810943604, 1.2286361455917358, 1.226521372795105, 1.2263916730880737, 1.2159650325775146, 1.2132669687271118, 1.2086681127548218, 1.2050014734268188, 1.2341293096542358, 1.1985740661621094, 1.1938340663909912, 1.1977638006210327, 1.1897422075271606, 1.1883459091186523, 1.1853880882263184, 1.1923400163650513, 1.178295612335205, 1.170852541923523, 1.173750638961792, 1.1643564701080322, 1.2323575019836426, 1.158339262008667, 1.167343258857727, 1.1527496576309204, 1.1539865732192993, 1.1508972644805908, 1.145164966583252, 1.1423265933990479, 1.149282693862915], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4881465435028076, 0.5517241358757019, 0.6584051847457886, 0.6551724076271057, 0.6616379022598267, 0.6153017282485962, 0.5732758641242981, 0.587284505367279, 0.5862069129943848, 0.5948275923728943, 0.610991358757019, 0.6282327771186829, 0.6519396305084229, 0.6368534564971924, 0.6530172228813171, 0.6540948152542114, 0.6379310488700867, 0.65625, 0.6637930870056152, 0.6584051847457886, 0.6648706793785095, 0.6831896305084229, 0.6745689511299133, 0.6853448152542114, 0.6724137663841248, 0.6767241358757019, 0.6788793206214905, 0.6853448152542114, 0.6831896305084229, 0.6637930870056152, 0.6519396305084229, 0.6831896305084229, 0.6691810488700867, 0.6831896305084229, 0.6767241358757019, 0.6799569129943848, 0.6778017282485962, 0.6831896305084229, 0.6831896305084229, 0.6788793206214905, 0.6799569129943848, 0.6778017282485962, 0.6778017282485962, 0.6831896305084229, 0.6853448152542114, 0.6885775923728943, 0.673491358757019, 0.6530172228813171, 0.6842672228813171, 0.693965494632721, 0.681034505367279, 0.6928879022598267, 0.6778017282485962, 0.6918103694915771, 0.6896551847457886, 0.6918103694915771, 0.662715494632721, 0.6885775923728943, 0.6928879022598267, 0.6821120977401733, 0.6659482717514038, 0.6842672228813171, 0.693965494632721, 0.693965494632721, 0.693965494632721, 0.6928879022598267, 0.6907327771186829, 0.6853448152542114, 0.6724137663841248, 0.7025862336158752, 0.6885775923728943, 0.6778017282485962, 0.7004310488700867, 0.6928879022598267, 0.7004310488700867, 0.693965494632721, 0.6519396305084229, 0.693965494632721, 0.6971982717514038, 0.6756465435028076, 0.6864224076271057, 0.6875, 0.6788793206214905, 0.6637930870056152, 0.6842672228813171, 0.6875, 0.6788793206214905, 0.693965494632721, 0.6206896305084229, 0.693965494632721, 0.6745689511299133, 0.6918103694915771, 0.6778017282485962, 0.6788793206214905, 0.6853448152542114, 0.6928879022598267, 0.6799569129943848]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 31ms/step - loss: 1.7727 - accuracy: 0.4890 - val_loss: 1.7674 - val_accuracy: 0.4966\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.7651 - accuracy: 0.5547"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 1.7581 - accuracy: 0.5512 - val_loss: 1.7582 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.7445 - accuracy: 0.5722 - val_loss: 1.7492 - val_accuracy: 0.4966\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7318 - accuracy: 0.5976 - val_loss: 1.7401 - val_accuracy: 0.5950\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7179 - accuracy: 0.6163 - val_loss: 1.7309 - val_accuracy: 0.6222\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.7029 - accuracy: 0.6152 - val_loss: 1.7214 - val_accuracy: 0.6527\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6876 - accuracy: 0.6353 - val_loss: 1.7128 - val_accuracy: 0.5385\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6745 - accuracy: 0.6276 - val_loss: 1.7024 - val_accuracy: 0.6018\n","Epoch 9/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6590 - accuracy: 0.6415 - val_loss: 1.6920 - val_accuracy: 0.6222\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6448 - accuracy: 0.6460 - val_loss: 1.6828 - val_accuracy: 0.5667\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6315 - accuracy: 0.6520 - val_loss: 1.6723 - val_accuracy: 0.5781\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6187 - accuracy: 0.6514 - val_loss: 1.6608 - val_accuracy: 0.5916\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6054 - accuracy: 0.6522 - val_loss: 1.6527 - val_accuracy: 0.5735\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5935 - accuracy: 0.6610 - val_loss: 1.6433 - val_accuracy: 0.5645\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5872 - accuracy: 0.6565 - val_loss: 1.6329 - val_accuracy: 0.5747\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5740 - accuracy: 0.6613 - val_loss: 1.6154 - val_accuracy: 0.6097\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5658 - accuracy: 0.6661 - val_loss: 1.6083 - val_accuracy: 0.5905\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5584 - accuracy: 0.6633 - val_loss: 1.6080 - val_accuracy: 0.5724\n","Epoch 19/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5459 - accuracy: 0.6686 - val_loss: 1.5881 - val_accuracy: 0.6018\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5381 - accuracy: 0.6630 - val_loss: 1.5761 - val_accuracy: 0.6097\n","Epoch 21/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.5286 - accuracy: 0.6653 - val_loss: 1.5915 - val_accuracy: 0.5667\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5258 - accuracy: 0.6630 - val_loss: 1.5418 - val_accuracy: 0.6776\n","Epoch 23/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.5121 - accuracy: 0.6749 - val_loss: 1.5505 - val_accuracy: 0.6188\n","Epoch 24/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5049 - accuracy: 0.6667 - val_loss: 1.5427 - val_accuracy: 0.6210\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4989 - accuracy: 0.6698 - val_loss: 1.5253 - val_accuracy: 0.6527\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4920 - accuracy: 0.6698 - val_loss: 1.5066 - val_accuracy: 0.6810\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4795 - accuracy: 0.6743 - val_loss: 1.4974 - val_accuracy: 0.6844\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4739 - accuracy: 0.6766 - val_loss: 1.4890 - val_accuracy: 0.6550\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4695 - accuracy: 0.6732 - val_loss: 1.4864 - val_accuracy: 0.6776\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4583 - accuracy: 0.6754 - val_loss: 1.4776 - val_accuracy: 0.6538\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4557 - accuracy: 0.6678 - val_loss: 1.4677 - val_accuracy: 0.6799\n","Epoch 32/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4542 - accuracy: 0.6667 - val_loss: 1.4693 - val_accuracy: 0.6753\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4376 - accuracy: 0.6831 - val_loss: 1.4531 - val_accuracy: 0.6776\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4307 - accuracy: 0.6828 - val_loss: 1.4530 - val_accuracy: 0.6776\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4245 - accuracy: 0.6817 - val_loss: 1.4402 - val_accuracy: 0.6833\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4157 - accuracy: 0.6856 - val_loss: 1.4367 - val_accuracy: 0.6584\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4082 - accuracy: 0.6805 - val_loss: 1.4278 - val_accuracy: 0.6799\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4023 - accuracy: 0.6856 - val_loss: 1.4219 - val_accuracy: 0.6765\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3960 - accuracy: 0.6836 - val_loss: 1.4158 - val_accuracy: 0.6765\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3934 - accuracy: 0.6865 - val_loss: 1.4165 - val_accuracy: 0.6527\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3824 - accuracy: 0.6870 - val_loss: 1.4077 - val_accuracy: 0.6776\n","Epoch 42/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3763 - accuracy: 0.6865 - val_loss: 1.3973 - val_accuracy: 0.6765\n","Epoch 43/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3693 - accuracy: 0.6868 - val_loss: 1.3964 - val_accuracy: 0.6561\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3645 - accuracy: 0.6876 - val_loss: 1.3854 - val_accuracy: 0.6787\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3568 - accuracy: 0.6882 - val_loss: 1.3804 - val_accuracy: 0.6787\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3517 - accuracy: 0.6961 - val_loss: 1.3733 - val_accuracy: 0.6821\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3427 - accuracy: 0.6879 - val_loss: 1.3680 - val_accuracy: 0.6844\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3353 - accuracy: 0.6989 - val_loss: 1.3649 - val_accuracy: 0.6765\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3331 - accuracy: 0.6853 - val_loss: 1.3590 - val_accuracy: 0.6821\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3260 - accuracy: 0.6930 - val_loss: 1.3512 - val_accuracy: 0.6833\n","Epoch 51/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3174 - accuracy: 0.6944 - val_loss: 1.3479 - val_accuracy: 0.6855\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3115 - accuracy: 0.6995 - val_loss: 1.3413 - val_accuracy: 0.6753\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3042 - accuracy: 0.6969 - val_loss: 1.3385 - val_accuracy: 0.6810\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2993 - accuracy: 0.6984 - val_loss: 1.3325 - val_accuracy: 0.6799\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2934 - accuracy: 0.7001 - val_loss: 1.3256 - val_accuracy: 0.6821\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2885 - accuracy: 0.7037 - val_loss: 1.3218 - val_accuracy: 0.6810\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2827 - accuracy: 0.7001 - val_loss: 1.3142 - val_accuracy: 0.6776\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2740 - accuracy: 0.7040 - val_loss: 1.3122 - val_accuracy: 0.6821\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2701 - accuracy: 0.7057 - val_loss: 1.3033 - val_accuracy: 0.6833\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2630 - accuracy: 0.7071 - val_loss: 1.2977 - val_accuracy: 0.6855\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2608 - accuracy: 0.7071 - val_loss: 1.3074 - val_accuracy: 0.6618\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2583 - accuracy: 0.7001 - val_loss: 1.2904 - val_accuracy: 0.6810\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2468 - accuracy: 0.7057 - val_loss: 1.2893 - val_accuracy: 0.6595\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2446 - accuracy: 0.7029 - val_loss: 1.2801 - val_accuracy: 0.6731\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2323 - accuracy: 0.7145 - val_loss: 1.2798 - val_accuracy: 0.6765\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2298 - accuracy: 0.7134 - val_loss: 1.2686 - val_accuracy: 0.6889\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2210 - accuracy: 0.7151 - val_loss: 1.2651 - val_accuracy: 0.6810\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2149 - accuracy: 0.7201 - val_loss: 1.2599 - val_accuracy: 0.6799\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2126 - accuracy: 0.7153 - val_loss: 1.2549 - val_accuracy: 0.6889\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2048 - accuracy: 0.7176 - val_loss: 1.2505 - val_accuracy: 0.6799\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2025 - accuracy: 0.7207 - val_loss: 1.2465 - val_accuracy: 0.6867\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1933 - accuracy: 0.7199 - val_loss: 1.2450 - val_accuracy: 0.6799\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1873 - accuracy: 0.7235 - val_loss: 1.2405 - val_accuracy: 0.6765\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1822 - accuracy: 0.7230 - val_loss: 1.2364 - val_accuracy: 0.6787\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1759 - accuracy: 0.7235 - val_loss: 1.2289 - val_accuracy: 0.6799\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1714 - accuracy: 0.7227 - val_loss: 1.2273 - val_accuracy: 0.6731\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1650 - accuracy: 0.7292 - val_loss: 1.2207 - val_accuracy: 0.6799\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1645 - accuracy: 0.7216 - val_loss: 1.2158 - val_accuracy: 0.6867\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1538 - accuracy: 0.7346 - val_loss: 1.2121 - val_accuracy: 0.6833\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1476 - accuracy: 0.7247 - val_loss: 1.2080 - val_accuracy: 0.6731\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1451 - accuracy: 0.7337 - val_loss: 1.2119 - val_accuracy: 0.6742\n","Epoch 82/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1406 - accuracy: 0.7298 - val_loss: 1.1995 - val_accuracy: 0.6799\n","Epoch 83/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1356 - accuracy: 0.7269 - val_loss: 1.1986 - val_accuracy: 0.6742\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1271 - accuracy: 0.7397 - val_loss: 1.1951 - val_accuracy: 0.6731\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1263 - accuracy: 0.7334 - val_loss: 1.1883 - val_accuracy: 0.6765\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1232 - accuracy: 0.7312 - val_loss: 1.1850 - val_accuracy: 0.6776\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1107 - accuracy: 0.7391 - val_loss: 1.1828 - val_accuracy: 0.6799\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1062 - accuracy: 0.7380 - val_loss: 1.1772 - val_accuracy: 0.6686\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1014 - accuracy: 0.7394 - val_loss: 1.1736 - val_accuracy: 0.6719\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0933 - accuracy: 0.7439 - val_loss: 1.1834 - val_accuracy: 0.6629\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0965 - accuracy: 0.7315 - val_loss: 1.1954 - val_accuracy: 0.6471\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0932 - accuracy: 0.7400 - val_loss: 1.1692 - val_accuracy: 0.6674\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0830 - accuracy: 0.7436 - val_loss: 1.1600 - val_accuracy: 0.6776\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0736 - accuracy: 0.7493 - val_loss: 1.1560 - val_accuracy: 0.6776\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0697 - accuracy: 0.7476 - val_loss: 1.1607 - val_accuracy: 0.6697\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0661 - accuracy: 0.7535 - val_loss: 1.1583 - val_accuracy: 0.6799\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0625 - accuracy: 0.7493 - val_loss: 1.1479 - val_accuracy: 0.6833\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0551 - accuracy: 0.7581 - val_loss: 1.1485 - val_accuracy: 0.6652\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0467 - accuracy: 0.7550 - val_loss: 1.1424 - val_accuracy: 0.6787\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0428 - accuracy: 0.7566 - val_loss: 1.1393 - val_accuracy: 0.6708\n","{'loss': [1.7727032899856567, 1.7580569982528687, 1.7445427179336548, 1.73183012008667, 1.7178665399551392, 1.7028529644012451, 1.6876225471496582, 1.6744725704193115, 1.658968210220337, 1.6447936296463013, 1.6314802169799805, 1.6186984777450562, 1.6054341793060303, 1.593529462814331, 1.5872259140014648, 1.573999285697937, 1.565847396850586, 1.558447003364563, 1.545940637588501, 1.538061499595642, 1.5285667181015015, 1.5257813930511475, 1.5121387243270874, 1.5049095153808594, 1.498927354812622, 1.4919735193252563, 1.4794806241989136, 1.4738863706588745, 1.4695361852645874, 1.4583156108856201, 1.4557445049285889, 1.4542101621627808, 1.4375584125518799, 1.430724859237671, 1.424489974975586, 1.4156655073165894, 1.4082111120224, 1.4023399353027344, 1.3960065841674805, 1.393373966217041, 1.3824224472045898, 1.3763090372085571, 1.369323968887329, 1.3644508123397827, 1.3567858934402466, 1.3516603708267212, 1.342712640762329, 1.3353121280670166, 1.3331477642059326, 1.3259899616241455, 1.3174492120742798, 1.3115200996398926, 1.304178237915039, 1.2992593050003052, 1.2934151887893677, 1.2884873151779175, 1.2826688289642334, 1.2739509344100952, 1.2700847387313843, 1.2630070447921753, 1.2608122825622559, 1.2583163976669312, 1.2468119859695435, 1.244563102722168, 1.2322779893875122, 1.2297985553741455, 1.2210131883621216, 1.2148691415786743, 1.2125778198242188, 1.2047507762908936, 1.2025399208068848, 1.1933190822601318, 1.1873270273208618, 1.182181715965271, 1.1758813858032227, 1.1714428663253784, 1.1650280952453613, 1.1645413637161255, 1.1538342237472534, 1.147643804550171, 1.1450912952423096, 1.1406068801879883, 1.1356230974197388, 1.127095341682434, 1.1263387203216553, 1.1232273578643799, 1.1106958389282227, 1.1062147617340088, 1.1014049053192139, 1.0932714939117432, 1.0965160131454468, 1.0932495594024658, 1.0829567909240723, 1.0736225843429565, 1.0697481632232666, 1.0661087036132812, 1.062514305114746, 1.0550769567489624, 1.0467240810394287, 1.0428111553192139], 'accuracy': [0.48896434903144836, 0.5512167811393738, 0.5721561908721924, 0.5976231098175049, 0.6162987947463989, 0.615166962146759, 0.6352574825286865, 0.6276174187660217, 0.6414827108383179, 0.646010160446167, 0.6519524455070496, 0.651386559009552, 0.6522354483604431, 0.6610073447227478, 0.6564798951148987, 0.6612903475761414, 0.6661007404327393, 0.6632710695266724, 0.6686474084854126, 0.6629881262779236, 0.6652518510818481, 0.6629881262779236, 0.674872636795044, 0.6666666865348816, 0.6697793006896973, 0.6697793006896973, 0.6743067502975464, 0.676570475101471, 0.6731748580932617, 0.6754385828971863, 0.6677985191345215, 0.6666666865348816, 0.6830786466598511, 0.6827957034111023, 0.6816638112068176, 0.6856253743171692, 0.6805319786071777, 0.6856253743171692, 0.6836445927619934, 0.6864742636680603, 0.6870402097702026, 0.6864742636680603, 0.6867572069168091, 0.6876060962677002, 0.6881720423698425, 0.6960950493812561, 0.6878890991210938, 0.698924720287323, 0.6853423714637756, 0.6929824352264404, 0.6943972706794739, 0.6994906663894653, 0.696943998336792, 0.6983587741851807, 0.7000566124916077, 0.7037351727485657, 0.7000566124916077, 0.7040181159973145, 0.7057158946990967, 0.7071307301521301, 0.7071307301521301, 0.7000566124916077, 0.7057158946990967, 0.7028862237930298, 0.7144878506660461, 0.7133559584617615, 0.7150537371635437, 0.7201471328735352, 0.7153367400169373, 0.7176004648208618, 0.7207130789756775, 0.7198641896247864, 0.7235427498817444, 0.722976803779602, 0.7235427498817444, 0.7226938605308533, 0.7292020320892334, 0.7215619683265686, 0.7345783710479736, 0.7246745824813843, 0.7337294816970825, 0.7297679781913757, 0.7269383072853088, 0.7396717667579651, 0.7334465384483337, 0.7311828136444092, 0.7391058206558228, 0.7379739880561829, 0.7393888235092163, 0.7439162135124207, 0.731465756893158, 0.7399547100067139, 0.7436332702636719, 0.7492926120758057, 0.7475947737693787, 0.7535370588302612, 0.7492926120758057, 0.7580645084381104, 0.7549518942832947, 0.7566496729850769], 'val_loss': [1.7673816680908203, 1.758225679397583, 1.7492314577102661, 1.7401173114776611, 1.7309175729751587, 1.7213808298110962, 1.7127747535705566, 1.7024221420288086, 1.692029356956482, 1.6828101873397827, 1.6723037958145142, 1.660794734954834, 1.6526516675949097, 1.643325924873352, 1.6328665018081665, 1.6154236793518066, 1.6082773208618164, 1.607993245124817, 1.5881291627883911, 1.5761464834213257, 1.5914969444274902, 1.5417782068252563, 1.550463318824768, 1.5427457094192505, 1.525343894958496, 1.5066064596176147, 1.4974071979522705, 1.4889594316482544, 1.4863637685775757, 1.4775954484939575, 1.467663288116455, 1.4693235158920288, 1.4531230926513672, 1.4530092477798462, 1.4402015209197998, 1.4366531372070312, 1.4278478622436523, 1.4218851327896118, 1.4157869815826416, 1.4165468215942383, 1.4077198505401611, 1.397308111190796, 1.396359920501709, 1.385448694229126, 1.3803913593292236, 1.373318076133728, 1.368011474609375, 1.3648656606674194, 1.3589779138565063, 1.3512048721313477, 1.347938060760498, 1.3413443565368652, 1.3384779691696167, 1.3324600458145142, 1.3256114721298218, 1.321842908859253, 1.314200520515442, 1.3122031688690186, 1.303303837776184, 1.2976666688919067, 1.3073852062225342, 1.2903945446014404, 1.2892862558364868, 1.2800546884536743, 1.2798142433166504, 1.268593668937683, 1.2650730609893799, 1.2599337100982666, 1.2549375295639038, 1.250467300415039, 1.2465413808822632, 1.2449781894683838, 1.2405239343643188, 1.236435055732727, 1.2288864850997925, 1.2272700071334839, 1.2207152843475342, 1.2157506942749023, 1.2121204137802124, 1.2079614400863647, 1.2119220495224, 1.199519395828247, 1.1986316442489624, 1.1951249837875366, 1.1882953643798828, 1.1849961280822754, 1.1827749013900757, 1.1771591901779175, 1.1736286878585815, 1.1833884716033936, 1.19539475440979, 1.169203758239746, 1.1600412130355835, 1.156043291091919, 1.1606982946395874, 1.158344030380249, 1.1478910446166992, 1.1485379934310913, 1.1424379348754883, 1.1393120288848877], 'val_accuracy': [0.49660632014274597, 0.4954751133918762, 0.49660632014274597, 0.5950226187705994, 0.622171938419342, 0.6527149081230164, 0.5384615659713745, 0.6018099784851074, 0.622171938419342, 0.5667420625686646, 0.5780543088912964, 0.5916289687156677, 0.5735294222831726, 0.564479649066925, 0.5746606588363647, 0.6097285151481628, 0.5904977321624756, 0.5723981857299805, 0.6018099784851074, 0.6097285151481628, 0.5667420625686646, 0.6776018142700195, 0.6187782883644104, 0.6210407018661499, 0.6527149081230164, 0.6809954643249512, 0.6843891143798828, 0.6549773812294006, 0.6776018142700195, 0.6538461446762085, 0.679864227771759, 0.6753393411636353, 0.6776018142700195, 0.6776018142700195, 0.6832579374313354, 0.6583710312843323, 0.679864227771759, 0.6764705777168274, 0.6764705777168274, 0.6527149081230164, 0.6776018142700195, 0.6764705777168274, 0.6561086177825928, 0.6787330508232117, 0.6787330508232117, 0.6821267008781433, 0.6843891143798828, 0.6764705777168274, 0.6821267008781433, 0.6832579374313354, 0.685520350933075, 0.6753393411636353, 0.6809954643249512, 0.679864227771759, 0.6821267008781433, 0.6809954643249512, 0.6776018142700195, 0.6821267008781433, 0.6832579374313354, 0.685520350933075, 0.6617646813392639, 0.6809954643249512, 0.6595022678375244, 0.6730769276618958, 0.6764705777168274, 0.6889140009880066, 0.6809954643249512, 0.679864227771759, 0.6889140009880066, 0.679864227771759, 0.6866515874862671, 0.679864227771759, 0.6764705777168274, 0.6787330508232117, 0.679864227771759, 0.6730769276618958, 0.679864227771759, 0.6866515874862671, 0.6832579374313354, 0.6730769276618958, 0.6742081642150879, 0.679864227771759, 0.6742081642150879, 0.6730769276618958, 0.6764705777168274, 0.6776018142700195, 0.679864227771759, 0.668552041053772, 0.6719456911087036, 0.662895917892456, 0.6470588445663452, 0.6674208045005798, 0.6776018142700195, 0.6776018142700195, 0.6696832776069641, 0.679864227771759, 0.6832579374313354, 0.6651583909988403, 0.6787330508232117, 0.6708144545555115]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 72ms/step - loss: 1.7709 - accuracy: 0.4948 - val_loss: 1.7664 - val_accuracy: 0.4855\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 19ms/step - loss: 1.7537 - accuracy: 0.5866 - val_loss: 1.7564 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7363 - accuracy: 0.5961 - val_loss: 1.7463 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.7202 - accuracy: 0.6220 - val_loss: 1.7360 - val_accuracy: 0.5424\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.7050 - accuracy: 0.6140 - val_loss: 1.7255 - val_accuracy: 0.6085\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6871 - accuracy: 0.6537 - val_loss: 1.7149 - val_accuracy: 0.6229\n","Epoch 7/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6694 - accuracy: 0.6618 - val_loss: 1.7039 - val_accuracy: 0.6219\n","Epoch 8/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6525 - accuracy: 0.6612 - val_loss: 1.6925 - val_accuracy: 0.6085\n","Epoch 9/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6403 - accuracy: 0.6587 - val_loss: 1.6846 - val_accuracy: 0.5279\n","Epoch 10/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6275 - accuracy: 0.6527 - val_loss: 1.6694 - val_accuracy: 0.6064\n","Epoch 11/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6086 - accuracy: 0.6589 - val_loss: 1.6593 - val_accuracy: 0.5702\n","Epoch 12/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.5957 - accuracy: 0.6698 - val_loss: 1.6482 - val_accuracy: 0.5682\n","Epoch 13/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5833 - accuracy: 0.6742 - val_loss: 1.6335 - val_accuracy: 0.6105\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5713 - accuracy: 0.6705 - val_loss: 1.6153 - val_accuracy: 0.6446\n","Epoch 15/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.5631 - accuracy: 0.6713 - val_loss: 1.6077 - val_accuracy: 0.6157\n","Epoch 16/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.5512 - accuracy: 0.6716 - val_loss: 1.5905 - val_accuracy: 0.6353\n","Epoch 17/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5413 - accuracy: 0.6726 - val_loss: 1.5851 - val_accuracy: 0.6157\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.5296 - accuracy: 0.6742 - val_loss: 1.5679 - val_accuracy: 0.6374\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5197 - accuracy: 0.6793 - val_loss: 1.5529 - val_accuracy: 0.6457\n","Epoch 20/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5102 - accuracy: 0.6775 - val_loss: 1.5472 - val_accuracy: 0.6415\n","Epoch 21/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5026 - accuracy: 0.6767 - val_loss: 1.5288 - val_accuracy: 0.6312\n","Epoch 22/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5007 - accuracy: 0.6729 - val_loss: 1.5340 - val_accuracy: 0.6405\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4860 - accuracy: 0.6786 - val_loss: 1.5088 - val_accuracy: 0.6426\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4813 - accuracy: 0.6693 - val_loss: 1.5003 - val_accuracy: 0.6477\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4687 - accuracy: 0.6835 - val_loss: 1.5076 - val_accuracy: 0.6508\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4590 - accuracy: 0.6897 - val_loss: 1.4986 - val_accuracy: 0.6519\n","Epoch 27/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4544 - accuracy: 0.6824 - val_loss: 1.4782 - val_accuracy: 0.6477\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4435 - accuracy: 0.6848 - val_loss: 1.4750 - val_accuracy: 0.6353\n","Epoch 29/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.4365 - accuracy: 0.6866 - val_loss: 1.4696 - val_accuracy: 0.6612\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4332 - accuracy: 0.6822 - val_loss: 1.4577 - val_accuracy: 0.6477\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4270 - accuracy: 0.6827 - val_loss: 1.4621 - val_accuracy: 0.6581\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4132 - accuracy: 0.6889 - val_loss: 1.4464 - val_accuracy: 0.6632\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4069 - accuracy: 0.6928 - val_loss: 1.4370 - val_accuracy: 0.6498\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3987 - accuracy: 0.6907 - val_loss: 1.4316 - val_accuracy: 0.6498\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3917 - accuracy: 0.6902 - val_loss: 1.4317 - val_accuracy: 0.6601\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3914 - accuracy: 0.6866 - val_loss: 1.4197 - val_accuracy: 0.6353\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3763 - accuracy: 0.6917 - val_loss: 1.4122 - val_accuracy: 0.6426\n","Epoch 38/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3701 - accuracy: 0.6928 - val_loss: 1.4148 - val_accuracy: 0.6302\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3624 - accuracy: 0.6953 - val_loss: 1.3987 - val_accuracy: 0.6477\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3562 - accuracy: 0.7000 - val_loss: 1.3995 - val_accuracy: 0.6653\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3501 - accuracy: 0.6979 - val_loss: 1.3867 - val_accuracy: 0.6477\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3404 - accuracy: 0.6995 - val_loss: 1.3834 - val_accuracy: 0.6570\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3358 - accuracy: 0.7008 - val_loss: 1.3747 - val_accuracy: 0.6508\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3286 - accuracy: 0.6951 - val_loss: 1.3707 - val_accuracy: 0.6353\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3216 - accuracy: 0.6959 - val_loss: 1.3649 - val_accuracy: 0.6384\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3179 - accuracy: 0.6984 - val_loss: 1.3592 - val_accuracy: 0.6364\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3095 - accuracy: 0.7041 - val_loss: 1.3526 - val_accuracy: 0.6426\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3077 - accuracy: 0.6941 - val_loss: 1.3464 - val_accuracy: 0.6477\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2986 - accuracy: 0.6948 - val_loss: 1.3396 - val_accuracy: 0.6467\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2903 - accuracy: 0.7003 - val_loss: 1.3339 - val_accuracy: 0.6446\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2814 - accuracy: 0.7054 - val_loss: 1.3281 - val_accuracy: 0.6508\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2758 - accuracy: 0.7044 - val_loss: 1.3231 - val_accuracy: 0.6519\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2688 - accuracy: 0.7088 - val_loss: 1.3175 - val_accuracy: 0.6508\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2645 - accuracy: 0.7103 - val_loss: 1.3123 - val_accuracy: 0.6498\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2618 - accuracy: 0.7039 - val_loss: 1.3101 - val_accuracy: 0.6550\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2508 - accuracy: 0.7052 - val_loss: 1.3128 - val_accuracy: 0.6250\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2462 - accuracy: 0.7083 - val_loss: 1.2971 - val_accuracy: 0.6488\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2408 - accuracy: 0.7098 - val_loss: 1.2954 - val_accuracy: 0.6364\n","Epoch 59/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2349 - accuracy: 0.7008 - val_loss: 1.2856 - val_accuracy: 0.6519\n","Epoch 60/100\n","31/31 [==============================] - 1s 41ms/step - loss: 1.2252 - accuracy: 0.7137 - val_loss: 1.2969 - val_accuracy: 0.6291\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2297 - accuracy: 0.7000 - val_loss: 1.2878 - val_accuracy: 0.6209\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2203 - accuracy: 0.7054 - val_loss: 1.2748 - val_accuracy: 0.6405\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2191 - accuracy: 0.7003 - val_loss: 1.2657 - val_accuracy: 0.6529\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2041 - accuracy: 0.7134 - val_loss: 1.2672 - val_accuracy: 0.6550\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1987 - accuracy: 0.7163 - val_loss: 1.2627 - val_accuracy: 0.6312\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1944 - accuracy: 0.7163 - val_loss: 1.2711 - val_accuracy: 0.6291\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1890 - accuracy: 0.7129 - val_loss: 1.2494 - val_accuracy: 0.6488\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1805 - accuracy: 0.7178 - val_loss: 1.2427 - val_accuracy: 0.6550\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1742 - accuracy: 0.7207 - val_loss: 1.2410 - val_accuracy: 0.6498\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1731 - accuracy: 0.7186 - val_loss: 1.2377 - val_accuracy: 0.6384\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1645 - accuracy: 0.7173 - val_loss: 1.2299 - val_accuracy: 0.6488\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1578 - accuracy: 0.7199 - val_loss: 1.2248 - val_accuracy: 0.6519\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1528 - accuracy: 0.7253 - val_loss: 1.2222 - val_accuracy: 0.6560\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1475 - accuracy: 0.7248 - val_loss: 1.2272 - val_accuracy: 0.6333\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1443 - accuracy: 0.7204 - val_loss: 1.2146 - val_accuracy: 0.6467\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1362 - accuracy: 0.7233 - val_loss: 1.2095 - val_accuracy: 0.6477\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1302 - accuracy: 0.7315 - val_loss: 1.2052 - val_accuracy: 0.6415\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1270 - accuracy: 0.7256 - val_loss: 1.2044 - val_accuracy: 0.6415\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1192 - accuracy: 0.7328 - val_loss: 1.1970 - val_accuracy: 0.6498\n","Epoch 80/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1158 - accuracy: 0.7287 - val_loss: 1.1939 - val_accuracy: 0.6477\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1093 - accuracy: 0.7295 - val_loss: 1.1921 - val_accuracy: 0.6426\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1056 - accuracy: 0.7362 - val_loss: 1.2009 - val_accuracy: 0.6415\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1029 - accuracy: 0.7302 - val_loss: 1.1817 - val_accuracy: 0.6622\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0932 - accuracy: 0.7344 - val_loss: 1.1916 - val_accuracy: 0.6550\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0967 - accuracy: 0.7269 - val_loss: 1.1728 - val_accuracy: 0.6488\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0832 - accuracy: 0.7364 - val_loss: 1.1707 - val_accuracy: 0.6570\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0823 - accuracy: 0.7351 - val_loss: 1.1880 - val_accuracy: 0.6508\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0808 - accuracy: 0.7300 - val_loss: 1.1634 - val_accuracy: 0.6488\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0723 - accuracy: 0.7377 - val_loss: 1.1631 - val_accuracy: 0.6426\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0677 - accuracy: 0.7346 - val_loss: 1.1832 - val_accuracy: 0.6333\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0671 - accuracy: 0.7297 - val_loss: 1.1652 - val_accuracy: 0.6426\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0554 - accuracy: 0.7473 - val_loss: 1.1675 - val_accuracy: 0.6415\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0488 - accuracy: 0.7491 - val_loss: 1.1562 - val_accuracy: 0.6395\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0443 - accuracy: 0.7426 - val_loss: 1.1434 - val_accuracy: 0.6529\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0541 - accuracy: 0.7305 - val_loss: 1.1655 - val_accuracy: 0.6488\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0358 - accuracy: 0.7457 - val_loss: 1.1370 - val_accuracy: 0.6508\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0284 - accuracy: 0.7460 - val_loss: 1.1406 - val_accuracy: 0.6405\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0306 - accuracy: 0.7434 - val_loss: 1.1421 - val_accuracy: 0.6581\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0211 - accuracy: 0.7481 - val_loss: 1.1387 - val_accuracy: 0.6436\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0151 - accuracy: 0.7499 - val_loss: 1.1260 - val_accuracy: 0.6591\n","{'loss': [1.7708606719970703, 1.7536953687667847, 1.736312747001648, 1.7201666831970215, 1.70499587059021, 1.6870653629302979, 1.6694296598434448, 1.6525429487228394, 1.6402605772018433, 1.6275174617767334, 1.6086243391036987, 1.5957280397415161, 1.5832867622375488, 1.5713165998458862, 1.5630502700805664, 1.551233172416687, 1.5413237810134888, 1.5296399593353271, 1.5196869373321533, 1.5102025270462036, 1.5025750398635864, 1.5006928443908691, 1.4860161542892456, 1.4812629222869873, 1.468706727027893, 1.4590171575546265, 1.454351544380188, 1.443462610244751, 1.4365057945251465, 1.433241367340088, 1.4270392656326294, 1.413210391998291, 1.4068794250488281, 1.3986883163452148, 1.3916774988174438, 1.39137864112854, 1.3762840032577515, 1.3701083660125732, 1.3624391555786133, 1.3562374114990234, 1.3501007556915283, 1.3404489755630493, 1.3358120918273926, 1.3285835981369019, 1.3215607404708862, 1.3179458379745483, 1.3095171451568604, 1.3077194690704346, 1.298582673072815, 1.290293574333191, 1.2813732624053955, 1.275763750076294, 1.2688148021697998, 1.264452576637268, 1.261759877204895, 1.2508474588394165, 1.2461645603179932, 1.2408277988433838, 1.234909176826477, 1.2252275943756104, 1.2296645641326904, 1.220320463180542, 1.2191064357757568, 1.2040945291519165, 1.1986591815948486, 1.1944154500961304, 1.1889933347702026, 1.1804754734039307, 1.1741927862167358, 1.17305588722229, 1.1645134687423706, 1.1577550172805786, 1.1528130769729614, 1.1475367546081543, 1.1442937850952148, 1.1361510753631592, 1.130179524421692, 1.1270370483398438, 1.1192330121994019, 1.1158032417297363, 1.109289526939392, 1.1055731773376465, 1.1029350757598877, 1.0931614637374878, 1.0966500043869019, 1.0832200050354004, 1.0822564363479614, 1.0808106660842896, 1.0723456144332886, 1.0676923990249634, 1.0671173334121704, 1.0554487705230713, 1.0487852096557617, 1.0443118810653687, 1.0540661811828613, 1.0358471870422363, 1.0284194946289062, 1.03060781955719, 1.021066665649414, 1.0151119232177734], 'accuracy': [0.49483203887939453, 0.5865632891654968, 0.5961240530014038, 0.6219637989997864, 0.6139534711837769, 0.6537467837333679, 0.6617571115493774, 0.6612403392791748, 0.6586563587188721, 0.6527131795883179, 0.6589147448539734, 0.669767439365387, 0.6741601824760437, 0.6705426573753357, 0.6713178157806396, 0.671576201915741, 0.672609806060791, 0.6741601824760437, 0.6793281435966492, 0.6775193810462952, 0.6767441630363464, 0.6728681921958923, 0.6785529851913452, 0.6692506670951843, 0.6834625601768494, 0.6896640658378601, 0.6824289560317993, 0.6847545504570007, 0.6865633130073547, 0.682170569896698, 0.6826873421669006, 0.6888889074325562, 0.6927648782730103, 0.6906976699829102, 0.6901808977127075, 0.6865633130073547, 0.6917312741279602, 0.6927648782730103, 0.695348858833313, 0.699999988079071, 0.6979328393936157, 0.6994832158088684, 0.7007752060890198, 0.6950904130935669, 0.6958656311035156, 0.6984496116638184, 0.7041343450546265, 0.6940568685531616, 0.6948320269584656, 0.7002583742141724, 0.7054263353347778, 0.7043927907943726, 0.7087855339050293, 0.710335910320282, 0.7038759589195251, 0.7051679491996765, 0.7082687616348267, 0.7098191380500793, 0.7007752060890198, 0.7136951088905334, 0.699999988079071, 0.7054263353347778, 0.7002583742141724, 0.7134366631507874, 0.7162790894508362, 0.7162790894508362, 0.7129198908805847, 0.7178294658660889, 0.7206718325614929, 0.7186046242713928, 0.7173126339912415, 0.7198966145515442, 0.7253230214118958, 0.7248061895370483, 0.7204134464263916, 0.7232558131217957, 0.7315245270729065, 0.7255814075469971, 0.7328165173530579, 0.7286821603775024, 0.7294573783874512, 0.7361757159233093, 0.7302325367927551, 0.7343669533729553, 0.7268733978271484, 0.7364341020584106, 0.7351421117782593, 0.7299741506576538, 0.737726092338562, 0.7346253395080566, 0.7297157645225525, 0.7472867965698242, 0.749095618724823, 0.7426356673240662, 0.7304909825325012, 0.7457364201545715, 0.7459948062896729, 0.7434108257293701, 0.748062014579773, 0.749870777130127], 'val_loss': [1.7664395570755005, 1.7563730478286743, 1.7462676763534546, 1.7359669208526611, 1.7255287170410156, 1.7148795127868652, 1.7038990259170532, 1.6925112009048462, 1.6845701932907104, 1.6693788766860962, 1.6593005657196045, 1.648209810256958, 1.6335488557815552, 1.6153303384780884, 1.607665777206421, 1.5905283689498901, 1.585144281387329, 1.5679056644439697, 1.5528920888900757, 1.5472302436828613, 1.5287611484527588, 1.5340189933776855, 1.5087532997131348, 1.5003412961959839, 1.5075809955596924, 1.4986258745193481, 1.4782236814498901, 1.4749857187271118, 1.4696286916732788, 1.457651138305664, 1.4620646238327026, 1.446412444114685, 1.4369704723358154, 1.4315998554229736, 1.4317045211791992, 1.4196590185165405, 1.4122306108474731, 1.414778709411621, 1.3987056016921997, 1.3995249271392822, 1.386680006980896, 1.3833659887313843, 1.3746591806411743, 1.370747447013855, 1.364885926246643, 1.359212040901184, 1.3526009321212769, 1.3464490175247192, 1.3395622968673706, 1.3338537216186523, 1.3280940055847168, 1.3230706453323364, 1.3174971342086792, 1.312288761138916, 1.310066819190979, 1.312796950340271, 1.2970725297927856, 1.295405626296997, 1.2856230735778809, 1.2968803644180298, 1.287760615348816, 1.2748098373413086, 1.2656885385513306, 1.2671546936035156, 1.2626837491989136, 1.271071195602417, 1.249436616897583, 1.2426557540893555, 1.2409902811050415, 1.2376738786697388, 1.229935646057129, 1.2247720956802368, 1.2221693992614746, 1.2272167205810547, 1.2146188020706177, 1.2094782590866089, 1.2051867246627808, 1.2044000625610352, 1.196995496749878, 1.1938663721084595, 1.1920689344406128, 1.200890064239502, 1.1817134618759155, 1.1916214227676392, 1.172813892364502, 1.1707345247268677, 1.18798828125, 1.1633731126785278, 1.1630507707595825, 1.1831841468811035, 1.16521155834198, 1.167511224746704, 1.156173825263977, 1.143418312072754, 1.1655058860778809, 1.1369752883911133, 1.140599250793457, 1.142113208770752, 1.138663411140442, 1.126049518585205], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5423553586006165, 0.6084710955619812, 0.6229338645935059, 0.6219007968902588, 0.6084710955619812, 0.5278925895690918, 0.6064049601554871, 0.5702479481697083, 0.5681818127632141, 0.6105371713638306, 0.64462810754776, 0.6157024502754211, 0.6353305578231812, 0.6157024502754211, 0.6373966932296753, 0.6456611752510071, 0.6415289044380188, 0.6311983466148376, 0.6404958963394165, 0.6425619721412659, 0.6477272510528564, 0.6508264541625977, 0.6518595218658447, 0.6477272510528564, 0.6353305578231812, 0.6611570119857788, 0.6477272510528564, 0.6580578684806824, 0.663223147392273, 0.6497933864593506, 0.6497933864593506, 0.6601239442825317, 0.6353305578231812, 0.6425619721412659, 0.6301652789115906, 0.6477272510528564, 0.6652892827987671, 0.6477272510528564, 0.6570248007774353, 0.6508264541625977, 0.6353305578231812, 0.6384297609329224, 0.6363636255264282, 0.6425619721412659, 0.6477272510528564, 0.6466942429542542, 0.64462810754776, 0.6508264541625977, 0.6518595218658447, 0.6508264541625977, 0.6497933864593506, 0.6549586653709412, 0.625, 0.6487603187561035, 0.6363636255264282, 0.6518595218658447, 0.6291322112083435, 0.6208677887916565, 0.6404958963394165, 0.6528925895690918, 0.6549586653709412, 0.6311983466148376, 0.6291322112083435, 0.6487603187561035, 0.6549586653709412, 0.6497933864593506, 0.6384297609329224, 0.6487603187561035, 0.6518595218658447, 0.6559917330741882, 0.6332644820213318, 0.6466942429542542, 0.6477272510528564, 0.6415289044380188, 0.6415289044380188, 0.6497933864593506, 0.6477272510528564, 0.6425619721412659, 0.6415289044380188, 0.6621900796890259, 0.6549586653709412, 0.6487603187561035, 0.6570248007774353, 0.6508264541625977, 0.6487603187561035, 0.6425619721412659, 0.6332644820213318, 0.6425619721412659, 0.6415289044380188, 0.6394628286361694, 0.6528925895690918, 0.6487603187561035, 0.6508264541625977, 0.6404958963394165, 0.6580578684806824, 0.6435950398445129, 0.6590909361839294]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 27ms/step - loss: 1.0933 - accuracy: 0.6991 - val_loss: 1.1996 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.0587 - accuracy: 0.7109"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 18ms/step - loss: 1.0828 - accuracy: 0.6988 - val_loss: 1.1942 - val_accuracy: 0.4892\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0670 - accuracy: 0.7190 - val_loss: 1.1859 - val_accuracy: 0.5819\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0595 - accuracy: 0.7276 - val_loss: 1.1790 - val_accuracy: 0.6821\n","Epoch 5/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0511 - accuracy: 0.7301 - val_loss: 1.1732 - val_accuracy: 0.6487\n","Epoch 6/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0475 - accuracy: 0.7258 - val_loss: 1.1675 - val_accuracy: 0.6261\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0401 - accuracy: 0.7271 - val_loss: 1.1621 - val_accuracy: 0.6002\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0326 - accuracy: 0.7287 - val_loss: 1.1555 - val_accuracy: 0.6034\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0269 - accuracy: 0.7381 - val_loss: 1.1519 - val_accuracy: 0.5787\n","Epoch 10/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0235 - accuracy: 0.7338 - val_loss: 1.1536 - val_accuracy: 0.5431\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0175 - accuracy: 0.7433 - val_loss: 1.1482 - val_accuracy: 0.5485\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0110 - accuracy: 0.7376 - val_loss: 1.1411 - val_accuracy: 0.5571\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0042 - accuracy: 0.7438 - val_loss: 1.1355 - val_accuracy: 0.5679\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0019 - accuracy: 0.7381 - val_loss: 1.1289 - val_accuracy: 0.5776\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9939 - accuracy: 0.7527 - val_loss: 1.1302 - val_accuracy: 0.5690\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9878 - accuracy: 0.7500 - val_loss: 1.1196 - val_accuracy: 0.5830\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9886 - accuracy: 0.7395 - val_loss: 1.0926 - val_accuracy: 0.6444\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9886 - accuracy: 0.7368 - val_loss: 1.1447 - val_accuracy: 0.5625\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9853 - accuracy: 0.7373 - val_loss: 1.0765 - val_accuracy: 0.6530\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9691 - accuracy: 0.7530 - val_loss: 1.0805 - val_accuracy: 0.6455\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9641 - accuracy: 0.7559 - val_loss: 1.0705 - val_accuracy: 0.6573\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9584 - accuracy: 0.7594 - val_loss: 1.0701 - val_accuracy: 0.6584\n","Epoch 23/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9548 - accuracy: 0.7578 - val_loss: 1.0397 - val_accuracy: 0.6789\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9518 - accuracy: 0.7551 - val_loss: 1.0243 - val_accuracy: 0.7015\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9441 - accuracy: 0.7624 - val_loss: 1.0399 - val_accuracy: 0.6821\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9410 - accuracy: 0.7637 - val_loss: 1.0168 - val_accuracy: 0.7058\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9370 - accuracy: 0.7589 - val_loss: 1.0140 - val_accuracy: 0.7037\n","Epoch 28/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9346 - accuracy: 0.7597 - val_loss: 1.0133 - val_accuracy: 0.6994\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9285 - accuracy: 0.7624 - val_loss: 1.0071 - val_accuracy: 0.7015\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9253 - accuracy: 0.7616 - val_loss: 1.0059 - val_accuracy: 0.7047\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9211 - accuracy: 0.7659 - val_loss: 1.0036 - val_accuracy: 0.7047\n","Epoch 32/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9151 - accuracy: 0.7670 - val_loss: 1.0010 - val_accuracy: 0.7047\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9127 - accuracy: 0.7621 - val_loss: 1.0003 - val_accuracy: 0.7091\n","Epoch 34/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9066 - accuracy: 0.7737 - val_loss: 1.0006 - val_accuracy: 0.7047\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9041 - accuracy: 0.7729 - val_loss: 0.9984 - val_accuracy: 0.7037\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9017 - accuracy: 0.7675 - val_loss: 0.9952 - val_accuracy: 0.7037\n","Epoch 37/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8965 - accuracy: 0.7756 - val_loss: 0.9988 - val_accuracy: 0.6972\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8937 - accuracy: 0.7659 - val_loss: 1.0031 - val_accuracy: 0.6907\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8864 - accuracy: 0.7759 - val_loss: 0.9927 - val_accuracy: 0.7026\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8766 - accuracy: 0.7853 - val_loss: 0.9870 - val_accuracy: 0.7058\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8739 - accuracy: 0.7812 - val_loss: 0.9950 - val_accuracy: 0.6918\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8727 - accuracy: 0.7775 - val_loss: 0.9850 - val_accuracy: 0.7004\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8737 - accuracy: 0.7761 - val_loss: 0.9956 - val_accuracy: 0.6961\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8662 - accuracy: 0.7821 - val_loss: 0.9850 - val_accuracy: 0.7037\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8615 - accuracy: 0.7861 - val_loss: 0.9819 - val_accuracy: 0.7004\n","Epoch 46/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8594 - accuracy: 0.7874 - val_loss: 1.0027 - val_accuracy: 0.6821\n","Epoch 47/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8635 - accuracy: 0.7753 - val_loss: 0.9919 - val_accuracy: 0.6864\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8477 - accuracy: 0.7923 - val_loss: 0.9829 - val_accuracy: 0.7004\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8413 - accuracy: 0.7923 - val_loss: 0.9857 - val_accuracy: 0.6961\n","Epoch 50/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8432 - accuracy: 0.7912 - val_loss: 0.9812 - val_accuracy: 0.6961\n","Epoch 51/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8489 - accuracy: 0.7788 - val_loss: 0.9927 - val_accuracy: 0.7015\n","Epoch 52/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8300 - accuracy: 0.7977 - val_loss: 0.9906 - val_accuracy: 0.6853\n","Epoch 53/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8290 - accuracy: 0.7936 - val_loss: 0.9751 - val_accuracy: 0.7015\n","Epoch 54/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8271 - accuracy: 0.7977 - val_loss: 0.9790 - val_accuracy: 0.6994\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8193 - accuracy: 0.8055 - val_loss: 0.9823 - val_accuracy: 0.7026\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8171 - accuracy: 0.8017 - val_loss: 0.9711 - val_accuracy: 0.6994\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8146 - accuracy: 0.8063 - val_loss: 0.9909 - val_accuracy: 0.6767\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8118 - accuracy: 0.7980 - val_loss: 0.9713 - val_accuracy: 0.6961\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8038 - accuracy: 0.8101 - val_loss: 0.9787 - val_accuracy: 0.6897\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8027 - accuracy: 0.8074 - val_loss: 0.9689 - val_accuracy: 0.6972\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7977 - accuracy: 0.8050 - val_loss: 0.9726 - val_accuracy: 0.6929\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7929 - accuracy: 0.8103 - val_loss: 1.0007 - val_accuracy: 0.6638\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7992 - accuracy: 0.8020 - val_loss: 0.9701 - val_accuracy: 0.6950\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7850 - accuracy: 0.8149 - val_loss: 0.9938 - val_accuracy: 0.6670\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7874 - accuracy: 0.8087 - val_loss: 0.9992 - val_accuracy: 0.6703\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7793 - accuracy: 0.8184 - val_loss: 0.9876 - val_accuracy: 0.6789\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7760 - accuracy: 0.8187 - val_loss: 0.9802 - val_accuracy: 0.6864\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7725 - accuracy: 0.8225 - val_loss: 0.9691 - val_accuracy: 0.6994\n","Epoch 69/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7719 - accuracy: 0.8152 - val_loss: 0.9699 - val_accuracy: 0.6907\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7677 - accuracy: 0.8163 - val_loss: 0.9718 - val_accuracy: 0.6886\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7620 - accuracy: 0.8311 - val_loss: 0.9689 - val_accuracy: 0.7015\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7575 - accuracy: 0.8260 - val_loss: 0.9988 - val_accuracy: 0.6692\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7557 - accuracy: 0.8265 - val_loss: 0.9711 - val_accuracy: 0.6843\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7465 - accuracy: 0.8314 - val_loss: 0.9702 - val_accuracy: 0.6821\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7457 - accuracy: 0.8284 - val_loss: 0.9864 - val_accuracy: 0.6918\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7465 - accuracy: 0.8238 - val_loss: 0.9721 - val_accuracy: 0.6800\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7360 - accuracy: 0.8373 - val_loss: 0.9986 - val_accuracy: 0.6681\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7456 - accuracy: 0.8203 - val_loss: 0.9726 - val_accuracy: 0.6994\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7359 - accuracy: 0.8300 - val_loss: 0.9795 - val_accuracy: 0.6983\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7293 - accuracy: 0.8392 - val_loss: 0.9903 - val_accuracy: 0.6746\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7269 - accuracy: 0.8273 - val_loss: 0.9998 - val_accuracy: 0.6670\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7314 - accuracy: 0.8316 - val_loss: 0.9696 - val_accuracy: 0.6875\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7176 - accuracy: 0.8378 - val_loss: 0.9736 - val_accuracy: 0.6918\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7264 - accuracy: 0.8316 - val_loss: 0.9925 - val_accuracy: 0.6703\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7197 - accuracy: 0.8338 - val_loss: 0.9772 - val_accuracy: 0.6929\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7195 - accuracy: 0.8359 - val_loss: 0.9734 - val_accuracy: 0.6821\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7075 - accuracy: 0.8419 - val_loss: 0.9762 - val_accuracy: 0.6800\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7279 - accuracy: 0.8241 - val_loss: 0.9754 - val_accuracy: 0.6950\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7025 - accuracy: 0.8473 - val_loss: 0.9744 - val_accuracy: 0.6886\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6984 - accuracy: 0.8478 - val_loss: 1.0081 - val_accuracy: 0.6519\n","Epoch 91/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6994 - accuracy: 0.8448 - val_loss: 0.9734 - val_accuracy: 0.6972\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6922 - accuracy: 0.8572 - val_loss: 1.0012 - val_accuracy: 0.6627\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6878 - accuracy: 0.8524 - val_loss: 0.9847 - val_accuracy: 0.6767\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6872 - accuracy: 0.8513 - val_loss: 0.9762 - val_accuracy: 0.6843\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.8543 - val_loss: 0.9827 - val_accuracy: 0.6692\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6770 - accuracy: 0.8583 - val_loss: 1.0081 - val_accuracy: 0.6562\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6886 - accuracy: 0.8419 - val_loss: 0.9756 - val_accuracy: 0.6918\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6727 - accuracy: 0.8580 - val_loss: 0.9903 - val_accuracy: 0.6897\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6876 - accuracy: 0.8400 - val_loss: 0.9935 - val_accuracy: 0.6713\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6679 - accuracy: 0.8610 - val_loss: 0.9812 - val_accuracy: 0.6789\n","{'loss': [1.0933244228363037, 1.0827958583831787, 1.0670075416564941, 1.0595322847366333, 1.0510910749435425, 1.0474525690078735, 1.0401421785354614, 1.0326416492462158, 1.0268707275390625, 1.0234535932540894, 1.0175307989120483, 1.010980486869812, 1.0041673183441162, 1.0018646717071533, 0.9939243197441101, 0.9878374338150024, 0.9886356592178345, 0.9886460304260254, 0.9852543473243713, 0.9690574407577515, 0.9640863537788391, 0.9583601951599121, 0.9547837376594543, 0.951779305934906, 0.9440510272979736, 0.9409619569778442, 0.9370010495185852, 0.9346123337745667, 0.928483784198761, 0.9253085851669312, 0.9211271405220032, 0.9150524735450745, 0.9127449989318848, 0.9065718650817871, 0.9040611982345581, 0.9017195701599121, 0.8965088129043579, 0.8936900496482849, 0.8864331841468811, 0.8766244649887085, 0.8738601803779602, 0.8727310299873352, 0.873714029788971, 0.866176962852478, 0.8615008592605591, 0.8594039678573608, 0.8634957075119019, 0.8476547598838806, 0.8412603735923767, 0.8432037234306335, 0.8488814830780029, 0.8299829959869385, 0.8289995789527893, 0.8271183371543884, 0.8193097710609436, 0.8170652985572815, 0.8145603537559509, 0.8118299245834351, 0.8038031458854675, 0.8027095794677734, 0.7976766228675842, 0.7929025888442993, 0.7991873621940613, 0.785038411617279, 0.787415623664856, 0.7793095111846924, 0.7759763598442078, 0.7725385427474976, 0.771918773651123, 0.7677230834960938, 0.7619972229003906, 0.7575069069862366, 0.7557151317596436, 0.7465487718582153, 0.7456886768341064, 0.7464984655380249, 0.7360364198684692, 0.7455543875694275, 0.7359114289283752, 0.729302167892456, 0.726924479007721, 0.7313651442527771, 0.7175665497779846, 0.7263546586036682, 0.7197450995445251, 0.7194949388504028, 0.7074862718582153, 0.7278995513916016, 0.7024823427200317, 0.6984293460845947, 0.6994441747665405, 0.692227840423584, 0.6877769231796265, 0.6872110962867737, 0.6803924441337585, 0.6769790053367615, 0.6886414885520935, 0.6727383732795715, 0.6875910758972168, 0.6679481863975525], 'accuracy': [0.6990840435028076, 0.6988146305084229, 0.7190194129943848, 0.7276400923728943, 0.7300646305084229, 0.7257543206214905, 0.7271012663841248, 0.7287176847457886, 0.7381465435028076, 0.7338362336158752, 0.7432650923728943, 0.7376077771186829, 0.743803858757019, 0.7381465435028076, 0.7526939511299133, 0.75, 0.7394935488700867, 0.7367995977401733, 0.7373383641242981, 0.7529633641242981, 0.7559267282485962, 0.759428858757019, 0.7578125, 0.7551185488700867, 0.7623922228813171, 0.7637392282485962, 0.7588900923728943, 0.7596982717514038, 0.7623922228813171, 0.7615840435028076, 0.7658944129943848, 0.766972005367279, 0.7621228694915771, 0.7737069129943848, 0.7728987336158752, 0.7675107717514038, 0.7755926847457886, 0.7658944129943848, 0.7758620977401733, 0.7852909564971924, 0.78125, 0.7774784564971924, 0.7761314511299133, 0.7820581793785095, 0.7860991358757019, 0.787446141242981, 0.7753232717514038, 0.7922952771186829, 0.7922952771186829, 0.7912176847457886, 0.7788254022598267, 0.7976831793785095, 0.7936422228813171, 0.7976831793785095, 0.8054956793785095, 0.8017241358757019, 0.806303858757019, 0.7979525923728943, 0.8100754022598267, 0.8073814511299133, 0.8049569129943848, 0.8103448152542114, 0.8019935488700867, 0.8149245977401733, 0.8087284564971924, 0.8184267282485962, 0.818696141242981, 0.8224676847457886, 0.8151939511299133, 0.8162715435028076, 0.8310883641242981, 0.8259698152542114, 0.826508641242981, 0.8313577771186829, 0.8283944129943848, 0.8238146305084229, 0.837284505367279, 0.8203125, 0.8300107717514038, 0.8391702771186829, 0.8273168206214905, 0.8316271305084229, 0.8378232717514038, 0.8316271305084229, 0.8337823152542114, 0.8359375, 0.8418642282485962, 0.8240840435028076, 0.8472521305084229, 0.8477909564971924, 0.8448275923728943, 0.8572198152542114, 0.8523706793785095, 0.8512930870056152, 0.8542564511299133, 0.8582974076271057, 0.8418642282485962, 0.858027994632721, 0.8399784564971924, 0.860991358757019], 'val_loss': [1.1995849609375, 1.1942453384399414, 1.1858594417572021, 1.1789642572402954, 1.1732003688812256, 1.167547345161438, 1.162122368812561, 1.15548574924469, 1.1518590450286865, 1.1535956859588623, 1.148189902305603, 1.1410963535308838, 1.135533332824707, 1.1289262771606445, 1.1301507949829102, 1.1196249723434448, 1.092572808265686, 1.1446988582611084, 1.076500415802002, 1.0804611444473267, 1.0705125331878662, 1.07009756565094, 1.0397427082061768, 1.0242502689361572, 1.039862871170044, 1.0167707204818726, 1.0140466690063477, 1.013322353363037, 1.0071122646331787, 1.0058794021606445, 1.0035916566848755, 1.0010180473327637, 1.0003468990325928, 1.0005961656570435, 0.9984423518180847, 0.9952420592308044, 0.9988453388214111, 1.0030871629714966, 0.9927156567573547, 0.9870147705078125, 0.995043933391571, 0.9850357174873352, 0.9955613613128662, 0.9849927425384521, 0.9818897843360901, 1.0026768445968628, 0.991888701915741, 0.9828657507896423, 0.9856905341148376, 0.9811992049217224, 0.9927077889442444, 0.9906300902366638, 0.9751107692718506, 0.9790186285972595, 0.9823209643363953, 0.9711105823516846, 0.9908724427223206, 0.971320390701294, 0.9786631464958191, 0.9689328670501709, 0.9726072549819946, 1.0006747245788574, 0.9701111912727356, 0.9937958121299744, 0.9992108345031738, 0.9875737428665161, 0.9802389740943909, 0.9691277146339417, 0.9699134230613708, 0.9718283414840698, 0.9689218997955322, 0.9987548589706421, 0.9711349606513977, 0.9702248573303223, 0.9864007234573364, 0.9721460938453674, 0.9985673427581787, 0.9725806713104248, 0.9794521927833557, 0.9903028607368469, 0.9998382925987244, 0.9695978760719299, 0.9735817909240723, 0.9925230741500854, 0.9771795868873596, 0.9734299778938293, 0.9762356281280518, 0.9753538966178894, 0.9744192957878113, 1.0080686807632446, 0.9733539819717407, 1.001181960105896, 0.9846710562705994, 0.9761879444122314, 0.9827467799186707, 1.0081366300582886, 0.9756264686584473, 0.9903090000152588, 0.9935457110404968, 0.9812321662902832], 'val_accuracy': [0.48491379618644714, 0.4892241358757019, 0.5818965435028076, 0.6821120977401733, 0.6487069129943848, 0.6260775923728943, 0.600215494632721, 0.6034482717514038, 0.5786637663841248, 0.5431034564971924, 0.548491358757019, 0.5571120977401733, 0.5678879022598267, 0.5775862336158752, 0.568965494632721, 0.5829741358757019, 0.6443965435028076, 0.5625, 0.6530172228813171, 0.6454741358757019, 0.6573275923728943, 0.6584051847457886, 0.6788793206214905, 0.701508641242981, 0.6821120977401733, 0.7058189511299133, 0.7036637663841248, 0.6993534564971924, 0.701508641242981, 0.704741358757019, 0.704741358757019, 0.704741358757019, 0.7090517282485962, 0.704741358757019, 0.7036637663841248, 0.7036637663841248, 0.6971982717514038, 0.6907327771186829, 0.7025862336158752, 0.7058189511299133, 0.6918103694915771, 0.7004310488700867, 0.6961206793785095, 0.7036637663841248, 0.7004310488700867, 0.6821120977401733, 0.6864224076271057, 0.7004310488700867, 0.6961206793785095, 0.6961206793785095, 0.701508641242981, 0.6853448152542114, 0.701508641242981, 0.6993534564971924, 0.7025862336158752, 0.6993534564971924, 0.6767241358757019, 0.6961206793785095, 0.6896551847457886, 0.6971982717514038, 0.6928879022598267, 0.6637930870056152, 0.6950430870056152, 0.6670258641242981, 0.670258641242981, 0.6788793206214905, 0.6864224076271057, 0.6993534564971924, 0.6907327771186829, 0.6885775923728943, 0.701508641242981, 0.6691810488700867, 0.6842672228813171, 0.6821120977401733, 0.6918103694915771, 0.6799569129943848, 0.6681034564971924, 0.6993534564971924, 0.6982758641242981, 0.6745689511299133, 0.6670258641242981, 0.6875, 0.6918103694915771, 0.670258641242981, 0.6928879022598267, 0.6821120977401733, 0.6799569129943848, 0.6950430870056152, 0.6885775923728943, 0.6519396305084229, 0.6971982717514038, 0.662715494632721, 0.6767241358757019, 0.6842672228813171, 0.6691810488700867, 0.65625, 0.6918103694915771, 0.6896551847457886, 0.6713362336158752, 0.6788793206214905]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 40ms/step - loss: 1.0932 - accuracy: 0.6986 - val_loss: 1.1997 - val_accuracy: 0.4955\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 24ms/step - loss: 1.0849 - accuracy: 0.7037 - val_loss: 1.1925 - val_accuracy: 0.5124\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0750 - accuracy: 0.7119 - val_loss: 1.1856 - val_accuracy: 0.5950\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0663 - accuracy: 0.7176 - val_loss: 1.1797 - val_accuracy: 0.6844\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0606 - accuracy: 0.7142 - val_loss: 1.1738 - val_accuracy: 0.6844\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0539 - accuracy: 0.7238 - val_loss: 1.1684 - val_accuracy: 0.6505\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0525 - accuracy: 0.7201 - val_loss: 1.1634 - val_accuracy: 0.6290\n","Epoch 8/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0464 - accuracy: 0.7250 - val_loss: 1.1593 - val_accuracy: 0.5962\n","Epoch 9/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0372 - accuracy: 0.7295 - val_loss: 1.1536 - val_accuracy: 0.5984\n","Epoch 10/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0366 - accuracy: 0.7250 - val_loss: 1.1551 - val_accuracy: 0.5532\n","Epoch 11/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0275 - accuracy: 0.7334 - val_loss: 1.1449 - val_accuracy: 0.5690\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0258 - accuracy: 0.7329 - val_loss: 1.1401 - val_accuracy: 0.5735\n","Epoch 13/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0177 - accuracy: 0.7298 - val_loss: 1.1240 - val_accuracy: 0.6278\n","Epoch 14/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0149 - accuracy: 0.7301 - val_loss: 1.1370 - val_accuracy: 0.5622\n","Epoch 15/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0088 - accuracy: 0.7332 - val_loss: 1.1345 - val_accuracy: 0.5633\n","Epoch 16/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0019 - accuracy: 0.7391 - val_loss: 1.1274 - val_accuracy: 0.5713\n","Epoch 17/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9975 - accuracy: 0.7414 - val_loss: 1.1276 - val_accuracy: 0.5713\n","Epoch 18/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9952 - accuracy: 0.7354 - val_loss: 1.1247 - val_accuracy: 0.5781\n","Epoch 19/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9911 - accuracy: 0.7337 - val_loss: 1.1106 - val_accuracy: 0.5995\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9834 - accuracy: 0.7414 - val_loss: 1.1007 - val_accuracy: 0.6131\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9770 - accuracy: 0.7479 - val_loss: 1.1056 - val_accuracy: 0.6097\n","Epoch 22/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9789 - accuracy: 0.7397 - val_loss: 1.0839 - val_accuracy: 0.6278\n","Epoch 23/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9685 - accuracy: 0.7510 - val_loss: 1.0615 - val_accuracy: 0.6505\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9652 - accuracy: 0.7530 - val_loss: 1.0606 - val_accuracy: 0.6527\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9629 - accuracy: 0.7467 - val_loss: 1.0391 - val_accuracy: 0.6753\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9562 - accuracy: 0.7561 - val_loss: 1.0453 - val_accuracy: 0.6572\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9555 - accuracy: 0.7499 - val_loss: 1.0149 - val_accuracy: 0.6923\n","Epoch 28/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9479 - accuracy: 0.7513 - val_loss: 1.0137 - val_accuracy: 0.6889\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9421 - accuracy: 0.7569 - val_loss: 1.0110 - val_accuracy: 0.6946\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9422 - accuracy: 0.7544 - val_loss: 1.0170 - val_accuracy: 0.6912\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9353 - accuracy: 0.7572 - val_loss: 1.0018 - val_accuracy: 0.6957\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9328 - accuracy: 0.7595 - val_loss: 1.0038 - val_accuracy: 0.6867\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9265 - accuracy: 0.7603 - val_loss: 0.9977 - val_accuracy: 0.6957\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9231 - accuracy: 0.7592 - val_loss: 0.9936 - val_accuracy: 0.6980\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9178 - accuracy: 0.7598 - val_loss: 1.0144 - val_accuracy: 0.6753\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9157 - accuracy: 0.7680 - val_loss: 0.9904 - val_accuracy: 0.6946\n","Epoch 37/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9144 - accuracy: 0.7600 - val_loss: 0.9890 - val_accuracy: 0.6991\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9077 - accuracy: 0.7592 - val_loss: 0.9894 - val_accuracy: 0.6923\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9021 - accuracy: 0.7731 - val_loss: 0.9863 - val_accuracy: 0.6934\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9027 - accuracy: 0.7654 - val_loss: 0.9845 - val_accuracy: 0.6957\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8975 - accuracy: 0.7674 - val_loss: 0.9807 - val_accuracy: 0.6957\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8888 - accuracy: 0.7668 - val_loss: 0.9887 - val_accuracy: 0.6900\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8850 - accuracy: 0.7733 - val_loss: 0.9815 - val_accuracy: 0.6889\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8792 - accuracy: 0.7770 - val_loss: 0.9845 - val_accuracy: 0.6946\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8855 - accuracy: 0.7603 - val_loss: 0.9764 - val_accuracy: 0.6946\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8733 - accuracy: 0.7750 - val_loss: 0.9785 - val_accuracy: 0.6867\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8692 - accuracy: 0.7773 - val_loss: 0.9739 - val_accuracy: 0.6923\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8745 - accuracy: 0.7762 - val_loss: 0.9690 - val_accuracy: 0.6980\n","Epoch 49/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8694 - accuracy: 0.7753 - val_loss: 0.9917 - val_accuracy: 0.6753\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8644 - accuracy: 0.7762 - val_loss: 0.9676 - val_accuracy: 0.7014\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8540 - accuracy: 0.7878 - val_loss: 0.9831 - val_accuracy: 0.6867\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8588 - accuracy: 0.7767 - val_loss: 0.9715 - val_accuracy: 0.6923\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8487 - accuracy: 0.7813 - val_loss: 0.9692 - val_accuracy: 0.6867\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8448 - accuracy: 0.7864 - val_loss: 0.9619 - val_accuracy: 0.6934\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8392 - accuracy: 0.7827 - val_loss: 0.9864 - val_accuracy: 0.6719\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8355 - accuracy: 0.7892 - val_loss: 0.9610 - val_accuracy: 0.6991\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8288 - accuracy: 0.7997 - val_loss: 1.0088 - val_accuracy: 0.6606\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8338 - accuracy: 0.7932 - val_loss: 0.9630 - val_accuracy: 0.6867\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8235 - accuracy: 0.7946 - val_loss: 0.9590 - val_accuracy: 0.6946\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8196 - accuracy: 0.7946 - val_loss: 0.9580 - val_accuracy: 0.6912\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8126 - accuracy: 0.8036 - val_loss: 0.9600 - val_accuracy: 0.6878\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8095 - accuracy: 0.7994 - val_loss: 0.9722 - val_accuracy: 0.6833\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8169 - accuracy: 0.7847 - val_loss: 0.9525 - val_accuracy: 0.6878\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8044 - accuracy: 0.8050 - val_loss: 0.9547 - val_accuracy: 0.6912\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7995 - accuracy: 0.8022 - val_loss: 0.9597 - val_accuracy: 0.6912\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7957 - accuracy: 0.8124 - val_loss: 0.9611 - val_accuracy: 0.6810\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7934 - accuracy: 0.8050 - val_loss: 0.9720 - val_accuracy: 0.6833\n","Epoch 68/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7957 - accuracy: 0.8028 - val_loss: 0.9562 - val_accuracy: 0.6923\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7849 - accuracy: 0.8141 - val_loss: 0.9527 - val_accuracy: 0.6855\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7841 - accuracy: 0.8036 - val_loss: 0.9542 - val_accuracy: 0.6912\n","Epoch 71/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7824 - accuracy: 0.8101 - val_loss: 0.9689 - val_accuracy: 0.6821\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7753 - accuracy: 0.8107 - val_loss: 0.9526 - val_accuracy: 0.6889\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7735 - accuracy: 0.8107 - val_loss: 0.9532 - val_accuracy: 0.6889\n","Epoch 74/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7696 - accuracy: 0.8079 - val_loss: 0.9558 - val_accuracy: 0.6833\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7821 - accuracy: 0.7974 - val_loss: 0.9594 - val_accuracy: 0.6821\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7656 - accuracy: 0.8161 - val_loss: 0.9506 - val_accuracy: 0.6878\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7610 - accuracy: 0.8132 - val_loss: 0.9497 - val_accuracy: 0.6844\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7508 - accuracy: 0.8203 - val_loss: 0.9579 - val_accuracy: 0.6810\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7528 - accuracy: 0.8195 - val_loss: 0.9744 - val_accuracy: 0.6765\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7594 - accuracy: 0.8065 - val_loss: 0.9498 - val_accuracy: 0.6923\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7449 - accuracy: 0.8237 - val_loss: 0.9501 - val_accuracy: 0.6923\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7404 - accuracy: 0.8277 - val_loss: 0.9555 - val_accuracy: 0.6821\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7357 - accuracy: 0.8268 - val_loss: 0.9470 - val_accuracy: 0.6867\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7387 - accuracy: 0.8203 - val_loss: 1.0106 - val_accuracy: 0.6629\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7416 - accuracy: 0.8189 - val_loss: 0.9513 - val_accuracy: 0.6799\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7276 - accuracy: 0.8288 - val_loss: 0.9488 - val_accuracy: 0.6934\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7222 - accuracy: 0.8302 - val_loss: 0.9554 - val_accuracy: 0.6787\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7180 - accuracy: 0.8353 - val_loss: 0.9546 - val_accuracy: 0.6799\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7179 - accuracy: 0.8297 - val_loss: 0.9701 - val_accuracy: 0.6787\n","Epoch 90/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7156 - accuracy: 0.8316 - val_loss: 0.9515 - val_accuracy: 0.6844\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7102 - accuracy: 0.8370 - val_loss: 0.9494 - val_accuracy: 0.6810\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7083 - accuracy: 0.8370 - val_loss: 0.9539 - val_accuracy: 0.6867\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7131 - accuracy: 0.8291 - val_loss: 0.9564 - val_accuracy: 0.6765\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7011 - accuracy: 0.8379 - val_loss: 0.9898 - val_accuracy: 0.6708\n","Epoch 95/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7040 - accuracy: 0.8342 - val_loss: 0.9509 - val_accuracy: 0.6821\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7014 - accuracy: 0.8350 - val_loss: 0.9922 - val_accuracy: 0.6821\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7077 - accuracy: 0.8277 - val_loss: 0.9546 - val_accuracy: 0.6787\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6908 - accuracy: 0.8364 - val_loss: 0.9643 - val_accuracy: 0.6855\n","Epoch 99/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.8444 - val_loss: 0.9653 - val_accuracy: 0.6821\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6936 - accuracy: 0.8379 - val_loss: 0.9594 - val_accuracy: 0.6810\n","{'loss': [1.0932133197784424, 1.0849072933197021, 1.074990153312683, 1.0662765502929688, 1.0606061220169067, 1.0538685321807861, 1.0525203943252563, 1.0464012622833252, 1.0371782779693604, 1.036623477935791, 1.027513861656189, 1.02584969997406, 1.0176749229431152, 1.0148789882659912, 1.0088214874267578, 1.0018813610076904, 0.9974594116210938, 0.9951828718185425, 0.9910666942596436, 0.9834015965461731, 0.9770451188087463, 0.9788687229156494, 0.9685187339782715, 0.9651975035667419, 0.9629237055778503, 0.956150233745575, 0.9555007219314575, 0.9479008316993713, 0.9421066641807556, 0.9421715140342712, 0.9353010058403015, 0.9328038096427917, 0.9265208840370178, 0.9230731129646301, 0.9177559018135071, 0.9156994223594666, 0.9143535494804382, 0.9077135920524597, 0.9021236300468445, 0.9027343392372131, 0.8975275158882141, 0.8888399600982666, 0.884967029094696, 0.8791813850402832, 0.8854997754096985, 0.8733044862747192, 0.8692192435264587, 0.8745317459106445, 0.8693889379501343, 0.864406406879425, 0.8540248870849609, 0.858785092830658, 0.8487328886985779, 0.8447539806365967, 0.8391783833503723, 0.8355469107627869, 0.8288252353668213, 0.8338054418563843, 0.8235108256340027, 0.8195956945419312, 0.8125510811805725, 0.8095127940177917, 0.8169472217559814, 0.804428219795227, 0.7995426654815674, 0.7956899404525757, 0.7934121489524841, 0.7957334518432617, 0.7848691344261169, 0.7841048836708069, 0.782446563243866, 0.7752847671508789, 0.773505687713623, 0.7695974111557007, 0.7820674180984497, 0.7656261324882507, 0.7610281705856323, 0.7507640719413757, 0.7528011798858643, 0.7594115138053894, 0.7448534965515137, 0.7404472827911377, 0.735718309879303, 0.7386522889137268, 0.7416322231292725, 0.7276338934898376, 0.7221644520759583, 0.7179714441299438, 0.7179484963417053, 0.7155601978302002, 0.710151731967926, 0.7082945704460144, 0.7131333947181702, 0.7011420130729675, 0.7040285468101501, 0.7013720870018005, 0.7077341079711914, 0.690785825252533, 0.6916002631187439, 0.6935543417930603], 'accuracy': [0.6986417770385742, 0.7037351727485657, 0.711941123008728, 0.7176004648208618, 0.7142048478126526, 0.7238256931304932, 0.7201471328735352, 0.7249575257301331, 0.7294849753379822, 0.7249575257301331, 0.7334465384483337, 0.7328805923461914, 0.7297679781913757, 0.7300509214401245, 0.7331635355949402, 0.7391058206558228, 0.7413695454597473, 0.7354272603988647, 0.7337294816970825, 0.7413695454597473, 0.7478777766227722, 0.7396717667579651, 0.7509903907775879, 0.7529711127281189, 0.7467458844184875, 0.7560837864875793, 0.7498584985733032, 0.7512733340263367, 0.7569326758384705, 0.7543859481811523, 0.7572156190872192, 0.7594793438911438, 0.7603282332420349, 0.759196400642395, 0.7597622871398926, 0.7679682970046997, 0.7600452899932861, 0.759196400642395, 0.7730616927146912, 0.7654216289520264, 0.7674023509025574, 0.7668364644050598, 0.7733446359634399, 0.777023196220398, 0.7603282332420349, 0.7750424742698669, 0.7773061394691467, 0.7761743068695068, 0.7753254175186157, 0.7761743068695068, 0.7877758741378784, 0.7767402529716492, 0.7812677025794983, 0.786361038684845, 0.7826825380325317, 0.7891907095909119, 0.7996604442596436, 0.7931522130966187, 0.7945670485496521, 0.7945670485496521, 0.8036219477653503, 0.7993775010108948, 0.7846632599830627, 0.8050367832183838, 0.8022071123123169, 0.8123939037322998, 0.8050367832183838, 0.8027730584144592, 0.814091682434082, 0.8036219477653503, 0.8101301789283752, 0.8106960654258728, 0.8106960654258728, 0.8078664541244507, 0.797396719455719, 0.8160724639892578, 0.8132427930831909, 0.8203169107437134, 0.8194680213928223, 0.8064516186714172, 0.8237125277519226, 0.8276740312576294, 0.8268251419067383, 0.8203169107437134, 0.8189020752906799, 0.8288058638572693, 0.8302206993103027, 0.8353140950202942, 0.8296547532081604, 0.8316355347633362, 0.8370118737220764, 0.8370118737220764, 0.8290888667106628, 0.8378607630729675, 0.8341822028160095, 0.8350311517715454, 0.8276740312576294, 0.8364459276199341, 0.8443689942359924, 0.8378607630729675], 'val_loss': [1.1997166872024536, 1.1924657821655273, 1.1856482028961182, 1.1796751022338867, 1.173780083656311, 1.1683642864227295, 1.1634154319763184, 1.1592637300491333, 1.1536122560501099, 1.155125617980957, 1.144852638244629, 1.1400865316390991, 1.1240320205688477, 1.136965036392212, 1.134541630744934, 1.1274125576019287, 1.1275659799575806, 1.1247233152389526, 1.1105549335479736, 1.1007351875305176, 1.1055958271026611, 1.083864688873291, 1.0614638328552246, 1.0606054067611694, 1.039123296737671, 1.0452598333358765, 1.0149489641189575, 1.013664960861206, 1.0109919309616089, 1.016963005065918, 1.0018073320388794, 1.0037800073623657, 0.9976798892021179, 0.9935798048973083, 1.0144166946411133, 0.9904489517211914, 0.9890247583389282, 0.9894407987594604, 0.9863144755363464, 0.9845299124717712, 0.9806755185127258, 0.9887229204177856, 0.9814819693565369, 0.9844500422477722, 0.9764261841773987, 0.9784547686576843, 0.9738873839378357, 0.9690067172050476, 0.9917171001434326, 0.9675949811935425, 0.9831429719924927, 0.9714792370796204, 0.9692431092262268, 0.9618731737136841, 0.98643958568573, 0.9610191583633423, 1.0087965726852417, 0.9629979133605957, 0.9590401649475098, 0.9580469727516174, 0.960049569606781, 0.9721552729606628, 0.9524731636047363, 0.9546983242034912, 0.9596503973007202, 0.9611197710037231, 0.9719842672348022, 0.9561629295349121, 0.9526702165603638, 0.9541884660720825, 0.968896210193634, 0.9525894522666931, 0.9531658887863159, 0.9558136463165283, 0.9593639373779297, 0.9506420493125916, 0.9496577382087708, 0.9579491019248962, 0.9743574857711792, 0.9497511386871338, 0.9500683546066284, 0.9555453658103943, 0.9470476508140564, 1.010600209236145, 0.9513397812843323, 0.948796272277832, 0.955381453037262, 0.954608142375946, 0.9701370596885681, 0.9515119791030884, 0.9493556618690491, 0.9538671970367432, 0.9564051628112793, 0.9898194074630737, 0.9509413242340088, 0.9921998381614685, 0.9546245336532593, 0.9642682671546936, 0.9653028249740601, 0.959448516368866], 'val_accuracy': [0.4954751133918762, 0.5124434232711792, 0.5950226187705994, 0.6843891143798828, 0.6843891143798828, 0.6504524946212769, 0.6289592981338501, 0.5961538553237915, 0.598416268825531, 0.5531674027442932, 0.5690045356750488, 0.5735294222831726, 0.627828061580658, 0.5622171759605408, 0.5633484125137329, 0.5712669491767883, 0.5712669491767883, 0.5780543088912964, 0.5995475053787231, 0.6131221652030945, 0.6097285151481628, 0.627828061580658, 0.6504524946212769, 0.6527149081230164, 0.6753393411636353, 0.6572397947311401, 0.692307710647583, 0.6889140009880066, 0.6945701241493225, 0.6911764740943909, 0.6957013607025146, 0.6866515874862671, 0.6957013607025146, 0.6979637742042542, 0.6753393411636353, 0.6945701241493225, 0.6990950107574463, 0.692307710647583, 0.6934388875961304, 0.6957013607025146, 0.6957013607025146, 0.6900452375411987, 0.6889140009880066, 0.6945701241493225, 0.6945701241493225, 0.6866515874862671, 0.692307710647583, 0.6979637742042542, 0.6753393411636353, 0.7013574838638306, 0.6866515874862671, 0.692307710647583, 0.6866515874862671, 0.6934388875961304, 0.6719456911087036, 0.6990950107574463, 0.6606335043907166, 0.6866515874862671, 0.6945701241493225, 0.6911764740943909, 0.6877828240394592, 0.6832579374313354, 0.6877828240394592, 0.6911764740943909, 0.6911764740943909, 0.6809954643249512, 0.6832579374313354, 0.692307710647583, 0.685520350933075, 0.6911764740943909, 0.6821267008781433, 0.6889140009880066, 0.6889140009880066, 0.6832579374313354, 0.6821267008781433, 0.6877828240394592, 0.6843891143798828, 0.6809954643249512, 0.6764705777168274, 0.692307710647583, 0.692307710647583, 0.6821267008781433, 0.6866515874862671, 0.662895917892456, 0.679864227771759, 0.6934388875961304, 0.6787330508232117, 0.679864227771759, 0.6787330508232117, 0.6843891143798828, 0.6809954643249512, 0.6866515874862671, 0.6764705777168274, 0.6708144545555115, 0.6821267008781433, 0.6821267008781433, 0.6787330508232117, 0.685520350933075, 0.6821267008781433, 0.6809954643249512]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 37ms/step - loss: 1.0831 - accuracy: 0.7124 - val_loss: 1.2000 - val_accuracy: 0.4855\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0695 - accuracy: 0.7181 - val_loss: 1.1932 - val_accuracy: 0.4938\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0656 - accuracy: 0.7152 - val_loss: 1.1843 - val_accuracy: 0.6198\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0554 - accuracy: 0.7238 - val_loss: 1.1770 - val_accuracy: 0.6632\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0487 - accuracy: 0.7276 - val_loss: 1.1701 - val_accuracy: 0.6632\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0454 - accuracy: 0.7266 - val_loss: 1.1675 - val_accuracy: 0.5723\n","Epoch 7/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0485 - accuracy: 0.7085 - val_loss: 1.1635 - val_accuracy: 0.5568\n","Epoch 8/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0301 - accuracy: 0.7323 - val_loss: 1.1549 - val_accuracy: 0.5795\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0253 - accuracy: 0.7333 - val_loss: 1.1509 - val_accuracy: 0.5671\n","Epoch 10/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0227 - accuracy: 0.7341 - val_loss: 1.1508 - val_accuracy: 0.5537\n","Epoch 11/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0189 - accuracy: 0.7357 - val_loss: 1.1370 - val_accuracy: 0.5837\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.7377 - val_loss: 1.1524 - val_accuracy: 0.5424\n","Epoch 13/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0168 - accuracy: 0.7261 - val_loss: 1.1459 - val_accuracy: 0.5537\n","Epoch 14/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0007 - accuracy: 0.7408 - val_loss: 1.1415 - val_accuracy: 0.5610\n","Epoch 15/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9961 - accuracy: 0.7398 - val_loss: 1.1244 - val_accuracy: 0.5878\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9904 - accuracy: 0.7452 - val_loss: 1.1504 - val_accuracy: 0.5620\n","Epoch 17/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9865 - accuracy: 0.7444 - val_loss: 1.1439 - val_accuracy: 0.5733\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9846 - accuracy: 0.7429 - val_loss: 1.0935 - val_accuracy: 0.6353\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9780 - accuracy: 0.7452 - val_loss: 1.0932 - val_accuracy: 0.6353\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9740 - accuracy: 0.7442 - val_loss: 1.1073 - val_accuracy: 0.6188\n","Epoch 21/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9780 - accuracy: 0.7370 - val_loss: 1.0451 - val_accuracy: 0.6798\n","Epoch 22/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9709 - accuracy: 0.7362 - val_loss: 1.0482 - val_accuracy: 0.6674\n","Epoch 23/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9640 - accuracy: 0.7468 - val_loss: 1.0536 - val_accuracy: 0.6643\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9548 - accuracy: 0.7527 - val_loss: 1.0360 - val_accuracy: 0.6839\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9531 - accuracy: 0.7517 - val_loss: 1.0433 - val_accuracy: 0.6684\n","Epoch 26/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9456 - accuracy: 0.7563 - val_loss: 1.0281 - val_accuracy: 0.6829\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9413 - accuracy: 0.7563 - val_loss: 1.0304 - val_accuracy: 0.6829\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9395 - accuracy: 0.7556 - val_loss: 1.0640 - val_accuracy: 0.6477\n","Epoch 29/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9385 - accuracy: 0.7514 - val_loss: 1.0300 - val_accuracy: 0.6694\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9346 - accuracy: 0.7496 - val_loss: 1.0214 - val_accuracy: 0.6767\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9317 - accuracy: 0.7522 - val_loss: 1.0270 - val_accuracy: 0.6684\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9264 - accuracy: 0.7649 - val_loss: 1.0233 - val_accuracy: 0.6767\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9220 - accuracy: 0.7543 - val_loss: 1.0174 - val_accuracy: 0.6746\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9138 - accuracy: 0.7607 - val_loss: 1.0255 - val_accuracy: 0.6674\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9149 - accuracy: 0.7576 - val_loss: 1.0122 - val_accuracy: 0.6849\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9061 - accuracy: 0.7682 - val_loss: 1.0101 - val_accuracy: 0.6798\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9020 - accuracy: 0.7656 - val_loss: 1.0102 - val_accuracy: 0.6829\n","Epoch 38/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8952 - accuracy: 0.7672 - val_loss: 1.0068 - val_accuracy: 0.6870\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8955 - accuracy: 0.7651 - val_loss: 1.0169 - val_accuracy: 0.6694\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8954 - accuracy: 0.7687 - val_loss: 1.0101 - val_accuracy: 0.6736\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8887 - accuracy: 0.7713 - val_loss: 1.0060 - val_accuracy: 0.6787\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8796 - accuracy: 0.7770 - val_loss: 0.9997 - val_accuracy: 0.6849\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8857 - accuracy: 0.7656 - val_loss: 1.0003 - val_accuracy: 0.6818\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8760 - accuracy: 0.7747 - val_loss: 0.9964 - val_accuracy: 0.6921\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8745 - accuracy: 0.7773 - val_loss: 0.9999 - val_accuracy: 0.6777\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8756 - accuracy: 0.7705 - val_loss: 1.0313 - val_accuracy: 0.6498\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8655 - accuracy: 0.7801 - val_loss: 0.9988 - val_accuracy: 0.6787\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8637 - accuracy: 0.7755 - val_loss: 0.9916 - val_accuracy: 0.6839\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8540 - accuracy: 0.7806 - val_loss: 0.9959 - val_accuracy: 0.6787\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8577 - accuracy: 0.7744 - val_loss: 0.9897 - val_accuracy: 0.6880\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8474 - accuracy: 0.7829 - val_loss: 0.9896 - val_accuracy: 0.6860\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8429 - accuracy: 0.7879 - val_loss: 0.9971 - val_accuracy: 0.6663\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8380 - accuracy: 0.7917 - val_loss: 0.9892 - val_accuracy: 0.6839\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8395 - accuracy: 0.7850 - val_loss: 0.9902 - val_accuracy: 0.6767\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8322 - accuracy: 0.7894 - val_loss: 0.9877 - val_accuracy: 0.6756\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8303 - accuracy: 0.7889 - val_loss: 0.9881 - val_accuracy: 0.6798\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8274 - accuracy: 0.7938 - val_loss: 0.9833 - val_accuracy: 0.6829\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8289 - accuracy: 0.7873 - val_loss: 0.9822 - val_accuracy: 0.6880\n","Epoch 59/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8194 - accuracy: 0.7959 - val_loss: 0.9815 - val_accuracy: 0.6890\n","Epoch 60/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8224 - accuracy: 0.7910 - val_loss: 0.9889 - val_accuracy: 0.6746\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8148 - accuracy: 0.7871 - val_loss: 0.9850 - val_accuracy: 0.6756\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8176 - accuracy: 0.7866 - val_loss: 0.9861 - val_accuracy: 0.6715\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8104 - accuracy: 0.7948 - val_loss: 0.9894 - val_accuracy: 0.6725\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8030 - accuracy: 0.7987 - val_loss: 0.9877 - val_accuracy: 0.6756\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8015 - accuracy: 0.7992 - val_loss: 0.9888 - val_accuracy: 0.6632\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7934 - accuracy: 0.8054 - val_loss: 0.9925 - val_accuracy: 0.6622\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7902 - accuracy: 0.8018 - val_loss: 0.9800 - val_accuracy: 0.6839\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7864 - accuracy: 0.8049 - val_loss: 0.9803 - val_accuracy: 0.6777\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7861 - accuracy: 0.8021 - val_loss: 1.0071 - val_accuracy: 0.6612\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7906 - accuracy: 0.7982 - val_loss: 0.9792 - val_accuracy: 0.6818\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7788 - accuracy: 0.8028 - val_loss: 0.9760 - val_accuracy: 0.6818\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7717 - accuracy: 0.8098 - val_loss: 0.9789 - val_accuracy: 0.6787\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7726 - accuracy: 0.8070 - val_loss: 0.9786 - val_accuracy: 0.6777\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7734 - accuracy: 0.8090 - val_loss: 0.9796 - val_accuracy: 0.6808\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7628 - accuracy: 0.8119 - val_loss: 0.9790 - val_accuracy: 0.6849\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7622 - accuracy: 0.8065 - val_loss: 0.9794 - val_accuracy: 0.6808\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7570 - accuracy: 0.8137 - val_loss: 0.9788 - val_accuracy: 0.6777\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7502 - accuracy: 0.8243 - val_loss: 0.9813 - val_accuracy: 0.6653\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7525 - accuracy: 0.8127 - val_loss: 0.9800 - val_accuracy: 0.6787\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7461 - accuracy: 0.8243 - val_loss: 0.9800 - val_accuracy: 0.6715\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7464 - accuracy: 0.8142 - val_loss: 0.9763 - val_accuracy: 0.6798\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7391 - accuracy: 0.8212 - val_loss: 1.0082 - val_accuracy: 0.6508\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7460 - accuracy: 0.8147 - val_loss: 0.9798 - val_accuracy: 0.6756\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7351 - accuracy: 0.8178 - val_loss: 0.9875 - val_accuracy: 0.6736\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7283 - accuracy: 0.8289 - val_loss: 0.9784 - val_accuracy: 0.6787\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7404 - accuracy: 0.8163 - val_loss: 0.9831 - val_accuracy: 0.6736\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7221 - accuracy: 0.8341 - val_loss: 0.9844 - val_accuracy: 0.6777\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7302 - accuracy: 0.8176 - val_loss: 1.0026 - val_accuracy: 0.6591\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7217 - accuracy: 0.8292 - val_loss: 0.9924 - val_accuracy: 0.6663\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7140 - accuracy: 0.8318 - val_loss: 0.9868 - val_accuracy: 0.6715\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7089 - accuracy: 0.8354 - val_loss: 0.9833 - val_accuracy: 0.6808\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7064 - accuracy: 0.8357 - val_loss: 1.0062 - val_accuracy: 0.6539\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7166 - accuracy: 0.8209 - val_loss: 0.9963 - val_accuracy: 0.6653\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7084 - accuracy: 0.8266 - val_loss: 0.9904 - val_accuracy: 0.6684\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7012 - accuracy: 0.8398 - val_loss: 0.9936 - val_accuracy: 0.6705\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7029 - accuracy: 0.8367 - val_loss: 0.9923 - val_accuracy: 0.6622\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6905 - accuracy: 0.8408 - val_loss: 0.9991 - val_accuracy: 0.6684\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7015 - accuracy: 0.8344 - val_loss: 1.0089 - val_accuracy: 0.6519\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.8450 - val_loss: 0.9955 - val_accuracy: 0.6591\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.8380 - val_loss: 0.9934 - val_accuracy: 0.6736\n","{'loss': [1.0831118822097778, 1.0695003271102905, 1.065577745437622, 1.0554277896881104, 1.0487138032913208, 1.045369267463684, 1.0484727621078491, 1.030104160308838, 1.0253185033798218, 1.0227034091949463, 1.018869161605835, 1.0086770057678223, 1.0168027877807617, 1.000728726387024, 0.9961422681808472, 0.9904049634933472, 0.9865027666091919, 0.9845597743988037, 0.9780195951461792, 0.9740085005760193, 0.9779619574546814, 0.9709378480911255, 0.9640365242958069, 0.9547904133796692, 0.9530814290046692, 0.9456443190574646, 0.9412788152694702, 0.9394917488098145, 0.9385232925415039, 0.9345504641532898, 0.9317331910133362, 0.9263615608215332, 0.921964704990387, 0.9137800931930542, 0.9148536920547485, 0.9061406850814819, 0.902023196220398, 0.8952310085296631, 0.8955296277999878, 0.8953562378883362, 0.8886814117431641, 0.8796247839927673, 0.8857043981552124, 0.8759740591049194, 0.8745277523994446, 0.8755800127983093, 0.8655382394790649, 0.8636516332626343, 0.8540125489234924, 0.8576691150665283, 0.8473536968231201, 0.842863917350769, 0.8380023837089539, 0.8394583463668823, 0.832177996635437, 0.830316960811615, 0.827361524105072, 0.8288504481315613, 0.8194119930267334, 0.8224265575408936, 0.8147993087768555, 0.8176451325416565, 0.8104130625724792, 0.8029630184173584, 0.8014734387397766, 0.7933986186981201, 0.7901797294616699, 0.7863925099372864, 0.7860572934150696, 0.790614664554596, 0.7788201570510864, 0.7717352509498596, 0.7725817561149597, 0.7733950018882751, 0.7627579569816589, 0.7622200846672058, 0.7570275664329529, 0.7502098083496094, 0.752453088760376, 0.7460774183273315, 0.7463589906692505, 0.7391044497489929, 0.7460476160049438, 0.7350738644599915, 0.7283383011817932, 0.740365207195282, 0.72213214635849, 0.7302013039588928, 0.7216557264328003, 0.713972270488739, 0.7088809013366699, 0.7063871622085571, 0.7165816426277161, 0.7084097862243652, 0.7012494802474976, 0.7028545141220093, 0.6904962658882141, 0.7015335559844971, 0.6896252632141113, 0.6927444338798523], 'accuracy': [0.7124031186103821, 0.7180878520011902, 0.7152454853057861, 0.7237725853919983, 0.7276485562324524, 0.7266150116920471, 0.708527147769928, 0.7322997450828552, 0.7333333492279053, 0.7341085076332092, 0.7356589436531067, 0.737726092338562, 0.7260981798171997, 0.7408268451690674, 0.7397933006286621, 0.7452196478843689, 0.7444444298744202, 0.7428940534591675, 0.7452196478843689, 0.7441860437393188, 0.7369509339332581, 0.7361757159233093, 0.7467700242996216, 0.7527132034301758, 0.7516795992851257, 0.7563307285308838, 0.7563307285308838, 0.7555555701255798, 0.7514212131500244, 0.7496123909950256, 0.7521963715553284, 0.7648578882217407, 0.7542635798454285, 0.7607235312461853, 0.7576227188110352, 0.7682170271873474, 0.7656330466270447, 0.7671834826469421, 0.765116274356842, 0.7687338590621948, 0.7713178396224976, 0.7770025730133057, 0.7656330466270447, 0.7746769785881042, 0.777260959148407, 0.7705426216125488, 0.7801033854484558, 0.775452196598053, 0.7806201577186584, 0.7744185924530029, 0.7829457521438599, 0.7878552675247192, 0.7917312383651733, 0.7850129008293152, 0.7894057035446167, 0.7888888716697693, 0.7937984466552734, 0.7873384952545166, 0.7958656549453735, 0.7909560799598694, 0.7870801091194153, 0.7865633368492126, 0.7948320508003235, 0.7987080216407776, 0.7992247939109802, 0.8054263591766357, 0.801808774471283, 0.8049095869064331, 0.8020671606063843, 0.7981911897659302, 0.802842378616333, 0.8098191022872925, 0.8069767355918884, 0.8090439438819885, 0.8118863105773926, 0.8064599633216858, 0.8136950731277466, 0.8242893815040588, 0.8126614689826965, 0.8242893815040588, 0.814211905002594, 0.8211886286735535, 0.8147286772727966, 0.817829430103302, 0.8289405703544617, 0.8162790536880493, 0.8341085314750671, 0.8175710439682007, 0.829198956489563, 0.8317829370498657, 0.8354005217552185, 0.8356589078903198, 0.8209302425384521, 0.8266149759292603, 0.8397932648658752, 0.8366925120353699, 0.8408268690109253, 0.8343669176101685, 0.8449612259864807, 0.8379845023155212], 'val_loss': [1.200018286705017, 1.193162441253662, 1.1843101978302002, 1.177040934562683, 1.1701061725616455, 1.1674699783325195, 1.163466453552246, 1.1548938751220703, 1.1508846282958984, 1.1508477926254272, 1.137007474899292, 1.1523548364639282, 1.1459163427352905, 1.141544222831726, 1.124390959739685, 1.1504398584365845, 1.1439207792282104, 1.093461513519287, 1.0931655168533325, 1.1072882413864136, 1.0451031923294067, 1.048183560371399, 1.0536075830459595, 1.0359588861465454, 1.0432517528533936, 1.0281487703323364, 1.0304452180862427, 1.0640345811843872, 1.0299612283706665, 1.0213878154754639, 1.0269707441329956, 1.0233474969863892, 1.0174381732940674, 1.0255253314971924, 1.0121715068817139, 1.010069489479065, 1.0102007389068604, 1.0068262815475464, 1.0169132947921753, 1.0100593566894531, 1.0060040950775146, 0.9996715188026428, 1.000313401222229, 0.9963972568511963, 0.9998857378959656, 1.0313454866409302, 0.9987971186637878, 0.9916244745254517, 0.9958869814872742, 0.9896976351737976, 0.9896003603935242, 0.9971281290054321, 0.9892292022705078, 0.9901738166809082, 0.9877004027366638, 0.9881271719932556, 0.9833328127861023, 0.9821920990943909, 0.9815196990966797, 0.9889340400695801, 0.9849690794944763, 0.9861148595809937, 0.9894399642944336, 0.9877183437347412, 0.9887887239456177, 0.9924737811088562, 0.980014979839325, 0.980341911315918, 1.0070935487747192, 0.9792196750640869, 0.9760172963142395, 0.9788954257965088, 0.9785901308059692, 0.979648232460022, 0.979022741317749, 0.9794331192970276, 0.9787735939025879, 0.9812642335891724, 0.9799771308898926, 0.9800258278846741, 0.9763128161430359, 1.008203387260437, 0.9797954559326172, 0.9874853491783142, 0.9783838987350464, 0.983050525188446, 0.9843664169311523, 1.0025638341903687, 0.9923990368843079, 0.9867530465126038, 0.9832532405853271, 1.0061758756637573, 0.996292233467102, 0.990376353263855, 0.993605375289917, 0.9923310279846191, 0.9990707039833069, 1.008901834487915, 0.9954779148101807, 0.9933773279190063], 'val_accuracy': [0.48553720116615295, 0.49380165338516235, 0.6198347210884094, 0.663223147392273, 0.663223147392273, 0.5723140239715576, 0.5568181872367859, 0.5795454382896423, 0.567148745059967, 0.5537189841270447, 0.5836777091026306, 0.5423553586006165, 0.5537189841270447, 0.5609503984451294, 0.5878099203109741, 0.5619834661483765, 0.5733470916748047, 0.6353305578231812, 0.6353305578231812, 0.6188016533851624, 0.6797520518302917, 0.6673553586006165, 0.66425621509552, 0.68388432264328, 0.6683884263038635, 0.682851254940033, 0.682851254940033, 0.6477272510528564, 0.6694214940071106, 0.6766529083251953, 0.6683884263038635, 0.6766529083251953, 0.6745867729187012, 0.6673553586006165, 0.6849173307418823, 0.6797520518302917, 0.682851254940033, 0.6869834661483765, 0.6694214940071106, 0.6735537052154541, 0.6787189841270447, 0.6849173307418823, 0.6818181872367859, 0.692148745059967, 0.6776859760284424, 0.6497933864593506, 0.6787189841270447, 0.68388432264328, 0.6787189841270447, 0.6880165338516235, 0.6859503984451294, 0.6663222908973694, 0.68388432264328, 0.6766529083251953, 0.6756198406219482, 0.6797520518302917, 0.682851254940033, 0.6880165338516235, 0.6890496015548706, 0.6745867729187012, 0.6756198406219482, 0.6714876294136047, 0.672520637512207, 0.6756198406219482, 0.663223147392273, 0.6621900796890259, 0.68388432264328, 0.6776859760284424, 0.6611570119857788, 0.6818181872367859, 0.6818181872367859, 0.6787189841270447, 0.6776859760284424, 0.6807851195335388, 0.6849173307418823, 0.6807851195335388, 0.6776859760284424, 0.6652892827987671, 0.6787189841270447, 0.6714876294136047, 0.6797520518302917, 0.6508264541625977, 0.6756198406219482, 0.6735537052154541, 0.6787189841270447, 0.6735537052154541, 0.6776859760284424, 0.6590909361839294, 0.6663222908973694, 0.6714876294136047, 0.6807851195335388, 0.6539255976676941, 0.6652892827987671, 0.6683884263038635, 0.6704545617103577, 0.6621900796890259, 0.6683884263038635, 0.6518595218658447, 0.6590909361839294, 0.6735537052154541]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 29ms/step - loss: 0.7562 - accuracy: 0.7963 - val_loss: 1.0188 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.6464 - accuracy: 0.8672"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 11ms/step - loss: 0.7333 - accuracy: 0.8160 - val_loss: 1.0174 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7403 - accuracy: 0.8101 - val_loss: 1.0088 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7262 - accuracy: 0.8200 - val_loss: 1.0026 - val_accuracy: 0.4925\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7155 - accuracy: 0.8262 - val_loss: 0.9885 - val_accuracy: 0.5679\n","Epoch 6/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7161 - accuracy: 0.8200 - val_loss: 0.9842 - val_accuracy: 0.5625\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7248 - accuracy: 0.8147 - val_loss: 0.9742 - val_accuracy: 0.6509\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7181 - accuracy: 0.8149 - val_loss: 0.9686 - val_accuracy: 0.6541\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7019 - accuracy: 0.8330 - val_loss: 0.9655 - val_accuracy: 0.6358\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6970 - accuracy: 0.8311 - val_loss: 0.9610 - val_accuracy: 0.6347\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7027 - accuracy: 0.8246 - val_loss: 0.9759 - val_accuracy: 0.5808\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6978 - accuracy: 0.8308 - val_loss: 0.9676 - val_accuracy: 0.5938\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6884 - accuracy: 0.8365 - val_loss: 0.9812 - val_accuracy: 0.5754\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6860 - accuracy: 0.8381 - val_loss: 0.9614 - val_accuracy: 0.6121\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.8456 - val_loss: 0.9725 - val_accuracy: 0.6121\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6852 - accuracy: 0.8389 - val_loss: 0.9734 - val_accuracy: 0.6131\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6777 - accuracy: 0.8427 - val_loss: 0.9682 - val_accuracy: 0.6228\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6787 - accuracy: 0.8421 - val_loss: 0.9595 - val_accuracy: 0.6466\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6704 - accuracy: 0.8454 - val_loss: 1.0171 - val_accuracy: 0.6175\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6666 - accuracy: 0.8486 - val_loss: 1.0273 - val_accuracy: 0.6196\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6694 - accuracy: 0.8454 - val_loss: 1.0158 - val_accuracy: 0.6336\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6610 - accuracy: 0.8499 - val_loss: 0.9188 - val_accuracy: 0.7004\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6628 - accuracy: 0.8494 - val_loss: 0.9082 - val_accuracy: 0.6961\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6531 - accuracy: 0.8516 - val_loss: 0.9055 - val_accuracy: 0.7155\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6511 - accuracy: 0.8521 - val_loss: 0.8749 - val_accuracy: 0.7209\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6506 - accuracy: 0.8545 - val_loss: 0.8730 - val_accuracy: 0.7263\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6566 - accuracy: 0.8475 - val_loss: 0.8713 - val_accuracy: 0.7295\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6421 - accuracy: 0.8626 - val_loss: 0.8765 - val_accuracy: 0.7241\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6480 - accuracy: 0.8551 - val_loss: 0.8765 - val_accuracy: 0.7274\n","Epoch 30/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6338 - accuracy: 0.8658 - val_loss: 0.8755 - val_accuracy: 0.7241\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6373 - accuracy: 0.8599 - val_loss: 0.9396 - val_accuracy: 0.6950\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6442 - accuracy: 0.8494 - val_loss: 0.8805 - val_accuracy: 0.7252\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6259 - accuracy: 0.8669 - val_loss: 0.8822 - val_accuracy: 0.7209\n","Epoch 34/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.8661 - val_loss: 0.8892 - val_accuracy: 0.7209\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6258 - accuracy: 0.8634 - val_loss: 0.9095 - val_accuracy: 0.7177\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6349 - accuracy: 0.8621 - val_loss: 0.9300 - val_accuracy: 0.6886\n","Epoch 37/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6324 - accuracy: 0.8578 - val_loss: 0.8886 - val_accuracy: 0.7155\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6149 - accuracy: 0.8731 - val_loss: 0.8906 - val_accuracy: 0.7220\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6122 - accuracy: 0.8731 - val_loss: 0.8892 - val_accuracy: 0.7198\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6116 - accuracy: 0.8685 - val_loss: 0.9003 - val_accuracy: 0.7123\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6070 - accuracy: 0.8742 - val_loss: 0.9004 - val_accuracy: 0.7155\n","Epoch 42/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6112 - accuracy: 0.8761 - val_loss: 0.9117 - val_accuracy: 0.7091\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6054 - accuracy: 0.8769 - val_loss: 0.9080 - val_accuracy: 0.7177\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6077 - accuracy: 0.8750 - val_loss: 0.9073 - val_accuracy: 0.7112\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5992 - accuracy: 0.8788 - val_loss: 0.9089 - val_accuracy: 0.7166\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5954 - accuracy: 0.8796 - val_loss: 0.9060 - val_accuracy: 0.7112\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5916 - accuracy: 0.8834 - val_loss: 0.8999 - val_accuracy: 0.7220\n","Epoch 48/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6014 - accuracy: 0.8718 - val_loss: 0.9243 - val_accuracy: 0.7026\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6012 - accuracy: 0.8664 - val_loss: 0.9053 - val_accuracy: 0.7166\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5872 - accuracy: 0.8850 - val_loss: 0.9076 - val_accuracy: 0.7123\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5839 - accuracy: 0.8842 - val_loss: 0.9036 - val_accuracy: 0.7177\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.8869 - val_loss: 0.9062 - val_accuracy: 0.7188\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5750 - accuracy: 0.8925 - val_loss: 0.9081 - val_accuracy: 0.7123\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5787 - accuracy: 0.8879 - val_loss: 0.9081 - val_accuracy: 0.7166\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5790 - accuracy: 0.8866 - val_loss: 0.9160 - val_accuracy: 0.7188\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5870 - accuracy: 0.8807 - val_loss: 0.9559 - val_accuracy: 0.7091\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5837 - accuracy: 0.8777 - val_loss: 0.9148 - val_accuracy: 0.7177\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5603 - accuracy: 0.8966 - val_loss: 0.9255 - val_accuracy: 0.7026\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5733 - accuracy: 0.8855 - val_loss: 0.9526 - val_accuracy: 0.7080\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5608 - accuracy: 0.8966 - val_loss: 0.9178 - val_accuracy: 0.7177\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5564 - accuracy: 0.9044 - val_loss: 0.9179 - val_accuracy: 0.7220\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5531 - accuracy: 0.9022 - val_loss: 0.9377 - val_accuracy: 0.7004\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5556 - accuracy: 0.8957 - val_loss: 0.9221 - val_accuracy: 0.7134\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5508 - accuracy: 0.9017 - val_loss: 0.9221 - val_accuracy: 0.7155\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.8963 - val_loss: 0.9435 - val_accuracy: 0.6972\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5493 - accuracy: 0.9009 - val_loss: 0.9352 - val_accuracy: 0.7069\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5459 - accuracy: 0.9006 - val_loss: 0.9226 - val_accuracy: 0.7177\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5423 - accuracy: 0.9006 - val_loss: 0.9295 - val_accuracy: 0.7091\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5354 - accuracy: 0.9073 - val_loss: 0.9351 - val_accuracy: 0.7134\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5351 - accuracy: 0.9108 - val_loss: 0.9455 - val_accuracy: 0.7134\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5405 - accuracy: 0.9068 - val_loss: 0.9347 - val_accuracy: 0.7123\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5370 - accuracy: 0.9071 - val_loss: 0.9740 - val_accuracy: 0.6983\n","Epoch 73/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5347 - accuracy: 0.9079 - val_loss: 0.9367 - val_accuracy: 0.7155\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5293 - accuracy: 0.9089 - val_loss: 0.9415 - val_accuracy: 0.7026\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5278 - accuracy: 0.9057 - val_loss: 0.9851 - val_accuracy: 0.6800\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5407 - accuracy: 0.9003 - val_loss: 0.9425 - val_accuracy: 0.7123\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5216 - accuracy: 0.9141 - val_loss: 0.9744 - val_accuracy: 0.6907\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5380 - accuracy: 0.8922 - val_loss: 0.9483 - val_accuracy: 0.7123\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5153 - accuracy: 0.9165 - val_loss: 0.9594 - val_accuracy: 0.7123\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5141 - accuracy: 0.9176 - val_loss: 0.9467 - val_accuracy: 0.7091\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5208 - accuracy: 0.9141 - val_loss: 0.9618 - val_accuracy: 0.7123\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5120 - accuracy: 0.9138 - val_loss: 0.9612 - val_accuracy: 0.7015\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5050 - accuracy: 0.9221 - val_loss: 0.9701 - val_accuracy: 0.6983\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5042 - accuracy: 0.9251 - val_loss: 0.9547 - val_accuracy: 0.7091\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4971 - accuracy: 0.9281 - val_loss: 0.9591 - val_accuracy: 0.7037\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5037 - accuracy: 0.9200 - val_loss: 0.9637 - val_accuracy: 0.7037\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5111 - accuracy: 0.9127 - val_loss: 0.9653 - val_accuracy: 0.7144\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4989 - accuracy: 0.9216 - val_loss: 0.9774 - val_accuracy: 0.6950\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4953 - accuracy: 0.9221 - val_loss: 0.9728 - val_accuracy: 0.6961\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4988 - accuracy: 0.9216 - val_loss: 0.9784 - val_accuracy: 0.6961\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5021 - accuracy: 0.9176 - val_loss: 0.9782 - val_accuracy: 0.7134\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4953 - accuracy: 0.9232 - val_loss: 1.0019 - val_accuracy: 0.6875\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4902 - accuracy: 0.9289 - val_loss: 1.0300 - val_accuracy: 0.6789\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4890 - accuracy: 0.9294 - val_loss: 0.9765 - val_accuracy: 0.7026\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4815 - accuracy: 0.9305 - val_loss: 0.9785 - val_accuracy: 0.6994\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4803 - accuracy: 0.9364 - val_loss: 0.9893 - val_accuracy: 0.7026\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4906 - accuracy: 0.9205 - val_loss: 0.9913 - val_accuracy: 0.6972\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4751 - accuracy: 0.9359 - val_loss: 0.9901 - val_accuracy: 0.7069\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4822 - accuracy: 0.9267 - val_loss: 1.0310 - val_accuracy: 0.6821\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4747 - accuracy: 0.9321 - val_loss: 1.0277 - val_accuracy: 0.7004\n","{'loss': [0.7562423944473267, 0.7332527041435242, 0.7403318881988525, 0.7262260913848877, 0.7155143022537231, 0.7160503268241882, 0.7247512340545654, 0.7180506587028503, 0.7019181251525879, 0.6969997882843018, 0.7026785612106323, 0.6978394985198975, 0.6883900165557861, 0.6860281229019165, 0.6828128099441528, 0.685151994228363, 0.6777059435844421, 0.6787341833114624, 0.670443058013916, 0.6665815711021423, 0.6693516969680786, 0.6610350608825684, 0.6628118753433228, 0.6531454920768738, 0.6511189937591553, 0.6506475806236267, 0.6565954089164734, 0.6421347856521606, 0.6479858756065369, 0.6338310241699219, 0.6373265981674194, 0.6442078351974487, 0.6258728504180908, 0.6227307319641113, 0.6258031725883484, 0.6349080801010132, 0.632351815700531, 0.6149417757987976, 0.6122106909751892, 0.6116411685943604, 0.6069891452789307, 0.6111913323402405, 0.6053694486618042, 0.6076667308807373, 0.5991522073745728, 0.5953582525253296, 0.5916147828102112, 0.6014039516448975, 0.601151704788208, 0.5871686339378357, 0.583942174911499, 0.5827110409736633, 0.5750364065170288, 0.5786539316177368, 0.5790178775787354, 0.5870127081871033, 0.5836701393127441, 0.5602702498435974, 0.5732630491256714, 0.5607864260673523, 0.5564313530921936, 0.5530828237533569, 0.555571973323822, 0.5508096814155579, 0.5493133664131165, 0.5492755770683289, 0.5458927154541016, 0.5423370599746704, 0.5354432463645935, 0.5350676774978638, 0.5404924154281616, 0.5370078682899475, 0.5346522927284241, 0.5292749404907227, 0.527815043926239, 0.5407031774520874, 0.5215576887130737, 0.5379720330238342, 0.5152578353881836, 0.5140594840049744, 0.5207872986793518, 0.5119849443435669, 0.5050357580184937, 0.5042316317558289, 0.49706485867500305, 0.5037461519241333, 0.511112630367279, 0.4989376366138458, 0.4953444302082062, 0.49875980615615845, 0.502058744430542, 0.4953036904335022, 0.49016520380973816, 0.4890270531177521, 0.48147544264793396, 0.48029500246047974, 0.49063584208488464, 0.4751037657260895, 0.482247918844223, 0.47470614314079285], 'accuracy': [0.7963362336158752, 0.8160021305084229, 0.8100754022598267, 0.8200430870056152, 0.8262392282485962, 0.8200430870056152, 0.8146551847457886, 0.8149245977401733, 0.8329741358757019, 0.8310883641242981, 0.8246228694915771, 0.8308189511299133, 0.8364762663841248, 0.8380926847457886, 0.8456357717514038, 0.8389008641242981, 0.8426724076271057, 0.842133641242981, 0.845366358757019, 0.8485991358757019, 0.845366358757019, 0.849946141242981, 0.8494073152542114, 0.8515625, 0.8521012663841248, 0.8545258641242981, 0.8475215435028076, 0.8626077771186829, 0.8550646305084229, 0.865840494632721, 0.8599137663841248, 0.8494073152542114, 0.8669180870056152, 0.8661099076271057, 0.8634159564971924, 0.8620689511299133, 0.857758641242981, 0.8731142282485962, 0.8731142282485962, 0.868534505367279, 0.8741918206214905, 0.8760775923728943, 0.8768857717514038, 0.875, 0.8787715435028076, 0.8795797228813171, 0.8833512663841248, 0.8717672228813171, 0.8663793206214905, 0.8849676847457886, 0.884159505367279, 0.8868534564971924, 0.8925107717514038, 0.8879310488700867, 0.8865840435028076, 0.8806573152542114, 0.8776939511299133, 0.8965517282485962, 0.8855064511299133, 0.8965517282485962, 0.9043642282485962, 0.9022090435028076, 0.8957435488700867, 0.9016702771186829, 0.8962823152542114, 0.9008620977401733, 0.9005926847457886, 0.9005926847457886, 0.9073275923728943, 0.9108297228813171, 0.9067887663841248, 0.9070581793785095, 0.907866358757019, 0.9089439511299133, 0.9057112336158752, 0.9003232717514038, 0.9140625, 0.892241358757019, 0.9164870977401733, 0.9175646305084229, 0.9140625, 0.9137930870056152, 0.9221444129943848, 0.9251077771186829, 0.928071141242981, 0.9199892282485962, 0.912715494632721, 0.9216055870056152, 0.9221444129943848, 0.9216055870056152, 0.9175646305084229, 0.923222005367279, 0.9288793206214905, 0.9294180870056152, 0.9304956793785095, 0.9364224076271057, 0.920527994632721, 0.935883641242981, 0.9267241358757019, 0.9321120977401733], 'val_loss': [1.0187633037567139, 1.0174046754837036, 1.0087685585021973, 1.0025793313980103, 0.9885023832321167, 0.9841546416282654, 0.9741963148117065, 0.9685921669006348, 0.9655329585075378, 0.9610124230384827, 0.9759411811828613, 0.9675647020339966, 0.981174886226654, 0.9613749980926514, 0.9725080132484436, 0.973433256149292, 0.9681718349456787, 0.9595049023628235, 1.0170824527740479, 1.0272974967956543, 1.0158467292785645, 0.9187766313552856, 0.9081985950469971, 0.9054977893829346, 0.8748870491981506, 0.8730034828186035, 0.871330976486206, 0.8765215277671814, 0.876471221446991, 0.8754942417144775, 0.9396337270736694, 0.8805121183395386, 0.8822067975997925, 0.8892391920089722, 0.9094904661178589, 0.930033802986145, 0.8885841965675354, 0.8905830979347229, 0.8892009854316711, 0.9002725481987, 0.9003968834877014, 0.9117382168769836, 0.908023476600647, 0.9072966575622559, 0.9088740944862366, 0.905993640422821, 0.8998780846595764, 0.9243102669715881, 0.9052931070327759, 0.907589316368103, 0.9035589694976807, 0.9062206745147705, 0.9080542922019958, 0.9081400036811829, 0.9160163402557373, 0.9559332132339478, 0.9147887229919434, 0.9255277514457703, 0.9526110291481018, 0.9177915453910828, 0.9179348945617676, 0.9376822710037231, 0.9220960140228271, 0.9221221804618835, 0.9435067772865295, 0.9352186918258667, 0.9225589036941528, 0.9295326471328735, 0.9351041913032532, 0.9455199241638184, 0.9347269535064697, 0.9739621877670288, 0.9367371201515198, 0.9415004849433899, 0.9850966930389404, 0.9424979090690613, 0.9744374752044678, 0.9483427405357361, 0.9593783020973206, 0.9466709494590759, 0.9617525339126587, 0.9611703753471375, 0.9700644016265869, 0.9547017812728882, 0.9591370224952698, 0.9636991620063782, 0.9653239846229553, 0.9773643016815186, 0.9727568030357361, 0.9784176349639893, 0.9781925678253174, 1.0018631219863892, 1.0299805402755737, 0.9765375852584839, 0.9785031080245972, 0.9893015623092651, 0.9912923574447632, 0.9901028275489807, 1.0309621095657349, 1.0276530981063843], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4924568831920624, 0.5678879022598267, 0.5625, 0.6508620977401733, 0.6540948152542114, 0.6357758641242981, 0.6346982717514038, 0.5808189511299133, 0.59375, 0.5754310488700867, 0.6120689511299133, 0.6120689511299133, 0.6131465435028076, 0.6228448152542114, 0.6465517282485962, 0.6174569129943848, 0.6196120977401733, 0.6336206793785095, 0.7004310488700867, 0.6961206793785095, 0.7155172228813171, 0.7209051847457886, 0.7262930870056152, 0.7295258641242981, 0.7241379022598267, 0.7273706793785095, 0.7241379022598267, 0.6950430870056152, 0.725215494632721, 0.7209051847457886, 0.7209051847457886, 0.7176724076271057, 0.6885775923728943, 0.7155172228813171, 0.7219827771186829, 0.7198275923728943, 0.712284505367279, 0.7155172228813171, 0.7090517282485962, 0.7176724076271057, 0.7112069129943848, 0.7165948152542114, 0.7112069129943848, 0.7219827771186829, 0.7025862336158752, 0.7165948152542114, 0.712284505367279, 0.7176724076271057, 0.71875, 0.712284505367279, 0.7165948152542114, 0.71875, 0.7090517282485962, 0.7176724076271057, 0.7025862336158752, 0.7079741358757019, 0.7176724076271057, 0.7219827771186829, 0.7004310488700867, 0.7133620977401733, 0.7155172228813171, 0.6971982717514038, 0.7068965435028076, 0.7176724076271057, 0.7090517282485962, 0.7133620977401733, 0.7133620977401733, 0.712284505367279, 0.6982758641242981, 0.7155172228813171, 0.7025862336158752, 0.6799569129943848, 0.712284505367279, 0.6907327771186829, 0.712284505367279, 0.712284505367279, 0.7090517282485962, 0.712284505367279, 0.701508641242981, 0.6982758641242981, 0.7090517282485962, 0.7036637663841248, 0.7036637663841248, 0.7144396305084229, 0.6950430870056152, 0.6961206793785095, 0.6961206793785095, 0.7133620977401733, 0.6875, 0.6788793206214905, 0.7025862336158752, 0.6993534564971924, 0.7025862336158752, 0.6971982717514038, 0.7068965435028076, 0.6821120977401733, 0.7004310488700867]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 40ms/step - loss: 0.7682 - accuracy: 0.7849 - val_loss: 1.0157 - val_accuracy: 0.4955\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 17ms/step - loss: 0.7467 - accuracy: 0.8062 - val_loss: 1.0139 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7386 - accuracy: 0.8073 - val_loss: 1.0093 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7446 - accuracy: 0.8062 - val_loss: 1.0038 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7410 - accuracy: 0.7991 - val_loss: 0.9902 - val_accuracy: 0.5328\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7283 - accuracy: 0.8144 - val_loss: 0.9815 - val_accuracy: 0.5747\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7255 - accuracy: 0.8141 - val_loss: 0.9771 - val_accuracy: 0.5769\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7265 - accuracy: 0.8113 - val_loss: 0.9672 - val_accuracy: 0.6505\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7334 - accuracy: 0.8048 - val_loss: 0.9623 - val_accuracy: 0.6697\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7086 - accuracy: 0.8206 - val_loss: 0.9539 - val_accuracy: 0.6742\n","Epoch 11/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7069 - accuracy: 0.8302 - val_loss: 0.9508 - val_accuracy: 0.6595\n","Epoch 12/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7022 - accuracy: 0.8226 - val_loss: 0.9443 - val_accuracy: 0.6629\n","Epoch 13/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7032 - accuracy: 0.8254 - val_loss: 0.9429 - val_accuracy: 0.6561\n","Epoch 14/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6953 - accuracy: 0.8305 - val_loss: 0.9362 - val_accuracy: 0.6640\n","Epoch 15/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6927 - accuracy: 0.8316 - val_loss: 0.9263 - val_accuracy: 0.6697\n","Epoch 16/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6889 - accuracy: 0.8302 - val_loss: 0.9478 - val_accuracy: 0.6267\n","Epoch 17/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6894 - accuracy: 0.8297 - val_loss: 0.9820 - val_accuracy: 0.5939\n","Epoch 18/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.8263 - val_loss: 0.9488 - val_accuracy: 0.6346\n","Epoch 19/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.8376 - val_loss: 0.9360 - val_accuracy: 0.6561\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6787 - accuracy: 0.8401 - val_loss: 1.0173 - val_accuracy: 0.5995\n","Epoch 21/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6755 - accuracy: 0.8435 - val_loss: 0.9941 - val_accuracy: 0.6165\n","Epoch 22/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6824 - accuracy: 0.8285 - val_loss: 0.8759 - val_accuracy: 0.7048\n","Epoch 23/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6804 - accuracy: 0.8342 - val_loss: 0.8611 - val_accuracy: 0.7081\n","Epoch 24/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6745 - accuracy: 0.8404 - val_loss: 0.8858 - val_accuracy: 0.7081\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6637 - accuracy: 0.8418 - val_loss: 0.8661 - val_accuracy: 0.7081\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6635 - accuracy: 0.8452 - val_loss: 0.8434 - val_accuracy: 0.7240\n","Epoch 27/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6573 - accuracy: 0.8486 - val_loss: 0.8548 - val_accuracy: 0.7172\n","Epoch 28/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6518 - accuracy: 0.8517 - val_loss: 0.8604 - val_accuracy: 0.7138\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6537 - accuracy: 0.8489 - val_loss: 0.8406 - val_accuracy: 0.7274\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6431 - accuracy: 0.8574 - val_loss: 0.8382 - val_accuracy: 0.7262\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6416 - accuracy: 0.8543 - val_loss: 0.8387 - val_accuracy: 0.7342\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6416 - accuracy: 0.8565 - val_loss: 0.8375 - val_accuracy: 0.7274\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6394 - accuracy: 0.8557 - val_loss: 0.8386 - val_accuracy: 0.7217\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6343 - accuracy: 0.8636 - val_loss: 0.8440 - val_accuracy: 0.7308\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6314 - accuracy: 0.8662 - val_loss: 0.8384 - val_accuracy: 0.7342\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6389 - accuracy: 0.8500 - val_loss: 0.8602 - val_accuracy: 0.7183\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6287 - accuracy: 0.8630 - val_loss: 0.8486 - val_accuracy: 0.7229\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6369 - accuracy: 0.8517 - val_loss: 0.8965 - val_accuracy: 0.6991\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6255 - accuracy: 0.8611 - val_loss: 0.8509 - val_accuracy: 0.7206\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6221 - accuracy: 0.8625 - val_loss: 0.8942 - val_accuracy: 0.7025\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6347 - accuracy: 0.8480 - val_loss: 0.8468 - val_accuracy: 0.7206\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6170 - accuracy: 0.8616 - val_loss: 0.8494 - val_accuracy: 0.7217\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6240 - accuracy: 0.8540 - val_loss: 0.8647 - val_accuracy: 0.7229\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6230 - accuracy: 0.8580 - val_loss: 0.8514 - val_accuracy: 0.7183\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6116 - accuracy: 0.8664 - val_loss: 0.8560 - val_accuracy: 0.7195\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6022 - accuracy: 0.8797 - val_loss: 0.8542 - val_accuracy: 0.7217\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5996 - accuracy: 0.8803 - val_loss: 0.8566 - val_accuracy: 0.7240\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5985 - accuracy: 0.8795 - val_loss: 0.8529 - val_accuracy: 0.7183\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5947 - accuracy: 0.8795 - val_loss: 0.8536 - val_accuracy: 0.7161\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5987 - accuracy: 0.8780 - val_loss: 0.8690 - val_accuracy: 0.7217\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5989 - accuracy: 0.8684 - val_loss: 0.8658 - val_accuracy: 0.7206\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5914 - accuracy: 0.8795 - val_loss: 0.8577 - val_accuracy: 0.7206\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5815 - accuracy: 0.8848 - val_loss: 0.8593 - val_accuracy: 0.7195\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5817 - accuracy: 0.8891 - val_loss: 0.8648 - val_accuracy: 0.7217\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5837 - accuracy: 0.8862 - val_loss: 0.8799 - val_accuracy: 0.7274\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5840 - accuracy: 0.8783 - val_loss: 0.8643 - val_accuracy: 0.7206\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5797 - accuracy: 0.8851 - val_loss: 0.8798 - val_accuracy: 0.7195\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5738 - accuracy: 0.8911 - val_loss: 0.8642 - val_accuracy: 0.7161\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5654 - accuracy: 0.9004 - val_loss: 0.8738 - val_accuracy: 0.7161\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5736 - accuracy: 0.8879 - val_loss: 0.8867 - val_accuracy: 0.7138\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5687 - accuracy: 0.8882 - val_loss: 0.8844 - val_accuracy: 0.7081\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5838 - accuracy: 0.8732 - val_loss: 0.8711 - val_accuracy: 0.7138\n","Epoch 63/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5563 - accuracy: 0.9018 - val_loss: 0.8716 - val_accuracy: 0.7183\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5596 - accuracy: 0.8950 - val_loss: 0.8797 - val_accuracy: 0.7138\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5591 - accuracy: 0.8925 - val_loss: 0.8715 - val_accuracy: 0.7183\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5614 - accuracy: 0.8874 - val_loss: 0.8888 - val_accuracy: 0.7229\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5520 - accuracy: 0.8970 - val_loss: 0.8968 - val_accuracy: 0.7115\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5447 - accuracy: 0.9063 - val_loss: 0.8796 - val_accuracy: 0.7195\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5499 - accuracy: 0.9010 - val_loss: 0.9183 - val_accuracy: 0.7036\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5487 - accuracy: 0.8978 - val_loss: 0.8963 - val_accuracy: 0.7081\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5420 - accuracy: 0.9100 - val_loss: 0.8863 - val_accuracy: 0.7138\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5342 - accuracy: 0.9114 - val_loss: 0.8894 - val_accuracy: 0.7093\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5430 - accuracy: 0.9035 - val_loss: 1.0398 - val_accuracy: 0.6934\n","Epoch 74/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5478 - accuracy: 0.8947 - val_loss: 0.9089 - val_accuracy: 0.7183\n","Epoch 75/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5450 - accuracy: 0.8956 - val_loss: 0.9437 - val_accuracy: 0.7025\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5415 - accuracy: 0.8984 - val_loss: 0.8953 - val_accuracy: 0.7127\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5209 - accuracy: 0.9182 - val_loss: 0.9024 - val_accuracy: 0.7081\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5241 - accuracy: 0.9151 - val_loss: 0.9019 - val_accuracy: 0.7127\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5343 - accuracy: 0.9012 - val_loss: 0.9016 - val_accuracy: 0.7104\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5168 - accuracy: 0.9160 - val_loss: 0.8990 - val_accuracy: 0.7127\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5164 - accuracy: 0.9151 - val_loss: 0.9044 - val_accuracy: 0.7183\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5094 - accuracy: 0.9230 - val_loss: 0.9074 - val_accuracy: 0.7093\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5071 - accuracy: 0.9239 - val_loss: 0.9048 - val_accuracy: 0.7172\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5114 - accuracy: 0.9205 - val_loss: 0.9155 - val_accuracy: 0.7104\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5147 - accuracy: 0.9117 - val_loss: 0.9104 - val_accuracy: 0.7115\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5071 - accuracy: 0.9219 - val_loss: 0.9822 - val_accuracy: 0.7014\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5166 - accuracy: 0.9128 - val_loss: 0.9184 - val_accuracy: 0.7081\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5105 - accuracy: 0.9182 - val_loss: 0.9464 - val_accuracy: 0.6968\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5004 - accuracy: 0.9216 - val_loss: 0.9224 - val_accuracy: 0.7172\n","Epoch 90/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4970 - accuracy: 0.9253 - val_loss: 0.9263 - val_accuracy: 0.7059\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5043 - accuracy: 0.9196 - val_loss: 0.9328 - val_accuracy: 0.6980\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.9160 - val_loss: 0.9532 - val_accuracy: 0.7149\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4898 - accuracy: 0.9278 - val_loss: 0.9316 - val_accuracy: 0.7059\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4855 - accuracy: 0.9307 - val_loss: 0.9509 - val_accuracy: 0.7093\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4934 - accuracy: 0.9199 - val_loss: 0.9276 - val_accuracy: 0.7070\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4899 - accuracy: 0.9307 - val_loss: 0.9366 - val_accuracy: 0.7048\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5086 - accuracy: 0.9063 - val_loss: 0.9365 - val_accuracy: 0.7048\n","Epoch 98/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4850 - accuracy: 0.9264 - val_loss: 0.9880 - val_accuracy: 0.6957\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4791 - accuracy: 0.9363 - val_loss: 0.9575 - val_accuracy: 0.6968\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4818 - accuracy: 0.9307 - val_loss: 0.9574 - val_accuracy: 0.6957\n","{'loss': [0.7682170271873474, 0.7467496395111084, 0.7385731339454651, 0.7446436882019043, 0.7409743070602417, 0.7282707691192627, 0.7255008220672607, 0.7264947295188904, 0.7334455251693726, 0.7086286544799805, 0.7068849205970764, 0.7021984457969666, 0.7031649351119995, 0.6952846646308899, 0.6926811933517456, 0.6888695955276489, 0.6894222497940063, 0.6880865693092346, 0.6808222532272339, 0.6787108182907104, 0.6755270957946777, 0.6824193596839905, 0.6804468631744385, 0.6745278835296631, 0.6636953949928284, 0.6635111570358276, 0.6573374271392822, 0.6518165469169617, 0.6536762118339539, 0.643105685710907, 0.6415767669677734, 0.6415918469429016, 0.6394117474555969, 0.6343380808830261, 0.6313920021057129, 0.6388686299324036, 0.6287434697151184, 0.6369026303291321, 0.6255452036857605, 0.6221324801445007, 0.6347452998161316, 0.617021381855011, 0.623988151550293, 0.6229847073554993, 0.6115511059761047, 0.6021953821182251, 0.5995886921882629, 0.5985272526741028, 0.5947083234786987, 0.5987058281898499, 0.598910391330719, 0.5914441347122192, 0.5815069675445557, 0.5817071199417114, 0.5837389230728149, 0.5839593410491943, 0.5797296762466431, 0.5737704038619995, 0.5654029846191406, 0.5735594630241394, 0.5686888098716736, 0.5838046073913574, 0.5563318133354187, 0.5596301555633545, 0.5591453909873962, 0.5614407658576965, 0.5520219206809998, 0.5447128415107727, 0.5498638153076172, 0.5487468242645264, 0.5419644117355347, 0.5341935753822327, 0.5429978370666504, 0.547764778137207, 0.5450108647346497, 0.5414782762527466, 0.5209298133850098, 0.5240941047668457, 0.5342810153961182, 0.516771137714386, 0.516407310962677, 0.50944584608078, 0.5070514678955078, 0.5114478468894958, 0.5147094130516052, 0.5070657730102539, 0.5166148543357849, 0.5104634761810303, 0.5003542900085449, 0.49696484208106995, 0.5042659044265747, 0.5035106539726257, 0.48975512385368347, 0.48546403646469116, 0.4934197664260864, 0.4899006187915802, 0.5086425542831421, 0.48500773310661316, 0.4791187345981598, 0.4817705452442169], 'accuracy': [0.7849462628364563, 0.8061686754226685, 0.8073005080223083, 0.8061686754226685, 0.7990944981575012, 0.8143746256828308, 0.814091682434082, 0.8112620115280151, 0.804753839969635, 0.8205999135971069, 0.8302206993103027, 0.8225806355476379, 0.8254103064537048, 0.8305037021636963, 0.8316355347633362, 0.8302206993103027, 0.8296547532081604, 0.826259195804596, 0.8375778198242188, 0.8401244878768921, 0.8435201048851013, 0.8285229206085205, 0.8341822028160095, 0.8404074907302856, 0.8418223261833191, 0.8452178835868835, 0.848613440990448, 0.8517261147499084, 0.8488964438438416, 0.8573853969573975, 0.8542727828025818, 0.8565365076065063, 0.8556876182556152, 0.8636106252670288, 0.8661573529243469, 0.8500282764434814, 0.8630446791648865, 0.8517261147499084, 0.8610639572143555, 0.8624787926673889, 0.8480475544929504, 0.8616299033164978, 0.853989839553833, 0.8579513430595398, 0.8664402961730957, 0.8797396421432495, 0.8803055882453918, 0.8794566988945007, 0.8794566988945007, 0.8780418634414673, 0.8684210777282715, 0.8794566988945007, 0.884833037853241, 0.8890775442123413, 0.8862478733062744, 0.8783248662948608, 0.8851160407066345, 0.8910582661628723, 0.9003961682319641, 0.8879456520080566, 0.8882286548614502, 0.8732314705848694, 0.9018110036849976, 0.8950198292732239, 0.8924731016159058, 0.8873797655105591, 0.8970005512237549, 0.9063384532928467, 0.9009620547294617, 0.897849440574646, 0.9100169539451599, 0.9114317893981934, 0.9035087823867798, 0.8947368264198303, 0.8955857157707214, 0.8984153866767883, 0.918222963809967, 0.9151103496551514, 0.9012450575828552, 0.9159592390060425, 0.9151103496551514, 0.9230334162712097, 0.9238823056221008, 0.9204866886138916, 0.9117147922515869, 0.921901524066925, 0.9128466248512268, 0.918222963809967, 0.9216185808181763, 0.9252971410751343, 0.9196377992630005, 0.9159592390060425, 0.9278438091278076, 0.9306734800338745, 0.9199207425117493, 0.9306734800338745, 0.9063384532928467, 0.9264289736747742, 0.9363327622413635, 0.9306734800338745], 'val_loss': [1.0157089233398438, 1.013868808746338, 1.0093060731887817, 1.0038405656814575, 0.9902421236038208, 0.9815425872802734, 0.977101743221283, 0.9672298431396484, 0.9623273611068726, 0.9539128541946411, 0.9508421421051025, 0.9442883133888245, 0.942888617515564, 0.9361512660980225, 0.9262519478797913, 0.9477874040603638, 0.9819640517234802, 0.9487782716751099, 0.9359537363052368, 1.0172760486602783, 0.9940534234046936, 0.8759426474571228, 0.8610869646072388, 0.8858239650726318, 0.8661484122276306, 0.8433578014373779, 0.8547862768173218, 0.8603686094284058, 0.8406246900558472, 0.8381552696228027, 0.8386945724487305, 0.8375168442726135, 0.83860182762146, 0.8439643383026123, 0.8384196162223816, 0.8602259755134583, 0.8485690355300903, 0.8965340852737427, 0.8509089946746826, 0.8941706418991089, 0.846817135810852, 0.8493550419807434, 0.8647480010986328, 0.8514232635498047, 0.855950117111206, 0.8542248606681824, 0.8566387891769409, 0.8529226183891296, 0.8536185026168823, 0.8690316677093506, 0.8658015727996826, 0.8576881289482117, 0.859329104423523, 0.8647627830505371, 0.8798513412475586, 0.8643242120742798, 0.8798351287841797, 0.8642162680625916, 0.8737893104553223, 0.8866892457008362, 0.8843825459480286, 0.8711286783218384, 0.8716142177581787, 0.8797144889831543, 0.8715276122093201, 0.8888120055198669, 0.8968433141708374, 0.8795919418334961, 0.9183183908462524, 0.8963249921798706, 0.8863158822059631, 0.8894134163856506, 1.0397859811782837, 0.9089094400405884, 0.9437116384506226, 0.8952728509902954, 0.9023841619491577, 0.9018825888633728, 0.9015910029411316, 0.8990309834480286, 0.9044374227523804, 0.9073977470397949, 0.9048019051551819, 0.9154882431030273, 0.9104021787643433, 0.9822173118591309, 0.9183732867240906, 0.9463789463043213, 0.9223921895027161, 0.9263089299201965, 0.9328243136405945, 0.95321124792099, 0.9316061735153198, 0.9508658647537231, 0.9276494383811951, 0.9365741014480591, 0.9365471005439758, 0.9879683256149292, 0.9575085043907166, 0.9573931097984314], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5328054428100586, 0.5746606588363647, 0.5769230723381042, 0.6504524946212769, 0.6696832776069641, 0.6742081642150879, 0.6595022678375244, 0.662895917892456, 0.6561086177825928, 0.6640271544456482, 0.6696832776069641, 0.6266968250274658, 0.5938913822174072, 0.6346153616905212, 0.6561086177825928, 0.5995475053787231, 0.6165158152580261, 0.7047511339187622, 0.7081447839736938, 0.7081447839736938, 0.7081447839736938, 0.7239819169044495, 0.7171945571899414, 0.7138009071350098, 0.7273755669593811, 0.726244330406189, 0.7341628670692444, 0.7273755669593811, 0.7217194437980652, 0.7307692170143127, 0.7341628670692444, 0.7183257937431335, 0.7228506803512573, 0.6990950107574463, 0.720588207244873, 0.7024886608123779, 0.720588207244873, 0.7217194437980652, 0.7228506803512573, 0.7183257937431335, 0.7194570302963257, 0.7217194437980652, 0.7239819169044495, 0.7183257937431335, 0.7160633206367493, 0.7217194437980652, 0.720588207244873, 0.720588207244873, 0.7194570302963257, 0.7217194437980652, 0.7273755669593811, 0.720588207244873, 0.7194570302963257, 0.7160633206367493, 0.7160633206367493, 0.7138009071350098, 0.7081447839736938, 0.7138009071350098, 0.7183257937431335, 0.7138009071350098, 0.7183257937431335, 0.7228506803512573, 0.7115384340286255, 0.7194570302963257, 0.7036198973655701, 0.7081447839736938, 0.7138009071350098, 0.709276020526886, 0.6934388875961304, 0.7183257937431335, 0.7024886608123779, 0.7126696705818176, 0.7081447839736938, 0.7126696705818176, 0.7104072570800781, 0.7126696705818176, 0.7183257937431335, 0.709276020526886, 0.7171945571899414, 0.7104072570800781, 0.7115384340286255, 0.7013574838638306, 0.7081447839736938, 0.6968325972557068, 0.7171945571899414, 0.7058823704719543, 0.6979637742042542, 0.7149321436882019, 0.7058823704719543, 0.709276020526886, 0.7070135474205017, 0.7047511339187622, 0.7047511339187622, 0.6957013607025146, 0.6968325972557068, 0.6957013607025146]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.7644 - accuracy: 0.7910"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 37ms/step - loss: 0.7644 - accuracy: 0.7910 - val_loss: 1.0195 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7538 - accuracy: 0.7984 - val_loss: 1.0164 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7387 - accuracy: 0.8028 - val_loss: 1.0092 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7340 - accuracy: 0.8067 - val_loss: 0.9993 - val_accuracy: 0.4959\n","Epoch 5/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7309 - accuracy: 0.8090 - val_loss: 0.9864 - val_accuracy: 0.5847\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7250 - accuracy: 0.8124 - val_loss: 0.9780 - val_accuracy: 0.6519\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7259 - accuracy: 0.8129 - val_loss: 0.9725 - val_accuracy: 0.6508\n","Epoch 8/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7170 - accuracy: 0.8158 - val_loss: 0.9679 - val_accuracy: 0.6312\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7135 - accuracy: 0.8186 - val_loss: 0.9714 - val_accuracy: 0.5981\n","Epoch 10/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7109 - accuracy: 0.8204 - val_loss: 0.9694 - val_accuracy: 0.6002\n","Epoch 11/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7084 - accuracy: 0.8160 - val_loss: 0.9606 - val_accuracy: 0.6188\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7025 - accuracy: 0.8318 - val_loss: 0.9781 - val_accuracy: 0.5868\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6991 - accuracy: 0.8284 - val_loss: 0.9826 - val_accuracy: 0.5919\n","Epoch 14/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7076 - accuracy: 0.8186 - val_loss: 0.9650 - val_accuracy: 0.6178\n","Epoch 15/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6970 - accuracy: 0.8233 - val_loss: 0.9979 - val_accuracy: 0.5992\n","Epoch 16/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.8346 - val_loss: 1.0450 - val_accuracy: 0.5775\n","Epoch 17/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6847 - accuracy: 0.8362 - val_loss: 1.0404 - val_accuracy: 0.5950\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.8310 - val_loss: 0.9774 - val_accuracy: 0.6333\n","Epoch 19/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6819 - accuracy: 0.8336 - val_loss: 0.9832 - val_accuracy: 0.6353\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.8300 - val_loss: 1.0625 - val_accuracy: 0.6167\n","Epoch 21/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6825 - accuracy: 0.8307 - val_loss: 0.9803 - val_accuracy: 0.6446\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6714 - accuracy: 0.8416 - val_loss: 0.9599 - val_accuracy: 0.6570\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6745 - accuracy: 0.8398 - val_loss: 0.9735 - val_accuracy: 0.6622\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6709 - accuracy: 0.8362 - val_loss: 0.9323 - val_accuracy: 0.6798\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6647 - accuracy: 0.8419 - val_loss: 0.8904 - val_accuracy: 0.6983\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6619 - accuracy: 0.8483 - val_loss: 0.9050 - val_accuracy: 0.6963\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6660 - accuracy: 0.8403 - val_loss: 0.8960 - val_accuracy: 0.7169\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6555 - accuracy: 0.8426 - val_loss: 0.9049 - val_accuracy: 0.6994\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6763 - accuracy: 0.8287 - val_loss: 0.9771 - val_accuracy: 0.6725\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6566 - accuracy: 0.8377 - val_loss: 0.9010 - val_accuracy: 0.6983\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6478 - accuracy: 0.8543 - val_loss: 0.9003 - val_accuracy: 0.7138\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6462 - accuracy: 0.8494 - val_loss: 0.8992 - val_accuracy: 0.7118\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6495 - accuracy: 0.8527 - val_loss: 0.9060 - val_accuracy: 0.7076\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6461 - accuracy: 0.8494 - val_loss: 0.9013 - val_accuracy: 0.7128\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6476 - accuracy: 0.8475 - val_loss: 0.9040 - val_accuracy: 0.7169\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6300 - accuracy: 0.8638 - val_loss: 0.9075 - val_accuracy: 0.7035\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6312 - accuracy: 0.8563 - val_loss: 0.9159 - val_accuracy: 0.6973\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6291 - accuracy: 0.8571 - val_loss: 0.9131 - val_accuracy: 0.6952\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6268 - accuracy: 0.8615 - val_loss: 0.9186 - val_accuracy: 0.7045\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6369 - accuracy: 0.8532 - val_loss: 0.9306 - val_accuracy: 0.6849\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6302 - accuracy: 0.8576 - val_loss: 0.9099 - val_accuracy: 0.7118\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6289 - accuracy: 0.8574 - val_loss: 0.9443 - val_accuracy: 0.6798\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6224 - accuracy: 0.8636 - val_loss: 0.9282 - val_accuracy: 0.6890\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6104 - accuracy: 0.8708 - val_loss: 0.9346 - val_accuracy: 0.6952\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6163 - accuracy: 0.8605 - val_loss: 0.9501 - val_accuracy: 0.6746\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6214 - accuracy: 0.8532 - val_loss: 0.9312 - val_accuracy: 0.6994\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6333 - accuracy: 0.8522 - val_loss: 0.9434 - val_accuracy: 0.6890\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6065 - accuracy: 0.8680 - val_loss: 0.9161 - val_accuracy: 0.7087\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6050 - accuracy: 0.8736 - val_loss: 0.9529 - val_accuracy: 0.6756\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6012 - accuracy: 0.8724 - val_loss: 0.9227 - val_accuracy: 0.6973\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5926 - accuracy: 0.8767 - val_loss: 0.9600 - val_accuracy: 0.6818\n","Epoch 52/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5945 - accuracy: 0.8747 - val_loss: 0.9242 - val_accuracy: 0.7128\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5994 - accuracy: 0.8744 - val_loss: 0.9311 - val_accuracy: 0.6942\n","Epoch 54/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6049 - accuracy: 0.8654 - val_loss: 0.9277 - val_accuracy: 0.7066\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5894 - accuracy: 0.8798 - val_loss: 0.9622 - val_accuracy: 0.6777\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5911 - accuracy: 0.8762 - val_loss: 0.9346 - val_accuracy: 0.6983\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5820 - accuracy: 0.8817 - val_loss: 0.9301 - val_accuracy: 0.7066\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5791 - accuracy: 0.8822 - val_loss: 0.9338 - val_accuracy: 0.7004\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5761 - accuracy: 0.8822 - val_loss: 0.9371 - val_accuracy: 0.6973\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5805 - accuracy: 0.8822 - val_loss: 0.9622 - val_accuracy: 0.6787\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5743 - accuracy: 0.8873 - val_loss: 0.9415 - val_accuracy: 0.6963\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5706 - accuracy: 0.8848 - val_loss: 0.9458 - val_accuracy: 0.7014\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5915 - accuracy: 0.8698 - val_loss: 1.0154 - val_accuracy: 0.6725\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5881 - accuracy: 0.8726 - val_loss: 0.9452 - val_accuracy: 0.7025\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5629 - accuracy: 0.8935 - val_loss: 0.9501 - val_accuracy: 0.6921\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5605 - accuracy: 0.8920 - val_loss: 0.9440 - val_accuracy: 0.7056\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5574 - accuracy: 0.8933 - val_loss: 0.9422 - val_accuracy: 0.7035\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5557 - accuracy: 0.8974 - val_loss: 0.9552 - val_accuracy: 0.6963\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5516 - accuracy: 0.8956 - val_loss: 1.0409 - val_accuracy: 0.6622\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5673 - accuracy: 0.8801 - val_loss: 0.9568 - val_accuracy: 0.6994\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5495 - accuracy: 0.8961 - val_loss: 0.9490 - val_accuracy: 0.7107\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5454 - accuracy: 0.8982 - val_loss: 0.9475 - val_accuracy: 0.7014\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5402 - accuracy: 0.9044 - val_loss: 0.9606 - val_accuracy: 0.6983\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5439 - accuracy: 0.9013 - val_loss: 0.9547 - val_accuracy: 0.7149\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5369 - accuracy: 0.9044 - val_loss: 1.0043 - val_accuracy: 0.6715\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5419 - accuracy: 0.8953 - val_loss: 0.9628 - val_accuracy: 0.6911\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5364 - accuracy: 0.9049 - val_loss: 0.9651 - val_accuracy: 0.6901\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5325 - accuracy: 0.9096 - val_loss: 0.9664 - val_accuracy: 0.7004\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5263 - accuracy: 0.9096 - val_loss: 0.9769 - val_accuracy: 0.6890\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5338 - accuracy: 0.9023 - val_loss: 0.9719 - val_accuracy: 0.6942\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5369 - accuracy: 0.8979 - val_loss: 0.9696 - val_accuracy: 0.7076\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5461 - accuracy: 0.8907 - val_loss: 0.9970 - val_accuracy: 0.6777\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5438 - accuracy: 0.8922 - val_loss: 1.0151 - val_accuracy: 0.6746\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5403 - accuracy: 0.8961 - val_loss: 1.0134 - val_accuracy: 0.6694\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5220 - accuracy: 0.9106 - val_loss: 0.9789 - val_accuracy: 0.6932\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5265 - accuracy: 0.9072 - val_loss: 0.9918 - val_accuracy: 0.6890\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5199 - accuracy: 0.9039 - val_loss: 0.9940 - val_accuracy: 0.6921\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5138 - accuracy: 0.9109 - val_loss: 0.9774 - val_accuracy: 0.7025\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5096 - accuracy: 0.9142 - val_loss: 1.0094 - val_accuracy: 0.6767\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5060 - accuracy: 0.9181 - val_loss: 0.9859 - val_accuracy: 0.6973\n","Epoch 91/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5073 - accuracy: 0.9183 - val_loss: 1.0050 - val_accuracy: 0.6798\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5130 - accuracy: 0.9085 - val_loss: 1.0118 - val_accuracy: 0.6767\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4988 - accuracy: 0.9209 - val_loss: 1.0406 - val_accuracy: 0.6694\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5066 - accuracy: 0.9137 - val_loss: 1.0224 - val_accuracy: 0.6787\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4976 - accuracy: 0.9253 - val_loss: 0.9915 - val_accuracy: 0.6932\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4978 - accuracy: 0.9222 - val_loss: 1.0006 - val_accuracy: 0.6901\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4980 - accuracy: 0.9196 - val_loss: 1.0124 - val_accuracy: 0.6829\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4914 - accuracy: 0.9245 - val_loss: 1.0008 - val_accuracy: 0.6983\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4932 - accuracy: 0.9176 - val_loss: 1.0300 - val_accuracy: 0.6787\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5003 - accuracy: 0.9114 - val_loss: 1.0038 - val_accuracy: 0.6921\n","{'loss': [0.7643947601318359, 0.7537871599197388, 0.7387393116950989, 0.7340092658996582, 0.7308757305145264, 0.7250211238861084, 0.7259439826011658, 0.7169731855392456, 0.7134884595870972, 0.7108603715896606, 0.7084081768989563, 0.7024558782577515, 0.6991228461265564, 0.7075931429862976, 0.6969667077064514, 0.6881210803985596, 0.6847435235977173, 0.6887712478637695, 0.6819438934326172, 0.681987464427948, 0.682464599609375, 0.6714184880256653, 0.6745402216911316, 0.6709362864494324, 0.6646836996078491, 0.6618812680244446, 0.665979266166687, 0.6555238962173462, 0.6762973666191101, 0.6566175818443298, 0.6478164196014404, 0.646247386932373, 0.6494941711425781, 0.6461495161056519, 0.6476230025291443, 0.6300156712532043, 0.6312478184700012, 0.6290900111198425, 0.6267958283424377, 0.6368731260299683, 0.6301518678665161, 0.6288720965385437, 0.6223861575126648, 0.610442578792572, 0.6163164377212524, 0.6213514804840088, 0.6332544088363647, 0.606452465057373, 0.6050316095352173, 0.6011649966239929, 0.5925936698913574, 0.5944709777832031, 0.5994203090667725, 0.6049178242683411, 0.589364230632782, 0.5910659432411194, 0.5819860100746155, 0.5791480541229248, 0.5760864615440369, 0.5805290341377258, 0.5742750763893127, 0.5705858469009399, 0.5915288925170898, 0.5880519151687622, 0.5629037618637085, 0.5604713559150696, 0.5574031472206116, 0.5556890964508057, 0.5516178607940674, 0.5673296451568604, 0.5495104789733887, 0.5453958511352539, 0.5402056574821472, 0.54387366771698, 0.5368531942367554, 0.5419490933418274, 0.5364049673080444, 0.5324912071228027, 0.5263314843177795, 0.5337736010551453, 0.536884605884552, 0.5461448431015015, 0.5437554717063904, 0.5402660369873047, 0.5219967365264893, 0.5264909267425537, 0.5199424028396606, 0.5137571692466736, 0.5096293091773987, 0.5060088634490967, 0.5073471069335938, 0.5129976868629456, 0.49883562326431274, 0.5066288113594055, 0.4976356029510498, 0.4978013038635254, 0.4980310797691345, 0.4914354085922241, 0.4931592047214508, 0.500308096408844], 'accuracy': [0.7909560799598694, 0.7984496355056763, 0.802842378616333, 0.8067183494567871, 0.8090439438819885, 0.8124030828475952, 0.8129199147224426, 0.8157622814178467, 0.8186046481132507, 0.8204134106636047, 0.816020667552948, 0.8317829370498657, 0.828423798084259, 0.8186046481132507, 0.8232558369636536, 0.8346253037452698, 0.8361757397651672, 0.8310077786445618, 0.8335917592048645, 0.8299741744995117, 0.8307493329048157, 0.841602087020874, 0.8397932648658752, 0.8361757397651672, 0.8418604731559753, 0.8483204245567322, 0.8403100967407227, 0.8426356315612793, 0.8286821842193604, 0.8377261161804199, 0.8542635440826416, 0.8493540287017822, 0.8527131676673889, 0.8493540287017822, 0.8475452065467834, 0.8638243079185486, 0.8563307523727417, 0.8571059703826904, 0.8614987134933472, 0.8532299995422363, 0.8576227426528931, 0.8573643565177917, 0.8635658621788025, 0.8708010315895081, 0.8604651093482971, 0.8532299995422363, 0.8521963953971863, 0.867958664894104, 0.8736433982849121, 0.8723514080047607, 0.8767442107200623, 0.8746770024299622, 0.8744186162948608, 0.8653746843338013, 0.8798449635505676, 0.8762273788452148, 0.8816537261009216, 0.882170557975769, 0.882170557975769, 0.882170557975769, 0.8873385190963745, 0.8847545385360718, 0.869767427444458, 0.8726097941398621, 0.8935400247573853, 0.8919896483421326, 0.8932816386222839, 0.8974159955978394, 0.8956072330474854, 0.880103349685669, 0.896124005317688, 0.8981912136077881, 0.9043927788734436, 0.9012919664382935, 0.9043927788734436, 0.895348846912384, 0.9049095511436462, 0.9095607399940491, 0.9095607399940491, 0.9023255705833435, 0.8979328274726868, 0.8906976580619812, 0.8922480344772339, 0.896124005317688, 0.9105943441390991, 0.9072351455688477, 0.9038759469985962, 0.9108527302742004, 0.9142118692398071, 0.9180878400802612, 0.9183462262153625, 0.908527135848999, 0.9209302067756653, 0.9136950969696045, 0.9253230094909668, 0.9222221970558167, 0.9196382164955139, 0.9245477914810181, 0.9175710678100586, 0.9113695025444031], 'val_loss': [1.019459843635559, 1.016356348991394, 1.0092109441757202, 0.9993224143981934, 0.9864259362220764, 0.9779757261276245, 0.972480058670044, 0.9678968787193298, 0.971423327922821, 0.9693780541419983, 0.9606162905693054, 0.9780677556991577, 0.9826226234436035, 0.964995265007019, 0.9978808164596558, 1.0450009107589722, 1.0404369831085205, 0.9773908257484436, 0.9831939935684204, 1.0624866485595703, 0.9803457260131836, 0.9598787426948547, 0.9735313653945923, 0.9322789907455444, 0.8904119729995728, 0.9049768447875977, 0.8960082530975342, 0.9048700928688049, 0.9770848155021667, 0.9009656310081482, 0.9002994298934937, 0.8991581201553345, 0.906022310256958, 0.9013332724571228, 0.904014527797699, 0.9074822068214417, 0.9158587455749512, 0.9130845665931702, 0.9186366200447083, 0.9306449294090271, 0.9098613858222961, 0.9443449974060059, 0.9281777739524841, 0.9345618486404419, 0.950096070766449, 0.9312358498573303, 0.9433597922325134, 0.9161019325256348, 0.9528940320014954, 0.9226726293563843, 0.9600369930267334, 0.9241769313812256, 0.931106448173523, 0.9276511073112488, 0.9622279405593872, 0.9345780611038208, 0.930076003074646, 0.9337943196296692, 0.9370713233947754, 0.9621607065200806, 0.9414564967155457, 0.9458343982696533, 1.0153950452804565, 0.9452425837516785, 0.9500572681427002, 0.9440281391143799, 0.9422170519828796, 0.9551997184753418, 1.0408515930175781, 0.9568374752998352, 0.9489880204200745, 0.947450578212738, 0.9605609774589539, 0.9546531438827515, 1.0043128728866577, 0.9627943634986877, 0.965063750743866, 0.96638423204422, 0.9769346117973328, 0.9719340205192566, 0.9696091413497925, 0.9970343708992004, 1.0151008367538452, 1.0133947134017944, 0.9789212942123413, 0.9917567372322083, 0.9939705729484558, 0.9773709177970886, 1.0094345808029175, 0.9858899116516113, 1.005017638206482, 1.011776089668274, 1.040592074394226, 1.022362232208252, 0.9915457963943481, 1.000588059425354, 1.012383222579956, 1.0007776021957397, 1.0299596786499023, 1.0038232803344727], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4958677589893341, 0.5847107172012329, 0.6518595218658447, 0.6508264541625977, 0.6311983466148376, 0.5981404781341553, 0.6002066135406494, 0.6188016533851624, 0.586776852607727, 0.5919421315193176, 0.6177685856819153, 0.5991735458374023, 0.577479362487793, 0.5950413346290588, 0.6332644820213318, 0.6353305578231812, 0.6167355179786682, 0.64462810754776, 0.6570248007774353, 0.6621900796890259, 0.6797520518302917, 0.6983470916748047, 0.6962810158729553, 0.7169421315193176, 0.6993801593780518, 0.672520637512207, 0.6983470916748047, 0.7138429880142212, 0.711776852607727, 0.7076446413993835, 0.7128099203109741, 0.7169421315193176, 0.7035123705863953, 0.6973140239715576, 0.6952479481697083, 0.7045454382896423, 0.6849173307418823, 0.711776852607727, 0.6797520518302917, 0.6890496015548706, 0.6952479481697083, 0.6745867729187012, 0.6993801593780518, 0.6890496015548706, 0.7086777091026306, 0.6756198406219482, 0.6973140239715576, 0.6818181872367859, 0.7128099203109741, 0.6942148804664612, 0.7066115736961365, 0.6776859760284424, 0.6983470916748047, 0.7066115736961365, 0.7004132270812988, 0.6973140239715576, 0.6787189841270447, 0.6962810158729553, 0.7014462947845459, 0.672520637512207, 0.702479362487793, 0.692148745059967, 0.7055785059928894, 0.7035123705863953, 0.6962810158729553, 0.6621900796890259, 0.6993801593780518, 0.71074378490448, 0.7014462947845459, 0.6983470916748047, 0.7148760557174683, 0.6714876294136047, 0.69111567735672, 0.6900826692581177, 0.7004132270812988, 0.6890496015548706, 0.6942148804664612, 0.7076446413993835, 0.6776859760284424, 0.6745867729187012, 0.6694214940071106, 0.6931818127632141, 0.6890496015548706, 0.692148745059967, 0.702479362487793, 0.6766529083251953, 0.6973140239715576, 0.6797520518302917, 0.6766529083251953, 0.6694214940071106, 0.6787189841270447, 0.6931818127632141, 0.6900826692581177, 0.682851254940033, 0.6983470916748047, 0.6787189841270447, 0.692148745059967]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 30ms/step - loss: 0.5738 - accuracy: 0.8769 - val_loss: 0.9899 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.5370 - accuracy: 0.8984"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 0.5501 - accuracy: 0.8839 - val_loss: 0.9871 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5463 - accuracy: 0.8885 - val_loss: 0.9872 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5356 - accuracy: 0.8936 - val_loss: 0.9781 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5278 - accuracy: 0.9006 - val_loss: 0.9635 - val_accuracy: 0.5140\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5229 - accuracy: 0.9027 - val_loss: 0.9537 - val_accuracy: 0.5312\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5200 - accuracy: 0.9114 - val_loss: 0.9299 - val_accuracy: 0.5884\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5187 - accuracy: 0.9065 - val_loss: 0.9232 - val_accuracy: 0.6164\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5351 - accuracy: 0.8925 - val_loss: 0.9206 - val_accuracy: 0.6045\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5380 - accuracy: 0.8957 - val_loss: 0.9077 - val_accuracy: 0.6509\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5096 - accuracy: 0.9114 - val_loss: 0.9049 - val_accuracy: 0.6412\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5038 - accuracy: 0.9162 - val_loss: 0.9055 - val_accuracy: 0.6466\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5041 - accuracy: 0.9114 - val_loss: 0.9159 - val_accuracy: 0.6369\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5090 - accuracy: 0.9103 - val_loss: 1.0046 - val_accuracy: 0.6056\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5093 - accuracy: 0.9122 - val_loss: 0.9214 - val_accuracy: 0.6519\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4968 - accuracy: 0.9165 - val_loss: 1.0068 - val_accuracy: 0.6164\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4992 - accuracy: 0.9130 - val_loss: 1.0452 - val_accuracy: 0.6196\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5018 - accuracy: 0.9111 - val_loss: 1.1372 - val_accuracy: 0.6067\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5047 - accuracy: 0.9103 - val_loss: 1.0801 - val_accuracy: 0.6315\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4846 - accuracy: 0.9251 - val_loss: 1.0598 - val_accuracy: 0.6498\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4819 - accuracy: 0.9273 - val_loss: 0.9506 - val_accuracy: 0.6940\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4812 - accuracy: 0.9291 - val_loss: 0.9399 - val_accuracy: 0.7069\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4829 - accuracy: 0.9259 - val_loss: 0.9352 - val_accuracy: 0.7112\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4767 - accuracy: 0.9300 - val_loss: 0.8796 - val_accuracy: 0.7338\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4770 - accuracy: 0.9305 - val_loss: 0.8851 - val_accuracy: 0.7371\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4859 - accuracy: 0.9205 - val_loss: 0.8536 - val_accuracy: 0.7403\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5176 - accuracy: 0.8963 - val_loss: 0.8777 - val_accuracy: 0.7295\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4826 - accuracy: 0.9181 - val_loss: 0.8879 - val_accuracy: 0.7414\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4709 - accuracy: 0.9351 - val_loss: 0.8520 - val_accuracy: 0.7500\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4614 - accuracy: 0.9370 - val_loss: 0.8560 - val_accuracy: 0.7446\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4627 - accuracy: 0.9367 - val_loss: 0.8603 - val_accuracy: 0.7511\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4651 - accuracy: 0.9359 - val_loss: 0.8700 - val_accuracy: 0.7543\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4648 - accuracy: 0.9348 - val_loss: 0.8636 - val_accuracy: 0.7511\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4532 - accuracy: 0.9415 - val_loss: 0.8906 - val_accuracy: 0.7328\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4616 - accuracy: 0.9378 - val_loss: 0.8677 - val_accuracy: 0.7435\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4664 - accuracy: 0.9318 - val_loss: 0.8711 - val_accuracy: 0.7414\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4552 - accuracy: 0.9372 - val_loss: 0.8684 - val_accuracy: 0.7554\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4550 - accuracy: 0.9397 - val_loss: 0.8717 - val_accuracy: 0.7500\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4525 - accuracy: 0.9413 - val_loss: 0.8882 - val_accuracy: 0.7317\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4482 - accuracy: 0.9421 - val_loss: 0.9238 - val_accuracy: 0.7295\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4481 - accuracy: 0.9410 - val_loss: 0.8821 - val_accuracy: 0.7446\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4464 - accuracy: 0.9440 - val_loss: 0.8811 - val_accuracy: 0.7468\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4410 - accuracy: 0.9472 - val_loss: 0.9333 - val_accuracy: 0.7252\n","Epoch 44/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4567 - accuracy: 0.9340 - val_loss: 0.9209 - val_accuracy: 0.7274\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4490 - accuracy: 0.9426 - val_loss: 0.9804 - val_accuracy: 0.7134\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4441 - accuracy: 0.9418 - val_loss: 0.8967 - val_accuracy: 0.7425\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4427 - accuracy: 0.9421 - val_loss: 0.8933 - val_accuracy: 0.7457\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4415 - accuracy: 0.9421 - val_loss: 0.9075 - val_accuracy: 0.7543\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4404 - accuracy: 0.9448 - val_loss: 0.9464 - val_accuracy: 0.7198\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4358 - accuracy: 0.9448 - val_loss: 0.8954 - val_accuracy: 0.7403\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4383 - accuracy: 0.9421 - val_loss: 0.9278 - val_accuracy: 0.7295\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4280 - accuracy: 0.9542 - val_loss: 0.9197 - val_accuracy: 0.7306\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4245 - accuracy: 0.9553 - val_loss: 0.9139 - val_accuracy: 0.7371\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4338 - accuracy: 0.9475 - val_loss: 0.8975 - val_accuracy: 0.7425\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.9496 - val_loss: 0.9112 - val_accuracy: 0.7349\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.9512 - val_loss: 0.9149 - val_accuracy: 0.7263\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4157 - accuracy: 0.9601 - val_loss: 0.9098 - val_accuracy: 0.7446\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4183 - accuracy: 0.9569 - val_loss: 0.9177 - val_accuracy: 0.7371\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4150 - accuracy: 0.9558 - val_loss: 0.9190 - val_accuracy: 0.7252\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4329 - accuracy: 0.9426 - val_loss: 0.9579 - val_accuracy: 0.7435\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4345 - accuracy: 0.9415 - val_loss: 0.9828 - val_accuracy: 0.7338\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4332 - accuracy: 0.9386 - val_loss: 0.9200 - val_accuracy: 0.7349\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4185 - accuracy: 0.9469 - val_loss: 0.9221 - val_accuracy: 0.7338\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.9580 - val_loss: 0.9554 - val_accuracy: 0.7263\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4062 - accuracy: 0.9580 - val_loss: 0.9346 - val_accuracy: 0.7306\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4018 - accuracy: 0.9623 - val_loss: 0.9284 - val_accuracy: 0.7349\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3985 - accuracy: 0.9647 - val_loss: 0.9475 - val_accuracy: 0.7338\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4071 - accuracy: 0.9569 - val_loss: 1.0403 - val_accuracy: 0.7015\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4046 - accuracy: 0.9588 - val_loss: 0.9645 - val_accuracy: 0.7306\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3967 - accuracy: 0.9639 - val_loss: 0.9333 - val_accuracy: 0.7349\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3987 - accuracy: 0.9623 - val_loss: 0.9660 - val_accuracy: 0.7284\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3997 - accuracy: 0.9617 - val_loss: 0.9381 - val_accuracy: 0.7392\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3992 - accuracy: 0.9591 - val_loss: 0.9574 - val_accuracy: 0.7209\n","Epoch 74/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3951 - accuracy: 0.9599 - val_loss: 0.9769 - val_accuracy: 0.7220\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.9607 - val_loss: 0.9496 - val_accuracy: 0.7360\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3906 - accuracy: 0.9644 - val_loss: 0.9524 - val_accuracy: 0.7392\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3930 - accuracy: 0.9596 - val_loss: 0.9767 - val_accuracy: 0.7306\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4075 - accuracy: 0.9491 - val_loss: 0.9620 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3983 - accuracy: 0.9566 - val_loss: 1.0163 - val_accuracy: 0.7381\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4205 - accuracy: 0.9461 - val_loss: 0.9937 - val_accuracy: 0.7317\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3965 - accuracy: 0.9572 - val_loss: 0.9751 - val_accuracy: 0.7295\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3842 - accuracy: 0.9661 - val_loss: 0.9651 - val_accuracy: 0.7403\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3862 - accuracy: 0.9650 - val_loss: 0.9610 - val_accuracy: 0.7349\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.9652 - val_loss: 0.9689 - val_accuracy: 0.7295\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3799 - accuracy: 0.9682 - val_loss: 0.9727 - val_accuracy: 0.7500\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3762 - accuracy: 0.9688 - val_loss: 0.9754 - val_accuracy: 0.7306\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3778 - accuracy: 0.9666 - val_loss: 0.9779 - val_accuracy: 0.7328\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3727 - accuracy: 0.9717 - val_loss: 0.9874 - val_accuracy: 0.7328\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3728 - accuracy: 0.9674 - val_loss: 0.9865 - val_accuracy: 0.7295\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3700 - accuracy: 0.9714 - val_loss: 0.9866 - val_accuracy: 0.7241\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3705 - accuracy: 0.9704 - val_loss: 0.9895 - val_accuracy: 0.7317\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3750 - accuracy: 0.9671 - val_loss: 1.0116 - val_accuracy: 0.7403\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3763 - accuracy: 0.9690 - val_loss: 0.9956 - val_accuracy: 0.7457\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.9709 - val_loss: 0.9957 - val_accuracy: 0.7328\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3654 - accuracy: 0.9728 - val_loss: 0.9932 - val_accuracy: 0.7338\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3638 - accuracy: 0.9714 - val_loss: 1.0012 - val_accuracy: 0.7306\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3786 - accuracy: 0.9644 - val_loss: 0.9965 - val_accuracy: 0.7306\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3746 - accuracy: 0.9671 - val_loss: 1.0015 - val_accuracy: 0.7295\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3672 - accuracy: 0.9725 - val_loss: 1.0425 - val_accuracy: 0.7166\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3639 - accuracy: 0.9736 - val_loss: 1.0158 - val_accuracy: 0.7144\n","{'loss': [0.5738043189048767, 0.550058126449585, 0.5463024973869324, 0.535613477230072, 0.527778148651123, 0.5228729844093323, 0.5199530720710754, 0.5186748504638672, 0.5350794792175293, 0.5379993319511414, 0.509583592414856, 0.5037623047828674, 0.5041478872299194, 0.5090203881263733, 0.5093352794647217, 0.49678900837898254, 0.4991879165172577, 0.5017770528793335, 0.5046744346618652, 0.48458248376846313, 0.48191574215888977, 0.48118144273757935, 0.48287221789360046, 0.4766516387462616, 0.47700509428977966, 0.4858897030353546, 0.5176038146018982, 0.482649028301239, 0.4708890914916992, 0.461445689201355, 0.46274346113204956, 0.465132474899292, 0.46478596329689026, 0.45316123962402344, 0.4616219401359558, 0.4663597643375397, 0.4552468955516815, 0.45499375462532043, 0.4524799585342407, 0.4482153654098511, 0.44814246892929077, 0.44638970494270325, 0.440952330827713, 0.4566974937915802, 0.44902411103248596, 0.44406163692474365, 0.4427013099193573, 0.4415467083454132, 0.44037607312202454, 0.4357694089412689, 0.4383407235145569, 0.42797911167144775, 0.42451781034469604, 0.4337628185749054, 0.42841559648513794, 0.42653805017471313, 0.41568723320961, 0.4182787835597992, 0.4149647355079651, 0.4328818917274475, 0.4345059096813202, 0.4331696927547455, 0.418539434671402, 0.40877416729927063, 0.4062291383743286, 0.40182358026504517, 0.3985157310962677, 0.4070826768875122, 0.4046427011489868, 0.3966706097126007, 0.3987411558628082, 0.3996508717536926, 0.3992188572883606, 0.3950826823711395, 0.3951534926891327, 0.3906210660934448, 0.3930276036262512, 0.40751227736473083, 0.3982521891593933, 0.4205048680305481, 0.3965158760547638, 0.3841714560985565, 0.38619834184646606, 0.3824011981487274, 0.3798954486846924, 0.37621551752090454, 0.37777507305145264, 0.37272512912750244, 0.3727720379829407, 0.37001216411590576, 0.3704502284526825, 0.37495458126068115, 0.3762895464897156, 0.3684479594230652, 0.3653601408004761, 0.36376503109931946, 0.3786049783229828, 0.374630868434906, 0.3672180473804474, 0.3638645112514496], 'accuracy': [0.8768857717514038, 0.8838900923728943, 0.8884698152542114, 0.8935883641242981, 0.9005926847457886, 0.9027478694915771, 0.9113685488700867, 0.9065194129943848, 0.8925107717514038, 0.8957435488700867, 0.9113685488700867, 0.9162176847457886, 0.9113685488700867, 0.9102909564971924, 0.9121767282485962, 0.9164870977401733, 0.9129849076271057, 0.9110991358757019, 0.9102909564971924, 0.9251077771186829, 0.9272629022598267, 0.9291487336158752, 0.9259159564971924, 0.9299569129943848, 0.9304956793785095, 0.920527994632721, 0.8962823152542114, 0.9181034564971924, 0.9350754022598267, 0.9369612336158752, 0.9366918206214905, 0.935883641242981, 0.9348060488700867, 0.9415409564971924, 0.9377694129943848, 0.9318426847457886, 0.9372305870056152, 0.9396551847457886, 0.9412715435028076, 0.9420797228813171, 0.9410021305084229, 0.943965494632721, 0.9471982717514038, 0.9339978694915771, 0.9426185488700867, 0.9418103694915771, 0.9420797228813171, 0.9420797228813171, 0.9447737336158752, 0.9447737336158752, 0.9420797228813171, 0.9542025923728943, 0.9552801847457886, 0.9474676847457886, 0.9496228694915771, 0.9512392282485962, 0.9601293206214905, 0.9568965435028076, 0.9558189511299133, 0.9426185488700867, 0.9415409564971924, 0.9385775923728943, 0.946928858757019, 0.9579741358757019, 0.9579741358757019, 0.962284505367279, 0.9647090435028076, 0.9568965435028076, 0.9587823152542114, 0.9639008641242981, 0.962284505367279, 0.9617456793785095, 0.9590517282485962, 0.9598599076271057, 0.9606680870056152, 0.9644396305084229, 0.959590494632721, 0.9490840435028076, 0.9566271305084229, 0.9461206793785095, 0.9571659564971924, 0.9660560488700867, 0.9649784564971924, 0.9652478694915771, 0.9682112336158752, 0.96875, 0.9665948152542114, 0.9717133641242981, 0.967402994632721, 0.9714439511299133, 0.970366358757019, 0.967133641242981, 0.9690194129943848, 0.9709051847457886, 0.9727909564971924, 0.9714439511299133, 0.9644396305084229, 0.967133641242981, 0.9725215435028076, 0.9735991358757019], 'val_loss': [0.9898648262023926, 0.9870596528053284, 0.987174928188324, 0.9780647158622742, 0.9634634852409363, 0.9537034034729004, 0.9298970699310303, 0.9232478737831116, 0.9205873608589172, 0.9077120423316956, 0.9049174189567566, 0.9054630398750305, 0.915917694568634, 1.004623293876648, 0.9213689565658569, 1.0068365335464478, 1.0451804399490356, 1.1371620893478394, 1.080121397972107, 1.0598132610321045, 0.9506404995918274, 0.9399319887161255, 0.9351520538330078, 0.8795958161354065, 0.8851358890533447, 0.853632390499115, 0.8776875734329224, 0.8878961801528931, 0.8519873023033142, 0.855980396270752, 0.8603160977363586, 0.8700167536735535, 0.8635645508766174, 0.8906199336051941, 0.8676583766937256, 0.8710632920265198, 0.8683711886405945, 0.87173992395401, 0.8881627917289734, 0.9238113760948181, 0.8820892572402954, 0.8811404705047607, 0.9333387613296509, 0.9209399819374084, 0.9803942441940308, 0.8966928124427795, 0.8933240175247192, 0.9075273871421814, 0.9463557600975037, 0.8953895568847656, 0.9278410077095032, 0.9197458624839783, 0.913882315158844, 0.8974916934967041, 0.911228358745575, 0.9149135947227478, 0.9097782373428345, 0.9176849126815796, 0.9189984798431396, 0.957912802696228, 0.9828102588653564, 0.9200276136398315, 0.9220547676086426, 0.9554368257522583, 0.9345619082450867, 0.9284036755561829, 0.9475057721138, 1.040279746055603, 0.9644866585731506, 0.9332544803619385, 0.9660043120384216, 0.9380603432655334, 0.957435131072998, 0.976908802986145, 0.9495904445648193, 0.952388346195221, 0.9767096042633057, 0.9619964957237244, 1.0163289308547974, 0.9936954975128174, 0.9751366376876831, 0.9650728702545166, 0.9609991312026978, 0.9688716530799866, 0.9727206826210022, 0.9753679633140564, 0.9779446125030518, 0.9873581528663635, 0.9865413904190063, 0.9865972995758057, 0.9894729256629944, 1.0115690231323242, 0.9956470131874084, 0.9956920742988586, 0.9931871294975281, 1.001184344291687, 0.9965004920959473, 1.0014842748641968, 1.0425233840942383, 1.0157681703567505], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4881465435028076, 0.514008641242981, 0.53125, 0.5883620977401733, 0.6163793206214905, 0.6045258641242981, 0.6508620977401733, 0.6411637663841248, 0.6465517282485962, 0.6368534564971924, 0.6056034564971924, 0.6519396305084229, 0.6163793206214905, 0.6196120977401733, 0.6066810488700867, 0.631465494632721, 0.649784505367279, 0.693965494632721, 0.7068965435028076, 0.7112069129943848, 0.7338362336158752, 0.7370689511299133, 0.7403017282485962, 0.7295258641242981, 0.7413793206214905, 0.75, 0.7446120977401733, 0.7510775923728943, 0.7543103694915771, 0.7510775923728943, 0.732758641242981, 0.743534505367279, 0.7413793206214905, 0.7553879022598267, 0.75, 0.7316810488700867, 0.7295258641242981, 0.7446120977401733, 0.7467672228813171, 0.725215494632721, 0.7273706793785095, 0.7133620977401733, 0.7424569129943848, 0.7456896305084229, 0.7543103694915771, 0.7198275923728943, 0.7403017282485962, 0.7295258641242981, 0.7306034564971924, 0.7370689511299133, 0.7424569129943848, 0.7349137663841248, 0.7262930870056152, 0.7446120977401733, 0.7370689511299133, 0.725215494632721, 0.743534505367279, 0.7338362336158752, 0.7349137663841248, 0.7338362336158752, 0.7262930870056152, 0.7306034564971924, 0.7349137663841248, 0.7338362336158752, 0.701508641242981, 0.7306034564971924, 0.7349137663841248, 0.7284482717514038, 0.7392241358757019, 0.7209051847457886, 0.7219827771186829, 0.735991358757019, 0.7392241358757019, 0.7306034564971924, 0.743534505367279, 0.7381465435028076, 0.7316810488700867, 0.7295258641242981, 0.7403017282485962, 0.7349137663841248, 0.7295258641242981, 0.75, 0.7306034564971924, 0.732758641242981, 0.732758641242981, 0.7295258641242981, 0.7241379022598267, 0.7316810488700867, 0.7403017282485962, 0.7456896305084229, 0.732758641242981, 0.7338362336158752, 0.7306034564971924, 0.7306034564971924, 0.7295258641242981, 0.7165948152542114, 0.7144396305084229]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.6022 - accuracy: 0.8513"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 41ms/step - loss: 0.6010 - accuracy: 0.8523 - val_loss: 0.9851 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5572 - accuracy: 0.8789 - val_loss: 0.9839 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5598 - accuracy: 0.8820 - val_loss: 0.9790 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5460 - accuracy: 0.8879 - val_loss: 0.9757 - val_accuracy: 0.4966\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5394 - accuracy: 0.8976 - val_loss: 0.9705 - val_accuracy: 0.5011\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5365 - accuracy: 0.8945 - val_loss: 0.9548 - val_accuracy: 0.5238\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5305 - accuracy: 0.9029 - val_loss: 0.9347 - val_accuracy: 0.5701\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5279 - accuracy: 0.9001 - val_loss: 0.9274 - val_accuracy: 0.5871\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5276 - accuracy: 0.8973 - val_loss: 0.9108 - val_accuracy: 0.6391\n","Epoch 10/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5298 - accuracy: 0.8947 - val_loss: 0.9083 - val_accuracy: 0.6324\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5166 - accuracy: 0.9075 - val_loss: 0.9037 - val_accuracy: 0.6493\n","Epoch 12/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5170 - accuracy: 0.9055 - val_loss: 0.8974 - val_accuracy: 0.6527\n","Epoch 13/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.5090 - accuracy: 0.9160 - val_loss: 0.8948 - val_accuracy: 0.6595\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5053 - accuracy: 0.9194 - val_loss: 0.8961 - val_accuracy: 0.6640\n","Epoch 15/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5052 - accuracy: 0.9151 - val_loss: 0.9297 - val_accuracy: 0.6335\n","Epoch 16/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5006 - accuracy: 0.9171 - val_loss: 0.9495 - val_accuracy: 0.6290\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5065 - accuracy: 0.9114 - val_loss: 0.9482 - val_accuracy: 0.6380\n","Epoch 18/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5017 - accuracy: 0.9117 - val_loss: 1.0140 - val_accuracy: 0.6222\n","Epoch 19/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5208 - accuracy: 0.9004 - val_loss: 0.9050 - val_accuracy: 0.6855\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5012 - accuracy: 0.9083 - val_loss: 1.0172 - val_accuracy: 0.6482\n","Epoch 21/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4937 - accuracy: 0.9148 - val_loss: 0.9937 - val_accuracy: 0.6640\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4873 - accuracy: 0.9208 - val_loss: 0.9434 - val_accuracy: 0.6934\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4834 - accuracy: 0.9261 - val_loss: 0.8982 - val_accuracy: 0.7048\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4838 - accuracy: 0.9242 - val_loss: 0.9046 - val_accuracy: 0.7127\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4887 - accuracy: 0.9230 - val_loss: 0.8596 - val_accuracy: 0.7296\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4797 - accuracy: 0.9278 - val_loss: 0.8741 - val_accuracy: 0.7319\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4713 - accuracy: 0.9344 - val_loss: 0.8051 - val_accuracy: 0.7534\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4752 - accuracy: 0.9298 - val_loss: 0.8673 - val_accuracy: 0.7376\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4768 - accuracy: 0.9253 - val_loss: 0.8000 - val_accuracy: 0.7715\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4690 - accuracy: 0.9312 - val_loss: 0.8142 - val_accuracy: 0.7500\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4652 - accuracy: 0.9360 - val_loss: 0.8016 - val_accuracy: 0.7590\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4640 - accuracy: 0.9338 - val_loss: 0.7985 - val_accuracy: 0.7670\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4607 - accuracy: 0.9363 - val_loss: 0.8008 - val_accuracy: 0.7704\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4554 - accuracy: 0.9386 - val_loss: 0.8135 - val_accuracy: 0.7511\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4671 - accuracy: 0.9329 - val_loss: 0.8141 - val_accuracy: 0.7670\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4620 - accuracy: 0.9318 - val_loss: 0.8332 - val_accuracy: 0.7500\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4763 - accuracy: 0.9177 - val_loss: 0.8485 - val_accuracy: 0.7545\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4707 - accuracy: 0.9196 - val_loss: 0.8382 - val_accuracy: 0.7466\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4591 - accuracy: 0.9327 - val_loss: 0.8586 - val_accuracy: 0.7342\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4611 - accuracy: 0.9304 - val_loss: 0.8123 - val_accuracy: 0.7692\n","Epoch 41/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4450 - accuracy: 0.9431 - val_loss: 0.8364 - val_accuracy: 0.7466\n","Epoch 42/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4473 - accuracy: 0.9417 - val_loss: 0.8262 - val_accuracy: 0.7636\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4545 - accuracy: 0.9332 - val_loss: 0.8268 - val_accuracy: 0.7568\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4621 - accuracy: 0.9259 - val_loss: 0.8599 - val_accuracy: 0.7455\n","Epoch 45/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4752 - accuracy: 0.9100 - val_loss: 0.8249 - val_accuracy: 0.7704\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4404 - accuracy: 0.9431 - val_loss: 0.8268 - val_accuracy: 0.7624\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4317 - accuracy: 0.9488 - val_loss: 0.8293 - val_accuracy: 0.7670\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4383 - accuracy: 0.9445 - val_loss: 0.8535 - val_accuracy: 0.7477\n","Epoch 49/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4287 - accuracy: 0.9482 - val_loss: 0.8374 - val_accuracy: 0.7624\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4255 - accuracy: 0.9516 - val_loss: 0.8474 - val_accuracy: 0.7602\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.9437 - val_loss: 0.8457 - val_accuracy: 0.7568\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4242 - accuracy: 0.9519 - val_loss: 0.8725 - val_accuracy: 0.7421\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4262 - accuracy: 0.9493 - val_loss: 0.8474 - val_accuracy: 0.7568\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4285 - accuracy: 0.9479 - val_loss: 0.8430 - val_accuracy: 0.7602\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4179 - accuracy: 0.9527 - val_loss: 0.8652 - val_accuracy: 0.7545\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.9505 - val_loss: 0.8778 - val_accuracy: 0.7443\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4229 - accuracy: 0.9499 - val_loss: 0.8521 - val_accuracy: 0.7579\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4214 - accuracy: 0.9525 - val_loss: 0.8557 - val_accuracy: 0.7545\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.9488 - val_loss: 0.8853 - val_accuracy: 0.7410\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4189 - accuracy: 0.9533 - val_loss: 0.8853 - val_accuracy: 0.7534\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4154 - accuracy: 0.9547 - val_loss: 0.8815 - val_accuracy: 0.7466\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4090 - accuracy: 0.9607 - val_loss: 0.8678 - val_accuracy: 0.7557\n","Epoch 63/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4071 - accuracy: 0.9610 - val_loss: 0.9038 - val_accuracy: 0.7443\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4104 - accuracy: 0.9505 - val_loss: 0.8683 - val_accuracy: 0.7590\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4136 - accuracy: 0.9533 - val_loss: 0.9053 - val_accuracy: 0.7443\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4038 - accuracy: 0.9584 - val_loss: 0.8766 - val_accuracy: 0.7500\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4003 - accuracy: 0.9578 - val_loss: 0.8839 - val_accuracy: 0.7466\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3989 - accuracy: 0.9643 - val_loss: 0.8867 - val_accuracy: 0.7523\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3985 - accuracy: 0.9598 - val_loss: 0.8761 - val_accuracy: 0.7545\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3986 - accuracy: 0.9624 - val_loss: 0.8816 - val_accuracy: 0.7466\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3971 - accuracy: 0.9618 - val_loss: 0.8851 - val_accuracy: 0.7523\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4018 - accuracy: 0.9553 - val_loss: 0.8983 - val_accuracy: 0.7443\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3925 - accuracy: 0.9638 - val_loss: 0.8956 - val_accuracy: 0.7466\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3901 - accuracy: 0.9626 - val_loss: 0.8869 - val_accuracy: 0.7579\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3912 - accuracy: 0.9598 - val_loss: 0.9105 - val_accuracy: 0.7466\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3979 - accuracy: 0.9561 - val_loss: 0.9102 - val_accuracy: 0.7443\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3848 - accuracy: 0.9672 - val_loss: 0.8996 - val_accuracy: 0.7466\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3957 - accuracy: 0.9610 - val_loss: 0.9110 - val_accuracy: 0.7466\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3871 - accuracy: 0.9646 - val_loss: 0.9031 - val_accuracy: 0.7545\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3829 - accuracy: 0.9649 - val_loss: 0.9080 - val_accuracy: 0.7500\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3845 - accuracy: 0.9655 - val_loss: 0.9526 - val_accuracy: 0.7466\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3792 - accuracy: 0.9677 - val_loss: 0.9152 - val_accuracy: 0.7477\n","Epoch 83/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3821 - accuracy: 0.9652 - val_loss: 0.9278 - val_accuracy: 0.7523\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3762 - accuracy: 0.9675 - val_loss: 0.9785 - val_accuracy: 0.7183\n","Epoch 85/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4049 - accuracy: 0.9505 - val_loss: 0.9655 - val_accuracy: 0.7262\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3810 - accuracy: 0.9615 - val_loss: 0.9147 - val_accuracy: 0.7489\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3768 - accuracy: 0.9680 - val_loss: 0.9197 - val_accuracy: 0.7568\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3747 - accuracy: 0.9649 - val_loss: 0.9470 - val_accuracy: 0.7421\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3803 - accuracy: 0.9643 - val_loss: 0.9785 - val_accuracy: 0.7330\n","Epoch 90/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4055 - accuracy: 0.9474 - val_loss: 0.9388 - val_accuracy: 0.7523\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3762 - accuracy: 0.9680 - val_loss: 0.9527 - val_accuracy: 0.7421\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3783 - accuracy: 0.9626 - val_loss: 0.9440 - val_accuracy: 0.7466\n","Epoch 93/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3689 - accuracy: 0.9692 - val_loss: 0.9463 - val_accuracy: 0.7364\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3703 - accuracy: 0.9686 - val_loss: 0.9444 - val_accuracy: 0.7511\n","Epoch 95/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3669 - accuracy: 0.9700 - val_loss: 0.9918 - val_accuracy: 0.7274\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3881 - accuracy: 0.9573 - val_loss: 1.0149 - val_accuracy: 0.7262\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3853 - accuracy: 0.9573 - val_loss: 0.9605 - val_accuracy: 0.7376\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3628 - accuracy: 0.9723 - val_loss: 0.9433 - val_accuracy: 0.7511\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3615 - accuracy: 0.9709 - val_loss: 0.9866 - val_accuracy: 0.7398\n","Epoch 100/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3624 - accuracy: 0.9720 - val_loss: 0.9542 - val_accuracy: 0.7477\n","{'loss': [0.6010209321975708, 0.5571668744087219, 0.5597997307777405, 0.5459731221199036, 0.539395809173584, 0.5365337133407593, 0.5305113792419434, 0.5278999209403992, 0.5275766849517822, 0.5297841429710388, 0.5166310667991638, 0.5170010328292847, 0.5089794993400574, 0.5053142309188843, 0.5052155256271362, 0.5006171464920044, 0.5064701437950134, 0.501720130443573, 0.5208013653755188, 0.5011873841285706, 0.49371039867401123, 0.48725825548171997, 0.4833904504776001, 0.4837881028652191, 0.4886667728424072, 0.47966471314430237, 0.4713173508644104, 0.4751952588558197, 0.4768337905406952, 0.4689694344997406, 0.4652288854122162, 0.46403640508651733, 0.460737943649292, 0.45535650849342346, 0.4670911133289337, 0.4619678854942322, 0.4763033092021942, 0.4706929922103882, 0.4591023027896881, 0.46105408668518066, 0.44501665234565735, 0.44728726148605347, 0.4544534385204315, 0.4620746374130249, 0.4752017557621002, 0.4404352605342865, 0.4316680431365967, 0.438254177570343, 0.4287284016609192, 0.4255031943321228, 0.4385290741920471, 0.4242269694805145, 0.4261791706085205, 0.42849987745285034, 0.4178657829761505, 0.4180792570114136, 0.422882616519928, 0.4214477241039276, 0.4227091372013092, 0.41887038946151733, 0.4153726100921631, 0.40895429253578186, 0.4070797562599182, 0.4104083478450775, 0.4135826528072357, 0.4038265347480774, 0.4002503454685211, 0.39886149764060974, 0.39845210313796997, 0.3985958397388458, 0.3970673978328705, 0.4017680585384369, 0.3924776017665863, 0.390063613653183, 0.3911808431148529, 0.3978685438632965, 0.38478970527648926, 0.3957192301750183, 0.3870844542980194, 0.3828950524330139, 0.384456604719162, 0.37917858362197876, 0.3821244537830353, 0.37617218494415283, 0.4049133360385895, 0.3809832036495209, 0.37677568197250366, 0.37465912103652954, 0.3802594244480133, 0.405489981174469, 0.37624701857566833, 0.37833961844444275, 0.3689408004283905, 0.37033897638320923, 0.3669087588787079, 0.3880619406700134, 0.38526207208633423, 0.3628442585468292, 0.3615334630012512, 0.362445205450058], 'accuracy': [0.852292001247406, 0.8788907527923584, 0.8820033669471741, 0.8879456520080566, 0.8975664973258972, 0.8944538831710815, 0.9029428362846375, 0.9001131653785706, 0.8972835540771484, 0.8947368264198303, 0.9074702858924866, 0.9054895043373108, 0.9159592390060425, 0.9193548560142517, 0.9151103496551514, 0.9170911312103271, 0.9114317893981934, 0.9117147922515869, 0.9003961682319641, 0.9083191752433777, 0.9148274064064026, 0.9207696914672852, 0.9261460304260254, 0.9241652488708496, 0.9230334162712097, 0.9278438091278076, 0.9343519806861877, 0.9298245906829834, 0.9252971410751343, 0.9312393665313721, 0.9360498189926147, 0.9337860941886902, 0.9363327622413635, 0.9385964870452881, 0.9329372048377991, 0.9318053126335144, 0.9176570177078247, 0.9196377992630005, 0.9326542019844055, 0.930390477180481, 0.9431239366531372, 0.9417091012001038, 0.9332201480865479, 0.9258630275726318, 0.9100169539451599, 0.9431239366531372, 0.9487832188606262, 0.9445387721061707, 0.9482173323631287, 0.9516128897666931, 0.9436898827552795, 0.9518958926200867, 0.9493491649627686, 0.9479343295097351, 0.9527447819709778, 0.9504810571670532, 0.9499151110649109, 0.9524617791175842, 0.9487832188606262, 0.9533106684684753, 0.9547255039215088, 0.9606677889823914, 0.9609507918357849, 0.9504810571670532, 0.9533106684684753, 0.9584040641784668, 0.9578381180763245, 0.9643463492393494, 0.9598188996315002, 0.9623655676841736, 0.961799681186676, 0.9552914500236511, 0.963780403137207, 0.9626485705375671, 0.9598188996315002, 0.9561403393745422, 0.9671760201454163, 0.9609507918357849, 0.9646292924880981, 0.9649122953414917, 0.965478241443634, 0.9677419066429138, 0.9651952385902405, 0.967458963394165, 0.9504810571670532, 0.9615166783332825, 0.9680249094963074, 0.9649122953414917, 0.9643463492393494, 0.9473684430122375, 0.9680249094963074, 0.9626485705375671, 0.9691567420959473, 0.9685908555984497, 0.9700056314468384, 0.9572722315788269, 0.9572722315788269, 0.9722693562507629, 0.9708545804023743, 0.9719864130020142], 'val_loss': [0.9850713014602661, 0.983915388584137, 0.978976845741272, 0.9756975173950195, 0.9704992771148682, 0.9548292756080627, 0.9346875548362732, 0.9274430274963379, 0.9108484387397766, 0.908327043056488, 0.9037254452705383, 0.8973725438117981, 0.8948473334312439, 0.8961010575294495, 0.9297181963920593, 0.9495227336883545, 0.9481993317604065, 1.0140049457550049, 0.9050289392471313, 1.017193078994751, 0.9936705827713013, 0.9434130787849426, 0.8981685042381287, 0.9046320915222168, 0.8596163392066956, 0.8741089105606079, 0.8050698637962341, 0.8673208951950073, 0.7999534010887146, 0.814222514629364, 0.8015541434288025, 0.7984911203384399, 0.8007760643959045, 0.8135097622871399, 0.8140738606452942, 0.8332216143608093, 0.8485147953033447, 0.8381748199462891, 0.8586181998252869, 0.8123474717140198, 0.8364042639732361, 0.8262022733688354, 0.8268219828605652, 0.8598958849906921, 0.8249473571777344, 0.8268402218818665, 0.8293419480323792, 0.8535203337669373, 0.837365448474884, 0.847395658493042, 0.8457341194152832, 0.8724552989006042, 0.8473973274230957, 0.8429780602455139, 0.8652313947677612, 0.8778057098388672, 0.8521271347999573, 0.8556845784187317, 0.8852626085281372, 0.8852993845939636, 0.8815426230430603, 0.8678366541862488, 0.9037953615188599, 0.8682624697685242, 0.9052703380584717, 0.8765595555305481, 0.8838689923286438, 0.886730432510376, 0.8761270046234131, 0.8816226124763489, 0.8850681185722351, 0.8983381390571594, 0.8955631852149963, 0.8868562579154968, 0.9104850888252258, 0.9101678729057312, 0.8995952606201172, 0.9110194444656372, 0.9031028151512146, 0.9080334305763245, 0.9526441693305969, 0.9152266383171082, 0.927829921245575, 0.9784743189811707, 0.9655156135559082, 0.914682924747467, 0.9196768403053284, 0.9469892978668213, 0.978520393371582, 0.9387646913528442, 0.9527265429496765, 0.9440396428108215, 0.9462799429893494, 0.9444222450256348, 0.9918023943901062, 1.0148670673370361, 0.9605230093002319, 0.9432684183120728, 0.9866290092468262, 0.954216718673706], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5011312365531921, 0.523755669593811, 0.570135772228241, 0.587104082107544, 0.639140248298645, 0.6323529481887817, 0.6493212580680847, 0.6527149081230164, 0.6595022678375244, 0.6640271544456482, 0.6334841847419739, 0.6289592981338501, 0.6380090713500977, 0.622171938419342, 0.685520350933075, 0.6481900215148926, 0.6640271544456482, 0.6934388875961304, 0.7047511339187622, 0.7126696705818176, 0.7296379804611206, 0.7319004535675049, 0.7533936500549316, 0.7375565767288208, 0.7714931964874268, 0.75, 0.7590497732162476, 0.766968309879303, 0.7703620195388794, 0.7511312365531921, 0.766968309879303, 0.75, 0.7545248866081238, 0.7466063499450684, 0.7341628670692444, 0.7692307829856873, 0.7466063499450684, 0.7635746598243713, 0.7567873597145081, 0.7454751133918762, 0.7703620195388794, 0.7624434232711792, 0.766968309879303, 0.7477375268936157, 0.7624434232711792, 0.7601810097694397, 0.7567873597145081, 0.7420814633369446, 0.7567873597145081, 0.7601810097694397, 0.7545248866081238, 0.7443438768386841, 0.7579185366630554, 0.7545248866081238, 0.7409502267837524, 0.7533936500549316, 0.7466063499450684, 0.7556561231613159, 0.7443438768386841, 0.7590497732162476, 0.7443438768386841, 0.75, 0.7466063499450684, 0.7522624731063843, 0.7545248866081238, 0.7466063499450684, 0.7522624731063843, 0.7443438768386841, 0.7466063499450684, 0.7579185366630554, 0.7466063499450684, 0.7443438768386841, 0.7466063499450684, 0.7466063499450684, 0.7545248866081238, 0.75, 0.7466063499450684, 0.7477375268936157, 0.7522624731063843, 0.7183257937431335, 0.726244330406189, 0.7488687634468079, 0.7567873597145081, 0.7420814633369446, 0.733031690120697, 0.7522624731063843, 0.7420814633369446, 0.7466063499450684, 0.7364253401756287, 0.7511312365531921, 0.7273755669593811, 0.726244330406189, 0.7375565767288208, 0.7511312365531921, 0.7398189902305603, 0.7477375268936157]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 29ms/step - loss: 0.5974 - accuracy: 0.8579 - val_loss: 0.9894 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.5825 - accuracy: 0.8516"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.5651 - accuracy: 0.8765 - val_loss: 0.9878 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5619 - accuracy: 0.8755 - val_loss: 0.9875 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5584 - accuracy: 0.8760 - val_loss: 0.9714 - val_accuracy: 0.4917\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5474 - accuracy: 0.8912 - val_loss: 0.9500 - val_accuracy: 0.5382\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5524 - accuracy: 0.8866 - val_loss: 0.9380 - val_accuracy: 0.5878\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5397 - accuracy: 0.8935 - val_loss: 0.9243 - val_accuracy: 0.6395\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5458 - accuracy: 0.8858 - val_loss: 0.9234 - val_accuracy: 0.6178\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5490 - accuracy: 0.8855 - val_loss: 0.9181 - val_accuracy: 0.6312\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5419 - accuracy: 0.8910 - val_loss: 0.9280 - val_accuracy: 0.6147\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5281 - accuracy: 0.8982 - val_loss: 0.9521 - val_accuracy: 0.6023\n","Epoch 12/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5397 - accuracy: 0.8899 - val_loss: 0.9445 - val_accuracy: 0.6116\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5257 - accuracy: 0.9021 - val_loss: 0.9748 - val_accuracy: 0.6074\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5231 - accuracy: 0.9016 - val_loss: 0.9886 - val_accuracy: 0.6116\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5363 - accuracy: 0.8933 - val_loss: 1.0653 - val_accuracy: 0.5981\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5315 - accuracy: 0.8930 - val_loss: 1.1180 - val_accuracy: 0.5992\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5144 - accuracy: 0.9052 - val_loss: 1.1596 - val_accuracy: 0.5919\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5195 - accuracy: 0.9026 - val_loss: 1.2790 - val_accuracy: 0.5816\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5128 - accuracy: 0.9062 - val_loss: 1.0049 - val_accuracy: 0.6508\n","Epoch 20/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5100 - accuracy: 0.9080 - val_loss: 1.0215 - val_accuracy: 0.6550\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5100 - accuracy: 0.9059 - val_loss: 1.1282 - val_accuracy: 0.6467\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5068 - accuracy: 0.9098 - val_loss: 1.1251 - val_accuracy: 0.6436\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5056 - accuracy: 0.9096 - val_loss: 0.9599 - val_accuracy: 0.6942\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4957 - accuracy: 0.9207 - val_loss: 0.9063 - val_accuracy: 0.7097\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5034 - accuracy: 0.9121 - val_loss: 1.1441 - val_accuracy: 0.6488\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5241 - accuracy: 0.8941 - val_loss: 0.9301 - val_accuracy: 0.7149\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4915 - accuracy: 0.9204 - val_loss: 0.9016 - val_accuracy: 0.7159\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4892 - accuracy: 0.9202 - val_loss: 0.8844 - val_accuracy: 0.7252\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4962 - accuracy: 0.9168 - val_loss: 0.8749 - val_accuracy: 0.7407\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4873 - accuracy: 0.9217 - val_loss: 0.8838 - val_accuracy: 0.7293\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4829 - accuracy: 0.9235 - val_loss: 0.8873 - val_accuracy: 0.7304\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4804 - accuracy: 0.9274 - val_loss: 0.8959 - val_accuracy: 0.7304\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4771 - accuracy: 0.9276 - val_loss: 0.8972 - val_accuracy: 0.7324\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4959 - accuracy: 0.9106 - val_loss: 0.9129 - val_accuracy: 0.7211\n","Epoch 35/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4737 - accuracy: 0.9289 - val_loss: 0.9420 - val_accuracy: 0.7128\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4813 - accuracy: 0.9202 - val_loss: 0.8999 - val_accuracy: 0.7293\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4804 - accuracy: 0.9199 - val_loss: 0.9126 - val_accuracy: 0.7283\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4706 - accuracy: 0.9274 - val_loss: 0.9014 - val_accuracy: 0.7386\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4677 - accuracy: 0.9344 - val_loss: 0.9000 - val_accuracy: 0.7252\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4725 - accuracy: 0.9300 - val_loss: 0.9303 - val_accuracy: 0.7190\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4660 - accuracy: 0.9313 - val_loss: 0.9656 - val_accuracy: 0.7169\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4677 - accuracy: 0.9279 - val_loss: 0.9626 - val_accuracy: 0.7221\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.9256 - val_loss: 0.9109 - val_accuracy: 0.7335\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4613 - accuracy: 0.9333 - val_loss: 0.9357 - val_accuracy: 0.7097\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4560 - accuracy: 0.9349 - val_loss: 0.9641 - val_accuracy: 0.7138\n","Epoch 46/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4636 - accuracy: 0.9282 - val_loss: 0.9196 - val_accuracy: 0.7242\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4547 - accuracy: 0.9339 - val_loss: 0.9310 - val_accuracy: 0.7190\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4503 - accuracy: 0.9406 - val_loss: 0.9236 - val_accuracy: 0.7376\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4486 - accuracy: 0.9413 - val_loss: 0.9250 - val_accuracy: 0.7169\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4507 - accuracy: 0.9354 - val_loss: 0.9841 - val_accuracy: 0.7149\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4566 - accuracy: 0.9315 - val_loss: 0.9438 - val_accuracy: 0.7242\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4438 - accuracy: 0.9362 - val_loss: 0.9292 - val_accuracy: 0.7231\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4423 - accuracy: 0.9447 - val_loss: 0.9518 - val_accuracy: 0.7231\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4424 - accuracy: 0.9395 - val_loss: 0.9296 - val_accuracy: 0.7231\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4521 - accuracy: 0.9300 - val_loss: 1.0832 - val_accuracy: 0.6983\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4652 - accuracy: 0.9248 - val_loss: 0.9429 - val_accuracy: 0.7273\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4416 - accuracy: 0.9416 - val_loss: 0.9431 - val_accuracy: 0.7273\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4297 - accuracy: 0.9470 - val_loss: 0.9537 - val_accuracy: 0.7242\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.9395 - val_loss: 0.9452 - val_accuracy: 0.7242\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4385 - accuracy: 0.9393 - val_loss: 0.9400 - val_accuracy: 0.7190\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4302 - accuracy: 0.9473 - val_loss: 0.9915 - val_accuracy: 0.7190\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4365 - accuracy: 0.9398 - val_loss: 0.9601 - val_accuracy: 0.7200\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4495 - accuracy: 0.9305 - val_loss: 0.9492 - val_accuracy: 0.7262\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4541 - accuracy: 0.9202 - val_loss: 0.9987 - val_accuracy: 0.7138\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4253 - accuracy: 0.9465 - val_loss: 0.9481 - val_accuracy: 0.7200\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4219 - accuracy: 0.9478 - val_loss: 0.9783 - val_accuracy: 0.7221\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4253 - accuracy: 0.9509 - val_loss: 0.9623 - val_accuracy: 0.7200\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4198 - accuracy: 0.9478 - val_loss: 0.9893 - val_accuracy: 0.7138\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.9509 - val_loss: 0.9787 - val_accuracy: 0.7118\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4129 - accuracy: 0.9506 - val_loss: 0.9664 - val_accuracy: 0.7190\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4142 - accuracy: 0.9545 - val_loss: 0.9901 - val_accuracy: 0.7128\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4098 - accuracy: 0.9568 - val_loss: 0.9865 - val_accuracy: 0.7252\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4068 - accuracy: 0.9566 - val_loss: 0.9776 - val_accuracy: 0.7283\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4061 - accuracy: 0.9587 - val_loss: 0.9719 - val_accuracy: 0.7242\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4077 - accuracy: 0.9548 - val_loss: 0.9837 - val_accuracy: 0.7231\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4074 - accuracy: 0.9532 - val_loss: 0.9796 - val_accuracy: 0.7211\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4039 - accuracy: 0.9548 - val_loss: 0.9757 - val_accuracy: 0.7231\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4023 - accuracy: 0.9550 - val_loss: 1.0259 - val_accuracy: 0.7076\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4192 - accuracy: 0.9450 - val_loss: 1.0177 - val_accuracy: 0.7149\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4056 - accuracy: 0.9568 - val_loss: 1.0339 - val_accuracy: 0.7045\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4192 - accuracy: 0.9421 - val_loss: 0.9952 - val_accuracy: 0.7190\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4039 - accuracy: 0.9486 - val_loss: 0.9961 - val_accuracy: 0.7211\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4021 - accuracy: 0.9563 - val_loss: 1.0118 - val_accuracy: 0.7200\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.9545 - val_loss: 1.0828 - val_accuracy: 0.7087\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3981 - accuracy: 0.9543 - val_loss: 1.0046 - val_accuracy: 0.7242\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3963 - accuracy: 0.9581 - val_loss: 1.0145 - val_accuracy: 0.7180\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3894 - accuracy: 0.9602 - val_loss: 1.0277 - val_accuracy: 0.7293\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3956 - accuracy: 0.9589 - val_loss: 1.0299 - val_accuracy: 0.7107\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4192 - accuracy: 0.9411 - val_loss: 1.0064 - val_accuracy: 0.7211\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4235 - accuracy: 0.9357 - val_loss: 1.0393 - val_accuracy: 0.7169\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3917 - accuracy: 0.9594 - val_loss: 1.0513 - val_accuracy: 0.7045\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3858 - accuracy: 0.9623 - val_loss: 1.0326 - val_accuracy: 0.7035\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3823 - accuracy: 0.9615 - val_loss: 1.0330 - val_accuracy: 0.7231\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3848 - accuracy: 0.9602 - val_loss: 1.0286 - val_accuracy: 0.7190\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3787 - accuracy: 0.9656 - val_loss: 1.0398 - val_accuracy: 0.7128\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3897 - accuracy: 0.9566 - val_loss: 1.0470 - val_accuracy: 0.7138\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3827 - accuracy: 0.9579 - val_loss: 1.0328 - val_accuracy: 0.7221\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3825 - accuracy: 0.9620 - val_loss: 1.0980 - val_accuracy: 0.6952\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3851 - accuracy: 0.9599 - val_loss: 1.0477 - val_accuracy: 0.7097\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3713 - accuracy: 0.9677 - val_loss: 1.1273 - val_accuracy: 0.7045\n","{'loss': [0.5973750948905945, 0.5650616884231567, 0.5619361996650696, 0.558434784412384, 0.5474061965942383, 0.5523663759231567, 0.5397375226020813, 0.5458015203475952, 0.5489668846130371, 0.5418749451637268, 0.5281484723091125, 0.5397363305091858, 0.525663435459137, 0.5230986475944519, 0.536348283290863, 0.5315099954605103, 0.5143957138061523, 0.5195194482803345, 0.512753963470459, 0.5099685192108154, 0.5099844336509705, 0.5067825317382812, 0.5055679082870483, 0.4956889748573303, 0.5034068822860718, 0.5241012573242188, 0.49145954847335815, 0.4892457127571106, 0.49624311923980713, 0.48731473088264465, 0.48288336396217346, 0.48037752509117126, 0.47707706689834595, 0.4959147274494171, 0.47374656796455383, 0.4812934994697571, 0.480355441570282, 0.47056910395622253, 0.46770960092544556, 0.4725183844566345, 0.46601602435112, 0.4677262604236603, 0.4690757691860199, 0.4613119959831238, 0.4559725522994995, 0.46360623836517334, 0.4547383189201355, 0.4503295123577118, 0.4485984444618225, 0.45069146156311035, 0.45664653182029724, 0.44375306367874146, 0.44227564334869385, 0.4424242675304413, 0.4521462023258209, 0.4651867747306824, 0.4415940046310425, 0.429747074842453, 0.4396100640296936, 0.4384653866291046, 0.4301576614379883, 0.4364522397518158, 0.44945138692855835, 0.45406392216682434, 0.42531654238700867, 0.42189639806747437, 0.42527464032173157, 0.41982975602149963, 0.41814109683036804, 0.41287675499916077, 0.414201557636261, 0.4098140001296997, 0.4068211019039154, 0.4061211943626404, 0.4077438712120056, 0.4074103832244873, 0.4038865268230438, 0.40227675437927246, 0.41923677921295166, 0.40559273958206177, 0.41921308636665344, 0.4038851261138916, 0.40212979912757874, 0.40300020575523376, 0.39805904030799866, 0.3963242769241333, 0.38941511511802673, 0.39563488960266113, 0.41916072368621826, 0.42351317405700684, 0.39168623089790344, 0.38578253984451294, 0.3822667598724365, 0.3848234713077545, 0.37866640090942383, 0.38967058062553406, 0.3827379643917084, 0.3825303912162781, 0.3850651681423187, 0.37132498621940613], 'accuracy': [0.8578811287879944, 0.8764857649803162, 0.8754522204399109, 0.8759689927101135, 0.8912144899368286, 0.8865633010864258, 0.8935400247573853, 0.8857881426811218, 0.8855296969413757, 0.8909560441970825, 0.8981912136077881, 0.8899224996566772, 0.9020671844482422, 0.9015504121780396, 0.8932816386222839, 0.8930232524871826, 0.9051679372787476, 0.9025839567184448, 0.9062015414237976, 0.9080103635787964, 0.9059431552886963, 0.9098191261291504, 0.9095607399940491, 0.920671820640564, 0.9121447205543518, 0.8940568566322327, 0.9204134345054626, 0.9201550483703613, 0.9167958498001099, 0.921705424785614, 0.923514187335968, 0.9273901581764221, 0.9276486039161682, 0.9105943441390991, 0.9289405941963196, 0.9201550483703613, 0.91989666223526, 0.9273901581764221, 0.9343669414520264, 0.9299741387367249, 0.9312661290168762, 0.9279069900512695, 0.9255813956260681, 0.9333333373069763, 0.934883713722229, 0.9281653761863708, 0.933850109577179, 0.9405684471130371, 0.9413436651229858, 0.9354005455970764, 0.9315245747566223, 0.9361757040023804, 0.9447028636932373, 0.9395349025726318, 0.9299741387367249, 0.9248061776161194, 0.9416020512580872, 0.947028398513794, 0.9395349025726318, 0.9392764568328857, 0.94728684425354, 0.9397932887077332, 0.9304909706115723, 0.9201550483703613, 0.9465116262435913, 0.9478036165237427, 0.950904369354248, 0.9478036165237427, 0.950904369354248, 0.9506459832191467, 0.9545219540596008, 0.9568475484848022, 0.9565891623497009, 0.9586563110351562, 0.9547803401947021, 0.9532299637794495, 0.9547803401947021, 0.9550387859344482, 0.9449612498283386, 0.9568475484848022, 0.9421188831329346, 0.9485788345336914, 0.9563307762145996, 0.9545219540596008, 0.9542635679244995, 0.9581395387649536, 0.9602067470550537, 0.9589147567749023, 0.9410852789878845, 0.9356589317321777, 0.959431529045105, 0.962273895740509, 0.9614987373352051, 0.9602067470550537, 0.9656330943107605, 0.9565891623497009, 0.9578811526298523, 0.9620155096054077, 0.9599483013153076, 0.9677002429962158], 'val_loss': [0.9894121885299683, 0.9877620339393616, 0.9875134825706482, 0.9714416861534119, 0.949980616569519, 0.9379749298095703, 0.9242821335792542, 0.9234262704849243, 0.9181069731712341, 0.928036630153656, 0.9520531296730042, 0.9445182681083679, 0.9748468399047852, 0.9885574579238892, 1.0652971267700195, 1.1180490255355835, 1.159631609916687, 1.2790262699127197, 1.0048567056655884, 1.0215264558792114, 1.1282459497451782, 1.1251107454299927, 0.959881067276001, 0.9063349366188049, 1.1441481113433838, 0.9300763010978699, 0.9016339182853699, 0.8843721747398376, 0.8749112486839294, 0.8837571144104004, 0.8872700333595276, 0.8959402441978455, 0.8971625566482544, 0.912910521030426, 0.9419726729393005, 0.8998633027076721, 0.9125788807868958, 0.9014195799827576, 0.9000306725502014, 0.9302581548690796, 0.9656184911727905, 0.962605893611908, 0.9108786582946777, 0.9357110261917114, 0.9640735387802124, 0.9196352362632751, 0.9309574961662292, 0.9236171841621399, 0.92497718334198, 0.9840735197067261, 0.9437986016273499, 0.9291545152664185, 0.9517596364021301, 0.9296289682388306, 1.0832247734069824, 0.9429330825805664, 0.9430955648422241, 0.9536511301994324, 0.9451686143875122, 0.9400395750999451, 0.991533100605011, 0.9601008892059326, 0.9492170214653015, 0.9986756443977356, 0.9480650424957275, 0.9783358573913574, 0.9623419642448425, 0.9893287420272827, 0.9787499904632568, 0.966417670249939, 0.9901154637336731, 0.986473560333252, 0.9775887727737427, 0.9719476699829102, 0.9836700558662415, 0.9795882105827332, 0.9756633043289185, 1.025872826576233, 1.0177334547042847, 1.0338815450668335, 0.9951848983764648, 0.9961280226707458, 1.011753797531128, 1.0828183889389038, 1.004579782485962, 1.014466643333435, 1.0276975631713867, 1.0299158096313477, 1.006360411643982, 1.0393309593200684, 1.051329255104065, 1.032599687576294, 1.0330302715301514, 1.0286283493041992, 1.0397969484329224, 1.0470131635665894, 1.0328338146209717, 1.098047137260437, 1.0476704835891724, 1.127306580543518], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4917355477809906, 0.538223147392273, 0.5878099203109741, 0.6394628286361694, 0.6177685856819153, 0.6311983466148376, 0.6146694421768188, 0.6022727489471436, 0.6115702390670776, 0.6074380278587341, 0.6115702390670776, 0.5981404781341553, 0.5991735458374023, 0.5919421315193176, 0.5816115736961365, 0.6508264541625977, 0.6549586653709412, 0.6466942429542542, 0.6435950398445129, 0.6942148804664612, 0.7097107172012329, 0.6487603187561035, 0.7148760557174683, 0.7159090638160706, 0.7252066135406494, 0.7407024502754211, 0.7293388247489929, 0.73037189245224, 0.73037189245224, 0.7324380278587341, 0.7210744023323059, 0.7128099203109741, 0.7293388247489929, 0.7283057570457458, 0.7386363744735718, 0.7252066135406494, 0.7190082669258118, 0.7169421315193176, 0.7221074104309082, 0.7334710955619812, 0.7097107172012329, 0.7138429880142212, 0.7241735458374023, 0.7190082669258118, 0.7376033067703247, 0.7169421315193176, 0.7148760557174683, 0.7241735458374023, 0.7231404781341553, 0.7231404781341553, 0.7231404781341553, 0.6983470916748047, 0.7272727489471436, 0.7272727489471436, 0.7241735458374023, 0.7241735458374023, 0.7190082669258118, 0.7190082669258118, 0.7200413346290588, 0.7262396812438965, 0.7138429880142212, 0.7200413346290588, 0.7221074104309082, 0.7200413346290588, 0.7138429880142212, 0.711776852607727, 0.7190082669258118, 0.7128099203109741, 0.7252066135406494, 0.7283057570457458, 0.7241735458374023, 0.7231404781341553, 0.7210744023323059, 0.7231404781341553, 0.7076446413993835, 0.7148760557174683, 0.7045454382896423, 0.7190082669258118, 0.7210744023323059, 0.7200413346290588, 0.7086777091026306, 0.7241735458374023, 0.7179751992225647, 0.7293388247489929, 0.71074378490448, 0.7210744023323059, 0.7169421315193176, 0.7045454382896423, 0.7035123705863953, 0.7231404781341553, 0.7190082669258118, 0.7128099203109741, 0.7138429880142212, 0.7221074104309082, 0.6952479481697083, 0.7097107172012329, 0.7045454382896423]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 27ms/step - loss: 0.5092 - accuracy: 0.8914 - val_loss: 0.9971 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4016 - accuracy: 0.9375"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 10ms/step - loss: 0.4253 - accuracy: 0.9410 - val_loss: 0.9957 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4203 - accuracy: 0.9459 - val_loss: 0.9895 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4225 - accuracy: 0.9432 - val_loss: 0.9866 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4177 - accuracy: 0.9448 - val_loss: 0.9600 - val_accuracy: 0.5183\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4123 - accuracy: 0.9472 - val_loss: 0.9467 - val_accuracy: 0.5312\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4055 - accuracy: 0.9520 - val_loss: 0.9269 - val_accuracy: 0.5711\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4040 - accuracy: 0.9529 - val_loss: 0.9262 - val_accuracy: 0.5690\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4048 - accuracy: 0.9502 - val_loss: 0.8981 - val_accuracy: 0.6304\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3994 - accuracy: 0.9564 - val_loss: 0.9001 - val_accuracy: 0.6347\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4038 - accuracy: 0.9477 - val_loss: 0.8925 - val_accuracy: 0.6530\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 0.9475 - val_loss: 0.8989 - val_accuracy: 0.6487\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3901 - accuracy: 0.9631 - val_loss: 0.9105 - val_accuracy: 0.6325\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.9620 - val_loss: 0.9507 - val_accuracy: 0.6358\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3863 - accuracy: 0.9607 - val_loss: 1.0099 - val_accuracy: 0.6293\n","Epoch 16/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3878 - accuracy: 0.9585 - val_loss: 1.1403 - val_accuracy: 0.6196\n","Epoch 17/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4078 - accuracy: 0.9480 - val_loss: 1.1934 - val_accuracy: 0.6218\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3998 - accuracy: 0.9537 - val_loss: 1.1795 - val_accuracy: 0.6293\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3823 - accuracy: 0.9644 - val_loss: 1.0606 - val_accuracy: 0.6659\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3804 - accuracy: 0.9647 - val_loss: 1.0439 - val_accuracy: 0.6800\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3750 - accuracy: 0.9663 - val_loss: 1.0201 - val_accuracy: 0.6972\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3778 - accuracy: 0.9650 - val_loss: 0.9392 - val_accuracy: 0.7295\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3841 - accuracy: 0.9615 - val_loss: 0.9245 - val_accuracy: 0.7457\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3747 - accuracy: 0.9671 - val_loss: 0.9486 - val_accuracy: 0.7489\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3811 - accuracy: 0.9599 - val_loss: 0.9035 - val_accuracy: 0.7651\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3715 - accuracy: 0.9663 - val_loss: 0.8472 - val_accuracy: 0.7769\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3664 - accuracy: 0.9712 - val_loss: 0.8395 - val_accuracy: 0.7748\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3705 - accuracy: 0.9677 - val_loss: 0.8418 - val_accuracy: 0.7791\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3732 - accuracy: 0.9682 - val_loss: 0.8423 - val_accuracy: 0.7866\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3627 - accuracy: 0.9733 - val_loss: 0.8648 - val_accuracy: 0.7586\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3659 - accuracy: 0.9693 - val_loss: 0.8544 - val_accuracy: 0.7834\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3606 - accuracy: 0.9723 - val_loss: 0.8434 - val_accuracy: 0.7888\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3743 - accuracy: 0.9666 - val_loss: 0.8734 - val_accuracy: 0.7888\n","Epoch 34/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3710 - accuracy: 0.9650 - val_loss: 0.8609 - val_accuracy: 0.7866\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3681 - accuracy: 0.9696 - val_loss: 0.9030 - val_accuracy: 0.7866\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3558 - accuracy: 0.9728 - val_loss: 0.8677 - val_accuracy: 0.7780\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3569 - accuracy: 0.9736 - val_loss: 0.9231 - val_accuracy: 0.7543\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3782 - accuracy: 0.9607 - val_loss: 0.8670 - val_accuracy: 0.7812\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3562 - accuracy: 0.9741 - val_loss: 0.8863 - val_accuracy: 0.7662\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3573 - accuracy: 0.9723 - val_loss: 0.9467 - val_accuracy: 0.7543\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.9747 - val_loss: 0.8819 - val_accuracy: 0.7683\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3505 - accuracy: 0.9744 - val_loss: 0.8826 - val_accuracy: 0.7705\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3491 - accuracy: 0.9766 - val_loss: 0.8895 - val_accuracy: 0.7640\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3446 - accuracy: 0.9771 - val_loss: 0.8889 - val_accuracy: 0.7856\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.9733 - val_loss: 0.8948 - val_accuracy: 0.7672\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3536 - accuracy: 0.9706 - val_loss: 0.8976 - val_accuracy: 0.7705\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3436 - accuracy: 0.9790 - val_loss: 0.8987 - val_accuracy: 0.7672\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3392 - accuracy: 0.9782 - val_loss: 0.8966 - val_accuracy: 0.7791\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3440 - accuracy: 0.9776 - val_loss: 0.9084 - val_accuracy: 0.7694\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3644 - accuracy: 0.9647 - val_loss: 0.9691 - val_accuracy: 0.7489\n","Epoch 51/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3525 - accuracy: 0.9706 - val_loss: 0.9079 - val_accuracy: 0.7716\n","Epoch 52/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3437 - accuracy: 0.9768 - val_loss: 0.9753 - val_accuracy: 0.7726\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3487 - accuracy: 0.9733 - val_loss: 0.9288 - val_accuracy: 0.7737\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3370 - accuracy: 0.9811 - val_loss: 0.9361 - val_accuracy: 0.7608\n","Epoch 55/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3358 - accuracy: 0.9814 - val_loss: 0.9273 - val_accuracy: 0.7737\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3352 - accuracy: 0.9809 - val_loss: 0.9145 - val_accuracy: 0.7694\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3368 - accuracy: 0.9793 - val_loss: 0.9815 - val_accuracy: 0.7812\n","Epoch 58/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3476 - accuracy: 0.9736 - val_loss: 0.9542 - val_accuracy: 0.7823\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3355 - accuracy: 0.9798 - val_loss: 0.9212 - val_accuracy: 0.7662\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3337 - accuracy: 0.9803 - val_loss: 0.9783 - val_accuracy: 0.7468\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3312 - accuracy: 0.9833 - val_loss: 0.9562 - val_accuracy: 0.7575\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3329 - accuracy: 0.9801 - val_loss: 1.0014 - val_accuracy: 0.7522\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3314 - accuracy: 0.9793 - val_loss: 0.9884 - val_accuracy: 0.7435\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3357 - accuracy: 0.9790 - val_loss: 0.9559 - val_accuracy: 0.7532\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3359 - accuracy: 0.9779 - val_loss: 0.9730 - val_accuracy: 0.7511\n","Epoch 66/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3374 - accuracy: 0.9790 - val_loss: 0.9714 - val_accuracy: 0.7565\n","Epoch 67/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3249 - accuracy: 0.9844 - val_loss: 0.9351 - val_accuracy: 0.7640\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3249 - accuracy: 0.9833 - val_loss: 0.9490 - val_accuracy: 0.7565\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3197 - accuracy: 0.9868 - val_loss: 0.9537 - val_accuracy: 0.7586\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3328 - accuracy: 0.9779 - val_loss: 1.0311 - val_accuracy: 0.7425\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3243 - accuracy: 0.9844 - val_loss: 0.9460 - val_accuracy: 0.7726\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3341 - accuracy: 0.9768 - val_loss: 1.0282 - val_accuracy: 0.7392\n","Epoch 73/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3521 - accuracy: 0.9698 - val_loss: 0.9924 - val_accuracy: 0.7856\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3241 - accuracy: 0.9855 - val_loss: 0.9475 - val_accuracy: 0.7683\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3196 - accuracy: 0.9857 - val_loss: 0.9625 - val_accuracy: 0.7586\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3173 - accuracy: 0.9868 - val_loss: 0.9792 - val_accuracy: 0.7812\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3189 - accuracy: 0.9857 - val_loss: 0.9729 - val_accuracy: 0.7586\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3251 - accuracy: 0.9828 - val_loss: 1.1066 - val_accuracy: 0.7274\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3639 - accuracy: 0.9588 - val_loss: 0.9658 - val_accuracy: 0.7694\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3257 - accuracy: 0.9809 - val_loss: 0.9717 - val_accuracy: 0.7619\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3192 - accuracy: 0.9849 - val_loss: 0.9803 - val_accuracy: 0.7511\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3212 - accuracy: 0.9846 - val_loss: 0.9981 - val_accuracy: 0.7489\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3147 - accuracy: 0.9852 - val_loss: 0.9689 - val_accuracy: 0.7662\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3107 - accuracy: 0.9857 - val_loss: 0.9833 - val_accuracy: 0.7532\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3087 - accuracy: 0.9906 - val_loss: 0.9808 - val_accuracy: 0.7619\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3103 - accuracy: 0.9876 - val_loss: 0.9766 - val_accuracy: 0.7629\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3261 - accuracy: 0.9779 - val_loss: 0.9909 - val_accuracy: 0.7640\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3145 - accuracy: 0.9860 - val_loss: 0.9886 - val_accuracy: 0.7672\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3086 - accuracy: 0.9879 - val_loss: 0.9838 - val_accuracy: 0.7640\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3073 - accuracy: 0.9873 - val_loss: 0.9848 - val_accuracy: 0.7608\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3060 - accuracy: 0.9892 - val_loss: 0.9885 - val_accuracy: 0.7532\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3170 - accuracy: 0.9809 - val_loss: 1.0109 - val_accuracy: 0.7694\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3090 - accuracy: 0.9865 - val_loss: 0.9983 - val_accuracy: 0.7651\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3055 - accuracy: 0.9895 - val_loss: 1.0321 - val_accuracy: 0.7823\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3092 - accuracy: 0.9881 - val_loss: 0.9937 - val_accuracy: 0.7629\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3096 - accuracy: 0.9857 - val_loss: 1.0046 - val_accuracy: 0.7640\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3054 - accuracy: 0.9887 - val_loss: 1.0019 - val_accuracy: 0.7597\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3032 - accuracy: 0.9900 - val_loss: 1.0246 - val_accuracy: 0.7522\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3027 - accuracy: 0.9900 - val_loss: 1.0136 - val_accuracy: 0.7532\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3011 - accuracy: 0.9892 - val_loss: 1.0174 - val_accuracy: 0.7532\n","{'loss': [0.5091654658317566, 0.4253110885620117, 0.4202830493450165, 0.4224707782268524, 0.4176681339740753, 0.4123092591762543, 0.4054678678512573, 0.4039609134197235, 0.4048280417919159, 0.3993641138076782, 0.4038115441799164, 0.4119518995285034, 0.390125572681427, 0.38858696818351746, 0.38626790046691895, 0.38777798414230347, 0.4077807366847992, 0.39975523948669434, 0.3823159337043762, 0.38035574555397034, 0.375017374753952, 0.3778260350227356, 0.3841429352760315, 0.3747187554836273, 0.3810862898826599, 0.3714546263217926, 0.3663839101791382, 0.37047770619392395, 0.37320539355278015, 0.362684965133667, 0.36592864990234375, 0.3606235682964325, 0.37431642413139343, 0.37099653482437134, 0.36807578802108765, 0.3558427095413208, 0.35685136914253235, 0.3781878650188446, 0.3562450110912323, 0.35731375217437744, 0.35463812947273254, 0.3504851758480072, 0.3491463363170624, 0.34456539154052734, 0.35455000400543213, 0.35363519191741943, 0.3435523211956024, 0.33916670083999634, 0.34400004148483276, 0.3643759489059448, 0.35250815749168396, 0.3436601459980011, 0.34866851568222046, 0.3370344936847687, 0.33584120869636536, 0.33520424365997314, 0.3368363678455353, 0.347562700510025, 0.33548441529273987, 0.33366718888282776, 0.3311949074268341, 0.33291149139404297, 0.33137473464012146, 0.33570557832717896, 0.3359130322933197, 0.3374462425708771, 0.32490235567092896, 0.32494181394577026, 0.3197009861469269, 0.3328213393688202, 0.32434430718421936, 0.33407488465309143, 0.35206153988838196, 0.3241226077079773, 0.3196185231208801, 0.3173183500766754, 0.3189130127429962, 0.3250860869884491, 0.3639330267906189, 0.32573404908180237, 0.31924331188201904, 0.3211830258369446, 0.31471318006515503, 0.3107301890850067, 0.3086547553539276, 0.3103320896625519, 0.32614439725875854, 0.3144865334033966, 0.3085625171661377, 0.30731526017189026, 0.3060215711593628, 0.317024827003479, 0.30904990434646606, 0.30547142028808594, 0.30920255184173584, 0.3096313774585724, 0.30539950728416443, 0.3031982481479645, 0.30270475149154663, 0.30113881826400757], 'accuracy': [0.8914331793785095, 0.9410021305084229, 0.9458512663841248, 0.9431573152542114, 0.9447737336158752, 0.9471982717514038, 0.9520474076271057, 0.9528555870056152, 0.9501616358757019, 0.9563577771186829, 0.9477370977401733, 0.9474676847457886, 0.9630926847457886, 0.9620150923728943, 0.9606680870056152, 0.9585129022598267, 0.9480064511299133, 0.9536637663841248, 0.9644396305084229, 0.9647090435028076, 0.9663254022598267, 0.9649784564971924, 0.9614762663841248, 0.967133641242981, 0.9598599076271057, 0.9663254022598267, 0.9711745977401733, 0.9676724076271057, 0.9682112336158752, 0.9733297228813171, 0.9692887663841248, 0.9722521305084229, 0.9665948152542114, 0.9649784564971924, 0.9695581793785095, 0.9727909564971924, 0.9735991358757019, 0.9606680870056152, 0.9741379022598267, 0.9722521305084229, 0.9746767282485962, 0.9744073152542114, 0.9765625, 0.9771012663841248, 0.9733297228813171, 0.9706357717514038, 0.9789870977401733, 0.978178858757019, 0.9776400923728943, 0.9647090435028076, 0.9706357717514038, 0.9768319129943848, 0.9733297228813171, 0.9811422228813171, 0.9814116358757019, 0.9808728694915771, 0.9792564511299133, 0.9735991358757019, 0.9797952771186829, 0.9803340435028076, 0.9832974076271057, 0.9800646305084229, 0.9792564511299133, 0.9789870977401733, 0.977909505367279, 0.9789870977401733, 0.984375, 0.9832974076271057, 0.9867995977401733, 0.977909505367279, 0.984375, 0.9768319129943848, 0.9698275923728943, 0.9854525923728943, 0.985722005367279, 0.9867995977401733, 0.985722005367279, 0.982758641242981, 0.9587823152542114, 0.9808728694915771, 0.9849137663841248, 0.9846444129943848, 0.9851831793785095, 0.985722005367279, 0.990571141242981, 0.9876077771186829, 0.977909505367279, 0.985991358757019, 0.9878771305084229, 0.9873383641242981, 0.9892241358757019, 0.9808728694915771, 0.9865301847457886, 0.9894935488700867, 0.9881465435028076, 0.985722005367279, 0.9886853694915771, 0.9900323152542114, 0.9900323152542114, 0.9892241358757019], 'val_loss': [0.9971277117729187, 0.9957133531570435, 0.989524781703949, 0.9865688681602478, 0.9600213170051575, 0.9467111229896545, 0.9269036054611206, 0.9261678457260132, 0.898124098777771, 0.9001292586326599, 0.8925046324729919, 0.8988747000694275, 0.9105432629585266, 0.9507279992103577, 1.0099364519119263, 1.1402881145477295, 1.1934319734573364, 1.1795138120651245, 1.0606331825256348, 1.0439163446426392, 1.020124912261963, 0.9392319321632385, 0.9244715571403503, 0.9485925436019897, 0.9035008549690247, 0.8472250699996948, 0.8394548296928406, 0.8417701721191406, 0.8422917723655701, 0.8647856116294861, 0.8544125556945801, 0.8433791995048523, 0.8734486103057861, 0.8608810305595398, 0.9029877781867981, 0.8677465915679932, 0.9230814576148987, 0.8669814467430115, 0.886289119720459, 0.9466972947120667, 0.8818694949150085, 0.8825697898864746, 0.8894945979118347, 0.8889304399490356, 0.8947924375534058, 0.8976160883903503, 0.8986892104148865, 0.8965957760810852, 0.9083925485610962, 0.9690882563591003, 0.9078547954559326, 0.9753389954566956, 0.9287959933280945, 0.936089277267456, 0.9273210167884827, 0.9144986271858215, 0.9814690947532654, 0.9541804790496826, 0.9211925268173218, 0.9783088564872742, 0.9562036395072937, 1.0013785362243652, 0.9883695840835571, 0.955888032913208, 0.9729663133621216, 0.9713588356971741, 0.9350736737251282, 0.9490136504173279, 0.9536907076835632, 1.0311146974563599, 0.9459569454193115, 1.028219223022461, 0.9923636317253113, 0.9475160241127014, 0.9624695777893066, 0.9791868329048157, 0.9729381203651428, 1.1066272258758545, 0.9657905697822571, 0.9716776609420776, 0.9803226590156555, 0.9981370568275452, 0.9689162969589233, 0.9833311438560486, 0.980842113494873, 0.9766061902046204, 0.9908931851387024, 0.9886108636856079, 0.983798086643219, 0.984757661819458, 0.9885150194168091, 1.0109142065048218, 0.9983222484588623, 1.0321035385131836, 0.9936570525169373, 1.0046324729919434, 1.0019221305847168, 1.0245678424835205, 1.0135908126831055, 1.0173720121383667], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.5183189511299133, 0.53125, 0.5711206793785095, 0.568965494632721, 0.6303879022598267, 0.6346982717514038, 0.6530172228813171, 0.6487069129943848, 0.6325430870056152, 0.6357758641242981, 0.6293103694915771, 0.6196120977401733, 0.6217672228813171, 0.6293103694915771, 0.6659482717514038, 0.6799569129943848, 0.6971982717514038, 0.7295258641242981, 0.7456896305084229, 0.7489224076271057, 0.7650862336158752, 0.7769396305084229, 0.774784505367279, 0.7790948152542114, 0.7866379022598267, 0.7586206793785095, 0.7834051847457886, 0.7887930870056152, 0.7887930870056152, 0.7866379022598267, 0.7866379022598267, 0.7780172228813171, 0.7543103694915771, 0.78125, 0.7661637663841248, 0.7543103694915771, 0.7683189511299133, 0.7704741358757019, 0.764008641242981, 0.7855603694915771, 0.767241358757019, 0.7704741358757019, 0.767241358757019, 0.7790948152542114, 0.7693965435028076, 0.7489224076271057, 0.7715517282485962, 0.7726293206214905, 0.7737069129943848, 0.7607758641242981, 0.7737069129943848, 0.7693965435028076, 0.78125, 0.7823275923728943, 0.7661637663841248, 0.7467672228813171, 0.7575430870056152, 0.7521551847457886, 0.743534505367279, 0.7532327771186829, 0.7510775923728943, 0.756465494632721, 0.764008641242981, 0.756465494632721, 0.7586206793785095, 0.7424569129943848, 0.7726293206214905, 0.7392241358757019, 0.7855603694915771, 0.7683189511299133, 0.7586206793785095, 0.78125, 0.7586206793785095, 0.7273706793785095, 0.7693965435028076, 0.7618534564971924, 0.7510775923728943, 0.7489224076271057, 0.7661637663841248, 0.7532327771186829, 0.7618534564971924, 0.7629310488700867, 0.764008641242981, 0.767241358757019, 0.764008641242981, 0.7607758641242981, 0.7532327771186829, 0.7693965435028076, 0.7650862336158752, 0.7823275923728943, 0.7629310488700867, 0.764008641242981, 0.7596982717514038, 0.7521551847457886, 0.7532327771186829, 0.7532327771186829]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 39ms/step - loss: 0.5129 - accuracy: 0.8860 - val_loss: 0.9927 - val_accuracy: 0.4955\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 17ms/step - loss: 0.4667 - accuracy: 0.9143 - val_loss: 0.9866 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4238 - accuracy: 0.9417 - val_loss: 0.9832 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4177 - accuracy: 0.9471 - val_loss: 0.9795 - val_accuracy: 0.4977\n","Epoch 5/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4209 - accuracy: 0.9392 - val_loss: 0.9692 - val_accuracy: 0.5057\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4083 - accuracy: 0.9522 - val_loss: 0.9476 - val_accuracy: 0.5238\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4067 - accuracy: 0.9493 - val_loss: 0.9407 - val_accuracy: 0.5396\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4019 - accuracy: 0.9539 - val_loss: 0.9237 - val_accuracy: 0.5769\n","Epoch 9/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3989 - accuracy: 0.9573 - val_loss: 0.8982 - val_accuracy: 0.6380\n","Epoch 10/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4034 - accuracy: 0.9508 - val_loss: 0.8917 - val_accuracy: 0.6244\n","Epoch 11/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4013 - accuracy: 0.9533 - val_loss: 0.8853 - val_accuracy: 0.6527\n","Epoch 12/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3944 - accuracy: 0.9556 - val_loss: 0.8854 - val_accuracy: 0.6516\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3927 - accuracy: 0.9590 - val_loss: 0.8849 - val_accuracy: 0.6561\n","Epoch 14/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4095 - accuracy: 0.9482 - val_loss: 0.8839 - val_accuracy: 0.6663\n","Epoch 15/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.9530 - val_loss: 0.9228 - val_accuracy: 0.6640\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3908 - accuracy: 0.9593 - val_loss: 0.9072 - val_accuracy: 0.6753\n","Epoch 17/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3846 - accuracy: 0.9601 - val_loss: 1.0316 - val_accuracy: 0.6425\n","Epoch 18/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3812 - accuracy: 0.9635 - val_loss: 0.9968 - val_accuracy: 0.6606\n","Epoch 19/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.9669 - val_loss: 1.0291 - val_accuracy: 0.6572\n","Epoch 20/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3793 - accuracy: 0.9615 - val_loss: 1.0689 - val_accuracy: 0.6629\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3841 - accuracy: 0.9584 - val_loss: 1.1246 - val_accuracy: 0.6595\n","Epoch 22/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3980 - accuracy: 0.9496 - val_loss: 1.1377 - val_accuracy: 0.6697\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3780 - accuracy: 0.9646 - val_loss: 0.9573 - val_accuracy: 0.7285\n","Epoch 24/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3707 - accuracy: 0.9697 - val_loss: 1.0155 - val_accuracy: 0.7138\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3932 - accuracy: 0.9556 - val_loss: 0.9783 - val_accuracy: 0.7308\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3745 - accuracy: 0.9618 - val_loss: 0.7867 - val_accuracy: 0.7885\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4020 - accuracy: 0.9468 - val_loss: 0.7798 - val_accuracy: 0.7817\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3757 - accuracy: 0.9632 - val_loss: 0.8948 - val_accuracy: 0.7704\n","Epoch 29/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3798 - accuracy: 0.9578 - val_loss: 0.7789 - val_accuracy: 0.7839\n","Epoch 30/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3749 - accuracy: 0.9615 - val_loss: 0.7729 - val_accuracy: 0.7930\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3651 - accuracy: 0.9677 - val_loss: 0.7831 - val_accuracy: 0.8020\n","Epoch 32/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3600 - accuracy: 0.9728 - val_loss: 0.7733 - val_accuracy: 0.8088\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3624 - accuracy: 0.9689 - val_loss: 0.8336 - val_accuracy: 0.7907\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3586 - accuracy: 0.9740 - val_loss: 0.8176 - val_accuracy: 0.7851\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3639 - accuracy: 0.9697 - val_loss: 0.8010 - val_accuracy: 0.7941\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3591 - accuracy: 0.9706 - val_loss: 0.7844 - val_accuracy: 0.7919\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3595 - accuracy: 0.9726 - val_loss: 0.8151 - val_accuracy: 0.7907\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3672 - accuracy: 0.9643 - val_loss: 0.8802 - val_accuracy: 0.7670\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3725 - accuracy: 0.9629 - val_loss: 0.8071 - val_accuracy: 0.7964\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3476 - accuracy: 0.9768 - val_loss: 0.7961 - val_accuracy: 0.7941\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3489 - accuracy: 0.9759 - val_loss: 0.8021 - val_accuracy: 0.7941\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3491 - accuracy: 0.9751 - val_loss: 0.8274 - val_accuracy: 0.7986\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3540 - accuracy: 0.9726 - val_loss: 0.8264 - val_accuracy: 0.7964\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3488 - accuracy: 0.9723 - val_loss: 0.8426 - val_accuracy: 0.7704\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3493 - accuracy: 0.9740 - val_loss: 0.8096 - val_accuracy: 0.7919\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3547 - accuracy: 0.9694 - val_loss: 0.8024 - val_accuracy: 0.7952\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3465 - accuracy: 0.9751 - val_loss: 0.8178 - val_accuracy: 0.7907\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3414 - accuracy: 0.9762 - val_loss: 0.8563 - val_accuracy: 0.7930\n","Epoch 49/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3431 - accuracy: 0.9788 - val_loss: 0.8179 - val_accuracy: 0.7964\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3459 - accuracy: 0.9734 - val_loss: 0.8414 - val_accuracy: 0.7805\n","Epoch 51/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3603 - accuracy: 0.9660 - val_loss: 0.8281 - val_accuracy: 0.8032\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3526 - accuracy: 0.9731 - val_loss: 0.8286 - val_accuracy: 0.7952\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3504 - accuracy: 0.9731 - val_loss: 0.8870 - val_accuracy: 0.7647\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.9431 - val_loss: 0.8574 - val_accuracy: 0.7964\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3554 - accuracy: 0.9692 - val_loss: 0.8518 - val_accuracy: 0.7783\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3486 - accuracy: 0.9717 - val_loss: 0.8588 - val_accuracy: 0.7964\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3499 - accuracy: 0.9717 - val_loss: 0.8588 - val_accuracy: 0.7794\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3390 - accuracy: 0.9774 - val_loss: 0.8400 - val_accuracy: 0.7930\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3355 - accuracy: 0.9779 - val_loss: 0.9013 - val_accuracy: 0.7613\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3521 - accuracy: 0.9689 - val_loss: 0.8440 - val_accuracy: 0.7907\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3422 - accuracy: 0.9734 - val_loss: 0.8854 - val_accuracy: 0.7647\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3346 - accuracy: 0.9799 - val_loss: 0.8697 - val_accuracy: 0.7862\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3336 - accuracy: 0.9819 - val_loss: 0.8757 - val_accuracy: 0.7873\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3402 - accuracy: 0.9754 - val_loss: 0.8844 - val_accuracy: 0.7896\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3425 - accuracy: 0.9720 - val_loss: 0.8587 - val_accuracy: 0.7930\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3336 - accuracy: 0.9791 - val_loss: 0.9407 - val_accuracy: 0.7704\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3284 - accuracy: 0.9805 - val_loss: 0.8659 - val_accuracy: 0.7919\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3228 - accuracy: 0.9827 - val_loss: 0.8545 - val_accuracy: 0.7919\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3239 - accuracy: 0.9833 - val_loss: 0.8868 - val_accuracy: 0.7783\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3274 - accuracy: 0.9788 - val_loss: 0.8604 - val_accuracy: 0.7828\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3239 - accuracy: 0.9839 - val_loss: 0.8622 - val_accuracy: 0.7839\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3215 - accuracy: 0.9825 - val_loss: 0.8776 - val_accuracy: 0.7873\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3215 - accuracy: 0.9847 - val_loss: 0.9171 - val_accuracy: 0.7715\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3509 - accuracy: 0.9663 - val_loss: 1.0380 - val_accuracy: 0.7285\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3428 - accuracy: 0.9717 - val_loss: 0.8937 - val_accuracy: 0.7760\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3220 - accuracy: 0.9813 - val_loss: 0.8648 - val_accuracy: 0.7873\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3321 - accuracy: 0.9751 - val_loss: 0.8644 - val_accuracy: 0.7975\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3317 - accuracy: 0.9768 - val_loss: 0.8842 - val_accuracy: 0.7862\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3201 - accuracy: 0.9836 - val_loss: 0.8675 - val_accuracy: 0.7941\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3212 - accuracy: 0.9830 - val_loss: 0.8720 - val_accuracy: 0.7919\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3171 - accuracy: 0.9836 - val_loss: 0.8944 - val_accuracy: 0.7873\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3159 - accuracy: 0.9847 - val_loss: 0.8697 - val_accuracy: 0.7885\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3157 - accuracy: 0.9850 - val_loss: 0.9294 - val_accuracy: 0.7839\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3166 - accuracy: 0.9847 - val_loss: 0.8926 - val_accuracy: 0.7885\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3125 - accuracy: 0.9836 - val_loss: 0.8917 - val_accuracy: 0.7794\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3118 - accuracy: 0.9861 - val_loss: 0.8796 - val_accuracy: 0.7941\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3097 - accuracy: 0.9873 - val_loss: 0.8913 - val_accuracy: 0.7907\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3149 - accuracy: 0.9853 - val_loss: 0.9251 - val_accuracy: 0.7885\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3207 - accuracy: 0.9819 - val_loss: 0.9117 - val_accuracy: 0.7896\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3193 - accuracy: 0.9822 - val_loss: 0.9149 - val_accuracy: 0.7760\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3188 - accuracy: 0.9825 - val_loss: 0.8966 - val_accuracy: 0.7851\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3134 - accuracy: 0.9839 - val_loss: 0.9121 - val_accuracy: 0.7851\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3132 - accuracy: 0.9836 - val_loss: 0.8977 - val_accuracy: 0.7862\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3108 - accuracy: 0.9839 - val_loss: 0.9106 - val_accuracy: 0.7851\n","Epoch 95/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3132 - accuracy: 0.9844 - val_loss: 0.9164 - val_accuracy: 0.7862\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3073 - accuracy: 0.9850 - val_loss: 0.9653 - val_accuracy: 0.7794\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3095 - accuracy: 0.9856 - val_loss: 0.9065 - val_accuracy: 0.7749\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3125 - accuracy: 0.9859 - val_loss: 0.9075 - val_accuracy: 0.7839\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3211 - accuracy: 0.9793 - val_loss: 0.9356 - val_accuracy: 0.7704\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3156 - accuracy: 0.9802 - val_loss: 0.9293 - val_accuracy: 0.7681\n","{'loss': [0.512941300868988, 0.46669697761535645, 0.4237653911113739, 0.41769829392433167, 0.4209442436695099, 0.4083418846130371, 0.4066828489303589, 0.401932954788208, 0.398886114358902, 0.40343746542930603, 0.4012715518474579, 0.3943679630756378, 0.392709881067276, 0.40951964259147644, 0.3942612111568451, 0.39082419872283936, 0.38461732864379883, 0.38121432065963745, 0.37695884704589844, 0.3793037235736847, 0.3840984106063843, 0.3979726731777191, 0.37799420952796936, 0.3706938326358795, 0.39317262172698975, 0.37451910972595215, 0.4019806683063507, 0.37568557262420654, 0.37977415323257446, 0.37493664026260376, 0.36512404680252075, 0.3600364625453949, 0.36244145035743713, 0.3586384057998657, 0.3639441430568695, 0.35914576053619385, 0.35946419835090637, 0.36716321110725403, 0.3724684417247772, 0.3476010859012604, 0.34888410568237305, 0.34909701347351074, 0.35398149490356445, 0.3488159775733948, 0.3493364155292511, 0.35467830300331116, 0.34654638171195984, 0.3413912057876587, 0.3430575132369995, 0.34587323665618896, 0.3602571189403534, 0.3525600731372833, 0.350396990776062, 0.39462965726852417, 0.3553779125213623, 0.348624050617218, 0.34994348883628845, 0.3389694392681122, 0.3355022072792053, 0.35212424397468567, 0.34216126799583435, 0.3345932364463806, 0.33357441425323486, 0.34023481607437134, 0.34249603748321533, 0.33361518383026123, 0.32838675379753113, 0.3227910101413727, 0.3239274322986603, 0.3273584842681885, 0.32385897636413574, 0.3215160369873047, 0.32147473096847534, 0.3509306311607361, 0.34279191493988037, 0.321965754032135, 0.3320765197277069, 0.33165571093559265, 0.32007646560668945, 0.3211515545845032, 0.3170883059501648, 0.31587961316108704, 0.3157285451889038, 0.3166442811489105, 0.31253889203071594, 0.3117801547050476, 0.30973899364471436, 0.31490808725357056, 0.32074445486068726, 0.3193370997905731, 0.31879109144210815, 0.3133613169193268, 0.31324365735054016, 0.3107674717903137, 0.3132075071334839, 0.3072594404220581, 0.3094674348831177, 0.3124619424343109, 0.3210955262184143, 0.31559091806411743], 'accuracy': [0.8859649300575256, 0.9142614603042603, 0.9417091012001038, 0.947085440158844, 0.9391624331474304, 0.9521788358688354, 0.9493491649627686, 0.9538766145706177, 0.9572722315788269, 0.950764000415802, 0.9533106684684753, 0.9555743932723999, 0.9589700102806091, 0.9482173323631287, 0.9530277252197266, 0.9592529535293579, 0.960101842880249, 0.9634974598884583, 0.9668930172920227, 0.9615166783332825, 0.9584040641784668, 0.9496321678161621, 0.9646292924880981, 0.9697226881980896, 0.9555743932723999, 0.961799681186676, 0.9468024969100952, 0.9632145166397095, 0.9578381180763245, 0.9615166783332825, 0.9677419066429138, 0.9728353023529053, 0.9688737988471985, 0.9739671945571899, 0.9697226881980896, 0.9705715775489807, 0.9725523591041565, 0.9643463492393494, 0.9629315137863159, 0.9767968058586121, 0.975947916507721, 0.9750990271568298, 0.9725523591041565, 0.9722693562507629, 0.9739671945571899, 0.9694397449493408, 0.9750990271568298, 0.9762309193611145, 0.9787775874137878, 0.9734012484550476, 0.9660441279411316, 0.9731183052062988, 0.9731183052062988, 0.9431239366531372, 0.9691567420959473, 0.9717034697532654, 0.9717034697532654, 0.9773627519607544, 0.9779286980628967, 0.9688737988471985, 0.9734012484550476, 0.9799094796180725, 0.9818902015686035, 0.9753820300102234, 0.9719864130020142, 0.9790605306625366, 0.9804753661155701, 0.9827390909194946, 0.983305037021637, 0.9787775874137878, 0.9838709831237793, 0.9824561476707458, 0.9847198724746704, 0.9663271307945251, 0.9717034697532654, 0.9813242554664612, 0.9750990271568298, 0.9767968058586121, 0.9835879802703857, 0.9830220937728882, 0.9835879802703857, 0.9847198724746704, 0.9850028157234192, 0.9847198724746704, 0.9835879802703857, 0.9861347079277039, 0.9872665405273438, 0.9852858185768127, 0.9818902015686035, 0.9821732044219971, 0.9824561476707458, 0.9838709831237793, 0.9835879802703857, 0.9838709831237793, 0.9844368696212769, 0.9850028157234192, 0.9855687618255615, 0.9858517050743103, 0.9793435335159302, 0.9801924228668213], 'val_loss': [0.9926769733428955, 0.9865913391113281, 0.9831541180610657, 0.979466438293457, 0.9691985845565796, 0.9476432800292969, 0.9407217502593994, 0.9236698746681213, 0.8981620669364929, 0.891659677028656, 0.8853082656860352, 0.8854309320449829, 0.884911060333252, 0.8838590979576111, 0.9228024482727051, 0.9071998596191406, 1.0316435098648071, 0.9968478083610535, 1.0291494131088257, 1.0688683986663818, 1.1246017217636108, 1.1376832723617554, 0.9573094844818115, 1.0155483484268188, 0.9782668352127075, 0.7867453098297119, 0.7797749638557434, 0.8948038816452026, 0.7789087295532227, 0.7728928923606873, 0.7830654978752136, 0.7733129858970642, 0.833644688129425, 0.8175773620605469, 0.8010179996490479, 0.7844117879867554, 0.815133810043335, 0.8801512122154236, 0.8071370124816895, 0.7960581183433533, 0.8020591139793396, 0.8274056911468506, 0.8263574242591858, 0.8425693511962891, 0.8096055388450623, 0.8023577332496643, 0.8177515268325806, 0.8563050031661987, 0.8179259300231934, 0.8414259552955627, 0.8280843496322632, 0.8286489248275757, 0.8870260715484619, 0.8573858737945557, 0.8517614603042603, 0.8587501049041748, 0.8588029742240906, 0.8399982452392578, 0.9012641906738281, 0.844020664691925, 0.8854209780693054, 0.869693398475647, 0.8757253885269165, 0.8844037055969238, 0.8586590886116028, 0.9407442808151245, 0.8658571839332581, 0.8544528484344482, 0.8868261575698853, 0.8604395389556885, 0.8622051477432251, 0.877555251121521, 0.9170688390731812, 1.0379711389541626, 0.8937495946884155, 0.8648410439491272, 0.864361047744751, 0.8841996788978577, 0.8674830198287964, 0.8719853758811951, 0.8943674564361572, 0.8697198629379272, 0.9293786883354187, 0.8925684094429016, 0.8917039632797241, 0.8796206116676331, 0.8913455009460449, 0.9250602126121521, 0.9117310643196106, 0.9149182438850403, 0.8965840935707092, 0.9120941758155823, 0.8976975679397583, 0.910625696182251, 0.9163848161697388, 0.9652561545372009, 0.9065210819244385, 0.907528281211853, 0.9355888962745667, 0.9292607307434082], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.5056561231613159, 0.523755669593811, 0.5395927429199219, 0.5769230723381042, 0.6380090713500977, 0.6244344115257263, 0.6527149081230164, 0.651583731174469, 0.6561086177825928, 0.6662895679473877, 0.6640271544456482, 0.6753393411636353, 0.6425339579582214, 0.6606335043907166, 0.6572397947311401, 0.662895917892456, 0.6595022678375244, 0.6696832776069641, 0.7285068035125732, 0.7138009071350098, 0.7307692170143127, 0.7884615659713745, 0.7816742062568665, 0.7703620195388794, 0.7839366793632507, 0.7929864525794983, 0.8020362257957458, 0.8088235259056091, 0.790723979473114, 0.7850678563117981, 0.7941176295280457, 0.7918552160263062, 0.790723979473114, 0.766968309879303, 0.7963801026344299, 0.7941176295280457, 0.7941176295280457, 0.7986425161361694, 0.7963801026344299, 0.7703620195388794, 0.7918552160263062, 0.7952488660812378, 0.790723979473114, 0.7929864525794983, 0.7963801026344299, 0.7805429697036743, 0.8031674027442932, 0.7952488660812378, 0.7647058963775635, 0.7963801026344299, 0.7782805562019348, 0.7963801026344299, 0.779411792755127, 0.7929864525794983, 0.7613122463226318, 0.790723979473114, 0.7647058963775635, 0.7861990928649902, 0.7873303294181824, 0.7895927429199219, 0.7929864525794983, 0.7703620195388794, 0.7918552160263062, 0.7918552160263062, 0.7782805562019348, 0.7828054428100586, 0.7839366793632507, 0.7873303294181824, 0.7714931964874268, 0.7285068035125732, 0.7760180830955505, 0.7873303294181824, 0.7975113391876221, 0.7861990928649902, 0.7941176295280457, 0.7918552160263062, 0.7873303294181824, 0.7884615659713745, 0.7839366793632507, 0.7884615659713745, 0.779411792755127, 0.7941176295280457, 0.790723979473114, 0.7884615659713745, 0.7895927429199219, 0.7760180830955505, 0.7850678563117981, 0.7850678563117981, 0.7861990928649902, 0.7850678563117981, 0.7861990928649902, 0.779411792755127, 0.7748869061470032, 0.7839366793632507, 0.7703620195388794, 0.7680995464324951]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 30ms/step - loss: 0.5144 - accuracy: 0.8948 - val_loss: 0.9971 - val_accuracy: 0.4855\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 16ms/step - loss: 0.4583 - accuracy: 0.9181 - val_loss: 0.9929 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4378 - accuracy: 0.9349 - val_loss: 0.9894 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4521 - accuracy: 0.9230 - val_loss: 0.9777 - val_accuracy: 0.4938\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4352 - accuracy: 0.9346 - val_loss: 0.9602 - val_accuracy: 0.5145\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4313 - accuracy: 0.9336 - val_loss: 0.9452 - val_accuracy: 0.5465\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4233 - accuracy: 0.9390 - val_loss: 0.9120 - val_accuracy: 0.6043\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4212 - accuracy: 0.9429 - val_loss: 0.9091 - val_accuracy: 0.6147\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4113 - accuracy: 0.9473 - val_loss: 0.9047 - val_accuracy: 0.6260\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4164 - accuracy: 0.9419 - val_loss: 0.9004 - val_accuracy: 0.6322\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.9455 - val_loss: 0.9141 - val_accuracy: 0.6229\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4057 - accuracy: 0.9509 - val_loss: 0.9332 - val_accuracy: 0.6312\n","Epoch 13/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4096 - accuracy: 0.9481 - val_loss: 1.0098 - val_accuracy: 0.6157\n","Epoch 14/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 0.9470 - val_loss: 1.0174 - val_accuracy: 0.6229\n","Epoch 15/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4014 - accuracy: 0.9525 - val_loss: 1.0570 - val_accuracy: 0.6147\n","Epoch 16/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4012 - accuracy: 0.9514 - val_loss: 1.0743 - val_accuracy: 0.6260\n","Epoch 17/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4040 - accuracy: 0.9499 - val_loss: 1.2038 - val_accuracy: 0.6198\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3919 - accuracy: 0.9579 - val_loss: 1.1672 - val_accuracy: 0.6405\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3926 - accuracy: 0.9571 - val_loss: 1.0115 - val_accuracy: 0.6715\n","Epoch 20/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4448 - accuracy: 0.9230 - val_loss: 1.6502 - val_accuracy: 0.5950\n","Epoch 21/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4199 - accuracy: 0.9408 - val_loss: 1.1880 - val_accuracy: 0.6570\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3886 - accuracy: 0.9599 - val_loss: 1.0969 - val_accuracy: 0.6942\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3907 - accuracy: 0.9579 - val_loss: 0.9422 - val_accuracy: 0.7283\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4182 - accuracy: 0.9370 - val_loss: 0.9994 - val_accuracy: 0.7159\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3934 - accuracy: 0.9522 - val_loss: 0.9027 - val_accuracy: 0.7428\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3812 - accuracy: 0.9633 - val_loss: 0.9452 - val_accuracy: 0.7448\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3798 - accuracy: 0.9636 - val_loss: 0.9070 - val_accuracy: 0.7531\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3781 - accuracy: 0.9610 - val_loss: 0.8889 - val_accuracy: 0.7676\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3869 - accuracy: 0.9589 - val_loss: 0.9279 - val_accuracy: 0.7531\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3814 - accuracy: 0.9620 - val_loss: 0.8933 - val_accuracy: 0.7686\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3754 - accuracy: 0.9633 - val_loss: 0.9108 - val_accuracy: 0.7614\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3725 - accuracy: 0.9680 - val_loss: 0.8934 - val_accuracy: 0.7624\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3744 - accuracy: 0.9638 - val_loss: 0.9006 - val_accuracy: 0.7665\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3717 - accuracy: 0.9669 - val_loss: 0.9117 - val_accuracy: 0.7614\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3714 - accuracy: 0.9643 - val_loss: 0.9030 - val_accuracy: 0.7665\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3671 - accuracy: 0.9672 - val_loss: 0.9164 - val_accuracy: 0.7541\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.9654 - val_loss: 0.9499 - val_accuracy: 0.7490\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.9602 - val_loss: 0.9187 - val_accuracy: 0.7603\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3648 - accuracy: 0.9682 - val_loss: 0.9171 - val_accuracy: 0.7572\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3631 - accuracy: 0.9682 - val_loss: 0.9345 - val_accuracy: 0.7645\n","Epoch 41/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3697 - accuracy: 0.9643 - val_loss: 0.9451 - val_accuracy: 0.7727\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3681 - accuracy: 0.9677 - val_loss: 0.9336 - val_accuracy: 0.7531\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3598 - accuracy: 0.9716 - val_loss: 0.9308 - val_accuracy: 0.7552\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3554 - accuracy: 0.9752 - val_loss: 0.9397 - val_accuracy: 0.7521\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3573 - accuracy: 0.9708 - val_loss: 0.9782 - val_accuracy: 0.7541\n","Epoch 46/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3627 - accuracy: 0.9674 - val_loss: 0.9488 - val_accuracy: 0.7500\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3568 - accuracy: 0.9726 - val_loss: 0.9484 - val_accuracy: 0.7541\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3644 - accuracy: 0.9651 - val_loss: 0.9602 - val_accuracy: 0.7645\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3576 - accuracy: 0.9693 - val_loss: 0.9835 - val_accuracy: 0.7531\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3571 - accuracy: 0.9695 - val_loss: 0.9646 - val_accuracy: 0.7510\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.9695 - val_loss: 0.9707 - val_accuracy: 0.7479\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3732 - accuracy: 0.9587 - val_loss: 1.0398 - val_accuracy: 0.7366\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3533 - accuracy: 0.9711 - val_loss: 0.9526 - val_accuracy: 0.7531\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3468 - accuracy: 0.9734 - val_loss: 0.9794 - val_accuracy: 0.7510\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3480 - accuracy: 0.9724 - val_loss: 1.0049 - val_accuracy: 0.7490\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3588 - accuracy: 0.9672 - val_loss: 0.9592 - val_accuracy: 0.7562\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3434 - accuracy: 0.9747 - val_loss: 0.9627 - val_accuracy: 0.7593\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3432 - accuracy: 0.9739 - val_loss: 0.9787 - val_accuracy: 0.7510\n","Epoch 59/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3421 - accuracy: 0.9765 - val_loss: 1.0816 - val_accuracy: 0.7231\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3500 - accuracy: 0.9718 - val_loss: 0.9873 - val_accuracy: 0.7500\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3399 - accuracy: 0.9765 - val_loss: 0.9790 - val_accuracy: 0.7521\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3406 - accuracy: 0.9773 - val_loss: 0.9882 - val_accuracy: 0.7572\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3460 - accuracy: 0.9703 - val_loss: 0.9938 - val_accuracy: 0.7438\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3597 - accuracy: 0.9636 - val_loss: 1.1107 - val_accuracy: 0.7355\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3555 - accuracy: 0.9674 - val_loss: 1.0072 - val_accuracy: 0.7510\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3388 - accuracy: 0.9770 - val_loss: 1.0016 - val_accuracy: 0.7521\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3351 - accuracy: 0.9791 - val_loss: 0.9889 - val_accuracy: 0.7459\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3341 - accuracy: 0.9780 - val_loss: 1.0106 - val_accuracy: 0.7417\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3387 - accuracy: 0.9734 - val_loss: 1.0034 - val_accuracy: 0.7521\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3464 - accuracy: 0.9700 - val_loss: 0.9984 - val_accuracy: 0.7562\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3425 - accuracy: 0.9693 - val_loss: 1.0159 - val_accuracy: 0.7521\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.9736 - val_loss: 1.0198 - val_accuracy: 0.7510\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3324 - accuracy: 0.9780 - val_loss: 1.0013 - val_accuracy: 0.7552\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3271 - accuracy: 0.9791 - val_loss: 1.0144 - val_accuracy: 0.7603\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3313 - accuracy: 0.9755 - val_loss: 1.0218 - val_accuracy: 0.7521\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3310 - accuracy: 0.9804 - val_loss: 1.0219 - val_accuracy: 0.7469\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3278 - accuracy: 0.9824 - val_loss: 1.0130 - val_accuracy: 0.7500\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3277 - accuracy: 0.9796 - val_loss: 1.0598 - val_accuracy: 0.7552\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3465 - accuracy: 0.9693 - val_loss: 1.0443 - val_accuracy: 0.7490\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3509 - accuracy: 0.9661 - val_loss: 1.3352 - val_accuracy: 0.6715\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3461 - accuracy: 0.9693 - val_loss: 1.0522 - val_accuracy: 0.7417\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3247 - accuracy: 0.9798 - val_loss: 1.0276 - val_accuracy: 0.7490\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3265 - accuracy: 0.9798 - val_loss: 1.1010 - val_accuracy: 0.7200\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3322 - accuracy: 0.9749 - val_loss: 1.0447 - val_accuracy: 0.7583\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3259 - accuracy: 0.9783 - val_loss: 1.0479 - val_accuracy: 0.7521\n","Epoch 86/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3203 - accuracy: 0.9817 - val_loss: 1.0274 - val_accuracy: 0.7531\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3303 - accuracy: 0.9755 - val_loss: 1.0989 - val_accuracy: 0.7335\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3228 - accuracy: 0.9804 - val_loss: 1.0442 - val_accuracy: 0.7479\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3208 - accuracy: 0.9806 - val_loss: 1.0647 - val_accuracy: 0.7510\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3308 - accuracy: 0.9767 - val_loss: 1.0964 - val_accuracy: 0.7252\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3247 - accuracy: 0.9804 - val_loss: 1.0410 - val_accuracy: 0.7459\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3214 - accuracy: 0.9801 - val_loss: 1.0715 - val_accuracy: 0.7500\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3195 - accuracy: 0.9832 - val_loss: 1.0487 - val_accuracy: 0.7386\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3164 - accuracy: 0.9832 - val_loss: 1.0516 - val_accuracy: 0.7552\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3131 - accuracy: 0.9840 - val_loss: 1.1352 - val_accuracy: 0.7056\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3214 - accuracy: 0.9793 - val_loss: 1.0881 - val_accuracy: 0.7438\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.9832 - val_loss: 1.1495 - val_accuracy: 0.7066\n","Epoch 98/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3120 - accuracy: 0.9855 - val_loss: 1.0709 - val_accuracy: 0.7448\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3148 - accuracy: 0.9832 - val_loss: 1.0565 - val_accuracy: 0.7552\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3151 - accuracy: 0.9829 - val_loss: 1.0739 - val_accuracy: 0.7428\n","{'loss': [0.5144041776657104, 0.45826536417007446, 0.4378264248371124, 0.45213934779167175, 0.4352279603481293, 0.43127191066741943, 0.4232640862464905, 0.4212242364883423, 0.41128629446029663, 0.4163745045661926, 0.4098435640335083, 0.4056893587112427, 0.40963295102119446, 0.40861380100250244, 0.4013915956020355, 0.40121862292289734, 0.40400800108909607, 0.39188745617866516, 0.3925841748714447, 0.44475284218788147, 0.4198704659938812, 0.38856241106987, 0.39068686962127686, 0.4181632101535797, 0.39335522055625916, 0.38124722242355347, 0.37982091307640076, 0.3781088590621948, 0.38692155480384827, 0.38142186403274536, 0.3753686249256134, 0.3725118935108185, 0.37437522411346436, 0.37170013785362244, 0.37140747904777527, 0.3670613169670105, 0.3712250590324402, 0.37576431035995483, 0.3648145794868469, 0.36310821771621704, 0.36972299218177795, 0.3680694103240967, 0.3597975969314575, 0.3554072976112366, 0.35725605487823486, 0.3627080023288727, 0.3568347096443176, 0.3643849790096283, 0.35755541920661926, 0.3570881485939026, 0.35804909467697144, 0.3731955885887146, 0.353319376707077, 0.3467807471752167, 0.34795835614204407, 0.35880374908447266, 0.3433983027935028, 0.34318116307258606, 0.3420686423778534, 0.34996870160102844, 0.33987492322921753, 0.3405808210372925, 0.3459605574607849, 0.3597199618816376, 0.3554677963256836, 0.33882495760917664, 0.3350592255592346, 0.3340786099433899, 0.3386784493923187, 0.34640148282051086, 0.3424857258796692, 0.3443286120891571, 0.33241787552833557, 0.3270840346813202, 0.3312876224517822, 0.33095452189445496, 0.3277553617954254, 0.3276512920856476, 0.3465207517147064, 0.35089343786239624, 0.3460911214351654, 0.32468169927597046, 0.32646963000297546, 0.33222660422325134, 0.3258582353591919, 0.3203185498714447, 0.3303234875202179, 0.32280775904655457, 0.3207647502422333, 0.3308214545249939, 0.3247074782848358, 0.3213770091533661, 0.3195073902606964, 0.3163599669933319, 0.3130541443824768, 0.32141637802124023, 0.3162788450717926, 0.3120328485965729, 0.31478679180145264, 0.31512635946273804], 'accuracy': [0.8948320150375366, 0.9180878400802612, 0.934883713722229, 0.9229974150657654, 0.9346253275871277, 0.9335917234420776, 0.9390180706977844, 0.9428940415382385, 0.94728684425354, 0.9418604373931885, 0.9454780220985413, 0.950904369354248, 0.948062002658844, 0.947028398513794, 0.9524548053741455, 0.9514212012290955, 0.9498708248138428, 0.9578811526298523, 0.9571059346199036, 0.9229974150657654, 0.9408268928527832, 0.9599483013153076, 0.9578811526298523, 0.9369509220123291, 0.9521963596343994, 0.9633074998855591, 0.9635658860206604, 0.9609819054603577, 0.9589147567749023, 0.9620155096054077, 0.9633074998855591, 0.9679586291313171, 0.9638242721557617, 0.9669250845909119, 0.9643411040306091, 0.9671834707260132, 0.9653746485710144, 0.9602067470550537, 0.9682170748710632, 0.9682170748710632, 0.9643411040306091, 0.9677002429962158, 0.9715762138366699, 0.9751937985420227, 0.970801055431366, 0.9674418568611145, 0.97260981798172, 0.9651162624359131, 0.9692506194114685, 0.9695090651512146, 0.9695090651512146, 0.9586563110351562, 0.9710594415664673, 0.9733850359916687, 0.9723514318466187, 0.9671834707260132, 0.9746770262718201, 0.9739018082618713, 0.9764857888221741, 0.9718345999717712, 0.9764857888221741, 0.9772610068321228, 0.9702842235565186, 0.9635658860206604, 0.9674418568611145, 0.9770025610923767, 0.9790697693824768, 0.9780361652374268, 0.9733850359916687, 0.9700258374214172, 0.9692506194114685, 0.97364342212677, 0.9780361652374268, 0.9790697693824768, 0.975452184677124, 0.9803617596626282, 0.9824289679527283, 0.9795865416526794, 0.9692506194114685, 0.9661498665809631, 0.9692506194114685, 0.9798449873924255, 0.9798449873924255, 0.9749354124069214, 0.9782945513725281, 0.9816537499427795, 0.975452184677124, 0.9803617596626282, 0.9806201457977295, 0.9767441749572754, 0.9803617596626282, 0.9801033735275269, 0.9832041263580322, 0.9832041263580322, 0.983979344367981, 0.9793281555175781, 0.9832041263580322, 0.9855297207832336, 0.9832041263580322, 0.9829457402229309], 'val_loss': [0.9970978498458862, 0.9928705096244812, 0.9893830418586731, 0.9776755571365356, 0.9602470993995667, 0.9451890587806702, 0.9120112657546997, 0.909107506275177, 0.9046977758407593, 0.9003899693489075, 0.9140561819076538, 0.9331970810890198, 1.0097613334655762, 1.0173943042755127, 1.0570039749145508, 1.0743355751037598, 1.203834891319275, 1.167240023612976, 1.0115054845809937, 1.6501957178115845, 1.1880245208740234, 1.0969254970550537, 0.9422364234924316, 0.9994460344314575, 0.9026768207550049, 0.945242702960968, 0.9070329666137695, 0.8888731002807617, 0.9279410243034363, 0.8932870030403137, 0.9107608795166016, 0.8934450745582581, 0.9006179571151733, 0.91166752576828, 0.9029829502105713, 0.9164385199546814, 0.9499099254608154, 0.9186840057373047, 0.9170843958854675, 0.9344862103462219, 0.9451088905334473, 0.9335669279098511, 0.9308469891548157, 0.9397300481796265, 0.9781587719917297, 0.9488227367401123, 0.9483988285064697, 0.9602342247962952, 0.9835256338119507, 0.964570939540863, 0.9706878662109375, 1.0397765636444092, 0.952592670917511, 0.9793566465377808, 1.0049151182174683, 0.9592325687408447, 0.9626662731170654, 0.9787120819091797, 1.081562876701355, 0.9873136281967163, 0.9789749383926392, 0.9881942868232727, 0.9938498139381409, 1.1107157468795776, 1.0072144269943237, 1.0015813112258911, 0.9888845682144165, 1.0105654001235962, 1.0034232139587402, 0.9984446167945862, 1.0158727169036865, 1.0198215246200562, 1.001280426979065, 1.0144137144088745, 1.0218403339385986, 1.0219371318817139, 1.0129773616790771, 1.059807538986206, 1.0442535877227783, 1.335219383239746, 1.052176594734192, 1.0276082754135132, 1.1009883880615234, 1.044708251953125, 1.0479233264923096, 1.0273767709732056, 1.0989233255386353, 1.044167399406433, 1.0646744966506958, 1.09638512134552, 1.0410206317901611, 1.0715047121047974, 1.0487468242645264, 1.0515841245651245, 1.1352355480194092, 1.0880844593048096, 1.1494957208633423, 1.070860505104065, 1.0565460920333862, 1.0739459991455078], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.49380165338516235, 0.5144628286361694, 0.5464876294136047, 0.6043388247489929, 0.6146694421768188, 0.6260330677032471, 0.6322314143180847, 0.6229338645935059, 0.6311983466148376, 0.6157024502754211, 0.6229338645935059, 0.6146694421768188, 0.6260330677032471, 0.6198347210884094, 0.6404958963394165, 0.6714876294136047, 0.5950413346290588, 0.6570248007774353, 0.6942148804664612, 0.7283057570457458, 0.7159090638160706, 0.7427685856819153, 0.7448347210884094, 0.7530992031097412, 0.7675619721412659, 0.7530992031097412, 0.7685950398445129, 0.7613636255264282, 0.7623966932296753, 0.7665289044380188, 0.7613636255264282, 0.7665289044380188, 0.7541322112083435, 0.7489669322967529, 0.7603305578231812, 0.7572314143180847, 0.7644628286361694, 0.7727272510528564, 0.7530992031097412, 0.7551652789115906, 0.7520661354064941, 0.7541322112083435, 0.75, 0.7541322112083435, 0.7644628286361694, 0.7530992031097412, 0.7510330677032471, 0.7479338645935059, 0.7365702390670776, 0.7530992031097412, 0.7510330677032471, 0.7489669322967529, 0.7561983466148376, 0.7592975497245789, 0.7510330677032471, 0.7231404781341553, 0.75, 0.7520661354064941, 0.7572314143180847, 0.7438016533851624, 0.7355371713638306, 0.7510330677032471, 0.7520661354064941, 0.7458677887916565, 0.7417355179786682, 0.7520661354064941, 0.7561983466148376, 0.7520661354064941, 0.7510330677032471, 0.7551652789115906, 0.7603305578231812, 0.7520661354064941, 0.7469007968902588, 0.75, 0.7551652789115906, 0.7489669322967529, 0.6714876294136047, 0.7417355179786682, 0.7489669322967529, 0.7200413346290588, 0.7582644820213318, 0.7520661354064941, 0.7530992031097412, 0.7334710955619812, 0.7479338645935059, 0.7510330677032471, 0.7252066135406494, 0.7458677887916565, 0.75, 0.7386363744735718, 0.7551652789115906, 0.7055785059928894, 0.7438016533851624, 0.7066115736961365, 0.7448347210884094, 0.7551652789115906, 0.7427685856819153]}\n","32/32 [==============================] - 0s 3ms/step\n"]}],"source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":161,"status":"ok","timestamp":1717437914846,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"y3RXIk-qZ7ts","outputId":"62b77f4f-89bc-4238-d598-02a261e81c5c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.657      0.698   0.554  0.618        0.554        0.760   \n","1        1     0.682      0.722   0.593  0.651        0.593        0.771   \n","2        2     0.662      0.676   0.620  0.647        0.620        0.703   \n","3        0     0.681      0.739   0.559  0.637        0.559        0.802   \n","4        1     0.708      0.725   0.672  0.697        0.672        0.744   \n","5        2     0.672      0.649   0.749  0.695        0.749        0.594   \n","6        0     0.714      0.752   0.637  0.690        0.637        0.791   \n","7        1     0.710      0.737   0.653  0.692        0.653        0.767   \n","8        2     0.710      0.674   0.813  0.737        0.813        0.606   \n","9        0     0.741      0.753   0.719  0.735        0.719        0.764   \n","10       1     0.733      0.722   0.758  0.740        0.758        0.708   \n","11       2     0.766      0.746   0.807  0.775        0.807        0.725   \n","12       0     0.767      0.778   0.747  0.762        0.747        0.787   \n","13       1     0.763      0.773   0.744  0.758        0.744        0.781   \n","14       2     0.790      0.808   0.761  0.784        0.761        0.819   \n","\n","    Kappa  \n","0   0.315  \n","1   0.364  \n","2   0.323  \n","3   0.362  \n","4   0.417  \n","5   0.343  \n","6   0.427  \n","7   0.419  \n","8   0.420  \n","9   0.482  \n","10  0.466  \n","11  0.532  \n","12  0.534  \n","13  0.525  \n","14  0.580  "],"text/html":["\n","  <div id=\"df-0a2b86d0-b204-43c6-84db-e38354441b89\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.657</td>\n","      <td>0.698</td>\n","      <td>0.554</td>\n","      <td>0.618</td>\n","      <td>0.554</td>\n","      <td>0.760</td>\n","      <td>0.315</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.682</td>\n","      <td>0.722</td>\n","      <td>0.593</td>\n","      <td>0.651</td>\n","      <td>0.593</td>\n","      <td>0.771</td>\n","      <td>0.364</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.662</td>\n","      <td>0.676</td>\n","      <td>0.620</td>\n","      <td>0.647</td>\n","      <td>0.620</td>\n","      <td>0.703</td>\n","      <td>0.323</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.681</td>\n","      <td>0.739</td>\n","      <td>0.559</td>\n","      <td>0.637</td>\n","      <td>0.559</td>\n","      <td>0.802</td>\n","      <td>0.362</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.708</td>\n","      <td>0.725</td>\n","      <td>0.672</td>\n","      <td>0.697</td>\n","      <td>0.672</td>\n","      <td>0.744</td>\n","      <td>0.417</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.672</td>\n","      <td>0.649</td>\n","      <td>0.749</td>\n","      <td>0.695</td>\n","      <td>0.749</td>\n","      <td>0.594</td>\n","      <td>0.343</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.714</td>\n","      <td>0.752</td>\n","      <td>0.637</td>\n","      <td>0.690</td>\n","      <td>0.637</td>\n","      <td>0.791</td>\n","      <td>0.427</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.710</td>\n","      <td>0.737</td>\n","      <td>0.653</td>\n","      <td>0.692</td>\n","      <td>0.653</td>\n","      <td>0.767</td>\n","      <td>0.419</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.710</td>\n","      <td>0.674</td>\n","      <td>0.813</td>\n","      <td>0.737</td>\n","      <td>0.813</td>\n","      <td>0.606</td>\n","      <td>0.420</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.741</td>\n","      <td>0.753</td>\n","      <td>0.719</td>\n","      <td>0.735</td>\n","      <td>0.719</td>\n","      <td>0.764</td>\n","      <td>0.482</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.733</td>\n","      <td>0.722</td>\n","      <td>0.758</td>\n","      <td>0.740</td>\n","      <td>0.758</td>\n","      <td>0.708</td>\n","      <td>0.466</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.766</td>\n","      <td>0.746</td>\n","      <td>0.807</td>\n","      <td>0.775</td>\n","      <td>0.807</td>\n","      <td>0.725</td>\n","      <td>0.532</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.767</td>\n","      <td>0.778</td>\n","      <td>0.747</td>\n","      <td>0.762</td>\n","      <td>0.747</td>\n","      <td>0.787</td>\n","      <td>0.534</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.763</td>\n","      <td>0.773</td>\n","      <td>0.744</td>\n","      <td>0.758</td>\n","      <td>0.744</td>\n","      <td>0.781</td>\n","      <td>0.525</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.790</td>\n","      <td>0.808</td>\n","      <td>0.761</td>\n","      <td>0.784</td>\n","      <td>0.761</td>\n","      <td>0.819</td>\n","      <td>0.580</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a2b86d0-b204-43c6-84db-e38354441b89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0a2b86d0-b204-43c6-84db-e38354441b89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0a2b86d0-b204-43c6-84db-e38354441b89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b5a50444-d3fa-4ca2-a831-1735b8f70757\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5a50444-d3fa-4ca2-a831-1735b8f70757')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b5a50444-d3fa-4ca2-a831-1735b8f70757 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04186452072146646,\n        \"min\": 0.657,\n        \"max\": 0.79,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.733,\n          0.767,\n          0.657\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04261600414778243,\n        \"min\": 0.649,\n        \"max\": 0.808,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.753,\n          0.778,\n          0.698\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.085920062516604,\n        \"min\": 0.554,\n        \"max\": 0.813,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.719,\n          0.807,\n          0.554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05295262932452885,\n        \"min\": 0.618,\n        \"max\": 0.784,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.735,\n          0.775,\n          0.618\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.085920062516604,\n        \"min\": 0.554,\n        \"max\": 0.813,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.719,\n          0.807,\n          0.554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06607124581699308,\n        \"min\": 0.594,\n        \"max\": 0.819,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.764,\n          0.725,\n          0.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08372358147641616,\n        \"min\": 0.315,\n        \"max\": 0.58,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.482,\n          0.532,\n          0.315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}],"source":["metrics_df_CNN.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iOLsKpkfzdG"},"outputs":[],"source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_GRU/Theta_time_CNN.csv', index = False)"]},{"cell_type":"markdown","source":["# gru\n"],"metadata":{"id":"x8YOZ0tQKOzX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieXSN-9PI4Dx"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Theta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Theta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-YKWxdsKbbP","executionInfo":{"status":"ok","timestamp":1717439089510,"user_tz":-360,"elapsed":1174806,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"73b75874-fa63-473e-c60f-1eea08372493"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.4312 - accuracy: 0.4971"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 53ms/step - loss: 1.4311 - accuracy: 0.4989 - val_loss: 1.4288 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4253 - accuracy: 0.5113 - val_loss: 1.4238 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4196 - accuracy: 0.5030 - val_loss: 1.4188 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4145 - accuracy: 0.5081 - val_loss: 1.4138 - val_accuracy: 0.4892\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4087 - accuracy: 0.5129 - val_loss: 1.4089 - val_accuracy: 0.6207\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4032 - accuracy: 0.5129 - val_loss: 1.4040 - val_accuracy: 0.5377\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3971 - accuracy: 0.5461 - val_loss: 1.3990 - val_accuracy: 0.5388\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3907 - accuracy: 0.5606 - val_loss: 1.3942 - val_accuracy: 0.5205\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3829 - accuracy: 0.5628 - val_loss: 1.3893 - val_accuracy: 0.5172\n","Epoch 10/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3735 - accuracy: 0.6102 - val_loss: 1.3838 - val_accuracy: 0.5280\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3648 - accuracy: 0.6115 - val_loss: 1.3785 - val_accuracy: 0.5291\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3549 - accuracy: 0.6263 - val_loss: 1.3707 - val_accuracy: 0.5647\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3456 - accuracy: 0.6142 - val_loss: 1.3655 - val_accuracy: 0.5420\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3331 - accuracy: 0.6409 - val_loss: 1.3650 - val_accuracy: 0.5269\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3192 - accuracy: 0.6425 - val_loss: 1.3496 - val_accuracy: 0.5679\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3148 - accuracy: 0.6363 - val_loss: 1.3512 - val_accuracy: 0.5388\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3036 - accuracy: 0.6387 - val_loss: 1.3419 - val_accuracy: 0.5571\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2941 - accuracy: 0.6589 - val_loss: 1.3339 - val_accuracy: 0.5733\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2885 - accuracy: 0.6546 - val_loss: 1.3109 - val_accuracy: 0.6272\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2804 - accuracy: 0.6630 - val_loss: 1.3119 - val_accuracy: 0.6045\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2784 - accuracy: 0.6506 - val_loss: 1.2903 - val_accuracy: 0.6541\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2711 - accuracy: 0.6598 - val_loss: 1.2813 - val_accuracy: 0.6562\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2603 - accuracy: 0.6670 - val_loss: 1.2645 - val_accuracy: 0.6692\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2581 - accuracy: 0.6641 - val_loss: 1.2901 - val_accuracy: 0.6336\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2541 - accuracy: 0.6673 - val_loss: 1.2561 - val_accuracy: 0.6606\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2492 - accuracy: 0.6643 - val_loss: 1.2479 - val_accuracy: 0.6681\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2427 - accuracy: 0.6700 - val_loss: 1.2423 - val_accuracy: 0.6724\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2399 - accuracy: 0.6686 - val_loss: 1.2380 - val_accuracy: 0.6789\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2341 - accuracy: 0.6748 - val_loss: 1.2342 - val_accuracy: 0.6767\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2319 - accuracy: 0.6711 - val_loss: 1.2453 - val_accuracy: 0.6692\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2316 - accuracy: 0.6659 - val_loss: 1.2288 - val_accuracy: 0.6616\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2225 - accuracy: 0.6719 - val_loss: 1.2298 - val_accuracy: 0.6670\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2242 - accuracy: 0.6673 - val_loss: 1.2281 - val_accuracy: 0.6584\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2173 - accuracy: 0.6686 - val_loss: 1.2245 - val_accuracy: 0.6659\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2119 - accuracy: 0.6697 - val_loss: 1.2139 - val_accuracy: 0.6627\n","Epoch 36/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2061 - accuracy: 0.6765 - val_loss: 1.2083 - val_accuracy: 0.6800\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2006 - accuracy: 0.6800 - val_loss: 1.2127 - val_accuracy: 0.6616\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1997 - accuracy: 0.6751 - val_loss: 1.2016 - val_accuracy: 0.6713\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1921 - accuracy: 0.6759 - val_loss: 1.2015 - val_accuracy: 0.6659\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1893 - accuracy: 0.6800 - val_loss: 1.2008 - val_accuracy: 0.6703\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1871 - accuracy: 0.6738 - val_loss: 1.1944 - val_accuracy: 0.6681\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1803 - accuracy: 0.6802 - val_loss: 1.1874 - val_accuracy: 0.6756\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1787 - accuracy: 0.6821 - val_loss: 1.1849 - val_accuracy: 0.6692\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1737 - accuracy: 0.6862 - val_loss: 1.1813 - val_accuracy: 0.6670\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1711 - accuracy: 0.6837 - val_loss: 1.1784 - val_accuracy: 0.6843\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1670 - accuracy: 0.6827 - val_loss: 1.1807 - val_accuracy: 0.6746\n","Epoch 47/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1633 - accuracy: 0.6840 - val_loss: 1.1706 - val_accuracy: 0.6853\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1593 - accuracy: 0.6883 - val_loss: 1.1768 - val_accuracy: 0.6735\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1561 - accuracy: 0.6848 - val_loss: 1.1642 - val_accuracy: 0.6853\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1501 - accuracy: 0.6883 - val_loss: 1.1728 - val_accuracy: 0.6724\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1462 - accuracy: 0.6907 - val_loss: 1.1586 - val_accuracy: 0.6746\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1450 - accuracy: 0.6872 - val_loss: 1.1641 - val_accuracy: 0.6735\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1458 - accuracy: 0.6816 - val_loss: 1.1542 - val_accuracy: 0.6703\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1356 - accuracy: 0.6918 - val_loss: 1.1492 - val_accuracy: 0.6832\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1320 - accuracy: 0.6888 - val_loss: 1.1464 - val_accuracy: 0.6746\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1323 - accuracy: 0.6864 - val_loss: 1.1427 - val_accuracy: 0.6800\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1267 - accuracy: 0.6956 - val_loss: 1.1466 - val_accuracy: 0.6735\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1219 - accuracy: 0.6942 - val_loss: 1.1399 - val_accuracy: 0.6724\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1165 - accuracy: 0.6948 - val_loss: 1.1340 - val_accuracy: 0.6832\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1178 - accuracy: 0.6883 - val_loss: 1.1335 - val_accuracy: 0.6756\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1134 - accuracy: 0.6945 - val_loss: 1.1279 - val_accuracy: 0.6843\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1074 - accuracy: 0.6953 - val_loss: 1.1252 - val_accuracy: 0.6821\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1045 - accuracy: 0.6915 - val_loss: 1.1236 - val_accuracy: 0.6756\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1022 - accuracy: 0.6910 - val_loss: 1.1226 - val_accuracy: 0.6746\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0993 - accuracy: 0.6972 - val_loss: 1.1182 - val_accuracy: 0.6800\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0959 - accuracy: 0.6953 - val_loss: 1.1222 - val_accuracy: 0.6724\n","Epoch 67/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0912 - accuracy: 0.7039 - val_loss: 1.1110 - val_accuracy: 0.6864\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0872 - accuracy: 0.7004 - val_loss: 1.1184 - val_accuracy: 0.6703\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0823 - accuracy: 0.7002 - val_loss: 1.1069 - val_accuracy: 0.6778\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0800 - accuracy: 0.7055 - val_loss: 1.1078 - val_accuracy: 0.6746\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0768 - accuracy: 0.7023 - val_loss: 1.1008 - val_accuracy: 0.6832\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0718 - accuracy: 0.7034 - val_loss: 1.0986 - val_accuracy: 0.6810\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0689 - accuracy: 0.7082 - val_loss: 1.0964 - val_accuracy: 0.6767\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0653 - accuracy: 0.7061 - val_loss: 1.0918 - val_accuracy: 0.6864\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0567 - accuracy: 0.7099 - val_loss: 1.0906 - val_accuracy: 0.6810\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0595 - accuracy: 0.7109 - val_loss: 1.1010 - val_accuracy: 0.6703\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0545 - accuracy: 0.7077 - val_loss: 1.0837 - val_accuracy: 0.6907\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0522 - accuracy: 0.7039 - val_loss: 1.0813 - val_accuracy: 0.6832\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0490 - accuracy: 0.7053 - val_loss: 1.0809 - val_accuracy: 0.6897\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0437 - accuracy: 0.7136 - val_loss: 1.0789 - val_accuracy: 0.6756\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0418 - accuracy: 0.7120 - val_loss: 1.0732 - val_accuracy: 0.6843\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0379 - accuracy: 0.7091 - val_loss: 1.0705 - val_accuracy: 0.6843\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0302 - accuracy: 0.7155 - val_loss: 1.0729 - val_accuracy: 0.6800\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0297 - accuracy: 0.7134 - val_loss: 1.0680 - val_accuracy: 0.6864\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0295 - accuracy: 0.7126 - val_loss: 1.0634 - val_accuracy: 0.6875\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0224 - accuracy: 0.7150 - val_loss: 1.0719 - val_accuracy: 0.6789\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0189 - accuracy: 0.7126 - val_loss: 1.0600 - val_accuracy: 0.6800\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0179 - accuracy: 0.7169 - val_loss: 1.0563 - val_accuracy: 0.6821\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0107 - accuracy: 0.7236 - val_loss: 1.0710 - val_accuracy: 0.6692\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0098 - accuracy: 0.7225 - val_loss: 1.0589 - val_accuracy: 0.6821\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0066 - accuracy: 0.7241 - val_loss: 1.0572 - val_accuracy: 0.6800\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0030 - accuracy: 0.7236 - val_loss: 1.0466 - val_accuracy: 0.6853\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9985 - accuracy: 0.7204 - val_loss: 1.0460 - val_accuracy: 0.6843\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9901 - accuracy: 0.7311 - val_loss: 1.0582 - val_accuracy: 0.6724\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9901 - accuracy: 0.7233 - val_loss: 1.0469 - val_accuracy: 0.6767\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9843 - accuracy: 0.7341 - val_loss: 1.0458 - val_accuracy: 0.6778\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9849 - accuracy: 0.7244 - val_loss: 1.0363 - val_accuracy: 0.6853\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9794 - accuracy: 0.7320 - val_loss: 1.0359 - val_accuracy: 0.6810\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9763 - accuracy: 0.7303 - val_loss: 1.0449 - val_accuracy: 0.6767\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9721 - accuracy: 0.7287 - val_loss: 1.0319 - val_accuracy: 0.6810\n","{'loss': [1.431052803993225, 1.4253486394882202, 1.4196135997772217, 1.4145255088806152, 1.408692717552185, 1.4031599760055542, 1.3970659971237183, 1.3907092809677124, 1.3828922510147095, 1.3735132217407227, 1.3647644519805908, 1.3549305200576782, 1.3455935716629028, 1.333086609840393, 1.3191502094268799, 1.3148071765899658, 1.3036068677902222, 1.2941373586654663, 1.2884594202041626, 1.280441164970398, 1.2784149646759033, 1.2710795402526855, 1.2602509260177612, 1.2581075429916382, 1.2540730237960815, 1.2492038011550903, 1.242653250694275, 1.2399169206619263, 1.2340943813323975, 1.2318559885025024, 1.2315512895584106, 1.2224863767623901, 1.2242028713226318, 1.217315673828125, 1.211876630783081, 1.2061232328414917, 1.200575828552246, 1.1996866464614868, 1.1921420097351074, 1.1893455982208252, 1.1871079206466675, 1.180293321609497, 1.178673505783081, 1.1737452745437622, 1.171090841293335, 1.1669590473175049, 1.1633265018463135, 1.1592975854873657, 1.1560801267623901, 1.1501346826553345, 1.1461949348449707, 1.1450157165527344, 1.1458475589752197, 1.1355646848678589, 1.1320128440856934, 1.1323401927947998, 1.126691222190857, 1.121948480606079, 1.1165293455123901, 1.1177914142608643, 1.113381266593933, 1.1073683500289917, 1.1045278310775757, 1.1022359132766724, 1.099250316619873, 1.0959113836288452, 1.0912458896636963, 1.0872406959533691, 1.0822899341583252, 1.080028772354126, 1.0767645835876465, 1.071811556816101, 1.0689293146133423, 1.0652563571929932, 1.0567065477371216, 1.0594501495361328, 1.054499864578247, 1.0521878004074097, 1.0490330457687378, 1.043731451034546, 1.0418074131011963, 1.0378772020339966, 1.0302451848983765, 1.0296865701675415, 1.029528260231018, 1.0224149227142334, 1.0188742876052856, 1.0179325342178345, 1.0107043981552124, 1.0098406076431274, 1.0065678358078003, 1.0030324459075928, 0.9985107779502869, 0.9900790452957153, 0.9900946021080017, 0.9843059778213501, 0.9848639369010925, 0.9793854355812073, 0.9762659668922424, 0.9721269011497498], 'accuracy': [0.4989224076271057, 0.5113146305084229, 0.5029633641242981, 0.5080819129943848, 0.5129310488700867, 0.5129310488700867, 0.5460668206214905, 0.5606142282485962, 0.5627694129943848, 0.6101831793785095, 0.6115301847457886, 0.626347005367279, 0.6142241358757019, 0.6408944129943848, 0.6425107717514038, 0.6363146305084229, 0.6387392282485962, 0.6589439511299133, 0.654633641242981, 0.6629849076271057, 0.6505926847457886, 0.6597521305084229, 0.6670258641242981, 0.6640625, 0.6672952771186829, 0.6643319129943848, 0.6699892282485962, 0.6686422228813171, 0.6748383641242981, 0.6710668206214905, 0.6659482717514038, 0.671875, 0.6672952771186829, 0.6686422228813171, 0.6697198152542114, 0.6764547228813171, 0.6799569129943848, 0.6751077771186829, 0.6759159564971924, 0.6799569129943848, 0.6737607717514038, 0.6802262663841248, 0.6821120977401733, 0.686152994632721, 0.6837284564971924, 0.6826508641242981, 0.6839978694915771, 0.6883081793785095, 0.6848060488700867, 0.6883081793785095, 0.6907327771186829, 0.6872305870056152, 0.6815732717514038, 0.6918103694915771, 0.688847005367279, 0.6864224076271057, 0.6955819129943848, 0.6942349076271057, 0.6947737336158752, 0.6883081793785095, 0.6945043206214905, 0.6953125, 0.6915409564971924, 0.6910021305084229, 0.6971982717514038, 0.6953125, 0.7039331793785095, 0.7004310488700867, 0.7001616358757019, 0.7055495977401733, 0.7023168206214905, 0.7033944129943848, 0.7082435488700867, 0.7060883641242981, 0.7098599076271057, 0.7109375, 0.7077047228813171, 0.7039331793785095, 0.7052801847457886, 0.7136314511299133, 0.7120150923728943, 0.7090517282485962, 0.7155172228813171, 0.7133620977401733, 0.712553858757019, 0.7149784564971924, 0.712553858757019, 0.7168642282485962, 0.7235991358757019, 0.7225215435028076, 0.7241379022598267, 0.7235991358757019, 0.720366358757019, 0.7311422228813171, 0.7233297228813171, 0.7341055870056152, 0.7244073152542114, 0.7319504022598267, 0.7303340435028076, 0.7287176847457886], 'val_loss': [1.4288222789764404, 1.4237802028656006, 1.4187836647033691, 1.4138115644454956, 1.4088842868804932, 1.4039933681488037, 1.3989942073822021, 1.3941737413406372, 1.3893367052078247, 1.3837668895721436, 1.3785184621810913, 1.370691180229187, 1.3654999732971191, 1.3649706840515137, 1.3496286869049072, 1.3511910438537598, 1.3419349193572998, 1.3338992595672607, 1.310908555984497, 1.3118808269500732, 1.2903401851654053, 1.2812809944152832, 1.264493465423584, 1.2901034355163574, 1.256075382232666, 1.2479329109191895, 1.2422590255737305, 1.2379887104034424, 1.2341715097427368, 1.2452843189239502, 1.2287559509277344, 1.229819416999817, 1.2281044721603394, 1.2244713306427002, 1.2138993740081787, 1.2083384990692139, 1.2127461433410645, 1.2015715837478638, 1.201543927192688, 1.2008031606674194, 1.1944315433502197, 1.1873799562454224, 1.184895634651184, 1.1812851428985596, 1.1783740520477295, 1.1807347536087036, 1.1706383228302002, 1.1767827272415161, 1.164219617843628, 1.172799825668335, 1.158624291419983, 1.1640570163726807, 1.154221534729004, 1.14922034740448, 1.146350622177124, 1.1426723003387451, 1.1465717554092407, 1.1399297714233398, 1.1340348720550537, 1.13353431224823, 1.1278860569000244, 1.1251959800720215, 1.1236034631729126, 1.1226272583007812, 1.1182385683059692, 1.1222232580184937, 1.110957384109497, 1.1183613538742065, 1.1069097518920898, 1.1078174114227295, 1.1007634401321411, 1.0986151695251465, 1.0963915586471558, 1.0918474197387695, 1.0906039476394653, 1.1009678840637207, 1.0837275981903076, 1.0812782049179077, 1.080867886543274, 1.078902244567871, 1.0731513500213623, 1.070540428161621, 1.072914481163025, 1.068011999130249, 1.063415288925171, 1.0719101428985596, 1.0599623918533325, 1.0562548637390137, 1.0709911584854126, 1.0588539838790894, 1.0571950674057007, 1.0465720891952515, 1.04598069190979, 1.0581952333450317, 1.04692542552948, 1.0457819700241089, 1.0363367795944214, 1.0358656644821167, 1.04485023021698, 1.031857967376709], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4892241358757019, 0.6206896305084229, 0.537715494632721, 0.5387930870056152, 0.5204741358757019, 0.517241358757019, 0.5280172228813171, 0.5290948152542114, 0.5646551847457886, 0.5420258641242981, 0.5269396305084229, 0.5678879022598267, 0.5387930870056152, 0.5571120977401733, 0.5732758641242981, 0.6271551847457886, 0.6045258641242981, 0.6540948152542114, 0.65625, 0.6691810488700867, 0.6336206793785095, 0.6605603694915771, 0.6681034564971924, 0.6724137663841248, 0.6788793206214905, 0.6767241358757019, 0.6691810488700867, 0.6616379022598267, 0.6670258641242981, 0.6584051847457886, 0.6659482717514038, 0.662715494632721, 0.6799569129943848, 0.6616379022598267, 0.6713362336158752, 0.6659482717514038, 0.670258641242981, 0.6681034564971924, 0.6756465435028076, 0.6691810488700867, 0.6670258641242981, 0.6842672228813171, 0.6745689511299133, 0.6853448152542114, 0.673491358757019, 0.6853448152542114, 0.6724137663841248, 0.6745689511299133, 0.673491358757019, 0.670258641242981, 0.6831896305084229, 0.6745689511299133, 0.6799569129943848, 0.673491358757019, 0.6724137663841248, 0.6831896305084229, 0.6756465435028076, 0.6842672228813171, 0.6821120977401733, 0.6756465435028076, 0.6745689511299133, 0.6799569129943848, 0.6724137663841248, 0.6864224076271057, 0.670258641242981, 0.6778017282485962, 0.6745689511299133, 0.6831896305084229, 0.681034505367279, 0.6767241358757019, 0.6864224076271057, 0.681034505367279, 0.670258641242981, 0.6907327771186829, 0.6831896305084229, 0.6896551847457886, 0.6756465435028076, 0.6842672228813171, 0.6842672228813171, 0.6799569129943848, 0.6864224076271057, 0.6875, 0.6788793206214905, 0.6799569129943848, 0.6821120977401733, 0.6691810488700867, 0.6821120977401733, 0.6799569129943848, 0.6853448152542114, 0.6842672228813171, 0.6724137663841248, 0.6767241358757019, 0.6778017282485962, 0.6853448152542114, 0.681034505367279, 0.6767241358757019, 0.681034505367279]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 7s 52ms/step - loss: 1.4314 - accuracy: 0.5014 - val_loss: 1.4290 - val_accuracy: 0.4955\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4254 - accuracy: 0.5062 - val_loss: 1.4242 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4206 - accuracy: 0.5008 - val_loss: 1.4194 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4152 - accuracy: 0.5059 - val_loss: 1.4147 - val_accuracy: 0.6007\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4099 - accuracy: 0.5040 - val_loss: 1.4100 - val_accuracy: 0.5158\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4040 - accuracy: 0.5323 - val_loss: 1.4054 - val_accuracy: 0.5045\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3986 - accuracy: 0.5374 - val_loss: 1.4008 - val_accuracy: 0.5045\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3919 - accuracy: 0.5475 - val_loss: 1.3962 - val_accuracy: 0.5045\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3833 - accuracy: 0.6138 - val_loss: 1.3910 - val_accuracy: 0.5181\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3783 - accuracy: 0.5628 - val_loss: 1.3883 - val_accuracy: 0.5045\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3693 - accuracy: 0.5917 - val_loss: 1.3842 - val_accuracy: 0.5045\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3607 - accuracy: 0.6160 - val_loss: 1.3793 - val_accuracy: 0.5079\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3500 - accuracy: 0.6304 - val_loss: 1.3723 - val_accuracy: 0.5192\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3406 - accuracy: 0.6186 - val_loss: 1.3653 - val_accuracy: 0.5283\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3292 - accuracy: 0.6296 - val_loss: 1.3630 - val_accuracy: 0.5283\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3196 - accuracy: 0.6367 - val_loss: 1.3579 - val_accuracy: 0.5294\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3109 - accuracy: 0.6364 - val_loss: 1.3582 - val_accuracy: 0.5283\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3010 - accuracy: 0.6443 - val_loss: 1.3452 - val_accuracy: 0.5532\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2925 - accuracy: 0.6579 - val_loss: 1.3318 - val_accuracy: 0.5758\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2905 - accuracy: 0.6440 - val_loss: 1.3322 - val_accuracy: 0.5679\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2820 - accuracy: 0.6454 - val_loss: 1.3073 - val_accuracy: 0.6154\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2789 - accuracy: 0.6491 - val_loss: 1.3180 - val_accuracy: 0.5894\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2729 - accuracy: 0.6508 - val_loss: 1.3091 - val_accuracy: 0.6029\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2643 - accuracy: 0.6616 - val_loss: 1.2840 - val_accuracy: 0.6425\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2590 - accuracy: 0.6607 - val_loss: 1.2862 - val_accuracy: 0.6301\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2554 - accuracy: 0.6630 - val_loss: 1.2737 - val_accuracy: 0.6482\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2518 - accuracy: 0.6641 - val_loss: 1.2584 - val_accuracy: 0.6697\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2540 - accuracy: 0.6548 - val_loss: 1.2604 - val_accuracy: 0.6584\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2424 - accuracy: 0.6613 - val_loss: 1.2522 - val_accuracy: 0.6674\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2397 - accuracy: 0.6630 - val_loss: 1.2465 - val_accuracy: 0.6776\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2370 - accuracy: 0.6548 - val_loss: 1.2436 - val_accuracy: 0.6629\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2292 - accuracy: 0.6729 - val_loss: 1.2400 - val_accuracy: 0.6731\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2232 - accuracy: 0.6669 - val_loss: 1.2365 - val_accuracy: 0.6765\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2214 - accuracy: 0.6698 - val_loss: 1.2343 - val_accuracy: 0.6697\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2172 - accuracy: 0.6695 - val_loss: 1.2299 - val_accuracy: 0.6719\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2159 - accuracy: 0.6644 - val_loss: 1.2303 - val_accuracy: 0.6595\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2134 - accuracy: 0.6641 - val_loss: 1.2222 - val_accuracy: 0.6753\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2025 - accuracy: 0.6760 - val_loss: 1.2194 - val_accuracy: 0.6742\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2035 - accuracy: 0.6686 - val_loss: 1.2221 - val_accuracy: 0.6561\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2001 - accuracy: 0.6675 - val_loss: 1.2139 - val_accuracy: 0.6731\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1955 - accuracy: 0.6706 - val_loss: 1.2092 - val_accuracy: 0.6753\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1946 - accuracy: 0.6655 - val_loss: 1.2059 - val_accuracy: 0.6731\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1895 - accuracy: 0.6703 - val_loss: 1.2025 - val_accuracy: 0.6731\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1843 - accuracy: 0.6701 - val_loss: 1.2021 - val_accuracy: 0.6719\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1815 - accuracy: 0.6743 - val_loss: 1.1962 - val_accuracy: 0.6708\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1776 - accuracy: 0.6701 - val_loss: 1.1925 - val_accuracy: 0.6731\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1713 - accuracy: 0.6771 - val_loss: 1.1947 - val_accuracy: 0.6663\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1706 - accuracy: 0.6828 - val_loss: 1.1871 - val_accuracy: 0.6686\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1648 - accuracy: 0.6845 - val_loss: 1.1893 - val_accuracy: 0.6606\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1618 - accuracy: 0.6746 - val_loss: 1.1850 - val_accuracy: 0.6629\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1569 - accuracy: 0.6808 - val_loss: 1.1775 - val_accuracy: 0.6708\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1537 - accuracy: 0.6817 - val_loss: 1.1767 - val_accuracy: 0.6697\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1518 - accuracy: 0.6783 - val_loss: 1.1735 - val_accuracy: 0.6674\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1478 - accuracy: 0.6834 - val_loss: 1.1688 - val_accuracy: 0.6731\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1453 - accuracy: 0.6817 - val_loss: 1.1658 - val_accuracy: 0.6731\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1383 - accuracy: 0.6873 - val_loss: 1.1630 - val_accuracy: 0.6674\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1394 - accuracy: 0.6797 - val_loss: 1.1618 - val_accuracy: 0.6640\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1324 - accuracy: 0.6885 - val_loss: 1.1583 - val_accuracy: 0.6697\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1267 - accuracy: 0.6882 - val_loss: 1.1546 - val_accuracy: 0.6674\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1221 - accuracy: 0.6899 - val_loss: 1.1533 - val_accuracy: 0.6640\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1204 - accuracy: 0.6921 - val_loss: 1.1479 - val_accuracy: 0.6697\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1177 - accuracy: 0.6924 - val_loss: 1.1458 - val_accuracy: 0.6618\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1147 - accuracy: 0.6853 - val_loss: 1.1438 - val_accuracy: 0.6674\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1113 - accuracy: 0.6916 - val_loss: 1.1471 - val_accuracy: 0.6697\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1119 - accuracy: 0.6910 - val_loss: 1.1406 - val_accuracy: 0.6663\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1061 - accuracy: 0.6904 - val_loss: 1.1386 - val_accuracy: 0.6697\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1002 - accuracy: 0.6921 - val_loss: 1.1400 - val_accuracy: 0.6640\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0977 - accuracy: 0.6921 - val_loss: 1.1284 - val_accuracy: 0.6697\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0944 - accuracy: 0.7009 - val_loss: 1.1266 - val_accuracy: 0.6686\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0923 - accuracy: 0.6947 - val_loss: 1.1240 - val_accuracy: 0.6652\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0840 - accuracy: 0.7043 - val_loss: 1.1217 - val_accuracy: 0.6686\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0873 - accuracy: 0.6919 - val_loss: 1.1225 - val_accuracy: 0.6663\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0824 - accuracy: 0.6958 - val_loss: 1.1195 - val_accuracy: 0.6686\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0778 - accuracy: 0.6998 - val_loss: 1.1125 - val_accuracy: 0.6742\n","Epoch 75/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0731 - accuracy: 0.7018 - val_loss: 1.1110 - val_accuracy: 0.6708\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0702 - accuracy: 0.7035 - val_loss: 1.1078 - val_accuracy: 0.6719\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0660 - accuracy: 0.7111 - val_loss: 1.1066 - val_accuracy: 0.6719\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0629 - accuracy: 0.6998 - val_loss: 1.1045 - val_accuracy: 0.6663\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0605 - accuracy: 0.7060 - val_loss: 1.1036 - val_accuracy: 0.6708\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0548 - accuracy: 0.7117 - val_loss: 1.0984 - val_accuracy: 0.6640\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0511 - accuracy: 0.7063 - val_loss: 1.0975 - val_accuracy: 0.6686\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0483 - accuracy: 0.7077 - val_loss: 1.0948 - val_accuracy: 0.6618\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0436 - accuracy: 0.7151 - val_loss: 1.0942 - val_accuracy: 0.6674\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0441 - accuracy: 0.7119 - val_loss: 1.0900 - val_accuracy: 0.6606\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0386 - accuracy: 0.7159 - val_loss: 1.0853 - val_accuracy: 0.6708\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0378 - accuracy: 0.7097 - val_loss: 1.0943 - val_accuracy: 0.6629\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0334 - accuracy: 0.7156 - val_loss: 1.0819 - val_accuracy: 0.6561\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0297 - accuracy: 0.7094 - val_loss: 1.0804 - val_accuracy: 0.6686\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0255 - accuracy: 0.7187 - val_loss: 1.0790 - val_accuracy: 0.6742\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0211 - accuracy: 0.7227 - val_loss: 1.0761 - val_accuracy: 0.6663\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0178 - accuracy: 0.7134 - val_loss: 1.0750 - val_accuracy: 0.6606\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0143 - accuracy: 0.7168 - val_loss: 1.0704 - val_accuracy: 0.6629\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0125 - accuracy: 0.7170 - val_loss: 1.0734 - val_accuracy: 0.6731\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0124 - accuracy: 0.7139 - val_loss: 1.0708 - val_accuracy: 0.6719\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0013 - accuracy: 0.7238 - val_loss: 1.0647 - val_accuracy: 0.6584\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0013 - accuracy: 0.7187 - val_loss: 1.0644 - val_accuracy: 0.6663\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9982 - accuracy: 0.7216 - val_loss: 1.0606 - val_accuracy: 0.6618\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9914 - accuracy: 0.7227 - val_loss: 1.0756 - val_accuracy: 0.6663\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9969 - accuracy: 0.7235 - val_loss: 1.0594 - val_accuracy: 0.6640\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9908 - accuracy: 0.7227 - val_loss: 1.0571 - val_accuracy: 0.6697\n","{'loss': [1.4313645362854004, 1.4253966808319092, 1.4206287860870361, 1.415206789970398, 1.4098914861679077, 1.4040230512619019, 1.3985956907272339, 1.3918932676315308, 1.383286952972412, 1.378268837928772, 1.3692787885665894, 1.3606826066970825, 1.3500258922576904, 1.3405946493148804, 1.3291743993759155, 1.3195931911468506, 1.3109021186828613, 1.301020860671997, 1.2925328016281128, 1.2904927730560303, 1.2820205688476562, 1.2789117097854614, 1.2729204893112183, 1.2642678022384644, 1.259009838104248, 1.2553547620773315, 1.2517532110214233, 1.25400710105896, 1.2423923015594482, 1.239701509475708, 1.2369952201843262, 1.2291803359985352, 1.2231826782226562, 1.2213627099990845, 1.2172305583953857, 1.2159253358840942, 1.2134292125701904, 1.202495813369751, 1.203519582748413, 1.2001190185546875, 1.1954749822616577, 1.1946138143539429, 1.1894640922546387, 1.1842646598815918, 1.181459903717041, 1.1776293516159058, 1.1712876558303833, 1.1706464290618896, 1.1648154258728027, 1.1617707014083862, 1.1568902730941772, 1.1536808013916016, 1.1517930030822754, 1.1477617025375366, 1.1453183889389038, 1.1383037567138672, 1.1394157409667969, 1.1323996782302856, 1.1267154216766357, 1.1221193075180054, 1.1203721761703491, 1.1176989078521729, 1.1147308349609375, 1.1112916469573975, 1.1119261980056763, 1.1061054468154907, 1.1002038717269897, 1.0977158546447754, 1.0944398641586304, 1.0923441648483276, 1.083999514579773, 1.087314486503601, 1.0824353694915771, 1.0777764320373535, 1.0730786323547363, 1.0702284574508667, 1.0659679174423218, 1.0629302263259888, 1.0604771375656128, 1.0547585487365723, 1.0510578155517578, 1.048261284828186, 1.0436019897460938, 1.0440608263015747, 1.038582682609558, 1.0378059148788452, 1.0333760976791382, 1.0296733379364014, 1.025533676147461, 1.0211126804351807, 1.0178231000900269, 1.0142567157745361, 1.0125128030776978, 1.0124026536941528, 1.0012612342834473, 1.0013035535812378, 0.9982133507728577, 0.9913976788520813, 0.9969112277030945, 0.9908373951911926], 'accuracy': [0.5014148354530334, 0.5062252283096313, 0.5008488893508911, 0.5059422850608826, 0.5039615035057068, 0.5322580933570862, 0.5373514294624329, 0.5475382208824158, 0.6137521266937256, 0.5628183484077454, 0.5916808247566223, 0.6160158514976501, 0.6304470896720886, 0.6185625195503235, 0.6295982003211975, 0.63667231798172, 0.6363893747329712, 0.6443123817443848, 0.6578947305679321, 0.644029438495636, 0.6454442739486694, 0.6491228342056274, 0.6508206129074097, 0.6615732908248901, 0.660724401473999, 0.6629881262779236, 0.6641199588775635, 0.6547821164131165, 0.6612903475761414, 0.6629881262779236, 0.6547821164131165, 0.6728919148445129, 0.6669496297836304, 0.6697793006896973, 0.6694962978363037, 0.664402961730957, 0.6641199588775635, 0.6760045289993286, 0.6686474084854126, 0.6675155758857727, 0.6706281900405884, 0.6655347943305969, 0.6703452467918396, 0.670062243938446, 0.6743067502975464, 0.670062243938446, 0.6771363615989685, 0.6827957034111023, 0.6844934821128845, 0.6745896935462952, 0.6808149218559265, 0.6816638112068176, 0.6782682538032532, 0.6833616495132446, 0.6816638112068176, 0.6873231530189514, 0.6796830892562866, 0.6884549856185913, 0.6881720423698425, 0.6898698210716248, 0.6921335458755493, 0.6924165487289429, 0.6853423714637756, 0.691567599773407, 0.6910017132759094, 0.6904357671737671, 0.6921335458755493, 0.6921335458755493, 0.7009055018424988, 0.6946802735328674, 0.7043010592460632, 0.6918506026268005, 0.6958121061325073, 0.6997736096382141, 0.7017543911933899, 0.7034521698951721, 0.7110922336578369, 0.6997736096382141, 0.7059988975524902, 0.7116581797599792, 0.706281840801239, 0.7076966762542725, 0.7150537371635437, 0.711941123008728, 0.7159026861190796, 0.7096773982048035, 0.715619683265686, 0.7093944549560547, 0.7187322974205017, 0.7226938605308533, 0.7133559584617615, 0.7167515754699707, 0.7170345187187195, 0.7139219045639038, 0.7238256931304932, 0.7187322974205017, 0.7215619683265686, 0.7226938605308533, 0.7235427498817444, 0.7226938605308533], 'val_loss': [1.429017186164856, 1.4242067337036133, 1.4194358587265015, 1.4146978855133057, 1.4099947214126587, 1.405361533164978, 1.4007748365402222, 1.3961797952651978, 1.3909918069839478, 1.3883129358291626, 1.3841904401779175, 1.3792959451675415, 1.3722822666168213, 1.365349531173706, 1.3630458116531372, 1.3578577041625977, 1.3582144975662231, 1.345180869102478, 1.331787347793579, 1.3321596384048462, 1.3073339462280273, 1.3179919719696045, 1.309121012687683, 1.2840012311935425, 1.2862416505813599, 1.2737489938735962, 1.2583885192871094, 1.2603838443756104, 1.252249836921692, 1.2465465068817139, 1.2435957193374634, 1.239999771118164, 1.2364916801452637, 1.2343343496322632, 1.2299367189407349, 1.2302972078323364, 1.222208857536316, 1.2194499969482422, 1.2221205234527588, 1.2139393091201782, 1.209170937538147, 1.2059178352355957, 1.2024677991867065, 1.2021136283874512, 1.1961586475372314, 1.192539930343628, 1.1947424411773682, 1.187052607536316, 1.1892603635787964, 1.1850050687789917, 1.1775116920471191, 1.1766583919525146, 1.1734994649887085, 1.1688485145568848, 1.165757417678833, 1.1629595756530762, 1.1617704629898071, 1.1582952737808228, 1.1545616388320923, 1.153343915939331, 1.1478759050369263, 1.145812749862671, 1.1438084840774536, 1.1470680236816406, 1.14060640335083, 1.1385513544082642, 1.1399914026260376, 1.1283915042877197, 1.1266093254089355, 1.124010682106018, 1.1217281818389893, 1.1224594116210938, 1.1195493936538696, 1.1124556064605713, 1.1110436916351318, 1.1077955961227417, 1.1066254377365112, 1.1045023202896118, 1.1035994291305542, 1.0983707904815674, 1.097459316253662, 1.0947738885879517, 1.094199776649475, 1.089996099472046, 1.085341215133667, 1.0942976474761963, 1.0818761587142944, 1.0803918838500977, 1.0790064334869385, 1.0761487483978271, 1.0749993324279785, 1.0704259872436523, 1.0733991861343384, 1.0707625150680542, 1.0647294521331787, 1.0643800497055054, 1.0606348514556885, 1.0755945444107056, 1.059376835823059, 1.0571119785308838], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.6006787419319153, 0.5158371329307556, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5180995464324951, 0.5045248866081238, 0.5045248866081238, 0.5079185366630554, 0.5192307829856873, 0.5282805562019348, 0.5282805562019348, 0.529411792755127, 0.5282805562019348, 0.5531674027442932, 0.5757918357849121, 0.5678732991218567, 0.6153846383094788, 0.5893664956092834, 0.6029411554336548, 0.6425339579582214, 0.6300904750823975, 0.6481900215148926, 0.6696832776069641, 0.6583710312843323, 0.6674208045005798, 0.6776018142700195, 0.662895917892456, 0.6730769276618958, 0.6764705777168274, 0.6696832776069641, 0.6719456911087036, 0.6595022678375244, 0.6753393411636353, 0.6742081642150879, 0.6561086177825928, 0.6730769276618958, 0.6753393411636353, 0.6730769276618958, 0.6730769276618958, 0.6719456911087036, 0.6708144545555115, 0.6730769276618958, 0.6662895679473877, 0.668552041053772, 0.6606335043907166, 0.662895917892456, 0.6708144545555115, 0.6696832776069641, 0.6674208045005798, 0.6730769276618958, 0.6730769276618958, 0.6674208045005798, 0.6640271544456482, 0.6696832776069641, 0.6674208045005798, 0.6640271544456482, 0.6696832776069641, 0.6617646813392639, 0.6674208045005798, 0.6696832776069641, 0.6662895679473877, 0.6696832776069641, 0.6640271544456482, 0.6696832776069641, 0.668552041053772, 0.6651583909988403, 0.668552041053772, 0.6662895679473877, 0.668552041053772, 0.6742081642150879, 0.6708144545555115, 0.6719456911087036, 0.6719456911087036, 0.6662895679473877, 0.6708144545555115, 0.6640271544456482, 0.668552041053772, 0.6617646813392639, 0.6674208045005798, 0.6606335043907166, 0.6708144545555115, 0.662895917892456, 0.6561086177825928, 0.668552041053772, 0.6742081642150879, 0.6662895679473877, 0.6606335043907166, 0.662895917892456, 0.6730769276618958, 0.6719456911087036, 0.6583710312843323, 0.6662895679473877, 0.6617646813392639, 0.6662895679473877, 0.6640271544456482, 0.6696832776069641]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 51ms/step - loss: 1.4308 - accuracy: 0.5109 - val_loss: 1.4285 - val_accuracy: 0.4855\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4239 - accuracy: 0.5121 - val_loss: 1.4232 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4184 - accuracy: 0.5059 - val_loss: 1.4179 - val_accuracy: 0.5114\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4119 - accuracy: 0.5119 - val_loss: 1.4127 - val_accuracy: 0.5775\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4055 - accuracy: 0.5209 - val_loss: 1.4076 - val_accuracy: 0.5186\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3986 - accuracy: 0.5571 - val_loss: 1.4022 - val_accuracy: 0.5351\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3894 - accuracy: 0.5636 - val_loss: 1.3974 - val_accuracy: 0.5165\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3808 - accuracy: 0.6047 - val_loss: 1.3917 - val_accuracy: 0.5227\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3708 - accuracy: 0.6209 - val_loss: 1.3858 - val_accuracy: 0.5413\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3599 - accuracy: 0.6276 - val_loss: 1.3816 - val_accuracy: 0.5227\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3478 - accuracy: 0.6398 - val_loss: 1.3748 - val_accuracy: 0.5351\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3340 - accuracy: 0.6442 - val_loss: 1.3677 - val_accuracy: 0.5455\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3244 - accuracy: 0.6483 - val_loss: 1.3664 - val_accuracy: 0.5320\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3146 - accuracy: 0.6486 - val_loss: 1.3602 - val_accuracy: 0.5403\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3013 - accuracy: 0.6527 - val_loss: 1.3514 - val_accuracy: 0.5537\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2935 - accuracy: 0.6576 - val_loss: 1.3462 - val_accuracy: 0.5640\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2844 - accuracy: 0.6713 - val_loss: 1.3515 - val_accuracy: 0.5506\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2794 - accuracy: 0.6687 - val_loss: 1.3295 - val_accuracy: 0.5878\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2719 - accuracy: 0.6705 - val_loss: 1.3141 - val_accuracy: 0.6054\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2646 - accuracy: 0.6744 - val_loss: 1.3120 - val_accuracy: 0.6054\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2649 - accuracy: 0.6677 - val_loss: 1.2866 - val_accuracy: 0.6436\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2548 - accuracy: 0.6700 - val_loss: 1.2958 - val_accuracy: 0.6271\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2496 - accuracy: 0.6744 - val_loss: 1.2766 - val_accuracy: 0.6477\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2457 - accuracy: 0.6760 - val_loss: 1.2781 - val_accuracy: 0.6374\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2420 - accuracy: 0.6819 - val_loss: 1.2708 - val_accuracy: 0.6446\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2373 - accuracy: 0.6752 - val_loss: 1.2576 - val_accuracy: 0.6374\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2323 - accuracy: 0.6827 - val_loss: 1.2581 - val_accuracy: 0.6457\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2326 - accuracy: 0.6780 - val_loss: 1.2521 - val_accuracy: 0.6374\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2243 - accuracy: 0.6796 - val_loss: 1.2486 - val_accuracy: 0.6405\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2188 - accuracy: 0.6796 - val_loss: 1.2435 - val_accuracy: 0.6405\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2145 - accuracy: 0.6796 - val_loss: 1.2401 - val_accuracy: 0.6405\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2112 - accuracy: 0.6793 - val_loss: 1.2368 - val_accuracy: 0.6374\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2094 - accuracy: 0.6775 - val_loss: 1.2564 - val_accuracy: 0.6302\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2014 - accuracy: 0.6868 - val_loss: 1.2313 - val_accuracy: 0.6415\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2008 - accuracy: 0.6824 - val_loss: 1.2281 - val_accuracy: 0.6322\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1966 - accuracy: 0.6806 - val_loss: 1.2224 - val_accuracy: 0.6364\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1892 - accuracy: 0.6853 - val_loss: 1.2282 - val_accuracy: 0.6364\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1871 - accuracy: 0.6824 - val_loss: 1.2188 - val_accuracy: 0.6364\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1834 - accuracy: 0.6907 - val_loss: 1.2132 - val_accuracy: 0.6415\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1790 - accuracy: 0.6855 - val_loss: 1.2200 - val_accuracy: 0.6384\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1746 - accuracy: 0.6876 - val_loss: 1.2048 - val_accuracy: 0.6415\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1713 - accuracy: 0.6842 - val_loss: 1.2073 - val_accuracy: 0.6343\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1674 - accuracy: 0.6904 - val_loss: 1.2033 - val_accuracy: 0.6405\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1624 - accuracy: 0.6915 - val_loss: 1.1972 - val_accuracy: 0.6395\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1608 - accuracy: 0.6879 - val_loss: 1.1936 - val_accuracy: 0.6415\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1535 - accuracy: 0.6938 - val_loss: 1.1883 - val_accuracy: 0.6374\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1488 - accuracy: 0.6979 - val_loss: 1.1955 - val_accuracy: 0.6395\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1460 - accuracy: 0.6948 - val_loss: 1.1838 - val_accuracy: 0.6405\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1446 - accuracy: 0.6910 - val_loss: 1.1847 - val_accuracy: 0.6374\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1396 - accuracy: 0.6912 - val_loss: 1.1758 - val_accuracy: 0.6395\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1344 - accuracy: 0.6946 - val_loss: 1.1797 - val_accuracy: 0.6353\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1339 - accuracy: 0.6853 - val_loss: 1.1706 - val_accuracy: 0.6395\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1274 - accuracy: 0.6938 - val_loss: 1.1688 - val_accuracy: 0.6426\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1244 - accuracy: 0.6956 - val_loss: 1.1678 - val_accuracy: 0.6415\n","Epoch 55/100\n","31/31 [==============================] - 2s 58ms/step - loss: 1.1214 - accuracy: 0.6935 - val_loss: 1.1751 - val_accuracy: 0.6508\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1184 - accuracy: 0.6941 - val_loss: 1.1589 - val_accuracy: 0.6426\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1167 - accuracy: 0.6897 - val_loss: 1.1567 - val_accuracy: 0.6426\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1105 - accuracy: 0.6943 - val_loss: 1.1548 - val_accuracy: 0.6488\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1066 - accuracy: 0.6966 - val_loss: 1.1503 - val_accuracy: 0.6415\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1039 - accuracy: 0.6951 - val_loss: 1.1501 - val_accuracy: 0.6415\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0989 - accuracy: 0.6961 - val_loss: 1.1441 - val_accuracy: 0.6395\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0958 - accuracy: 0.6961 - val_loss: 1.1441 - val_accuracy: 0.6384\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0913 - accuracy: 0.7054 - val_loss: 1.1386 - val_accuracy: 0.6384\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0914 - accuracy: 0.6995 - val_loss: 1.1355 - val_accuracy: 0.6467\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0892 - accuracy: 0.6961 - val_loss: 1.1356 - val_accuracy: 0.6519\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0816 - accuracy: 0.7067 - val_loss: 1.1329 - val_accuracy: 0.6405\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0803 - accuracy: 0.6979 - val_loss: 1.1278 - val_accuracy: 0.6457\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0783 - accuracy: 0.7034 - val_loss: 1.1239 - val_accuracy: 0.6488\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0722 - accuracy: 0.7005 - val_loss: 1.1234 - val_accuracy: 0.6395\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0687 - accuracy: 0.6995 - val_loss: 1.1351 - val_accuracy: 0.6374\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0678 - accuracy: 0.7034 - val_loss: 1.1145 - val_accuracy: 0.6488\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0622 - accuracy: 0.7000 - val_loss: 1.1128 - val_accuracy: 0.6488\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0582 - accuracy: 0.7119 - val_loss: 1.1095 - val_accuracy: 0.6488\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0587 - accuracy: 0.7026 - val_loss: 1.1068 - val_accuracy: 0.6508\n","Epoch 75/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0487 - accuracy: 0.7083 - val_loss: 1.1098 - val_accuracy: 0.6539\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0558 - accuracy: 0.6982 - val_loss: 1.1136 - val_accuracy: 0.6374\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0454 - accuracy: 0.7075 - val_loss: 1.0998 - val_accuracy: 0.6488\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0427 - accuracy: 0.7041 - val_loss: 1.0970 - val_accuracy: 0.6488\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0388 - accuracy: 0.7085 - val_loss: 1.1008 - val_accuracy: 0.6405\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0349 - accuracy: 0.7080 - val_loss: 1.0924 - val_accuracy: 0.6477\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0321 - accuracy: 0.7106 - val_loss: 1.0899 - val_accuracy: 0.6488\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0340 - accuracy: 0.7067 - val_loss: 1.0855 - val_accuracy: 0.6467\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0243 - accuracy: 0.7140 - val_loss: 1.0844 - val_accuracy: 0.6477\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0228 - accuracy: 0.7124 - val_loss: 1.0881 - val_accuracy: 0.6426\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0173 - accuracy: 0.7168 - val_loss: 1.0813 - val_accuracy: 0.6467\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0147 - accuracy: 0.7119 - val_loss: 1.0776 - val_accuracy: 0.6498\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0142 - accuracy: 0.7168 - val_loss: 1.0751 - val_accuracy: 0.6498\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0075 - accuracy: 0.7147 - val_loss: 1.0847 - val_accuracy: 0.6333\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0037 - accuracy: 0.7196 - val_loss: 1.0705 - val_accuracy: 0.6529\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0020 - accuracy: 0.7129 - val_loss: 1.0704 - val_accuracy: 0.6560\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9973 - accuracy: 0.7222 - val_loss: 1.0668 - val_accuracy: 0.6467\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9922 - accuracy: 0.7209 - val_loss: 1.0642 - val_accuracy: 0.6508\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9893 - accuracy: 0.7186 - val_loss: 1.0660 - val_accuracy: 0.6498\n","Epoch 94/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9877 - accuracy: 0.7212 - val_loss: 1.0599 - val_accuracy: 0.6570\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9876 - accuracy: 0.7163 - val_loss: 1.0718 - val_accuracy: 0.6498\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9809 - accuracy: 0.7243 - val_loss: 1.0566 - val_accuracy: 0.6529\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9764 - accuracy: 0.7248 - val_loss: 1.0540 - val_accuracy: 0.6498\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9708 - accuracy: 0.7248 - val_loss: 1.0508 - val_accuracy: 0.6457\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9718 - accuracy: 0.7261 - val_loss: 1.0554 - val_accuracy: 0.6467\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9677 - accuracy: 0.7245 - val_loss: 1.0479 - val_accuracy: 0.6539\n","{'loss': [1.430786371231079, 1.4238909482955933, 1.4183852672576904, 1.4119139909744263, 1.405503749847412, 1.398634433746338, 1.3894085884094238, 1.3808377981185913, 1.3707542419433594, 1.3598734140396118, 1.3477619886398315, 1.3339589834213257, 1.3243595361709595, 1.3145599365234375, 1.301275372505188, 1.2935030460357666, 1.28443443775177, 1.2794023752212524, 1.271930456161499, 1.2646362781524658, 1.2649339437484741, 1.2548261880874634, 1.249619483947754, 1.2456574440002441, 1.241994023323059, 1.2372698783874512, 1.2322884798049927, 1.2325820922851562, 1.2242902517318726, 1.2187540531158447, 1.2144579887390137, 1.2111809253692627, 1.2094268798828125, 1.2014323472976685, 1.2008414268493652, 1.1965738534927368, 1.1892415285110474, 1.1871381998062134, 1.1833745241165161, 1.178952693939209, 1.174584984779358, 1.1712653636932373, 1.1673593521118164, 1.1623940467834473, 1.1608203649520874, 1.153465986251831, 1.1487940549850464, 1.145972490310669, 1.1445772647857666, 1.1395821571350098, 1.1344255208969116, 1.133913516998291, 1.1273750066757202, 1.1244287490844727, 1.121359944343567, 1.1183935403823853, 1.1166526079177856, 1.1105409860610962, 1.106567144393921, 1.1038562059402466, 1.0989229679107666, 1.095805048942566, 1.091269612312317, 1.0913640260696411, 1.089233636856079, 1.081627368927002, 1.0802515745162964, 1.0783042907714844, 1.0721659660339355, 1.0686852931976318, 1.0678104162216187, 1.0622247457504272, 1.0582294464111328, 1.0587314367294312, 1.0487215518951416, 1.055817723274231, 1.0454275608062744, 1.0426791906356812, 1.038757562637329, 1.0349253416061401, 1.0321383476257324, 1.0340310335159302, 1.024299144744873, 1.0227630138397217, 1.0172557830810547, 1.0147099494934082, 1.014222264289856, 1.0075057744979858, 1.0037168264389038, 1.0020309686660767, 0.9972648620605469, 0.9922202825546265, 0.9893184900283813, 0.9877451062202454, 0.9875831604003906, 0.9808741807937622, 0.976359486579895, 0.9708213806152344, 0.9717945456504822, 0.9677116274833679], 'accuracy': [0.5108526945114136, 0.5121446847915649, 0.5059431791305542, 0.5118862986564636, 0.5209302306175232, 0.5571059584617615, 0.5635659098625183, 0.604651153087616, 0.6209302544593811, 0.6276485919952393, 0.6397932767868042, 0.6441860198974609, 0.6483204364776611, 0.6485788226127625, 0.6527131795883179, 0.657622754573822, 0.6713178157806396, 0.6687338352203369, 0.6705426573753357, 0.6744186282157898, 0.6677002310752869, 0.6700258255004883, 0.6744186282157898, 0.6759690046310425, 0.6819121241569519, 0.6751937866210938, 0.6826873421669006, 0.6780361533164978, 0.6795865893363953, 0.6795865893363953, 0.6795865893363953, 0.6793281435966492, 0.6775193810462952, 0.686821699142456, 0.6824289560317993, 0.6806201338768005, 0.6852713227272034, 0.6824289560317993, 0.6906976699829102, 0.6855297088623047, 0.6875969171524048, 0.6842377185821533, 0.6904392838478088, 0.6914728879928589, 0.6878553032875061, 0.6937984228134155, 0.6979328393936157, 0.6948320269584656, 0.6909560561180115, 0.6912144422531128, 0.6945736408233643, 0.6852713227272034, 0.6937984228134155, 0.6956072449684143, 0.6935400366783142, 0.6940568685531616, 0.6896640658378601, 0.6943152546882629, 0.6966408491134644, 0.6950904130935669, 0.6961240172386169, 0.6961240172386169, 0.7054263353347778, 0.6994832158088684, 0.6961240172386169, 0.7067183256149292, 0.6979328393936157, 0.7033591866493225, 0.7005168199539185, 0.6994832158088684, 0.7033591866493225, 0.699999988079071, 0.7118862867355347, 0.7025839686393738, 0.7082687616348267, 0.698191225528717, 0.7074935436248779, 0.7041343450546265, 0.708527147769928, 0.7080103158950806, 0.7105942964553833, 0.7067183256149292, 0.7139534950256348, 0.7124031186103821, 0.7167958617210388, 0.7118862867355347, 0.7167958617210388, 0.7147286534309387, 0.7196382284164429, 0.7129198908805847, 0.7222222089767456, 0.7209302186965942, 0.7186046242713928, 0.7211886048316956, 0.7162790894508362, 0.7242894172668457, 0.7248061895370483, 0.7248061895370483, 0.7260981798171997, 0.724547803401947], 'val_loss': [1.4284710884094238, 1.4231548309326172, 1.4179049730300903, 1.4126917123794556, 1.4075770378112793, 1.4022186994552612, 1.3974276781082153, 1.3917274475097656, 1.3857555389404297, 1.381631851196289, 1.3747711181640625, 1.3676835298538208, 1.3663781881332397, 1.360221266746521, 1.3513685464859009, 1.3462004661560059, 1.3514652252197266, 1.329525351524353, 1.3141266107559204, 1.3119674921035767, 1.2865917682647705, 1.295760154724121, 1.2766426801681519, 1.2780718803405762, 1.270788550376892, 1.2575539350509644, 1.2580653429031372, 1.252134919166565, 1.2485555410385132, 1.2434624433517456, 1.2401130199432373, 1.2368457317352295, 1.2563869953155518, 1.2312966585159302, 1.2280529737472534, 1.2224065065383911, 1.2281780242919922, 1.2188105583190918, 1.2131658792495728, 1.2200018167495728, 1.2047605514526367, 1.2073049545288086, 1.2032610177993774, 1.1971997022628784, 1.193602204322815, 1.1882519721984863, 1.1955478191375732, 1.1837608814239502, 1.1846755743026733, 1.1757569313049316, 1.1797159910202026, 1.1706026792526245, 1.1687922477722168, 1.1677820682525635, 1.1750797033309937, 1.1588941812515259, 1.1567174196243286, 1.1547818183898926, 1.150302529335022, 1.1501418352127075, 1.1441041231155396, 1.1440951824188232, 1.1385540962219238, 1.1355202198028564, 1.1355996131896973, 1.132865309715271, 1.1278263330459595, 1.1239346265792847, 1.1233724355697632, 1.1351450681686401, 1.1144709587097168, 1.1127753257751465, 1.1095458269119263, 1.106778621673584, 1.1098214387893677, 1.1136459112167358, 1.0998194217681885, 1.0969942808151245, 1.1008455753326416, 1.0924386978149414, 1.0899072885513306, 1.085471749305725, 1.0843651294708252, 1.0881425142288208, 1.0813465118408203, 1.077606439590454, 1.075118064880371, 1.0846903324127197, 1.0705146789550781, 1.070365309715271, 1.0667526721954346, 1.0641593933105469, 1.066001057624817, 1.0599133968353271, 1.0717597007751465, 1.0566319227218628, 1.0540422201156616, 1.0508326292037964, 1.0553582906723022, 1.047890305519104], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.5113636255264282, 0.577479362487793, 0.5185950398445129, 0.5351239442825317, 0.5165289044380188, 0.5227272510528564, 0.5413222908973694, 0.5227272510528564, 0.5351239442825317, 0.5454545617103577, 0.5320248007774353, 0.5402892827987671, 0.5537189841270447, 0.5640496015548706, 0.5506198406219482, 0.5878099203109741, 0.60537189245224, 0.60537189245224, 0.6435950398445129, 0.6270661354064941, 0.6477272510528564, 0.6373966932296753, 0.64462810754776, 0.6373966932296753, 0.6456611752510071, 0.6373966932296753, 0.6404958963394165, 0.6404958963394165, 0.6404958963394165, 0.6373966932296753, 0.6301652789115906, 0.6415289044380188, 0.6322314143180847, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6415289044380188, 0.6384297609329224, 0.6415289044380188, 0.6342975497245789, 0.6404958963394165, 0.6394628286361694, 0.6415289044380188, 0.6373966932296753, 0.6394628286361694, 0.6404958963394165, 0.6373966932296753, 0.6394628286361694, 0.6353305578231812, 0.6394628286361694, 0.6425619721412659, 0.6415289044380188, 0.6508264541625977, 0.6425619721412659, 0.6425619721412659, 0.6487603187561035, 0.6415289044380188, 0.6415289044380188, 0.6394628286361694, 0.6384297609329224, 0.6384297609329224, 0.6466942429542542, 0.6518595218658447, 0.6404958963394165, 0.6456611752510071, 0.6487603187561035, 0.6394628286361694, 0.6373966932296753, 0.6487603187561035, 0.6487603187561035, 0.6487603187561035, 0.6508264541625977, 0.6539255976676941, 0.6373966932296753, 0.6487603187561035, 0.6487603187561035, 0.6404958963394165, 0.6477272510528564, 0.6487603187561035, 0.6466942429542542, 0.6477272510528564, 0.6425619721412659, 0.6466942429542542, 0.6497933864593506, 0.6497933864593506, 0.6332644820213318, 0.6528925895690918, 0.6559917330741882, 0.6466942429542542, 0.6508264541625977, 0.6497933864593506, 0.6570248007774353, 0.6497933864593506, 0.6528925895690918, 0.6497933864593506, 0.6456611752510071, 0.6466942429542542, 0.6539255976676941]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 1.0060 - accuracy: 0.6959"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 53ms/step - loss: 1.0067 - accuracy: 0.6980 - val_loss: 1.1095 - val_accuracy: 0.5830\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0008 - accuracy: 0.7015 - val_loss: 1.1056 - val_accuracy: 0.5603\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9939 - accuracy: 0.7115 - val_loss: 1.1019 - val_accuracy: 0.5571\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9918 - accuracy: 0.7072 - val_loss: 1.0999 - val_accuracy: 0.5345\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9870 - accuracy: 0.7112 - val_loss: 1.0984 - val_accuracy: 0.5280\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9788 - accuracy: 0.7147 - val_loss: 1.0976 - val_accuracy: 0.5226\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9764 - accuracy: 0.7152 - val_loss: 1.0945 - val_accuracy: 0.5237\n","Epoch 8/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9776 - accuracy: 0.7042 - val_loss: 1.0897 - val_accuracy: 0.5302\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9746 - accuracy: 0.7123 - val_loss: 1.0911 - val_accuracy: 0.5226\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9655 - accuracy: 0.7155 - val_loss: 1.0872 - val_accuracy: 0.5280\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9632 - accuracy: 0.7217 - val_loss: 1.0878 - val_accuracy: 0.5248\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9592 - accuracy: 0.7196 - val_loss: 1.0786 - val_accuracy: 0.5334\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9591 - accuracy: 0.7109 - val_loss: 1.0780 - val_accuracy: 0.5356\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9553 - accuracy: 0.7163 - val_loss: 1.0852 - val_accuracy: 0.5312\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9498 - accuracy: 0.7228 - val_loss: 1.0677 - val_accuracy: 0.5593\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9452 - accuracy: 0.7182 - val_loss: 1.0593 - val_accuracy: 0.5744\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9394 - accuracy: 0.7255 - val_loss: 1.0662 - val_accuracy: 0.5657\n","Epoch 18/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9363 - accuracy: 0.7252 - val_loss: 1.0560 - val_accuracy: 0.5851\n","Epoch 19/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9336 - accuracy: 0.7284 - val_loss: 1.0512 - val_accuracy: 0.5894\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9337 - accuracy: 0.7188 - val_loss: 1.0443 - val_accuracy: 0.5991\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9297 - accuracy: 0.7282 - val_loss: 1.0505 - val_accuracy: 0.6002\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.9243 - accuracy: 0.7295 - val_loss: 1.0244 - val_accuracy: 0.6369\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.9205 - accuracy: 0.7338 - val_loss: 0.9870 - val_accuracy: 0.6703\n","Epoch 24/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9174 - accuracy: 0.7336 - val_loss: 0.9617 - val_accuracy: 0.6918\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9166 - accuracy: 0.7333 - val_loss: 0.9660 - val_accuracy: 0.6875\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9121 - accuracy: 0.7306 - val_loss: 0.9686 - val_accuracy: 0.6918\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9061 - accuracy: 0.7422 - val_loss: 0.9473 - val_accuracy: 0.7080\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9036 - accuracy: 0.7338 - val_loss: 0.9483 - val_accuracy: 0.7015\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9057 - accuracy: 0.7293 - val_loss: 0.9450 - val_accuracy: 0.7015\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8983 - accuracy: 0.7400 - val_loss: 0.9438 - val_accuracy: 0.7026\n","Epoch 31/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8941 - accuracy: 0.7317 - val_loss: 0.9407 - val_accuracy: 0.7091\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8987 - accuracy: 0.7303 - val_loss: 0.9440 - val_accuracy: 0.6994\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8860 - accuracy: 0.7452 - val_loss: 0.9369 - val_accuracy: 0.7080\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8837 - accuracy: 0.7373 - val_loss: 0.9364 - val_accuracy: 0.7069\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8835 - accuracy: 0.7441 - val_loss: 0.9336 - val_accuracy: 0.7069\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8788 - accuracy: 0.7465 - val_loss: 0.9417 - val_accuracy: 0.6897\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8806 - accuracy: 0.7419 - val_loss: 0.9337 - val_accuracy: 0.6994\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8805 - accuracy: 0.7381 - val_loss: 0.9298 - val_accuracy: 0.7080\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8741 - accuracy: 0.7513 - val_loss: 0.9272 - val_accuracy: 0.7026\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8654 - accuracy: 0.7446 - val_loss: 0.9456 - val_accuracy: 0.6843\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8574 - accuracy: 0.7530 - val_loss: 0.9430 - val_accuracy: 0.6821\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8595 - accuracy: 0.7465 - val_loss: 0.9259 - val_accuracy: 0.6983\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8541 - accuracy: 0.7484 - val_loss: 0.9509 - val_accuracy: 0.6724\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8502 - accuracy: 0.7592 - val_loss: 0.9280 - val_accuracy: 0.6929\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8478 - accuracy: 0.7548 - val_loss: 0.9434 - val_accuracy: 0.6821\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8465 - accuracy: 0.7538 - val_loss: 0.9178 - val_accuracy: 0.7058\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8440 - accuracy: 0.7532 - val_loss: 0.9459 - val_accuracy: 0.6789\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8357 - accuracy: 0.7584 - val_loss: 0.9188 - val_accuracy: 0.6950\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8312 - accuracy: 0.7600 - val_loss: 0.9165 - val_accuracy: 0.7026\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8309 - accuracy: 0.7551 - val_loss: 0.9182 - val_accuracy: 0.7047\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8226 - accuracy: 0.7670 - val_loss: 0.9134 - val_accuracy: 0.7069\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8237 - accuracy: 0.7683 - val_loss: 0.9230 - val_accuracy: 0.6929\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8222 - accuracy: 0.7624 - val_loss: 0.9122 - val_accuracy: 0.7058\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8189 - accuracy: 0.7621 - val_loss: 0.9105 - val_accuracy: 0.6994\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8130 - accuracy: 0.7694 - val_loss: 0.9126 - val_accuracy: 0.7080\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8121 - accuracy: 0.7662 - val_loss: 0.9134 - val_accuracy: 0.6940\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8178 - accuracy: 0.7608 - val_loss: 0.9066 - val_accuracy: 0.6983\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8086 - accuracy: 0.7724 - val_loss: 0.9204 - val_accuracy: 0.6940\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8038 - accuracy: 0.7707 - val_loss: 0.9065 - val_accuracy: 0.7037\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7922 - accuracy: 0.7788 - val_loss: 0.9075 - val_accuracy: 0.6972\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7913 - accuracy: 0.7748 - val_loss: 0.9088 - val_accuracy: 0.6918\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7941 - accuracy: 0.7740 - val_loss: 0.9079 - val_accuracy: 0.7069\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7939 - accuracy: 0.7775 - val_loss: 0.9008 - val_accuracy: 0.7015\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7868 - accuracy: 0.7764 - val_loss: 0.9081 - val_accuracy: 0.6961\n","Epoch 65/100\n","29/29 [==============================] - 2s 53ms/step - loss: 0.7800 - accuracy: 0.7823 - val_loss: 0.9011 - val_accuracy: 0.7123\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7901 - accuracy: 0.7683 - val_loss: 0.9021 - val_accuracy: 0.7026\n","Epoch 67/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7812 - accuracy: 0.7786 - val_loss: 0.9355 - val_accuracy: 0.6746\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7747 - accuracy: 0.7807 - val_loss: 0.9235 - val_accuracy: 0.6843\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7701 - accuracy: 0.7831 - val_loss: 0.9113 - val_accuracy: 0.6961\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7724 - accuracy: 0.7839 - val_loss: 0.9206 - val_accuracy: 0.6875\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7680 - accuracy: 0.7794 - val_loss: 0.9003 - val_accuracy: 0.7058\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7639 - accuracy: 0.7807 - val_loss: 0.9338 - val_accuracy: 0.6627\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7640 - accuracy: 0.7831 - val_loss: 0.9018 - val_accuracy: 0.6929\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7545 - accuracy: 0.7885 - val_loss: 0.9187 - val_accuracy: 0.6789\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7529 - accuracy: 0.7837 - val_loss: 0.9149 - val_accuracy: 0.6767\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7503 - accuracy: 0.7931 - val_loss: 0.9010 - val_accuracy: 0.7015\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7470 - accuracy: 0.7918 - val_loss: 0.9050 - val_accuracy: 0.7004\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7410 - accuracy: 0.7958 - val_loss: 0.9047 - val_accuracy: 0.6972\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7404 - accuracy: 0.7934 - val_loss: 0.8966 - val_accuracy: 0.7112\n","Epoch 80/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7374 - accuracy: 0.7982 - val_loss: 0.9092 - val_accuracy: 0.6886\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7310 - accuracy: 0.7998 - val_loss: 0.9059 - val_accuracy: 0.6907\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7270 - accuracy: 0.8058 - val_loss: 0.8966 - val_accuracy: 0.7069\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7272 - accuracy: 0.8015 - val_loss: 0.8996 - val_accuracy: 0.6929\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7256 - accuracy: 0.7942 - val_loss: 0.8974 - val_accuracy: 0.7080\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7395 - accuracy: 0.7947 - val_loss: 0.9000 - val_accuracy: 0.6929\n","Epoch 86/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7265 - accuracy: 0.8039 - val_loss: 0.9042 - val_accuracy: 0.6821\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7122 - accuracy: 0.8039 - val_loss: 0.9051 - val_accuracy: 0.6929\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7151 - accuracy: 0.8074 - val_loss: 0.9074 - val_accuracy: 0.6875\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7097 - accuracy: 0.8071 - val_loss: 0.9017 - val_accuracy: 0.6832\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7050 - accuracy: 0.8044 - val_loss: 0.9159 - val_accuracy: 0.6767\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7027 - accuracy: 0.8052 - val_loss: 0.8931 - val_accuracy: 0.7058\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7003 - accuracy: 0.8071 - val_loss: 0.9112 - val_accuracy: 0.6853\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7007 - accuracy: 0.8165 - val_loss: 0.8944 - val_accuracy: 0.7101\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7006 - accuracy: 0.8106 - val_loss: 0.9021 - val_accuracy: 0.6918\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7078 - accuracy: 0.8020 - val_loss: 0.8979 - val_accuracy: 0.6875\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6981 - accuracy: 0.8077 - val_loss: 0.9250 - val_accuracy: 0.6681\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6875 - accuracy: 0.8165 - val_loss: 0.8916 - val_accuracy: 0.7058\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6763 - accuracy: 0.8195 - val_loss: 0.8984 - val_accuracy: 0.7037\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6751 - accuracy: 0.8176 - val_loss: 0.9007 - val_accuracy: 0.6972\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6777 - accuracy: 0.8171 - val_loss: 0.9147 - val_accuracy: 0.6800\n","{'loss': [1.006662130355835, 1.0007723569869995, 0.99393230676651, 0.9918236136436462, 0.9870367646217346, 0.9788228869438171, 0.9763843417167664, 0.9776067137718201, 0.9745798707008362, 0.9655041694641113, 0.9631733298301697, 0.9592123627662659, 0.9591289758682251, 0.9552736878395081, 0.9497752785682678, 0.9452125430107117, 0.9394494295120239, 0.9363179206848145, 0.9336198568344116, 0.933685839176178, 0.9296746253967285, 0.9242701530456543, 0.9204583764076233, 0.9174163341522217, 0.9166109561920166, 0.9121139049530029, 0.9060895442962646, 0.9035640954971313, 0.9057425260543823, 0.8982514142990112, 0.8941483497619629, 0.8986658453941345, 0.8859863877296448, 0.883731484413147, 0.8835329413414001, 0.8787789940834045, 0.880565881729126, 0.8805495500564575, 0.8740763068199158, 0.8654252886772156, 0.8573984503746033, 0.859484076499939, 0.8541331887245178, 0.8502026796340942, 0.8477847576141357, 0.8464857935905457, 0.8439509868621826, 0.8357300758361816, 0.8311512470245361, 0.8309231400489807, 0.8226292133331299, 0.8237332701683044, 0.8221535086631775, 0.8188830614089966, 0.8130218386650085, 0.8120793700218201, 0.8178284168243408, 0.8086463212966919, 0.8038217425346375, 0.7921891212463379, 0.791323721408844, 0.7941126823425293, 0.7938741445541382, 0.7867867946624756, 0.7799593210220337, 0.7901473045349121, 0.7812430262565613, 0.7747416496276855, 0.7701149582862854, 0.7723905444145203, 0.7680264115333557, 0.7638952136039734, 0.7640339136123657, 0.7545120716094971, 0.7529421448707581, 0.7503275871276855, 0.7469671368598938, 0.7409799695014954, 0.7404219508171082, 0.7374185919761658, 0.7310212254524231, 0.7269886136054993, 0.7272102236747742, 0.7255796194076538, 0.7395148873329163, 0.7265396118164062, 0.712205171585083, 0.7150566577911377, 0.709748387336731, 0.7049878239631653, 0.7027091979980469, 0.7003123760223389, 0.7007261514663696, 0.7005969285964966, 0.7077611684799194, 0.6981117725372314, 0.6874980330467224, 0.67631995677948, 0.6751075983047485, 0.677678644657135], 'accuracy': [0.6980064511299133, 0.701508641242981, 0.7114762663841248, 0.7071659564971924, 0.7112069129943848, 0.7147090435028076, 0.7152478694915771, 0.7042025923728943, 0.712284505367279, 0.7155172228813171, 0.7217133641242981, 0.7195581793785095, 0.7109375, 0.7163254022598267, 0.7227909564971924, 0.7182112336158752, 0.7254849076271057, 0.725215494632721, 0.7284482717514038, 0.71875, 0.728178858757019, 0.7295258641242981, 0.7338362336158752, 0.7335668206214905, 0.7332974076271057, 0.7306034564971924, 0.7421875, 0.7338362336158752, 0.7292564511299133, 0.7400323152542114, 0.7316810488700867, 0.7303340435028076, 0.7451508641242981, 0.7373383641242981, 0.7440732717514038, 0.7464978694915771, 0.7419180870056152, 0.7381465435028076, 0.751347005367279, 0.7446120977401733, 0.7529633641242981, 0.7464978694915771, 0.748383641242981, 0.759159505367279, 0.7548491358757019, 0.7537715435028076, 0.7532327771186829, 0.7583512663841248, 0.7599676847457886, 0.7551185488700867, 0.766972005367279, 0.7683189511299133, 0.7623922228813171, 0.7621228694915771, 0.7693965435028076, 0.7661637663841248, 0.7607758641242981, 0.7723599076271057, 0.7707435488700867, 0.7788254022598267, 0.774784505367279, 0.7739762663841248, 0.7774784564971924, 0.7764008641242981, 0.7823275923728943, 0.7683189511299133, 0.7785560488700867, 0.7807112336158752, 0.7831357717514038, 0.7839439511299133, 0.7793642282485962, 0.7807112336158752, 0.7831357717514038, 0.7885237336158752, 0.7836745977401733, 0.7931034564971924, 0.7917564511299133, 0.7957974076271057, 0.7933728694915771, 0.798222005367279, 0.7998383641242981, 0.8057650923728943, 0.8014547228813171, 0.7941810488700867, 0.7947198152542114, 0.8038793206214905, 0.8038793206214905, 0.8073814511299133, 0.8071120977401733, 0.8044180870056152, 0.8052262663841248, 0.8071120977401733, 0.8165409564971924, 0.8106142282485962, 0.8019935488700867, 0.8076508641242981, 0.8165409564971924, 0.8195043206214905, 0.8176185488700867, 0.8170797228813171], 'val_loss': [1.109462022781372, 1.1056441068649292, 1.1018743515014648, 1.099936604499817, 1.098413109779358, 1.0975879430770874, 1.0944732427597046, 1.0897128582000732, 1.091141939163208, 1.0872429609298706, 1.087783932685852, 1.0785719156265259, 1.0779731273651123, 1.0852042436599731, 1.0677164793014526, 1.0593053102493286, 1.0662200450897217, 1.0559512376785278, 1.0512083768844604, 1.0443048477172852, 1.0505170822143555, 1.024375557899475, 0.9870427846908569, 0.9616672992706299, 0.965985894203186, 0.9686035513877869, 0.9472885727882385, 0.9483190178871155, 0.945043683052063, 0.9438318014144897, 0.940726637840271, 0.9440348148345947, 0.9368513226509094, 0.9364098310470581, 0.9336372017860413, 0.941683828830719, 0.9336764812469482, 0.9297948479652405, 0.9271846413612366, 0.9456266164779663, 0.9430472254753113, 0.9259281754493713, 0.9509291648864746, 0.9280173778533936, 0.9434112906455994, 0.9178034663200378, 0.945894718170166, 0.9187906384468079, 0.916532039642334, 0.9181776642799377, 0.9133897423744202, 0.9229921698570251, 0.9121972322463989, 0.9104870557785034, 0.912588894367218, 0.913360595703125, 0.9066039323806763, 0.9203758239746094, 0.9064648151397705, 0.9074815511703491, 0.9087821245193481, 0.9078773856163025, 0.9007668495178223, 0.9081487059593201, 0.9011021852493286, 0.9021354913711548, 0.9355087280273438, 0.9235066771507263, 0.9112665057182312, 0.9206207394599915, 0.9002784490585327, 0.933775782585144, 0.9017656445503235, 0.918746292591095, 0.9148741364479065, 0.9009829163551331, 0.9050210118293762, 0.904738187789917, 0.8965772986412048, 0.9091842770576477, 0.9059168696403503, 0.8965778946876526, 0.8995819091796875, 0.8974115252494812, 0.9000449180603027, 0.9042146801948547, 0.9051050543785095, 0.9074229598045349, 0.9016925692558289, 0.9158852696418762, 0.8931339979171753, 0.9111589789390564, 0.8944186568260193, 0.9020869731903076, 0.8979370594024658, 0.9249500632286072, 0.8916288018226624, 0.8984286189079285, 0.900723934173584, 0.9147149920463562], 'val_accuracy': [0.5829741358757019, 0.5603448152542114, 0.5571120977401733, 0.5344827771186829, 0.5280172228813171, 0.5226293206214905, 0.5237069129943848, 0.5301724076271057, 0.5226293206214905, 0.5280172228813171, 0.524784505367279, 0.5334051847457886, 0.5355603694915771, 0.53125, 0.5592672228813171, 0.5743534564971924, 0.5657327771186829, 0.5851293206214905, 0.5894396305084229, 0.5991379022598267, 0.600215494632721, 0.6368534564971924, 0.670258641242981, 0.6918103694915771, 0.6875, 0.6918103694915771, 0.7079741358757019, 0.701508641242981, 0.701508641242981, 0.7025862336158752, 0.7090517282485962, 0.6993534564971924, 0.7079741358757019, 0.7068965435028076, 0.7068965435028076, 0.6896551847457886, 0.6993534564971924, 0.7079741358757019, 0.7025862336158752, 0.6842672228813171, 0.6821120977401733, 0.6982758641242981, 0.6724137663841248, 0.6928879022598267, 0.6821120977401733, 0.7058189511299133, 0.6788793206214905, 0.6950430870056152, 0.7025862336158752, 0.704741358757019, 0.7068965435028076, 0.6928879022598267, 0.7058189511299133, 0.6993534564971924, 0.7079741358757019, 0.693965494632721, 0.6982758641242981, 0.693965494632721, 0.7036637663841248, 0.6971982717514038, 0.6918103694915771, 0.7068965435028076, 0.701508641242981, 0.6961206793785095, 0.712284505367279, 0.7025862336158752, 0.6745689511299133, 0.6842672228813171, 0.6961206793785095, 0.6875, 0.7058189511299133, 0.662715494632721, 0.6928879022598267, 0.6788793206214905, 0.6767241358757019, 0.701508641242981, 0.7004310488700867, 0.6971982717514038, 0.7112069129943848, 0.6885775923728943, 0.6907327771186829, 0.7068965435028076, 0.6928879022598267, 0.7079741358757019, 0.6928879022598267, 0.6821120977401733, 0.6928879022598267, 0.6875, 0.6831896305084229, 0.6767241358757019, 0.7058189511299133, 0.6853448152542114, 0.7101293206214905, 0.6918103694915771, 0.6875, 0.6681034564971924, 0.7058189511299133, 0.7036637663841248, 0.6971982717514038, 0.6799569129943848]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 1.0123 - accuracy: 0.6999"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 55ms/step - loss: 1.0105 - accuracy: 0.7015 - val_loss: 1.1102 - val_accuracy: 0.5724\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0054 - accuracy: 0.7026 - val_loss: 1.1068 - val_accuracy: 0.5577\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0039 - accuracy: 0.6984 - val_loss: 1.1053 - val_accuracy: 0.5238\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0001 - accuracy: 0.6995 - val_loss: 1.1017 - val_accuracy: 0.5351\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9931 - accuracy: 0.7051 - val_loss: 1.1010 - val_accuracy: 0.5215\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9891 - accuracy: 0.7085 - val_loss: 1.0997 - val_accuracy: 0.5170\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9871 - accuracy: 0.7035 - val_loss: 1.0981 - val_accuracy: 0.5181\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9840 - accuracy: 0.7100 - val_loss: 1.0950 - val_accuracy: 0.5204\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9787 - accuracy: 0.7037 - val_loss: 1.0931 - val_accuracy: 0.5215\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9796 - accuracy: 0.7068 - val_loss: 1.0995 - val_accuracy: 0.5090\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9733 - accuracy: 0.7080 - val_loss: 1.0863 - val_accuracy: 0.5283\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9672 - accuracy: 0.7117 - val_loss: 1.0906 - val_accuracy: 0.5226\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9615 - accuracy: 0.7125 - val_loss: 1.0815 - val_accuracy: 0.5328\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9604 - accuracy: 0.7201 - val_loss: 1.0911 - val_accuracy: 0.5260\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9566 - accuracy: 0.7151 - val_loss: 1.0796 - val_accuracy: 0.5373\n","Epoch 16/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9529 - accuracy: 0.7213 - val_loss: 1.0928 - val_accuracy: 0.5283\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9531 - accuracy: 0.7168 - val_loss: 1.0780 - val_accuracy: 0.5486\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9500 - accuracy: 0.7230 - val_loss: 1.0577 - val_accuracy: 0.5826\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9453 - accuracy: 0.7182 - val_loss: 1.0547 - val_accuracy: 0.5848\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9430 - accuracy: 0.7238 - val_loss: 1.0579 - val_accuracy: 0.5837\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9432 - accuracy: 0.7139 - val_loss: 1.0306 - val_accuracy: 0.6210\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9339 - accuracy: 0.7289 - val_loss: 1.0520 - val_accuracy: 0.5928\n","Epoch 23/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9315 - accuracy: 0.7315 - val_loss: 1.0180 - val_accuracy: 0.6369\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9262 - accuracy: 0.7298 - val_loss: 1.0161 - val_accuracy: 0.6357\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9279 - accuracy: 0.7286 - val_loss: 0.9874 - val_accuracy: 0.6663\n","Epoch 26/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.9209 - accuracy: 0.7315 - val_loss: 0.9759 - val_accuracy: 0.6776\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9153 - accuracy: 0.7317 - val_loss: 0.9839 - val_accuracy: 0.6742\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9106 - accuracy: 0.7397 - val_loss: 0.9931 - val_accuracy: 0.6629\n","Epoch 29/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9092 - accuracy: 0.7380 - val_loss: 0.9587 - val_accuracy: 0.6912\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9042 - accuracy: 0.7391 - val_loss: 0.9730 - val_accuracy: 0.6765\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9054 - accuracy: 0.7312 - val_loss: 0.9565 - val_accuracy: 0.6821\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9043 - accuracy: 0.7320 - val_loss: 0.9955 - val_accuracy: 0.6561\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9075 - accuracy: 0.7241 - val_loss: 0.9532 - val_accuracy: 0.6844\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8952 - accuracy: 0.7402 - val_loss: 0.9585 - val_accuracy: 0.6810\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8912 - accuracy: 0.7374 - val_loss: 0.9517 - val_accuracy: 0.6810\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8982 - accuracy: 0.7301 - val_loss: 0.9448 - val_accuracy: 0.6878\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8871 - accuracy: 0.7334 - val_loss: 0.9452 - val_accuracy: 0.6889\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8800 - accuracy: 0.7442 - val_loss: 0.9551 - val_accuracy: 0.6867\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8769 - accuracy: 0.7450 - val_loss: 0.9467 - val_accuracy: 0.6821\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8748 - accuracy: 0.7402 - val_loss: 0.9431 - val_accuracy: 0.6855\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8724 - accuracy: 0.7493 - val_loss: 0.9465 - val_accuracy: 0.6889\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8719 - accuracy: 0.7436 - val_loss: 0.9403 - val_accuracy: 0.6855\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8618 - accuracy: 0.7507 - val_loss: 0.9373 - val_accuracy: 0.6889\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8588 - accuracy: 0.7501 - val_loss: 0.9448 - val_accuracy: 0.6833\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8595 - accuracy: 0.7493 - val_loss: 0.9485 - val_accuracy: 0.6844\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8601 - accuracy: 0.7456 - val_loss: 0.9471 - val_accuracy: 0.6867\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8502 - accuracy: 0.7490 - val_loss: 0.9437 - val_accuracy: 0.6776\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8483 - accuracy: 0.7484 - val_loss: 0.9331 - val_accuracy: 0.6844\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8448 - accuracy: 0.7541 - val_loss: 0.9299 - val_accuracy: 0.6900\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8435 - accuracy: 0.7521 - val_loss: 0.9397 - val_accuracy: 0.6844\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8409 - accuracy: 0.7541 - val_loss: 0.9351 - val_accuracy: 0.6844\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8346 - accuracy: 0.7606 - val_loss: 0.9258 - val_accuracy: 0.6889\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8332 - accuracy: 0.7524 - val_loss: 0.9257 - val_accuracy: 0.6867\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8198 - accuracy: 0.7674 - val_loss: 0.9247 - val_accuracy: 0.6889\n","Epoch 55/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8189 - accuracy: 0.7671 - val_loss: 0.9293 - val_accuracy: 0.6799\n","Epoch 56/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8249 - accuracy: 0.7581 - val_loss: 0.9269 - val_accuracy: 0.6799\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8140 - accuracy: 0.7674 - val_loss: 0.9266 - val_accuracy: 0.6855\n","Epoch 58/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8143 - accuracy: 0.7629 - val_loss: 0.9309 - val_accuracy: 0.6878\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8104 - accuracy: 0.7705 - val_loss: 0.9273 - val_accuracy: 0.6889\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8116 - accuracy: 0.7609 - val_loss: 0.9604 - val_accuracy: 0.6686\n","Epoch 61/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8052 - accuracy: 0.7722 - val_loss: 0.9172 - val_accuracy: 0.6889\n","Epoch 62/100\n","28/28 [==============================] - 2s 65ms/step - loss: 0.8023 - accuracy: 0.7742 - val_loss: 0.9238 - val_accuracy: 0.6934\n","Epoch 63/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.7996 - accuracy: 0.7685 - val_loss: 0.9220 - val_accuracy: 0.6900\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7945 - accuracy: 0.7790 - val_loss: 0.9198 - val_accuracy: 0.6912\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7912 - accuracy: 0.7691 - val_loss: 0.9327 - val_accuracy: 0.6855\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8012 - accuracy: 0.7583 - val_loss: 0.9304 - val_accuracy: 0.6833\n","Epoch 67/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7905 - accuracy: 0.7671 - val_loss: 0.9168 - val_accuracy: 0.6968\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7743 - accuracy: 0.7892 - val_loss: 0.9198 - val_accuracy: 0.6934\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7784 - accuracy: 0.7824 - val_loss: 0.9190 - val_accuracy: 0.6934\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7737 - accuracy: 0.7838 - val_loss: 0.9216 - val_accuracy: 0.6934\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7680 - accuracy: 0.7906 - val_loss: 0.9220 - val_accuracy: 0.6912\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7635 - accuracy: 0.7852 - val_loss: 0.9316 - val_accuracy: 0.6946\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7741 - accuracy: 0.7767 - val_loss: 0.9226 - val_accuracy: 0.6923\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7599 - accuracy: 0.7937 - val_loss: 0.9574 - val_accuracy: 0.6663\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7688 - accuracy: 0.7813 - val_loss: 0.9129 - val_accuracy: 0.6923\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7542 - accuracy: 0.7881 - val_loss: 0.9143 - val_accuracy: 0.6923\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7500 - accuracy: 0.7909 - val_loss: 0.9145 - val_accuracy: 0.6912\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7456 - accuracy: 0.7954 - val_loss: 0.9260 - val_accuracy: 0.6867\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7557 - accuracy: 0.7875 - val_loss: 0.9272 - val_accuracy: 0.6855\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7447 - accuracy: 0.7889 - val_loss: 0.9174 - val_accuracy: 0.6923\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7319 - accuracy: 0.8073 - val_loss: 0.9117 - val_accuracy: 0.6968\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7327 - accuracy: 0.7977 - val_loss: 0.9228 - val_accuracy: 0.6991\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7267 - accuracy: 0.8036 - val_loss: 0.9138 - val_accuracy: 0.6912\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7261 - accuracy: 0.8070 - val_loss: 0.9286 - val_accuracy: 0.6867\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7186 - accuracy: 0.8107 - val_loss: 0.9200 - val_accuracy: 0.6957\n","Epoch 86/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7163 - accuracy: 0.8070 - val_loss: 0.9236 - val_accuracy: 0.6878\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7123 - accuracy: 0.8070 - val_loss: 0.9196 - val_accuracy: 0.6900\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7119 - accuracy: 0.8056 - val_loss: 0.9202 - val_accuracy: 0.6946\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7121 - accuracy: 0.8033 - val_loss: 0.9161 - val_accuracy: 0.6957\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7030 - accuracy: 0.8115 - val_loss: 0.9198 - val_accuracy: 0.6912\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7044 - accuracy: 0.8161 - val_loss: 0.9301 - val_accuracy: 0.6878\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7062 - accuracy: 0.8098 - val_loss: 0.9198 - val_accuracy: 0.6934\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6961 - accuracy: 0.8124 - val_loss: 0.9188 - val_accuracy: 0.7036\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6883 - accuracy: 0.8181 - val_loss: 0.9216 - val_accuracy: 0.6912\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6951 - accuracy: 0.8132 - val_loss: 0.9366 - val_accuracy: 0.6844\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6878 - accuracy: 0.8183 - val_loss: 0.9255 - val_accuracy: 0.7036\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6803 - accuracy: 0.8237 - val_loss: 0.9310 - val_accuracy: 0.6934\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6856 - accuracy: 0.8189 - val_loss: 0.9241 - val_accuracy: 0.6934\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6809 - accuracy: 0.8234 - val_loss: 0.9260 - val_accuracy: 0.6923\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6895 - accuracy: 0.8127 - val_loss: 0.9309 - val_accuracy: 0.6980\n","{'loss': [1.0105448961257935, 1.005401372909546, 1.0038915872573853, 1.0000813007354736, 0.9931050539016724, 0.9891238808631897, 0.9870967864990234, 0.9840108156204224, 0.9787282347679138, 0.9796323180198669, 0.9732932448387146, 0.9671953916549683, 0.9614560604095459, 0.9603607654571533, 0.9566464424133301, 0.9528685212135315, 0.9530947208404541, 0.9499660730361938, 0.9453381896018982, 0.9430174827575684, 0.9431995153427124, 0.9339224696159363, 0.9314733147621155, 0.9262177348136902, 0.9279429912567139, 0.9209066033363342, 0.9153108596801758, 0.9105579257011414, 0.9092362523078918, 0.904209554195404, 0.9053658843040466, 0.9043385982513428, 0.9075214862823486, 0.8952385783195496, 0.8912417888641357, 0.8982324600219727, 0.8871296644210815, 0.8799735903739929, 0.8769321441650391, 0.8748114109039307, 0.8723770380020142, 0.8719267845153809, 0.8618260622024536, 0.8587921261787415, 0.8594667911529541, 0.8600592017173767, 0.8502197861671448, 0.8483218550682068, 0.8448403477668762, 0.8434646129608154, 0.8408579230308533, 0.834632158279419, 0.8332449197769165, 0.8198072910308838, 0.8189271092414856, 0.8248769044876099, 0.8140040040016174, 0.8142799735069275, 0.810386598110199, 0.8116480708122253, 0.8052394986152649, 0.8022831082344055, 0.7996430993080139, 0.7945231795310974, 0.791153073310852, 0.8011568784713745, 0.7904836535453796, 0.7742777466773987, 0.7784319519996643, 0.7736577391624451, 0.7679542303085327, 0.7634895443916321, 0.774060845375061, 0.7598586678504944, 0.7688325643539429, 0.754153847694397, 0.7500318884849548, 0.745623767375946, 0.7557166218757629, 0.7446545362472534, 0.7318564057350159, 0.7326586246490479, 0.7267230749130249, 0.726063072681427, 0.7186337113380432, 0.7163174152374268, 0.7123358845710754, 0.711885929107666, 0.7121465802192688, 0.7029761075973511, 0.7043965458869934, 0.706169068813324, 0.6961456537246704, 0.6882545351982117, 0.69514399766922, 0.6878404021263123, 0.6803323030471802, 0.685627281665802, 0.680854082107544, 0.689526379108429], 'accuracy': [0.7014714479446411, 0.702603280544281, 0.6983587741851807, 0.6994906663894653, 0.7051499485969543, 0.7085455656051636, 0.7034521698951721, 0.709960401058197, 0.7037351727485657, 0.7068477869033813, 0.7079796195030212, 0.7116581797599792, 0.7125070691108704, 0.7201471328735352, 0.7150537371635437, 0.7212790250778198, 0.7167515754699707, 0.722976803779602, 0.7181664109230042, 0.7238256931304932, 0.7139219045639038, 0.7289190888404846, 0.731465756893158, 0.7297679781913757, 0.7286360859870911, 0.731465756893158, 0.7317487001419067, 0.7396717667579651, 0.7379739880561829, 0.7391058206558228, 0.7311828136444092, 0.7320317029953003, 0.7241086363792419, 0.7402377128601074, 0.7374080419540405, 0.7300509214401245, 0.7334465384483337, 0.7441992163658142, 0.7450481057167053, 0.7402377128601074, 0.7492926120758057, 0.7436332702636719, 0.7507073879241943, 0.7501415014266968, 0.7492926120758057, 0.7456140518188477, 0.7490096092224121, 0.7484436631202698, 0.7541030049324036, 0.7521222233772278, 0.7541030049324036, 0.7606111764907837, 0.7524052262306213, 0.7674023509025574, 0.7671194076538086, 0.7580645084381104, 0.7674023509025574, 0.7628749012947083, 0.7705150246620178, 0.7608941793441772, 0.7722128033638, 0.774193525314331, 0.768534243106842, 0.7790039777755737, 0.7691001892089844, 0.7583475112915039, 0.7671194076538086, 0.7891907095909119, 0.7823995351791382, 0.7838143706321716, 0.7906055450439453, 0.7852292060852051, 0.7767402529716492, 0.793718159198761, 0.7812677025794983, 0.788058876991272, 0.7908884882926941, 0.7954159379005432, 0.7874929308891296, 0.7889077663421631, 0.8073005080223083, 0.7976796627044678, 0.8036219477653503, 0.8070175647735596, 0.8106960654258728, 0.8070175647735596, 0.8070175647735596, 0.8056027293205261, 0.8033390045166016, 0.8115450143814087, 0.8160724639892578, 0.8098471760749817, 0.8123939037322998, 0.8180531859397888, 0.8132427930831909, 0.8183361887931824, 0.8237125277519226, 0.8189020752906799, 0.823429524898529, 0.8126768469810486], 'val_loss': [1.1102254390716553, 1.10675847530365, 1.1052931547164917, 1.1017354726791382, 1.1010054349899292, 1.0996729135513306, 1.0981497764587402, 1.095028281211853, 1.0931363105773926, 1.099537968635559, 1.0863326787948608, 1.0905790328979492, 1.0814731121063232, 1.0910751819610596, 1.0796104669570923, 1.092782735824585, 1.078046202659607, 1.0577205419540405, 1.0546510219573975, 1.057879090309143, 1.0305593013763428, 1.05199134349823, 1.0180383920669556, 1.016086220741272, 0.9874017834663391, 0.9759328365325928, 0.9839406609535217, 0.9931002259254456, 0.9587334394454956, 0.9729900360107422, 0.9564973711967468, 0.995543897151947, 0.9532353281974792, 0.958512544631958, 0.9516977071762085, 0.9448273181915283, 0.9452400207519531, 0.9550755023956299, 0.9466987252235413, 0.9431488513946533, 0.9464819431304932, 0.9402610063552856, 0.9372734427452087, 0.944786548614502, 0.9485409259796143, 0.9471380114555359, 0.9437156319618225, 0.9331110715866089, 0.9299459457397461, 0.9396635293960571, 0.9351114630699158, 0.9258310198783875, 0.9256731271743774, 0.9246712923049927, 0.9293494820594788, 0.9269486665725708, 0.9265509843826294, 0.9309183955192566, 0.9273179769515991, 0.9603874683380127, 0.9171630144119263, 0.9238266944885254, 0.9220205545425415, 0.9198377132415771, 0.9327253103256226, 0.9304407835006714, 0.9168029427528381, 0.9198421239852905, 0.9190198183059692, 0.92156982421875, 0.9219560623168945, 0.9315873384475708, 0.9225992560386658, 0.9574080109596252, 0.9129289388656616, 0.9143173694610596, 0.9145390391349792, 0.9260234832763672, 0.9271687865257263, 0.9173992872238159, 0.9117187261581421, 0.9228301644325256, 0.9137783050537109, 0.9285545945167542, 0.9200385808944702, 0.9236481189727783, 0.919603705406189, 0.9202221035957336, 0.916100025177002, 0.9197730422019958, 0.9301304221153259, 0.9198429584503174, 0.9187945127487183, 0.9215843081474304, 0.9366235733032227, 0.9255393147468567, 0.9309661984443665, 0.9241029024124146, 0.9260348081588745, 0.9309216141700745], 'val_accuracy': [0.5723981857299805, 0.557692289352417, 0.523755669593811, 0.5350678563117981, 0.5214931964874268, 0.516968309879303, 0.5180995464324951, 0.5203620195388794, 0.5214931964874268, 0.5090497732162476, 0.5282805562019348, 0.5226244330406189, 0.5328054428100586, 0.5260180830955505, 0.5373303294181824, 0.5282805562019348, 0.5486425161361694, 0.5825791954994202, 0.5848416090011597, 0.5837104320526123, 0.6210407018661499, 0.5927602052688599, 0.6368778347969055, 0.6357465982437134, 0.6662895679473877, 0.6776018142700195, 0.6742081642150879, 0.662895917892456, 0.6911764740943909, 0.6764705777168274, 0.6821267008781433, 0.6561086177825928, 0.6843891143798828, 0.6809954643249512, 0.6809954643249512, 0.6877828240394592, 0.6889140009880066, 0.6866515874862671, 0.6821267008781433, 0.685520350933075, 0.6889140009880066, 0.685520350933075, 0.6889140009880066, 0.6832579374313354, 0.6843891143798828, 0.6866515874862671, 0.6776018142700195, 0.6843891143798828, 0.6900452375411987, 0.6843891143798828, 0.6843891143798828, 0.6889140009880066, 0.6866515874862671, 0.6889140009880066, 0.679864227771759, 0.679864227771759, 0.685520350933075, 0.6877828240394592, 0.6889140009880066, 0.668552041053772, 0.6889140009880066, 0.6934388875961304, 0.6900452375411987, 0.6911764740943909, 0.685520350933075, 0.6832579374313354, 0.6968325972557068, 0.6934388875961304, 0.6934388875961304, 0.6934388875961304, 0.6911764740943909, 0.6945701241493225, 0.692307710647583, 0.6662895679473877, 0.692307710647583, 0.692307710647583, 0.6911764740943909, 0.6866515874862671, 0.685520350933075, 0.692307710647583, 0.6968325972557068, 0.6990950107574463, 0.6911764740943909, 0.6866515874862671, 0.6957013607025146, 0.6877828240394592, 0.6900452375411987, 0.6945701241493225, 0.6957013607025146, 0.6911764740943909, 0.6877828240394592, 0.6934388875961304, 0.7036198973655701, 0.6911764740943909, 0.6843891143798828, 0.7036198973655701, 0.6934388875961304, 0.6934388875961304, 0.692307710647583, 0.6979637742042542]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.9993 - accuracy: 0.6999"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 54ms/step - loss: 1.0018 - accuracy: 0.6972 - val_loss: 1.1088 - val_accuracy: 0.6250\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9939 - accuracy: 0.7096 - val_loss: 1.1049 - val_accuracy: 0.5837\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9897 - accuracy: 0.7062 - val_loss: 1.1023 - val_accuracy: 0.5434\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9887 - accuracy: 0.7052 - val_loss: 1.1004 - val_accuracy: 0.5331\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9874 - accuracy: 0.7085 - val_loss: 1.0976 - val_accuracy: 0.5320\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9781 - accuracy: 0.7165 - val_loss: 1.0954 - val_accuracy: 0.5320\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9758 - accuracy: 0.7132 - val_loss: 1.0947 - val_accuracy: 0.5248\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9714 - accuracy: 0.7199 - val_loss: 1.0877 - val_accuracy: 0.5362\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9697 - accuracy: 0.7124 - val_loss: 1.0869 - val_accuracy: 0.5341\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9615 - accuracy: 0.7194 - val_loss: 1.0915 - val_accuracy: 0.5248\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9601 - accuracy: 0.7194 - val_loss: 1.0926 - val_accuracy: 0.5248\n","Epoch 12/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9581 - accuracy: 0.7251 - val_loss: 1.0790 - val_accuracy: 0.5455\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9505 - accuracy: 0.7248 - val_loss: 1.0858 - val_accuracy: 0.5351\n","Epoch 14/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9486 - accuracy: 0.7266 - val_loss: 1.0819 - val_accuracy: 0.5424\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9484 - accuracy: 0.7191 - val_loss: 1.0712 - val_accuracy: 0.5599\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9430 - accuracy: 0.7238 - val_loss: 1.0610 - val_accuracy: 0.5785\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9360 - accuracy: 0.7207 - val_loss: 1.0582 - val_accuracy: 0.5899\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9374 - accuracy: 0.7243 - val_loss: 1.0392 - val_accuracy: 0.6116\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9318 - accuracy: 0.7258 - val_loss: 1.0370 - val_accuracy: 0.6136\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9308 - accuracy: 0.7227 - val_loss: 1.0467 - val_accuracy: 0.6116\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9279 - accuracy: 0.7279 - val_loss: 0.9991 - val_accuracy: 0.6653\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9225 - accuracy: 0.7339 - val_loss: 0.9981 - val_accuracy: 0.6622\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9174 - accuracy: 0.7276 - val_loss: 1.0100 - val_accuracy: 0.6498\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9138 - accuracy: 0.7328 - val_loss: 0.9903 - val_accuracy: 0.6694\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9103 - accuracy: 0.7297 - val_loss: 0.9931 - val_accuracy: 0.6612\n","Epoch 26/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9135 - accuracy: 0.7251 - val_loss: 0.9733 - val_accuracy: 0.6746\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9113 - accuracy: 0.7266 - val_loss: 0.9765 - val_accuracy: 0.6725\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9051 - accuracy: 0.7313 - val_loss: 0.9702 - val_accuracy: 0.6725\n","Epoch 29/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9016 - accuracy: 0.7295 - val_loss: 0.9707 - val_accuracy: 0.6787\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9007 - accuracy: 0.7302 - val_loss: 0.9697 - val_accuracy: 0.6736\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8945 - accuracy: 0.7351 - val_loss: 0.9748 - val_accuracy: 0.6663\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8887 - accuracy: 0.7393 - val_loss: 0.9665 - val_accuracy: 0.6829\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8870 - accuracy: 0.7344 - val_loss: 0.9651 - val_accuracy: 0.6808\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8818 - accuracy: 0.7408 - val_loss: 0.9722 - val_accuracy: 0.6746\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8825 - accuracy: 0.7483 - val_loss: 0.9621 - val_accuracy: 0.6736\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8724 - accuracy: 0.7447 - val_loss: 0.9614 - val_accuracy: 0.6787\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8737 - accuracy: 0.7429 - val_loss: 0.9596 - val_accuracy: 0.6787\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8732 - accuracy: 0.7432 - val_loss: 0.9587 - val_accuracy: 0.6767\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8764 - accuracy: 0.7398 - val_loss: 0.9588 - val_accuracy: 0.6694\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8656 - accuracy: 0.7470 - val_loss: 0.9580 - val_accuracy: 0.6705\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8598 - accuracy: 0.7478 - val_loss: 0.9597 - val_accuracy: 0.6674\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8564 - accuracy: 0.7522 - val_loss: 0.9629 - val_accuracy: 0.6643\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8533 - accuracy: 0.7512 - val_loss: 0.9635 - val_accuracy: 0.6550\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8521 - accuracy: 0.7525 - val_loss: 0.9513 - val_accuracy: 0.6736\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8438 - accuracy: 0.7545 - val_loss: 0.9583 - val_accuracy: 0.6581\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8419 - accuracy: 0.7545 - val_loss: 0.9512 - val_accuracy: 0.6818\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8419 - accuracy: 0.7545 - val_loss: 0.9483 - val_accuracy: 0.6777\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8362 - accuracy: 0.7584 - val_loss: 0.9551 - val_accuracy: 0.6756\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8334 - accuracy: 0.7587 - val_loss: 0.9521 - val_accuracy: 0.6787\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8303 - accuracy: 0.7584 - val_loss: 0.9489 - val_accuracy: 0.6767\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8273 - accuracy: 0.7561 - val_loss: 0.9530 - val_accuracy: 0.6746\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8250 - accuracy: 0.7605 - val_loss: 0.9471 - val_accuracy: 0.6777\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8224 - accuracy: 0.7548 - val_loss: 0.9431 - val_accuracy: 0.6715\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8146 - accuracy: 0.7625 - val_loss: 0.9498 - val_accuracy: 0.6736\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8143 - accuracy: 0.7599 - val_loss: 0.9446 - val_accuracy: 0.6684\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8184 - accuracy: 0.7625 - val_loss: 0.9538 - val_accuracy: 0.6539\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8101 - accuracy: 0.7633 - val_loss: 0.9495 - val_accuracy: 0.6798\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8029 - accuracy: 0.7677 - val_loss: 0.9451 - val_accuracy: 0.6715\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7984 - accuracy: 0.7693 - val_loss: 0.9525 - val_accuracy: 0.6756\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7989 - accuracy: 0.7708 - val_loss: 0.9371 - val_accuracy: 0.6756\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8000 - accuracy: 0.7677 - val_loss: 0.9429 - val_accuracy: 0.6684\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7952 - accuracy: 0.7682 - val_loss: 0.9384 - val_accuracy: 0.6746\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7870 - accuracy: 0.7809 - val_loss: 0.9442 - val_accuracy: 0.6684\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7818 - accuracy: 0.7780 - val_loss: 0.9550 - val_accuracy: 0.6694\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7839 - accuracy: 0.7791 - val_loss: 0.9381 - val_accuracy: 0.6746\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7785 - accuracy: 0.7755 - val_loss: 0.9351 - val_accuracy: 0.6829\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7728 - accuracy: 0.7840 - val_loss: 0.9396 - val_accuracy: 0.6632\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7674 - accuracy: 0.7848 - val_loss: 0.9431 - val_accuracy: 0.6818\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7635 - accuracy: 0.7868 - val_loss: 0.9412 - val_accuracy: 0.6715\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7607 - accuracy: 0.7848 - val_loss: 0.9559 - val_accuracy: 0.6529\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7623 - accuracy: 0.7855 - val_loss: 0.9363 - val_accuracy: 0.6756\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7529 - accuracy: 0.7897 - val_loss: 0.9472 - val_accuracy: 0.6756\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7539 - accuracy: 0.7951 - val_loss: 0.9560 - val_accuracy: 0.6767\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7561 - accuracy: 0.7925 - val_loss: 0.9594 - val_accuracy: 0.6777\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7484 - accuracy: 0.7904 - val_loss: 0.9484 - val_accuracy: 0.6787\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7439 - accuracy: 0.7915 - val_loss: 0.9357 - val_accuracy: 0.6674\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7379 - accuracy: 0.7977 - val_loss: 0.9469 - val_accuracy: 0.6798\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7372 - accuracy: 0.7972 - val_loss: 0.9404 - val_accuracy: 0.6643\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7318 - accuracy: 0.7977 - val_loss: 0.9406 - val_accuracy: 0.6725\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7365 - accuracy: 0.7876 - val_loss: 0.9695 - val_accuracy: 0.6725\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7271 - accuracy: 0.7977 - val_loss: 0.9374 - val_accuracy: 0.6756\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7235 - accuracy: 0.7982 - val_loss: 0.9633 - val_accuracy: 0.6725\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7290 - accuracy: 0.7982 - val_loss: 0.9373 - val_accuracy: 0.6601\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7185 - accuracy: 0.8023 - val_loss: 0.9448 - val_accuracy: 0.6777\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7211 - accuracy: 0.8021 - val_loss: 0.9432 - val_accuracy: 0.6622\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7204 - accuracy: 0.7964 - val_loss: 0.9391 - val_accuracy: 0.6808\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7066 - accuracy: 0.8116 - val_loss: 0.9536 - val_accuracy: 0.6787\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7022 - accuracy: 0.8062 - val_loss: 0.9524 - val_accuracy: 0.6570\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6990 - accuracy: 0.8070 - val_loss: 0.9452 - val_accuracy: 0.6663\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6971 - accuracy: 0.8111 - val_loss: 0.9481 - val_accuracy: 0.6643\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.8114 - val_loss: 0.9421 - val_accuracy: 0.6777\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6972 - accuracy: 0.8054 - val_loss: 0.9426 - val_accuracy: 0.6767\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6920 - accuracy: 0.8116 - val_loss: 0.9912 - val_accuracy: 0.6663\n","Epoch 94/100\n","31/31 [==============================] - 2s 50ms/step - loss: 0.6918 - accuracy: 0.8096 - val_loss: 0.9553 - val_accuracy: 0.6849\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6877 - accuracy: 0.8199 - val_loss: 0.9418 - val_accuracy: 0.6705\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6824 - accuracy: 0.8186 - val_loss: 0.9445 - val_accuracy: 0.6767\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6795 - accuracy: 0.8171 - val_loss: 0.9492 - val_accuracy: 0.6860\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6692 - accuracy: 0.8243 - val_loss: 0.9703 - val_accuracy: 0.6519\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6659 - accuracy: 0.8230 - val_loss: 0.9745 - val_accuracy: 0.6725\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6710 - accuracy: 0.8181 - val_loss: 0.9513 - val_accuracy: 0.6684\n","{'loss': [1.0018236637115479, 0.993927538394928, 0.9897274374961853, 0.9887401461601257, 0.987423300743103, 0.9781495332717896, 0.9757578372955322, 0.9714244604110718, 0.9696571826934814, 0.9615098237991333, 0.9601166248321533, 0.958061933517456, 0.9504824280738831, 0.9485911130905151, 0.9484086036682129, 0.942988395690918, 0.9360246658325195, 0.93735271692276, 0.9318307638168335, 0.9307805895805359, 0.9278653264045715, 0.9224506616592407, 0.9173732399940491, 0.9138335585594177, 0.9103487730026245, 0.9135088324546814, 0.9113392233848572, 0.9051200151443481, 0.9015918970108032, 0.9007163643836975, 0.8945435285568237, 0.8887123465538025, 0.8869706988334656, 0.8818058371543884, 0.8824989795684814, 0.8724175095558167, 0.8737233281135559, 0.8731831312179565, 0.8764461278915405, 0.8655513525009155, 0.8597748875617981, 0.8563646078109741, 0.8532660603523254, 0.8521052598953247, 0.8438286781311035, 0.8419312834739685, 0.8419010043144226, 0.8362287282943726, 0.8334498405456543, 0.8303058743476868, 0.8273441791534424, 0.8250157833099365, 0.8223822116851807, 0.8145620822906494, 0.8143334984779358, 0.8184307217597961, 0.8101462721824646, 0.8029225468635559, 0.7983770370483398, 0.7988849878311157, 0.7999638915061951, 0.7951854467391968, 0.7870186567306519, 0.7817997336387634, 0.78388911485672, 0.7784503698348999, 0.7728045582771301, 0.767351508140564, 0.763525128364563, 0.760686993598938, 0.7623315453529358, 0.7528553605079651, 0.7539423108100891, 0.7561412453651428, 0.7484207153320312, 0.743946373462677, 0.7378804087638855, 0.7371934056282043, 0.7317800521850586, 0.7364522218704224, 0.727135181427002, 0.7235391736030579, 0.7289722561836243, 0.7185482382774353, 0.7211414575576782, 0.7203658819198608, 0.7066344618797302, 0.7022373080253601, 0.699008584022522, 0.6971299648284912, 0.6934410333633423, 0.6971963047981262, 0.6919563412666321, 0.6917752623558044, 0.6876710057258606, 0.682442307472229, 0.6794751882553101, 0.6692185997962952, 0.6658857464790344, 0.6710354685783386], 'accuracy': [0.697157621383667, 0.709560751914978, 0.7062015533447266, 0.7051679491996765, 0.708527147769928, 0.7165374755859375, 0.713178277015686, 0.7198966145515442, 0.7124031186103821, 0.7193798422813416, 0.7193798422813416, 0.7250645756721497, 0.7248061895370483, 0.7266150116920471, 0.7191214561462402, 0.7237725853919983, 0.7206718325614929, 0.7242894172668457, 0.7258397936820984, 0.722739040851593, 0.7279070019721985, 0.7338501214981079, 0.7276485562324524, 0.7328165173530579, 0.7297157645225525, 0.7250645756721497, 0.7266150116920471, 0.7312661409378052, 0.7294573783874512, 0.7302325367927551, 0.7351421117782593, 0.7392764687538147, 0.7343669533729553, 0.7408268451690674, 0.7483204007148743, 0.7447028160095215, 0.7428940534591675, 0.7431524395942688, 0.7397933006286621, 0.7470284104347229, 0.7478036284446716, 0.7521963715553284, 0.7511627674102783, 0.7524547576904297, 0.7545219659805298, 0.7545219659805298, 0.7545219659805298, 0.7583979368209839, 0.7586563229560852, 0.7583979368209839, 0.7560723423957825, 0.760465145111084, 0.7547803521156311, 0.7625322937965393, 0.7599483132362366, 0.7625322937965393, 0.763307511806488, 0.7677002549171448, 0.7692506313323975, 0.7708010077476501, 0.7677002549171448, 0.7682170271873474, 0.7808785438537598, 0.7780361771583557, 0.7790697813034058, 0.775452196598053, 0.7839793562889099, 0.7847545146942139, 0.786821722984314, 0.7847545146942139, 0.7855297327041626, 0.789664089679718, 0.7950904369354248, 0.7925064563751221, 0.790439248085022, 0.791472852230072, 0.7976744174957275, 0.7971576452255249, 0.7976744174957275, 0.7875968813896179, 0.7976744174957275, 0.7981911897659302, 0.7981911897659302, 0.8023256063461304, 0.8020671606063843, 0.7963824272155762, 0.8116279244422913, 0.8062015771865845, 0.8069767355918884, 0.8111110925674438, 0.8113695383071899, 0.8054263591766357, 0.8116279244422913, 0.8095607161521912, 0.8198966383934021, 0.8186046481132507, 0.817054271697998, 0.8242893815040588, 0.8229973912239075, 0.8180878758430481], 'val_loss': [1.10882568359375, 1.1049333810806274, 1.1023333072662354, 1.100416898727417, 1.0976171493530273, 1.0954028367996216, 1.0947281122207642, 1.0877333879470825, 1.086852788925171, 1.0914937257766724, 1.0926074981689453, 1.0789592266082764, 1.0858103036880493, 1.0818668603897095, 1.0711544752120972, 1.0609592199325562, 1.058225393295288, 1.0392448902130127, 1.0369994640350342, 1.04665207862854, 0.999137282371521, 0.9981425404548645, 1.0099976062774658, 0.9902819991111755, 0.9931347966194153, 0.9732663035392761, 0.9765042662620544, 0.9702361822128296, 0.9706538319587708, 0.9696590304374695, 0.9747691750526428, 0.9665108323097229, 0.9651392698287964, 0.9721912741661072, 0.962101936340332, 0.9613639116287231, 0.9595835208892822, 0.9586526155471802, 0.9587752819061279, 0.9580001831054688, 0.9597104787826538, 0.9628830552101135, 0.9635123610496521, 0.9512601494789124, 0.9582938551902771, 0.9511545896530151, 0.9483002424240112, 0.9550951719284058, 0.9520543217658997, 0.9489409327507019, 0.9530408978462219, 0.9471347332000732, 0.9431248903274536, 0.9497565627098083, 0.944562554359436, 0.9538030624389648, 0.9495230913162231, 0.945091962814331, 0.9524663686752319, 0.9371151924133301, 0.9428808093070984, 0.9383817315101624, 0.944169819355011, 0.9550058245658875, 0.9381466507911682, 0.9350947141647339, 0.9396413564682007, 0.9430829286575317, 0.9411755204200745, 0.9559252858161926, 0.9363364577293396, 0.9472015500068665, 0.9559972286224365, 0.9594099521636963, 0.9484387040138245, 0.935745120048523, 0.946947455406189, 0.9403896927833557, 0.9405611157417297, 0.9695329666137695, 0.9373890161514282, 0.96329665184021, 0.9372715353965759, 0.9448080658912659, 0.9432132244110107, 0.939093828201294, 0.9536167979240417, 0.9524481892585754, 0.945181667804718, 0.9481287598609924, 0.9420992136001587, 0.9425691962242126, 0.9912161231040955, 0.9553308486938477, 0.9417744278907776, 0.944503903388977, 0.9492226839065552, 0.9702968001365662, 0.974477231502533, 0.9513461589813232], 'val_accuracy': [0.625, 0.5836777091026306, 0.5433884263038635, 0.5330578684806824, 0.5320248007774353, 0.5320248007774353, 0.5247933864593506, 0.5361570119857788, 0.5340909361839294, 0.5247933864593506, 0.5247933864593506, 0.5454545617103577, 0.5351239442825317, 0.5423553586006165, 0.5599173307418823, 0.5785123705863953, 0.5898760557174683, 0.6115702390670776, 0.6136363744735718, 0.6115702390670776, 0.6652892827987671, 0.6621900796890259, 0.6497933864593506, 0.6694214940071106, 0.6611570119857788, 0.6745867729187012, 0.672520637512207, 0.672520637512207, 0.6787189841270447, 0.6735537052154541, 0.6663222908973694, 0.682851254940033, 0.6807851195335388, 0.6745867729187012, 0.6735537052154541, 0.6787189841270447, 0.6787189841270447, 0.6766529083251953, 0.6694214940071106, 0.6704545617103577, 0.6673553586006165, 0.66425621509552, 0.6549586653709412, 0.6735537052154541, 0.6580578684806824, 0.6818181872367859, 0.6776859760284424, 0.6756198406219482, 0.6787189841270447, 0.6766529083251953, 0.6745867729187012, 0.6776859760284424, 0.6714876294136047, 0.6735537052154541, 0.6683884263038635, 0.6539255976676941, 0.6797520518302917, 0.6714876294136047, 0.6756198406219482, 0.6756198406219482, 0.6683884263038635, 0.6745867729187012, 0.6683884263038635, 0.6694214940071106, 0.6745867729187012, 0.682851254940033, 0.663223147392273, 0.6818181872367859, 0.6714876294136047, 0.6528925895690918, 0.6756198406219482, 0.6756198406219482, 0.6766529083251953, 0.6776859760284424, 0.6787189841270447, 0.6673553586006165, 0.6797520518302917, 0.66425621509552, 0.672520637512207, 0.672520637512207, 0.6756198406219482, 0.672520637512207, 0.6601239442825317, 0.6776859760284424, 0.6621900796890259, 0.6807851195335388, 0.6787189841270447, 0.6570248007774353, 0.6663222908973694, 0.66425621509552, 0.6776859760284424, 0.6766529083251953, 0.6663222908973694, 0.6849173307418823, 0.6704545617103577, 0.6766529083251953, 0.6859503984451294, 0.6518595218658447, 0.672520637512207, 0.6683884263038635]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.7345 - accuracy: 0.7797"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 50ms/step - loss: 0.7379 - accuracy: 0.7775 - val_loss: 0.9502 - val_accuracy: 0.5140\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7264 - accuracy: 0.7877 - val_loss: 0.9467 - val_accuracy: 0.5399\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7165 - accuracy: 0.7899 - val_loss: 0.9423 - val_accuracy: 0.6713\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7126 - accuracy: 0.7985 - val_loss: 0.9385 - val_accuracy: 0.6724\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7141 - accuracy: 0.7926 - val_loss: 0.9347 - val_accuracy: 0.6724\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7081 - accuracy: 0.7990 - val_loss: 0.9327 - val_accuracy: 0.6142\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7020 - accuracy: 0.8047 - val_loss: 0.9285 - val_accuracy: 0.6131\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.8025 - val_loss: 0.9258 - val_accuracy: 0.6013\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6983 - accuracy: 0.8015 - val_loss: 0.9228 - val_accuracy: 0.6002\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.8055 - val_loss: 0.9276 - val_accuracy: 0.5636\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.8058 - val_loss: 0.9271 - val_accuracy: 0.5625\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.8085 - val_loss: 0.9255 - val_accuracy: 0.5722\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6868 - accuracy: 0.8001 - val_loss: 0.9111 - val_accuracy: 0.5991\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.8071 - val_loss: 0.9420 - val_accuracy: 0.5571\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.8047 - val_loss: 0.9248 - val_accuracy: 0.5862\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.8120 - val_loss: 0.9267 - val_accuracy: 0.5884\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6746 - accuracy: 0.8133 - val_loss: 0.9092 - val_accuracy: 0.6142\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6734 - accuracy: 0.8179 - val_loss: 0.9044 - val_accuracy: 0.6239\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6642 - accuracy: 0.8165 - val_loss: 0.9465 - val_accuracy: 0.6002\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6564 - accuracy: 0.8179 - val_loss: 0.9323 - val_accuracy: 0.6196\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6659 - accuracy: 0.8133 - val_loss: 0.9467 - val_accuracy: 0.6153\n","Epoch 22/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6639 - accuracy: 0.8103 - val_loss: 0.9002 - val_accuracy: 0.6401\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6583 - accuracy: 0.8214 - val_loss: 0.8992 - val_accuracy: 0.6390\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6486 - accuracy: 0.8287 - val_loss: 0.8481 - val_accuracy: 0.6875\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6511 - accuracy: 0.8171 - val_loss: 0.8137 - val_accuracy: 0.7220\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6409 - accuracy: 0.8300 - val_loss: 0.8734 - val_accuracy: 0.6800\n","Epoch 27/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6369 - accuracy: 0.8281 - val_loss: 0.8012 - val_accuracy: 0.7435\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6440 - accuracy: 0.8184 - val_loss: 0.7972 - val_accuracy: 0.7435\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6479 - accuracy: 0.8176 - val_loss: 0.8042 - val_accuracy: 0.7403\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6357 - accuracy: 0.8327 - val_loss: 0.8118 - val_accuracy: 0.7425\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6339 - accuracy: 0.8292 - val_loss: 0.8018 - val_accuracy: 0.7403\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6282 - accuracy: 0.8341 - val_loss: 0.8063 - val_accuracy: 0.7392\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6244 - accuracy: 0.8416 - val_loss: 0.8027 - val_accuracy: 0.7457\n","Epoch 34/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6274 - accuracy: 0.8332 - val_loss: 0.8040 - val_accuracy: 0.7511\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6192 - accuracy: 0.8343 - val_loss: 0.8162 - val_accuracy: 0.7263\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6178 - accuracy: 0.8335 - val_loss: 0.8054 - val_accuracy: 0.7371\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6080 - accuracy: 0.8432 - val_loss: 0.8288 - val_accuracy: 0.7231\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6121 - accuracy: 0.8386 - val_loss: 0.8174 - val_accuracy: 0.7295\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6082 - accuracy: 0.8408 - val_loss: 0.8115 - val_accuracy: 0.7392\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5990 - accuracy: 0.8489 - val_loss: 0.8159 - val_accuracy: 0.7349\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5962 - accuracy: 0.8502 - val_loss: 0.8153 - val_accuracy: 0.7284\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6030 - accuracy: 0.8451 - val_loss: 0.8125 - val_accuracy: 0.7338\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5991 - accuracy: 0.8448 - val_loss: 0.8154 - val_accuracy: 0.7381\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5900 - accuracy: 0.8526 - val_loss: 0.8103 - val_accuracy: 0.7392\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5884 - accuracy: 0.8489 - val_loss: 0.8327 - val_accuracy: 0.7241\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5867 - accuracy: 0.8497 - val_loss: 0.8227 - val_accuracy: 0.7241\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6008 - accuracy: 0.8443 - val_loss: 0.8403 - val_accuracy: 0.7231\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5893 - accuracy: 0.8473 - val_loss: 0.8301 - val_accuracy: 0.7274\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5853 - accuracy: 0.8529 - val_loss: 0.8344 - val_accuracy: 0.7220\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5927 - accuracy: 0.8478 - val_loss: 0.8486 - val_accuracy: 0.7123\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5842 - accuracy: 0.8475 - val_loss: 0.8414 - val_accuracy: 0.7274\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5730 - accuracy: 0.8591 - val_loss: 0.8232 - val_accuracy: 0.7284\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5725 - accuracy: 0.8505 - val_loss: 0.8276 - val_accuracy: 0.7241\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5666 - accuracy: 0.8586 - val_loss: 0.8262 - val_accuracy: 0.7306\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5621 - accuracy: 0.8591 - val_loss: 0.8338 - val_accuracy: 0.7306\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5668 - accuracy: 0.8561 - val_loss: 0.8271 - val_accuracy: 0.7306\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5582 - accuracy: 0.8572 - val_loss: 0.8360 - val_accuracy: 0.7381\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5585 - accuracy: 0.8570 - val_loss: 0.8419 - val_accuracy: 0.7274\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5528 - accuracy: 0.8658 - val_loss: 0.8334 - val_accuracy: 0.7263\n","Epoch 60/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5600 - accuracy: 0.8559 - val_loss: 0.8549 - val_accuracy: 0.7123\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5672 - accuracy: 0.8508 - val_loss: 0.8561 - val_accuracy: 0.7069\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5565 - accuracy: 0.8626 - val_loss: 0.8424 - val_accuracy: 0.7220\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5492 - accuracy: 0.8602 - val_loss: 0.8292 - val_accuracy: 0.7252\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5504 - accuracy: 0.8583 - val_loss: 0.8369 - val_accuracy: 0.7231\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5503 - accuracy: 0.8640 - val_loss: 0.8356 - val_accuracy: 0.7263\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5615 - accuracy: 0.8532 - val_loss: 0.8249 - val_accuracy: 0.7263\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5383 - accuracy: 0.8621 - val_loss: 0.8346 - val_accuracy: 0.7198\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5407 - accuracy: 0.8629 - val_loss: 0.8624 - val_accuracy: 0.7101\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5296 - accuracy: 0.8693 - val_loss: 0.8720 - val_accuracy: 0.7004\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5350 - accuracy: 0.8683 - val_loss: 0.8472 - val_accuracy: 0.7231\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5441 - accuracy: 0.8599 - val_loss: 0.8404 - val_accuracy: 0.7220\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5403 - accuracy: 0.8602 - val_loss: 0.9828 - val_accuracy: 0.6498\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5317 - accuracy: 0.8688 - val_loss: 0.8388 - val_accuracy: 0.7209\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5160 - accuracy: 0.8777 - val_loss: 0.8509 - val_accuracy: 0.7091\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5198 - accuracy: 0.8710 - val_loss: 0.8421 - val_accuracy: 0.7220\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5154 - accuracy: 0.8782 - val_loss: 0.8514 - val_accuracy: 0.7209\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5187 - accuracy: 0.8761 - val_loss: 0.8539 - val_accuracy: 0.7220\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5085 - accuracy: 0.8823 - val_loss: 0.8464 - val_accuracy: 0.7188\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5153 - accuracy: 0.8739 - val_loss: 0.8558 - val_accuracy: 0.7231\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5054 - accuracy: 0.8852 - val_loss: 0.8544 - val_accuracy: 0.7252\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5013 - accuracy: 0.8828 - val_loss: 0.8637 - val_accuracy: 0.7188\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4991 - accuracy: 0.8847 - val_loss: 0.8707 - val_accuracy: 0.7058\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5007 - accuracy: 0.8877 - val_loss: 0.8656 - val_accuracy: 0.7069\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5020 - accuracy: 0.8834 - val_loss: 0.8956 - val_accuracy: 0.7091\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.8801 - val_loss: 0.8755 - val_accuracy: 0.7037\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4822 - accuracy: 0.8901 - val_loss: 0.8859 - val_accuracy: 0.7047\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4928 - accuracy: 0.8871 - val_loss: 0.8783 - val_accuracy: 0.7058\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5000 - accuracy: 0.8828 - val_loss: 0.8802 - val_accuracy: 0.7069\n","Epoch 89/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4884 - accuracy: 0.8869 - val_loss: 0.9152 - val_accuracy: 0.6994\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4785 - accuracy: 0.8928 - val_loss: 0.9074 - val_accuracy: 0.6940\n","Epoch 91/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4833 - accuracy: 0.8909 - val_loss: 0.8853 - val_accuracy: 0.7112\n","Epoch 92/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4999 - accuracy: 0.8766 - val_loss: 0.8862 - val_accuracy: 0.7188\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4824 - accuracy: 0.8917 - val_loss: 0.9028 - val_accuracy: 0.6994\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4881 - accuracy: 0.8820 - val_loss: 0.8866 - val_accuracy: 0.6961\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4797 - accuracy: 0.8898 - val_loss: 0.8781 - val_accuracy: 0.7220\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4711 - accuracy: 0.8960 - val_loss: 0.9094 - val_accuracy: 0.6886\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4809 - accuracy: 0.8869 - val_loss: 0.8859 - val_accuracy: 0.7134\n","Epoch 98/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4634 - accuracy: 0.8982 - val_loss: 0.8889 - val_accuracy: 0.7112\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4724 - accuracy: 0.8976 - val_loss: 0.8922 - val_accuracy: 0.7091\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4603 - accuracy: 0.8990 - val_loss: 0.8950 - val_accuracy: 0.7080\n","{'loss': [0.7379432320594788, 0.7264007329940796, 0.7164521217346191, 0.7126479148864746, 0.7141193747520447, 0.7080751657485962, 0.7020204067230225, 0.6939420104026794, 0.6983420252799988, 0.6892431378364563, 0.69279545545578, 0.681947648525238, 0.6867725849151611, 0.6890689134597778, 0.6847541928291321, 0.6797069311141968, 0.6746331453323364, 0.6733890771865845, 0.6642422676086426, 0.6563552618026733, 0.6658755540847778, 0.6638990044593811, 0.6582579612731934, 0.6485540866851807, 0.6510810852050781, 0.6409415602684021, 0.6369184255599976, 0.6439610123634338, 0.6478918194770813, 0.6356551051139832, 0.6339179277420044, 0.6282036304473877, 0.6244382262229919, 0.6273780465126038, 0.6191529035568237, 0.6177561283111572, 0.607998788356781, 0.6121124625205994, 0.6081902980804443, 0.5990474224090576, 0.5962030291557312, 0.6029843091964722, 0.5990545153617859, 0.5900318026542664, 0.5883806347846985, 0.5867017507553101, 0.6007815599441528, 0.5893144011497498, 0.5853185057640076, 0.5926766395568848, 0.5841540098190308, 0.5729976296424866, 0.5724709033966064, 0.5666216015815735, 0.5621333122253418, 0.5667812824249268, 0.5581547021865845, 0.5584898591041565, 0.5527542233467102, 0.5600115060806274, 0.5672349333763123, 0.5565404295921326, 0.5491797924041748, 0.5503848791122437, 0.5502828359603882, 0.5614560842514038, 0.5383198261260986, 0.5406808257102966, 0.5295650362968445, 0.5349889993667603, 0.5441350340843201, 0.5402535796165466, 0.531714916229248, 0.5159593224525452, 0.5197767615318298, 0.5154258012771606, 0.5186718106269836, 0.508479654788971, 0.5153433084487915, 0.5053561925888062, 0.5012718439102173, 0.4990527331829071, 0.5007032752037048, 0.5019711852073669, 0.5000131726264954, 0.4822036027908325, 0.4927951693534851, 0.49997174739837646, 0.48842453956604004, 0.47849684953689575, 0.4833281934261322, 0.4998854398727417, 0.4823542833328247, 0.4881003797054291, 0.4797027111053467, 0.47110968828201294, 0.48088064789772034, 0.4634275436401367, 0.47236692905426025, 0.4603003263473511], 'accuracy': [0.7774784564971924, 0.787715494632721, 0.7898706793785095, 0.798491358757019, 0.7925646305084229, 0.7990301847457886, 0.8046875, 0.8025323152542114, 0.8014547228813171, 0.8054956793785095, 0.8057650923728943, 0.8084590435028076, 0.8001077771186829, 0.8071120977401733, 0.8046875, 0.8119612336158752, 0.8133081793785095, 0.8178879022598267, 0.8165409564971924, 0.8178879022598267, 0.8133081793785095, 0.8103448152542114, 0.8213900923728943, 0.8286637663841248, 0.8170797228813171, 0.8300107717514038, 0.828125, 0.8184267282485962, 0.8176185488700867, 0.8327047228813171, 0.8292025923728943, 0.8340517282485962, 0.8415948152542114, 0.8332435488700867, 0.834321141242981, 0.8335129022598267, 0.8432112336158752, 0.8386314511299133, 0.8407866358757019, 0.8488685488700867, 0.850215494632721, 0.845097005367279, 0.8448275923728943, 0.8526400923728943, 0.8488685488700867, 0.8496767282485962, 0.8442887663841248, 0.8472521305084229, 0.852909505367279, 0.8477909564971924, 0.8475215435028076, 0.8591055870056152, 0.8504849076271057, 0.8585668206214905, 0.8591055870056152, 0.8561422228813171, 0.8572198152542114, 0.8569504022598267, 0.865840494632721, 0.8558728694915771, 0.8507543206214905, 0.8626077771186829, 0.8601831793785095, 0.8582974076271057, 0.8639547228813171, 0.853178858757019, 0.8620689511299133, 0.8628771305084229, 0.8693426847457886, 0.8682650923728943, 0.8599137663841248, 0.8601831793785095, 0.868803858757019, 0.8776939511299133, 0.8709590435028076, 0.8782327771186829, 0.8760775923728943, 0.8822737336158752, 0.8739224076271057, 0.8852370977401733, 0.8828125, 0.8846982717514038, 0.8876616358757019, 0.8833512663841248, 0.8801185488700867, 0.8900862336158752, 0.8871228694915771, 0.8828125, 0.8868534564971924, 0.8927801847457886, 0.8908944129943848, 0.876616358757019, 0.8917025923728943, 0.8820043206214905, 0.8898168206214905, 0.8960129022598267, 0.8868534564971924, 0.8981680870056152, 0.8976293206214905, 0.8989762663841248], 'val_loss': [0.9501563310623169, 0.9466800689697266, 0.9423441290855408, 0.9384537935256958, 0.9346994161605835, 0.9326805472373962, 0.9284806251525879, 0.9257820844650269, 0.9228463768959045, 0.927643895149231, 0.9271241426467896, 0.9254884123802185, 0.911078691482544, 0.9419859647750854, 0.9247838854789734, 0.9267023801803589, 0.909225344657898, 0.9044080972671509, 0.9465190172195435, 0.932273805141449, 0.9467188119888306, 0.9002134203910828, 0.8992291688919067, 0.8480858206748962, 0.8137481212615967, 0.8734022974967957, 0.8011641502380371, 0.7972450256347656, 0.8042108416557312, 0.8117789030075073, 0.8017866611480713, 0.8063244819641113, 0.8026707172393799, 0.8039767742156982, 0.8162074685096741, 0.8054338693618774, 0.8287578225135803, 0.8173957467079163, 0.8114650845527649, 0.815884530544281, 0.8153108358383179, 0.8125470280647278, 0.8153836727142334, 0.8102890253067017, 0.8327234983444214, 0.8227078914642334, 0.8402716517448425, 0.8301466703414917, 0.834402322769165, 0.8485831022262573, 0.8413724303245544, 0.82316654920578, 0.8275625705718994, 0.8261703848838806, 0.8337587118148804, 0.8270694613456726, 0.8360410332679749, 0.8419222235679626, 0.8333579897880554, 0.8549206852912903, 0.8560972809791565, 0.8424116373062134, 0.8292456865310669, 0.8368819952011108, 0.8355631232261658, 0.8248969316482544, 0.8345768451690674, 0.862403392791748, 0.8719900846481323, 0.8471508622169495, 0.8403939604759216, 0.9828380942344666, 0.8387894034385681, 0.8509266972541809, 0.8421231508255005, 0.8514140844345093, 0.8538714051246643, 0.8464499711990356, 0.8558459877967834, 0.8544095754623413, 0.8636603951454163, 0.8706766963005066, 0.8656118512153625, 0.8955737352371216, 0.8755002021789551, 0.8859391212463379, 0.8782846331596375, 0.8801620006561279, 0.9151796102523804, 0.9074346423149109, 0.8853098750114441, 0.8861905932426453, 0.9028179049491882, 0.8866062760353088, 0.8780894875526428, 0.9093587398529053, 0.8859393000602722, 0.8889215588569641, 0.8921974897384644, 0.8950052857398987], 'val_accuracy': [0.514008641242981, 0.5398706793785095, 0.6713362336158752, 0.6724137663841248, 0.6724137663841248, 0.6142241358757019, 0.6131465435028076, 0.6012930870056152, 0.600215494632721, 0.5635775923728943, 0.5625, 0.5721982717514038, 0.5991379022598267, 0.5571120977401733, 0.5862069129943848, 0.5883620977401733, 0.6142241358757019, 0.6239224076271057, 0.600215494632721, 0.6196120977401733, 0.6153017282485962, 0.6400862336158752, 0.639008641242981, 0.6875, 0.7219827771186829, 0.6799569129943848, 0.743534505367279, 0.743534505367279, 0.7403017282485962, 0.7424569129943848, 0.7403017282485962, 0.7392241358757019, 0.7456896305084229, 0.7510775923728943, 0.7262930870056152, 0.7370689511299133, 0.7230603694915771, 0.7295258641242981, 0.7392241358757019, 0.7349137663841248, 0.7284482717514038, 0.7338362336158752, 0.7381465435028076, 0.7392241358757019, 0.7241379022598267, 0.7241379022598267, 0.7230603694915771, 0.7273706793785095, 0.7219827771186829, 0.712284505367279, 0.7273706793785095, 0.7284482717514038, 0.7241379022598267, 0.7306034564971924, 0.7306034564971924, 0.7306034564971924, 0.7381465435028076, 0.7273706793785095, 0.7262930870056152, 0.712284505367279, 0.7068965435028076, 0.7219827771186829, 0.725215494632721, 0.7230603694915771, 0.7262930870056152, 0.7262930870056152, 0.7198275923728943, 0.7101293206214905, 0.7004310488700867, 0.7230603694915771, 0.7219827771186829, 0.649784505367279, 0.7209051847457886, 0.7090517282485962, 0.7219827771186829, 0.7209051847457886, 0.7219827771186829, 0.71875, 0.7230603694915771, 0.725215494632721, 0.71875, 0.7058189511299133, 0.7068965435028076, 0.7090517282485962, 0.7036637663841248, 0.704741358757019, 0.7058189511299133, 0.7068965435028076, 0.6993534564971924, 0.693965494632721, 0.7112069129943848, 0.71875, 0.6993534564971924, 0.6961206793785095, 0.7219827771186829, 0.6885775923728943, 0.7133620977401733, 0.7112069129943848, 0.7090517282485962, 0.7079741358757019]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.7446 - accuracy: 0.7728"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 65ms/step - loss: 0.7463 - accuracy: 0.7733 - val_loss: 0.9497 - val_accuracy: 0.5204\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7353 - accuracy: 0.7827 - val_loss: 0.9466 - val_accuracy: 0.5848\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7223 - accuracy: 0.7844 - val_loss: 0.9430 - val_accuracy: 0.6606\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7201 - accuracy: 0.7869 - val_loss: 0.9402 - val_accuracy: 0.6595\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7174 - accuracy: 0.7903 - val_loss: 0.9375 - val_accuracy: 0.6357\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7096 - accuracy: 0.8011 - val_loss: 0.9366 - val_accuracy: 0.5837\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7115 - accuracy: 0.7971 - val_loss: 0.9306 - val_accuracy: 0.6188\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7025 - accuracy: 0.7954 - val_loss: 0.9331 - val_accuracy: 0.5781\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7067 - accuracy: 0.7943 - val_loss: 0.9316 - val_accuracy: 0.5724\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6997 - accuracy: 0.7974 - val_loss: 0.9372 - val_accuracy: 0.5566\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7021 - accuracy: 0.7906 - val_loss: 0.9385 - val_accuracy: 0.5475\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7056 - accuracy: 0.7917 - val_loss: 0.9169 - val_accuracy: 0.5962\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6847 - accuracy: 0.8147 - val_loss: 0.9162 - val_accuracy: 0.5962\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6877 - accuracy: 0.8036 - val_loss: 0.9284 - val_accuracy: 0.5758\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6816 - accuracy: 0.8110 - val_loss: 0.9424 - val_accuracy: 0.5679\n","Epoch 16/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6723 - accuracy: 0.8172 - val_loss: 0.8977 - val_accuracy: 0.6233\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6819 - accuracy: 0.8050 - val_loss: 0.9501 - val_accuracy: 0.5769\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6703 - accuracy: 0.8147 - val_loss: 0.9191 - val_accuracy: 0.6063\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6639 - accuracy: 0.8198 - val_loss: 0.8841 - val_accuracy: 0.6459\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6708 - accuracy: 0.8110 - val_loss: 0.9088 - val_accuracy: 0.6312\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6679 - accuracy: 0.8209 - val_loss: 0.8743 - val_accuracy: 0.6618\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6653 - accuracy: 0.8121 - val_loss: 0.9359 - val_accuracy: 0.6256\n","Epoch 23/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6570 - accuracy: 0.8240 - val_loss: 0.8692 - val_accuracy: 0.6708\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6613 - accuracy: 0.8158 - val_loss: 0.8990 - val_accuracy: 0.6606\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6625 - accuracy: 0.8104 - val_loss: 0.8460 - val_accuracy: 0.6934\n","Epoch 26/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6513 - accuracy: 0.8268 - val_loss: 0.8340 - val_accuracy: 0.7104\n","Epoch 27/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6408 - accuracy: 0.8319 - val_loss: 0.7972 - val_accuracy: 0.7364\n","Epoch 28/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6413 - accuracy: 0.8288 - val_loss: 0.8036 - val_accuracy: 0.7398\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6467 - accuracy: 0.8212 - val_loss: 0.8551 - val_accuracy: 0.7048\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6379 - accuracy: 0.8243 - val_loss: 0.7988 - val_accuracy: 0.7387\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6280 - accuracy: 0.8308 - val_loss: 0.8033 - val_accuracy: 0.7387\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6338 - accuracy: 0.8311 - val_loss: 0.8333 - val_accuracy: 0.7149\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6353 - accuracy: 0.8254 - val_loss: 0.8133 - val_accuracy: 0.7319\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6331 - accuracy: 0.8314 - val_loss: 0.8060 - val_accuracy: 0.7353\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6162 - accuracy: 0.8362 - val_loss: 0.8025 - val_accuracy: 0.7432\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6257 - accuracy: 0.8328 - val_loss: 0.8057 - val_accuracy: 0.7398\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6138 - accuracy: 0.8441 - val_loss: 0.8138 - val_accuracy: 0.7353\n","Epoch 38/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6140 - accuracy: 0.8376 - val_loss: 0.8085 - val_accuracy: 0.7466\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6104 - accuracy: 0.8387 - val_loss: 0.8047 - val_accuracy: 0.7455\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6078 - accuracy: 0.8404 - val_loss: 0.8164 - val_accuracy: 0.7398\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6045 - accuracy: 0.8410 - val_loss: 0.8131 - val_accuracy: 0.7455\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6008 - accuracy: 0.8438 - val_loss: 0.8260 - val_accuracy: 0.7296\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6021 - accuracy: 0.8489 - val_loss: 0.8124 - val_accuracy: 0.7443\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5888 - accuracy: 0.8486 - val_loss: 0.8152 - val_accuracy: 0.7387\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5855 - accuracy: 0.8526 - val_loss: 0.8120 - val_accuracy: 0.7443\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5914 - accuracy: 0.8497 - val_loss: 0.8598 - val_accuracy: 0.7172\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5945 - accuracy: 0.8461 - val_loss: 0.8289 - val_accuracy: 0.7296\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5861 - accuracy: 0.8475 - val_loss: 0.8358 - val_accuracy: 0.7274\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5824 - accuracy: 0.8514 - val_loss: 0.8242 - val_accuracy: 0.7443\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5835 - accuracy: 0.8512 - val_loss: 0.8221 - val_accuracy: 0.7410\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5766 - accuracy: 0.8514 - val_loss: 0.8246 - val_accuracy: 0.7410\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5788 - accuracy: 0.8512 - val_loss: 0.8234 - val_accuracy: 0.7342\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5793 - accuracy: 0.8495 - val_loss: 0.8304 - val_accuracy: 0.7274\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5737 - accuracy: 0.8560 - val_loss: 0.8290 - val_accuracy: 0.7330\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5634 - accuracy: 0.8580 - val_loss: 0.8415 - val_accuracy: 0.7262\n","Epoch 56/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5639 - accuracy: 0.8543 - val_loss: 0.8328 - val_accuracy: 0.7477\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5620 - accuracy: 0.8557 - val_loss: 0.8340 - val_accuracy: 0.7432\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5559 - accuracy: 0.8619 - val_loss: 0.8341 - val_accuracy: 0.7432\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5510 - accuracy: 0.8636 - val_loss: 0.8486 - val_accuracy: 0.7240\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5550 - accuracy: 0.8633 - val_loss: 0.8391 - val_accuracy: 0.7296\n","Epoch 61/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5560 - accuracy: 0.8591 - val_loss: 0.8446 - val_accuracy: 0.7489\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5444 - accuracy: 0.8698 - val_loss: 0.8404 - val_accuracy: 0.7353\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5538 - accuracy: 0.8594 - val_loss: 0.8643 - val_accuracy: 0.7251\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5478 - accuracy: 0.8628 - val_loss: 0.8461 - val_accuracy: 0.7319\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5350 - accuracy: 0.8721 - val_loss: 0.8613 - val_accuracy: 0.7262\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5492 - accuracy: 0.8582 - val_loss: 0.8449 - val_accuracy: 0.7364\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5547 - accuracy: 0.8537 - val_loss: 0.8333 - val_accuracy: 0.7364\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5363 - accuracy: 0.8704 - val_loss: 0.8534 - val_accuracy: 0.7342\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5228 - accuracy: 0.8795 - val_loss: 0.8710 - val_accuracy: 0.7240\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5360 - accuracy: 0.8630 - val_loss: 0.8536 - val_accuracy: 0.7274\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5271 - accuracy: 0.8724 - val_loss: 0.8512 - val_accuracy: 0.7410\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5172 - accuracy: 0.8775 - val_loss: 0.8666 - val_accuracy: 0.7319\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5134 - accuracy: 0.8783 - val_loss: 0.8664 - val_accuracy: 0.7251\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5178 - accuracy: 0.8761 - val_loss: 0.8699 - val_accuracy: 0.7285\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5180 - accuracy: 0.8746 - val_loss: 0.9671 - val_accuracy: 0.6799\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5207 - accuracy: 0.8721 - val_loss: 0.8665 - val_accuracy: 0.7285\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5055 - accuracy: 0.8848 - val_loss: 0.8636 - val_accuracy: 0.7319\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5035 - accuracy: 0.8840 - val_loss: 0.8726 - val_accuracy: 0.7195\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5109 - accuracy: 0.8812 - val_loss: 0.8680 - val_accuracy: 0.7308\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5092 - accuracy: 0.8797 - val_loss: 0.8951 - val_accuracy: 0.7240\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5089 - accuracy: 0.8755 - val_loss: 1.0137 - val_accuracy: 0.6686\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5202 - accuracy: 0.8662 - val_loss: 0.9074 - val_accuracy: 0.7059\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5064 - accuracy: 0.8797 - val_loss: 0.8698 - val_accuracy: 0.7217\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4896 - accuracy: 0.8928 - val_loss: 0.8987 - val_accuracy: 0.7251\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4846 - accuracy: 0.8882 - val_loss: 0.8816 - val_accuracy: 0.7330\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4824 - accuracy: 0.8894 - val_loss: 0.8852 - val_accuracy: 0.7217\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4862 - accuracy: 0.8939 - val_loss: 0.8913 - val_accuracy: 0.7172\n","Epoch 88/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4805 - accuracy: 0.8908 - val_loss: 0.8880 - val_accuracy: 0.7353\n","Epoch 89/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4821 - accuracy: 0.8933 - val_loss: 0.9001 - val_accuracy: 0.7229\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4783 - accuracy: 0.8925 - val_loss: 0.8942 - val_accuracy: 0.7229\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4744 - accuracy: 0.8925 - val_loss: 0.9072 - val_accuracy: 0.7127\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4817 - accuracy: 0.8899 - val_loss: 0.8928 - val_accuracy: 0.7251\n","Epoch 93/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4723 - accuracy: 0.8942 - val_loss: 0.9267 - val_accuracy: 0.7183\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4699 - accuracy: 0.8933 - val_loss: 0.9008 - val_accuracy: 0.7183\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4762 - accuracy: 0.8860 - val_loss: 0.9114 - val_accuracy: 0.7138\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4648 - accuracy: 0.8959 - val_loss: 0.9030 - val_accuracy: 0.7093\n","Epoch 97/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4707 - accuracy: 0.8945 - val_loss: 0.9123 - val_accuracy: 0.7319\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4626 - accuracy: 0.8953 - val_loss: 0.9210 - val_accuracy: 0.7183\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4730 - accuracy: 0.8899 - val_loss: 0.9034 - val_accuracy: 0.7195\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4635 - accuracy: 0.8959 - val_loss: 0.8991 - val_accuracy: 0.7274\n","{'loss': [0.7463252544403076, 0.7353308200836182, 0.722325325012207, 0.7200607061386108, 0.7174477577209473, 0.7095938324928284, 0.711521327495575, 0.7024604678153992, 0.7066850066184998, 0.6997460126876831, 0.7021175622940063, 0.7055976390838623, 0.6846566796302795, 0.6876701712608337, 0.6816067099571228, 0.6722581386566162, 0.6818559765815735, 0.6702601313591003, 0.663860559463501, 0.6708237528800964, 0.6678871512413025, 0.6653302311897278, 0.6570377349853516, 0.6613383889198303, 0.6625031232833862, 0.6513306498527527, 0.6407735347747803, 0.6413053274154663, 0.6466870903968811, 0.6378816366195679, 0.6280268430709839, 0.6337563395500183, 0.6353216767311096, 0.6330771446228027, 0.6161519885063171, 0.625680685043335, 0.6137727499008179, 0.6140089631080627, 0.6103938221931458, 0.6078444719314575, 0.6044780015945435, 0.6007808446884155, 0.602099597454071, 0.5888237357139587, 0.5855000615119934, 0.5914483070373535, 0.5945280194282532, 0.5861039161682129, 0.5823970437049866, 0.5834733843803406, 0.57664555311203, 0.5788329839706421, 0.5793155431747437, 0.5737473964691162, 0.5634053945541382, 0.563941478729248, 0.5620452761650085, 0.5558960437774658, 0.5510208010673523, 0.5549531579017639, 0.5560222268104553, 0.5444187521934509, 0.553764283657074, 0.5478224158287048, 0.5350119471549988, 0.5492295622825623, 0.5546690821647644, 0.5362843871116638, 0.5228292942047119, 0.5359805822372437, 0.5270994901657104, 0.5172119736671448, 0.5134337544441223, 0.5178187489509583, 0.5180044770240784, 0.5207043290138245, 0.5054751038551331, 0.503533124923706, 0.5109149813652039, 0.5092096924781799, 0.5088590979576111, 0.5201988816261292, 0.5063949227333069, 0.4895530641078949, 0.4846300482749939, 0.4824170768260956, 0.48624342679977417, 0.4805206060409546, 0.4821297228336334, 0.47832801938056946, 0.4743983745574951, 0.481699675321579, 0.4722595810890198, 0.46986138820648193, 0.47617384791374207, 0.4647749066352844, 0.4707295000553131, 0.46258020401000977, 0.47301873564720154, 0.4635334014892578], 'accuracy': [0.7733446359634399, 0.7826825380325317, 0.784380316734314, 0.7869269847869873, 0.7903226017951965, 0.801075279712677, 0.7971137762069702, 0.7954159379005432, 0.7942841053009033, 0.797396719455719, 0.7906055450439453, 0.79173743724823, 0.8146576285362244, 0.8036219477653503, 0.8109790682792664, 0.8172042965888977, 0.8050367832183838, 0.8146576285362244, 0.819750964641571, 0.8109790682792664, 0.8208828568458557, 0.8121109008789062, 0.8239954710006714, 0.8157894611358643, 0.810413122177124, 0.8268251419067383, 0.831918478012085, 0.8288058638572693, 0.8211658000946045, 0.8242784142494202, 0.8307866454124451, 0.8310695886611938, 0.8254103064537048, 0.8313525915145874, 0.8361629843711853, 0.8327674269676208, 0.8440860509872437, 0.8375778198242188, 0.8387096524238586, 0.8404074907302856, 0.8409733772277832, 0.8438030481338501, 0.8488964438438416, 0.848613440990448, 0.8525750041007996, 0.8497453331947327, 0.8460667729377747, 0.8474816083908081, 0.8514431118965149, 0.8511601686477661, 0.8514431118965149, 0.8511601686477661, 0.8494623899459839, 0.855970561504364, 0.8579513430595398, 0.8542727828025818, 0.8556876182556152, 0.8619128465652466, 0.8636106252670288, 0.86332768201828, 0.8590831756591797, 0.8698358535766602, 0.8593661785125732, 0.8627617359161377, 0.8720995783805847, 0.8582342863082886, 0.8537068367004395, 0.8704017996788025, 0.8794566988945007, 0.8630446791648865, 0.8723825812339783, 0.8774759769439697, 0.8783248662948608, 0.8760611414909363, 0.8746463060379028, 0.8720995783805847, 0.884833037853241, 0.8839841485023499, 0.881154477596283, 0.8797396421432495, 0.875495195388794, 0.8661573529243469, 0.8797396421432495, 0.8927561044692993, 0.8882286548614502, 0.8893604874610901, 0.8938879370689392, 0.8907753229141235, 0.8933219909667969, 0.8924731016159058, 0.8924731016159058, 0.8899264335632324, 0.8941709399223328, 0.8933219909667969, 0.8859649300575256, 0.895868718624115, 0.8944538831710815, 0.8953027725219727, 0.8899264335632324, 0.895868718624115], 'val_loss': [0.9496567845344543, 0.9466221332550049, 0.9429888129234314, 0.9401510953903198, 0.937540590763092, 0.9365994334220886, 0.9305591583251953, 0.9331386089324951, 0.9316490292549133, 0.9371801018714905, 0.9385468363761902, 0.9169411659240723, 0.916191816329956, 0.9284384250640869, 0.9424260854721069, 0.8976562023162842, 0.9501113295555115, 0.9191031455993652, 0.8841323256492615, 0.9088397026062012, 0.8742688894271851, 0.9359116554260254, 0.8691810965538025, 0.8990157246589661, 0.8460253477096558, 0.8339762091636658, 0.7972490787506104, 0.8035884499549866, 0.8550754189491272, 0.7987934350967407, 0.8033419251441956, 0.8332566022872925, 0.8133452534675598, 0.805993378162384, 0.8025180101394653, 0.8057137727737427, 0.8137800097465515, 0.8085389137268066, 0.8047321438789368, 0.8163946270942688, 0.8130504488945007, 0.8260363340377808, 0.8124385476112366, 0.8151938319206238, 0.8120331168174744, 0.8597988486289978, 0.8288743495941162, 0.8358396887779236, 0.8242192268371582, 0.8220738172531128, 0.8245582580566406, 0.8234135508537292, 0.8303501009941101, 0.8289584517478943, 0.8415091037750244, 0.8327780365943909, 0.8340221643447876, 0.8341031074523926, 0.8485849499702454, 0.839052140712738, 0.844639003276825, 0.8404209613800049, 0.8642690181732178, 0.8461155891418457, 0.8613133430480957, 0.8448678851127625, 0.8333073854446411, 0.853387176990509, 0.8709514737129211, 0.8536456823348999, 0.8511595726013184, 0.8666132092475891, 0.866369903087616, 0.869944155216217, 0.9671291708946228, 0.8664581775665283, 0.8635837435722351, 0.8725876212120056, 0.8679936528205872, 0.8951134085655212, 1.0136935710906982, 0.9073625206947327, 0.8697635531425476, 0.8987308144569397, 0.8816489577293396, 0.8851853013038635, 0.8912986516952515, 0.8879826664924622, 0.9001003503799438, 0.894248366355896, 0.9071934223175049, 0.8927803039550781, 0.9266566038131714, 0.9008457064628601, 0.9114248752593994, 0.9029862880706787, 0.9122571349143982, 0.9210386872291565, 0.9033984541893005, 0.8990623354911804], 'val_accuracy': [0.5203620195388794, 0.5848416090011597, 0.6606335043907166, 0.6595022678375244, 0.6357465982437134, 0.5837104320526123, 0.6187782883644104, 0.5780543088912964, 0.5723981857299805, 0.5565611124038696, 0.5475113391876221, 0.5961538553237915, 0.5961538553237915, 0.5757918357849121, 0.5678732991218567, 0.6233031749725342, 0.5769230723381042, 0.6063348650932312, 0.6459276080131531, 0.6312217116355896, 0.6617646813392639, 0.6255655884742737, 0.6708144545555115, 0.6606335043907166, 0.6934388875961304, 0.7104072570800781, 0.7364253401756287, 0.7398189902305603, 0.7047511339187622, 0.7386877536773682, 0.7386877536773682, 0.7149321436882019, 0.7319004535675049, 0.7352941036224365, 0.7432126402854919, 0.7398189902305603, 0.7352941036224365, 0.7466063499450684, 0.7454751133918762, 0.7398189902305603, 0.7454751133918762, 0.7296379804611206, 0.7443438768386841, 0.7386877536773682, 0.7443438768386841, 0.7171945571899414, 0.7296379804611206, 0.7273755669593811, 0.7443438768386841, 0.7409502267837524, 0.7409502267837524, 0.7341628670692444, 0.7273755669593811, 0.733031690120697, 0.726244330406189, 0.7477375268936157, 0.7432126402854919, 0.7432126402854919, 0.7239819169044495, 0.7296379804611206, 0.7488687634468079, 0.7352941036224365, 0.7251130938529968, 0.7319004535675049, 0.726244330406189, 0.7364253401756287, 0.7364253401756287, 0.7341628670692444, 0.7239819169044495, 0.7273755669593811, 0.7409502267837524, 0.7319004535675049, 0.7251130938529968, 0.7285068035125732, 0.679864227771759, 0.7285068035125732, 0.7319004535675049, 0.7194570302963257, 0.7307692170143127, 0.7239819169044495, 0.668552041053772, 0.7058823704719543, 0.7217194437980652, 0.7251130938529968, 0.733031690120697, 0.7217194437980652, 0.7171945571899414, 0.7352941036224365, 0.7228506803512573, 0.7228506803512573, 0.7126696705818176, 0.7251130938529968, 0.7183257937431335, 0.7183257937431335, 0.7138009071350098, 0.709276020526886, 0.7319004535675049, 0.7183257937431335, 0.7194570302963257, 0.7273755669593811]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 49ms/step - loss: 0.7493 - accuracy: 0.7703 - val_loss: 0.9500 - val_accuracy: 0.5114\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7335 - accuracy: 0.7889 - val_loss: 0.9454 - val_accuracy: 0.6767\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7235 - accuracy: 0.7858 - val_loss: 0.9412 - val_accuracy: 0.6870\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7294 - accuracy: 0.7819 - val_loss: 0.9366 - val_accuracy: 0.6921\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7217 - accuracy: 0.7884 - val_loss: 0.9334 - val_accuracy: 0.6302\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7127 - accuracy: 0.7977 - val_loss: 0.9349 - val_accuracy: 0.5692\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7182 - accuracy: 0.7866 - val_loss: 0.9314 - val_accuracy: 0.5775\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7041 - accuracy: 0.8003 - val_loss: 0.9244 - val_accuracy: 0.5899\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7051 - accuracy: 0.7969 - val_loss: 0.9328 - val_accuracy: 0.5640\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7092 - accuracy: 0.7907 - val_loss: 0.9364 - val_accuracy: 0.5558\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7089 - accuracy: 0.7951 - val_loss: 0.9191 - val_accuracy: 0.5909\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6987 - accuracy: 0.7977 - val_loss: 0.9402 - val_accuracy: 0.5599\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.8047 - val_loss: 0.9162 - val_accuracy: 0.5930\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.8062 - val_loss: 0.9225 - val_accuracy: 0.5919\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6827 - accuracy: 0.8039 - val_loss: 0.9074 - val_accuracy: 0.6002\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.8121 - val_loss: 0.9545 - val_accuracy: 0.5826\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6782 - accuracy: 0.8109 - val_loss: 0.9546 - val_accuracy: 0.5888\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6833 - accuracy: 0.8000 - val_loss: 0.8837 - val_accuracy: 0.6384\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6801 - accuracy: 0.8085 - val_loss: 0.9388 - val_accuracy: 0.6064\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6670 - accuracy: 0.8083 - val_loss: 0.8634 - val_accuracy: 0.6529\n","Epoch 21/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6823 - accuracy: 0.8021 - val_loss: 0.9286 - val_accuracy: 0.6374\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6713 - accuracy: 0.8072 - val_loss: 0.8440 - val_accuracy: 0.6818\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6658 - accuracy: 0.8150 - val_loss: 0.9219 - val_accuracy: 0.6395\n","Epoch 24/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6558 - accuracy: 0.8220 - val_loss: 0.8349 - val_accuracy: 0.7076\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6608 - accuracy: 0.8137 - val_loss: 0.9464 - val_accuracy: 0.6384\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6582 - accuracy: 0.8121 - val_loss: 0.8425 - val_accuracy: 0.7200\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6455 - accuracy: 0.8266 - val_loss: 0.8412 - val_accuracy: 0.7159\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6498 - accuracy: 0.8176 - val_loss: 0.8461 - val_accuracy: 0.7128\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6469 - accuracy: 0.8227 - val_loss: 0.8506 - val_accuracy: 0.7180\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6410 - accuracy: 0.8220 - val_loss: 0.8514 - val_accuracy: 0.7076\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6418 - accuracy: 0.8261 - val_loss: 0.8662 - val_accuracy: 0.6942\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6387 - accuracy: 0.8240 - val_loss: 0.8598 - val_accuracy: 0.7128\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6383 - accuracy: 0.8238 - val_loss: 0.8599 - val_accuracy: 0.7025\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6309 - accuracy: 0.8302 - val_loss: 0.8617 - val_accuracy: 0.7128\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6275 - accuracy: 0.8346 - val_loss: 0.8594 - val_accuracy: 0.7200\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6389 - accuracy: 0.8279 - val_loss: 0.8660 - val_accuracy: 0.7045\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6211 - accuracy: 0.8318 - val_loss: 0.8663 - val_accuracy: 0.7118\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6330 - accuracy: 0.8238 - val_loss: 0.8681 - val_accuracy: 0.7087\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6148 - accuracy: 0.8382 - val_loss: 0.8608 - val_accuracy: 0.7190\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6132 - accuracy: 0.8326 - val_loss: 0.8698 - val_accuracy: 0.7087\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6146 - accuracy: 0.8380 - val_loss: 0.8966 - val_accuracy: 0.7076\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6168 - accuracy: 0.8292 - val_loss: 0.8740 - val_accuracy: 0.6932\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6026 - accuracy: 0.8460 - val_loss: 0.8727 - val_accuracy: 0.7097\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6114 - accuracy: 0.8315 - val_loss: 0.8803 - val_accuracy: 0.7159\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5994 - accuracy: 0.8377 - val_loss: 0.8949 - val_accuracy: 0.7087\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5959 - accuracy: 0.8457 - val_loss: 0.9292 - val_accuracy: 0.6932\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6002 - accuracy: 0.8442 - val_loss: 0.8742 - val_accuracy: 0.7107\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5992 - accuracy: 0.8401 - val_loss: 0.8813 - val_accuracy: 0.7087\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5891 - accuracy: 0.8455 - val_loss: 0.8802 - val_accuracy: 0.7025\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5831 - accuracy: 0.8519 - val_loss: 0.8964 - val_accuracy: 0.6973\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5858 - accuracy: 0.8525 - val_loss: 0.8821 - val_accuracy: 0.7076\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5942 - accuracy: 0.8413 - val_loss: 0.8853 - val_accuracy: 0.7097\n","Epoch 53/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5828 - accuracy: 0.8442 - val_loss: 0.8878 - val_accuracy: 0.7097\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5776 - accuracy: 0.8530 - val_loss: 0.8798 - val_accuracy: 0.7087\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5765 - accuracy: 0.8574 - val_loss: 0.8916 - val_accuracy: 0.7118\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5651 - accuracy: 0.8581 - val_loss: 0.8857 - val_accuracy: 0.7045\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5729 - accuracy: 0.8442 - val_loss: 0.8907 - val_accuracy: 0.7107\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5722 - accuracy: 0.8540 - val_loss: 0.8938 - val_accuracy: 0.7180\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5647 - accuracy: 0.8576 - val_loss: 0.9038 - val_accuracy: 0.7076\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5675 - accuracy: 0.8545 - val_loss: 0.9059 - val_accuracy: 0.7004\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5605 - accuracy: 0.8584 - val_loss: 0.8884 - val_accuracy: 0.7014\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5457 - accuracy: 0.8654 - val_loss: 0.8978 - val_accuracy: 0.7045\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5609 - accuracy: 0.8540 - val_loss: 0.9107 - val_accuracy: 0.7056\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5566 - accuracy: 0.8579 - val_loss: 0.9161 - val_accuracy: 0.7128\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5501 - accuracy: 0.8649 - val_loss: 0.9013 - val_accuracy: 0.7035\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5553 - accuracy: 0.8594 - val_loss: 0.9086 - val_accuracy: 0.7056\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5613 - accuracy: 0.8550 - val_loss: 0.9050 - val_accuracy: 0.7128\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5359 - accuracy: 0.8734 - val_loss: 0.9310 - val_accuracy: 0.7087\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5372 - accuracy: 0.8641 - val_loss: 0.9176 - val_accuracy: 0.7035\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5479 - accuracy: 0.8615 - val_loss: 0.9428 - val_accuracy: 0.6808\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5525 - accuracy: 0.8597 - val_loss: 0.9082 - val_accuracy: 0.7118\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5430 - accuracy: 0.8571 - val_loss: 0.9803 - val_accuracy: 0.6880\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5442 - accuracy: 0.8620 - val_loss: 0.9093 - val_accuracy: 0.6921\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5384 - accuracy: 0.8649 - val_loss: 0.9273 - val_accuracy: 0.7014\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5505 - accuracy: 0.8514 - val_loss: 0.9217 - val_accuracy: 0.6921\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5191 - accuracy: 0.8749 - val_loss: 0.9154 - val_accuracy: 0.7035\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5156 - accuracy: 0.8716 - val_loss: 0.9288 - val_accuracy: 0.6870\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5188 - accuracy: 0.8752 - val_loss: 0.9366 - val_accuracy: 0.6963\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5337 - accuracy: 0.8651 - val_loss: 0.9258 - val_accuracy: 0.7014\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5306 - accuracy: 0.8625 - val_loss: 0.9632 - val_accuracy: 0.6839\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5212 - accuracy: 0.8716 - val_loss: 0.9220 - val_accuracy: 0.6983\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5106 - accuracy: 0.8729 - val_loss: 0.9456 - val_accuracy: 0.6932\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5156 - accuracy: 0.8736 - val_loss: 0.9361 - val_accuracy: 0.6973\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5078 - accuracy: 0.8801 - val_loss: 0.9785 - val_accuracy: 0.6942\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5121 - accuracy: 0.8734 - val_loss: 0.9419 - val_accuracy: 0.6983\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5041 - accuracy: 0.8793 - val_loss: 0.9323 - val_accuracy: 0.6983\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5110 - accuracy: 0.8744 - val_loss: 0.9508 - val_accuracy: 0.7035\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4986 - accuracy: 0.8848 - val_loss: 0.9360 - val_accuracy: 0.6932\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4937 - accuracy: 0.8824 - val_loss: 0.9783 - val_accuracy: 0.6901\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4988 - accuracy: 0.8829 - val_loss: 0.9664 - val_accuracy: 0.6849\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4911 - accuracy: 0.8855 - val_loss: 0.9681 - val_accuracy: 0.6880\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4969 - accuracy: 0.8809 - val_loss: 0.9506 - val_accuracy: 0.6880\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4818 - accuracy: 0.8884 - val_loss: 0.9512 - val_accuracy: 0.6983\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4794 - accuracy: 0.8920 - val_loss: 0.9587 - val_accuracy: 0.6973\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4817 - accuracy: 0.8858 - val_loss: 1.0285 - val_accuracy: 0.6932\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4966 - accuracy: 0.8744 - val_loss: 0.9808 - val_accuracy: 0.6880\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4892 - accuracy: 0.8842 - val_loss: 0.9659 - val_accuracy: 0.6952\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4804 - accuracy: 0.8879 - val_loss: 0.9760 - val_accuracy: 0.6839\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4829 - accuracy: 0.8848 - val_loss: 0.9708 - val_accuracy: 0.6890\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4791 - accuracy: 0.8855 - val_loss: 0.9743 - val_accuracy: 0.6994\n","{'loss': [0.749274730682373, 0.7335221767425537, 0.7235153317451477, 0.7294221520423889, 0.7217069864273071, 0.7127352952957153, 0.7181677222251892, 0.7040777206420898, 0.7051011323928833, 0.7092384099960327, 0.7088785767555237, 0.6986678242683411, 0.6892353296279907, 0.684536874294281, 0.6826918125152588, 0.6819133162498474, 0.6781812906265259, 0.6832590699195862, 0.6800928711891174, 0.6670397520065308, 0.6823347806930542, 0.6713362336158752, 0.665846049785614, 0.6558245420455933, 0.6608253717422485, 0.6582474708557129, 0.6455492973327637, 0.6498066782951355, 0.646927535533905, 0.6409504413604736, 0.6418266892433167, 0.6386845111846924, 0.6383300423622131, 0.6308903694152832, 0.62748783826828, 0.6388976573944092, 0.6210897564888, 0.632964551448822, 0.6147655844688416, 0.613230288028717, 0.6146196126937866, 0.6167709827423096, 0.6025968194007874, 0.6113799214363098, 0.5993573665618896, 0.595924973487854, 0.6002128720283508, 0.599240779876709, 0.5890953540802002, 0.5831224322319031, 0.5857948064804077, 0.5942034125328064, 0.5827574729919434, 0.577552855014801, 0.5765454769134521, 0.5650807023048401, 0.5728954076766968, 0.5721503496170044, 0.5646959543228149, 0.5674504041671753, 0.5604742765426636, 0.545728325843811, 0.560907781124115, 0.5565539002418518, 0.5501124858856201, 0.5553343892097473, 0.5613406896591187, 0.5358878970146179, 0.5372152924537659, 0.5478641390800476, 0.5525459051132202, 0.543035626411438, 0.5441519021987915, 0.5384077429771423, 0.5505374670028687, 0.5191012024879456, 0.5155807733535767, 0.5187509059906006, 0.5337338447570801, 0.5305858850479126, 0.521243691444397, 0.5106224417686462, 0.5155654549598694, 0.5078141689300537, 0.5121153593063354, 0.5041083097457886, 0.5109935402870178, 0.49862220883369446, 0.49365684390068054, 0.49876368045806885, 0.4911121428012848, 0.49689239263534546, 0.48175421357154846, 0.4793746769428253, 0.48171600699424744, 0.4965507686138153, 0.48916271328926086, 0.4803996980190277, 0.48289570212364197, 0.4791117310523987], 'accuracy': [0.7702842354774475, 0.7888888716697693, 0.7857881188392639, 0.7819121479988098, 0.7883720993995667, 0.7976744174957275, 0.7865633368492126, 0.8002583980560303, 0.7968991994857788, 0.7906976938247681, 0.7950904369354248, 0.7976744174957275, 0.804651141166687, 0.8062015771865845, 0.8038759827613831, 0.8121446967124939, 0.8108527064323425, 0.800000011920929, 0.8085271120071411, 0.8082687258720398, 0.8020671606063843, 0.8072351217269897, 0.814987063407898, 0.8219638466835022, 0.8136950731277466, 0.8121446967124939, 0.8266149759292603, 0.8175710439682007, 0.8227390050888062, 0.8219638466835022, 0.8260982036590576, 0.8240309953689575, 0.8237726092338562, 0.830232560634613, 0.8346253037452698, 0.8279069662094116, 0.8317829370498657, 0.8237726092338562, 0.8382428884506226, 0.8325581550598145, 0.8379845023155212, 0.829198956489563, 0.8459948301315308, 0.8315245509147644, 0.8377261161804199, 0.8457364439964294, 0.8441860675811768, 0.8400516510009766, 0.8454780578613281, 0.851938009262085, 0.8524547815322876, 0.8413436412811279, 0.8441860675811768, 0.8529715538024902, 0.8573643565177917, 0.8581395149230957, 0.8441860675811768, 0.8540051579475403, 0.8576227426528931, 0.8545219898223877, 0.8583979606628418, 0.8653746843338013, 0.8540051579475403, 0.8578811287879944, 0.8648578524589539, 0.8594315052032471, 0.8550387620925903, 0.8733850121498108, 0.8640826940536499, 0.8614987134933472, 0.8596899509429932, 0.8571059703826904, 0.8620154857635498, 0.8648578524589539, 0.8514211773872375, 0.8749353885650635, 0.8715762495994568, 0.8751937747001648, 0.8651162981987, 0.8625323176383972, 0.8715762495994568, 0.8728682398796082, 0.8736433982849121, 0.880103349685669, 0.8733850121498108, 0.879328191280365, 0.8744186162948608, 0.8847545385360718, 0.8824289441108704, 0.882945716381073, 0.8855296969413757, 0.8808785676956177, 0.8883720636367798, 0.8919896483421326, 0.8857881426811218, 0.8744186162948608, 0.8842377066612244, 0.8878552913665771, 0.8847545385360718, 0.8855296969413757], 'val_loss': [0.950026273727417, 0.9453818202018738, 0.9412285685539246, 0.9365720152854919, 0.933381199836731, 0.93490070104599, 0.931424081325531, 0.9243839383125305, 0.932826817035675, 0.9364177584648132, 0.9190580248832703, 0.940171480178833, 0.9161928296089172, 0.922454833984375, 0.9073754549026489, 0.9544569849967957, 0.9546312689781189, 0.8837271928787231, 0.9387664198875427, 0.8634351491928101, 0.9286032319068909, 0.8439627289772034, 0.9219006896018982, 0.8349048495292664, 0.9464086294174194, 0.8424912095069885, 0.8412494659423828, 0.8461316227912903, 0.8506010174751282, 0.8514370322227478, 0.8661746978759766, 0.8598280549049377, 0.8599032759666443, 0.8617413640022278, 0.8594481348991394, 0.8659981489181519, 0.8662658333778381, 0.8680978417396545, 0.8608429431915283, 0.8698357343673706, 0.8966215252876282, 0.8740165829658508, 0.8726771473884583, 0.8802979588508606, 0.8949413299560547, 0.9291948676109314, 0.8742484450340271, 0.8812845349311829, 0.8802417516708374, 0.8964263200759888, 0.8821365237236023, 0.8852580189704895, 0.8877562284469604, 0.8797891139984131, 0.891576886177063, 0.8857257962226868, 0.8907244801521301, 0.893770158290863, 0.903774619102478, 0.9059005379676819, 0.888433575630188, 0.8978025913238525, 0.9107416868209839, 0.916130542755127, 0.9012748599052429, 0.9085968732833862, 0.9049965143203735, 0.9310012459754944, 0.917600154876709, 0.9428049325942993, 0.9081550240516663, 0.9802788496017456, 0.9093301296234131, 0.9272757172584534, 0.9217496514320374, 0.9154015183448792, 0.928830087184906, 0.9366276264190674, 0.9258273243904114, 0.963208794593811, 0.9219802618026733, 0.9456171989440918, 0.936073899269104, 0.9784898161888123, 0.9418939352035522, 0.9322854280471802, 0.9507682919502258, 0.9360179901123047, 0.9782792329788208, 0.9664419889450073, 0.9680988788604736, 0.9506410956382751, 0.9512221217155457, 0.9586689472198486, 1.0284793376922607, 0.9807726740837097, 0.9658563733100891, 0.9760302305221558, 0.9707680940628052, 0.9743377566337585], 'val_accuracy': [0.5113636255264282, 0.6766529083251953, 0.6869834661483765, 0.692148745059967, 0.6301652789115906, 0.5692148804664612, 0.577479362487793, 0.5898760557174683, 0.5640496015548706, 0.5557851195335388, 0.5909090638160706, 0.5599173307418823, 0.5929751992225647, 0.5919421315193176, 0.6002066135406494, 0.5826446413993835, 0.5888429880142212, 0.6384297609329224, 0.6064049601554871, 0.6528925895690918, 0.6373966932296753, 0.6818181872367859, 0.6394628286361694, 0.7076446413993835, 0.6384297609329224, 0.7200413346290588, 0.7159090638160706, 0.7128099203109741, 0.7179751992225647, 0.7076446413993835, 0.6942148804664612, 0.7128099203109741, 0.702479362487793, 0.7128099203109741, 0.7200413346290588, 0.7045454382896423, 0.711776852607727, 0.7086777091026306, 0.7190082669258118, 0.7086777091026306, 0.7076446413993835, 0.6931818127632141, 0.7097107172012329, 0.7159090638160706, 0.7086777091026306, 0.6931818127632141, 0.71074378490448, 0.7086777091026306, 0.702479362487793, 0.6973140239715576, 0.7076446413993835, 0.7097107172012329, 0.7097107172012329, 0.7086777091026306, 0.711776852607727, 0.7045454382896423, 0.71074378490448, 0.7179751992225647, 0.7076446413993835, 0.7004132270812988, 0.7014462947845459, 0.7045454382896423, 0.7055785059928894, 0.7128099203109741, 0.7035123705863953, 0.7055785059928894, 0.7128099203109741, 0.7086777091026306, 0.7035123705863953, 0.6807851195335388, 0.711776852607727, 0.6880165338516235, 0.692148745059967, 0.7014462947845459, 0.692148745059967, 0.7035123705863953, 0.6869834661483765, 0.6962810158729553, 0.7014462947845459, 0.68388432264328, 0.6983470916748047, 0.6931818127632141, 0.6973140239715576, 0.6942148804664612, 0.6983470916748047, 0.6983470916748047, 0.7035123705863953, 0.6931818127632141, 0.6900826692581177, 0.6849173307418823, 0.6880165338516235, 0.6880165338516235, 0.6983470916748047, 0.6973140239715576, 0.6931818127632141, 0.6880165338516235, 0.6952479481697083, 0.68388432264328, 0.6890496015548706, 0.6993801593780518]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.5692 - accuracy: 0.8400"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 51ms/step - loss: 0.5673 - accuracy: 0.8424 - val_loss: 0.8979 - val_accuracy: 0.4881\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5416 - accuracy: 0.8526 - val_loss: 0.8933 - val_accuracy: 0.4946\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5411 - accuracy: 0.8570 - val_loss: 0.8862 - val_accuracy: 0.5323\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5239 - accuracy: 0.8685 - val_loss: 0.8795 - val_accuracy: 0.5679\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5296 - accuracy: 0.8602 - val_loss: 0.8735 - val_accuracy: 0.6336\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5382 - accuracy: 0.8505 - val_loss: 0.8679 - val_accuracy: 0.6433\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5140 - accuracy: 0.8704 - val_loss: 0.8648 - val_accuracy: 0.6390\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5080 - accuracy: 0.8720 - val_loss: 0.8619 - val_accuracy: 0.6304\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5061 - accuracy: 0.8702 - val_loss: 0.8557 - val_accuracy: 0.6412\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5162 - accuracy: 0.8648 - val_loss: 0.8570 - val_accuracy: 0.6304\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5080 - accuracy: 0.8691 - val_loss: 0.8702 - val_accuracy: 0.6013\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5031 - accuracy: 0.8750 - val_loss: 0.8835 - val_accuracy: 0.5884\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5003 - accuracy: 0.8739 - val_loss: 0.8860 - val_accuracy: 0.5959\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4990 - accuracy: 0.8772 - val_loss: 0.9147 - val_accuracy: 0.5744\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4955 - accuracy: 0.8809 - val_loss: 0.9153 - val_accuracy: 0.5862\n","Epoch 16/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4910 - accuracy: 0.8807 - val_loss: 0.8834 - val_accuracy: 0.6228\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4848 - accuracy: 0.8852 - val_loss: 0.9588 - val_accuracy: 0.5851\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4949 - accuracy: 0.8739 - val_loss: 0.9821 - val_accuracy: 0.5916\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4781 - accuracy: 0.8863 - val_loss: 0.9329 - val_accuracy: 0.6282\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4807 - accuracy: 0.8836 - val_loss: 1.0273 - val_accuracy: 0.6002\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4801 - accuracy: 0.8825 - val_loss: 0.9363 - val_accuracy: 0.6412\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4758 - accuracy: 0.8825 - val_loss: 0.8668 - val_accuracy: 0.6886\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4722 - accuracy: 0.8820 - val_loss: 0.8715 - val_accuracy: 0.6821\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4680 - accuracy: 0.8928 - val_loss: 0.7862 - val_accuracy: 0.7241\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4598 - accuracy: 0.8925 - val_loss: 0.8468 - val_accuracy: 0.7177\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4842 - accuracy: 0.8769 - val_loss: 0.7683 - val_accuracy: 0.7349\n","Epoch 27/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4747 - accuracy: 0.8895 - val_loss: 0.7708 - val_accuracy: 0.7392\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4601 - accuracy: 0.8893 - val_loss: 0.7615 - val_accuracy: 0.7457\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4486 - accuracy: 0.8987 - val_loss: 0.7727 - val_accuracy: 0.7522\n","Epoch 30/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4498 - accuracy: 0.8957 - val_loss: 0.7589 - val_accuracy: 0.7608\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4529 - accuracy: 0.8936 - val_loss: 0.7773 - val_accuracy: 0.7522\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4496 - accuracy: 0.8979 - val_loss: 0.7659 - val_accuracy: 0.7608\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4577 - accuracy: 0.8952 - val_loss: 0.7720 - val_accuracy: 0.7522\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 0.8990 - val_loss: 0.7796 - val_accuracy: 0.7554\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.8974 - val_loss: 0.8020 - val_accuracy: 0.7392\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4425 - accuracy: 0.9054 - val_loss: 0.7756 - val_accuracy: 0.7586\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4547 - accuracy: 0.8920 - val_loss: 0.7683 - val_accuracy: 0.7705\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4462 - accuracy: 0.8976 - val_loss: 0.7926 - val_accuracy: 0.7500\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4348 - accuracy: 0.9057 - val_loss: 0.7806 - val_accuracy: 0.7575\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4380 - accuracy: 0.9025 - val_loss: 0.8206 - val_accuracy: 0.7338\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4376 - accuracy: 0.9033 - val_loss: 0.7776 - val_accuracy: 0.7619\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4286 - accuracy: 0.9073 - val_loss: 0.7862 - val_accuracy: 0.7608\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4340 - accuracy: 0.9057 - val_loss: 0.8024 - val_accuracy: 0.7468\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4366 - accuracy: 0.8963 - val_loss: 0.7799 - val_accuracy: 0.7672\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4399 - accuracy: 0.8968 - val_loss: 0.7858 - val_accuracy: 0.7629\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4421 - accuracy: 0.8966 - val_loss: 0.7950 - val_accuracy: 0.7381\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4307 - accuracy: 0.9076 - val_loss: 0.7829 - val_accuracy: 0.7640\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4264 - accuracy: 0.9060 - val_loss: 0.8060 - val_accuracy: 0.7489\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4177 - accuracy: 0.9114 - val_loss: 0.7908 - val_accuracy: 0.7608\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4259 - accuracy: 0.9044 - val_loss: 0.8008 - val_accuracy: 0.7651\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4244 - accuracy: 0.9073 - val_loss: 0.8887 - val_accuracy: 0.7220\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4091 - accuracy: 0.9162 - val_loss: 0.8015 - val_accuracy: 0.7532\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4151 - accuracy: 0.9095 - val_loss: 0.8031 - val_accuracy: 0.7597\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4131 - accuracy: 0.9133 - val_loss: 0.8082 - val_accuracy: 0.7511\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4047 - accuracy: 0.9165 - val_loss: 0.9013 - val_accuracy: 0.7220\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4057 - accuracy: 0.9173 - val_loss: 0.8329 - val_accuracy: 0.7435\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4162 - accuracy: 0.9087 - val_loss: 0.8468 - val_accuracy: 0.7425\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4093 - accuracy: 0.9079 - val_loss: 0.8789 - val_accuracy: 0.7231\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3996 - accuracy: 0.9162 - val_loss: 0.8022 - val_accuracy: 0.7683\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.9211 - val_loss: 0.8224 - val_accuracy: 0.7349\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3910 - accuracy: 0.9208 - val_loss: 0.8201 - val_accuracy: 0.7532\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3947 - accuracy: 0.9192 - val_loss: 0.8308 - val_accuracy: 0.7532\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3947 - accuracy: 0.9189 - val_loss: 0.8197 - val_accuracy: 0.7662\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3935 - accuracy: 0.9232 - val_loss: 0.9045 - val_accuracy: 0.7177\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4001 - accuracy: 0.9184 - val_loss: 0.8235 - val_accuracy: 0.7640\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3906 - accuracy: 0.9219 - val_loss: 0.8395 - val_accuracy: 0.7446\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4008 - accuracy: 0.9195 - val_loss: 0.9019 - val_accuracy: 0.7328\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3984 - accuracy: 0.9162 - val_loss: 0.8306 - val_accuracy: 0.7360\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3806 - accuracy: 0.9240 - val_loss: 0.8482 - val_accuracy: 0.7457\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3815 - accuracy: 0.9254 - val_loss: 0.8398 - val_accuracy: 0.7478\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3761 - accuracy: 0.9283 - val_loss: 0.8803 - val_accuracy: 0.7403\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.9230 - val_loss: 0.8388 - val_accuracy: 0.7619\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3802 - accuracy: 0.9248 - val_loss: 0.8483 - val_accuracy: 0.7478\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3838 - accuracy: 0.9235 - val_loss: 0.8516 - val_accuracy: 0.7511\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 0.9335 - val_loss: 0.8507 - val_accuracy: 0.7425\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3727 - accuracy: 0.9294 - val_loss: 0.8710 - val_accuracy: 0.7328\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3741 - accuracy: 0.9270 - val_loss: 0.8824 - val_accuracy: 0.7425\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3811 - accuracy: 0.9221 - val_loss: 0.8658 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3738 - accuracy: 0.9275 - val_loss: 0.8728 - val_accuracy: 0.7284\n","Epoch 80/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3783 - accuracy: 0.9256 - val_loss: 0.8540 - val_accuracy: 0.7414\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3693 - accuracy: 0.9294 - val_loss: 0.8622 - val_accuracy: 0.7414\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3655 - accuracy: 0.9318 - val_loss: 0.8939 - val_accuracy: 0.7360\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3695 - accuracy: 0.9265 - val_loss: 0.9070 - val_accuracy: 0.7241\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3904 - accuracy: 0.9205 - val_loss: 0.8778 - val_accuracy: 0.7435\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3700 - accuracy: 0.9310 - val_loss: 0.8601 - val_accuracy: 0.7511\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3801 - accuracy: 0.9230 - val_loss: 0.9346 - val_accuracy: 0.7144\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3555 - accuracy: 0.9348 - val_loss: 0.9006 - val_accuracy: 0.7306\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3544 - accuracy: 0.9327 - val_loss: 0.9637 - val_accuracy: 0.7284\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3648 - accuracy: 0.9329 - val_loss: 0.8795 - val_accuracy: 0.7446\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3579 - accuracy: 0.9289 - val_loss: 0.9062 - val_accuracy: 0.7284\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3517 - accuracy: 0.9391 - val_loss: 0.8808 - val_accuracy: 0.7478\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3466 - accuracy: 0.9410 - val_loss: 0.8882 - val_accuracy: 0.7328\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3480 - accuracy: 0.9378 - val_loss: 0.9351 - val_accuracy: 0.7295\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3670 - accuracy: 0.9278 - val_loss: 0.9121 - val_accuracy: 0.7435\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3516 - accuracy: 0.9356 - val_loss: 0.9092 - val_accuracy: 0.7414\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3470 - accuracy: 0.9353 - val_loss: 0.9049 - val_accuracy: 0.7403\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3460 - accuracy: 0.9348 - val_loss: 0.9207 - val_accuracy: 0.7349\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3366 - accuracy: 0.9442 - val_loss: 0.9207 - val_accuracy: 0.7425\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.9364 - val_loss: 0.9197 - val_accuracy: 0.7360\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3420 - accuracy: 0.9399 - val_loss: 0.9481 - val_accuracy: 0.7414\n","{'loss': [0.567308783531189, 0.5416041612625122, 0.541143536567688, 0.5238862633705139, 0.5296115279197693, 0.5381670594215393, 0.5139978528022766, 0.5080209970474243, 0.5060970187187195, 0.5162240862846375, 0.5079952478408813, 0.5031381249427795, 0.5003367066383362, 0.4989964962005615, 0.49549999833106995, 0.4910076856613159, 0.48479390144348145, 0.49493569135665894, 0.47810032963752747, 0.48069900274276733, 0.480084091424942, 0.4757748246192932, 0.4722275137901306, 0.4679892361164093, 0.4598322808742523, 0.48418691754341125, 0.47468334436416626, 0.4600803852081299, 0.44858428835868835, 0.4497639238834381, 0.4528772532939911, 0.4496147632598877, 0.45770975947380066, 0.44492781162261963, 0.44381898641586304, 0.4424647390842438, 0.45468756556510925, 0.44618648290634155, 0.43480929732322693, 0.4379776120185852, 0.43763723969459534, 0.4286400079727173, 0.4339946210384369, 0.43661239743232727, 0.43987029790878296, 0.44205692410469055, 0.43065211176872253, 0.4264371395111084, 0.4177008867263794, 0.42591679096221924, 0.4243522882461548, 0.40906426310539246, 0.41505715250968933, 0.41310110688209534, 0.4046698212623596, 0.40565988421440125, 0.4162268340587616, 0.409330278635025, 0.3995956778526306, 0.39273038506507874, 0.3910161256790161, 0.3946560025215149, 0.3946780562400818, 0.3935381770133972, 0.4000777006149292, 0.3906497359275818, 0.40075570344924927, 0.39838382601737976, 0.38062742352485657, 0.38149556517601013, 0.3761071264743805, 0.3769915699958801, 0.380158931016922, 0.3837677538394928, 0.3691408336162567, 0.3727256655693054, 0.37409406900405884, 0.38109150528907776, 0.3737812638282776, 0.3782742917537689, 0.369269996881485, 0.36546212434768677, 0.36949998140335083, 0.39042940735816956, 0.37003812193870544, 0.3801201581954956, 0.35553738474845886, 0.3543897271156311, 0.36477839946746826, 0.35785728693008423, 0.35173046588897705, 0.34663304686546326, 0.3480221629142761, 0.3670097589492798, 0.35161155462265015, 0.3470021188259125, 0.3459772765636444, 0.33659300208091736, 0.34541890025138855, 0.3419777750968933], 'accuracy': [0.842402994632721, 0.8526400923728943, 0.8569504022598267, 0.868534505367279, 0.8601831793785095, 0.8504849076271057, 0.8704202771186829, 0.8720366358757019, 0.8701508641242981, 0.8647629022598267, 0.8690732717514038, 0.875, 0.8739224076271057, 0.8771551847457886, 0.8809267282485962, 0.8806573152542114, 0.8852370977401733, 0.8739224076271057, 0.8863146305084229, 0.8836206793785095, 0.8825430870056152, 0.8825430870056152, 0.8820043206214905, 0.8927801847457886, 0.8925107717514038, 0.8768857717514038, 0.8895474076271057, 0.889277994632721, 0.8987069129943848, 0.8957435488700867, 0.8935883641242981, 0.8978987336158752, 0.8952047228813171, 0.8989762663841248, 0.8973599076271057, 0.9054418206214905, 0.891972005367279, 0.8976293206214905, 0.9057112336158752, 0.9024784564971924, 0.9032866358757019, 0.9073275923728943, 0.9057112336158752, 0.8962823152542114, 0.896821141242981, 0.8965517282485962, 0.907597005367279, 0.9059805870056152, 0.9113685488700867, 0.9043642282485962, 0.9073275923728943, 0.9162176847457886, 0.9094827771186829, 0.9132543206214905, 0.9164870977401733, 0.9172952771186829, 0.9086745977401733, 0.907866358757019, 0.9162176847457886, 0.9210668206214905, 0.9207974076271057, 0.9191810488700867, 0.9189116358757019, 0.923222005367279, 0.9183728694915771, 0.921875, 0.9194504022598267, 0.9162176847457886, 0.9240301847457886, 0.9253771305084229, 0.928340494632721, 0.9229525923728943, 0.9248383641242981, 0.923491358757019, 0.9334590435028076, 0.9294180870056152, 0.9269935488700867, 0.9221444129943848, 0.9275323152542114, 0.9256465435028076, 0.9294180870056152, 0.9318426847457886, 0.9264547228813171, 0.920527994632721, 0.931034505367279, 0.9229525923728943, 0.9348060488700867, 0.9326508641242981, 0.9329202771186829, 0.9288793206214905, 0.939116358757019, 0.9410021305084229, 0.9377694129943848, 0.9278017282485962, 0.9356142282485962, 0.9353448152542114, 0.9348060488700867, 0.9442349076271057, 0.9364224076271057, 0.9399245977401733], 'val_loss': [0.897943913936615, 0.8933311104774475, 0.8861668705940247, 0.8795093894004822, 0.8735393285751343, 0.8678504824638367, 0.8648406863212585, 0.8619396090507507, 0.8557136654853821, 0.8570051789283752, 0.870237410068512, 0.883490800857544, 0.8860170245170593, 0.9146762490272522, 0.9153103828430176, 0.8834055662155151, 0.9588186740875244, 0.9820603728294373, 0.932859480381012, 1.0273362398147583, 0.9362525343894958, 0.8667678833007812, 0.8714513182640076, 0.7862458825111389, 0.8467990159988403, 0.7683339715003967, 0.7707995772361755, 0.7614725232124329, 0.7726501226425171, 0.7589017748832703, 0.7773057222366333, 0.7659496665000916, 0.7719713449478149, 0.7796419262886047, 0.8020047545433044, 0.7756182551383972, 0.7682874798774719, 0.7926105260848999, 0.7806358933448792, 0.8206020593643188, 0.7776447534561157, 0.7861686944961548, 0.8024418950080872, 0.7798548340797424, 0.7857614159584045, 0.7949553728103638, 0.7829000353813171, 0.8060430288314819, 0.790809690952301, 0.8007686138153076, 0.8887486457824707, 0.8014891147613525, 0.8030624389648438, 0.8082404136657715, 0.9012669920921326, 0.8329482078552246, 0.8468175530433655, 0.8789163827896118, 0.8021768927574158, 0.8224194645881653, 0.8201099038124084, 0.8307563662528992, 0.819709300994873, 0.9044972062110901, 0.8235312700271606, 0.8394604325294495, 0.9019133448600769, 0.8306134343147278, 0.8481686115264893, 0.8398094177246094, 0.880306601524353, 0.8388253450393677, 0.8482963442802429, 0.8515934348106384, 0.8507419228553772, 0.871041476726532, 0.882408618927002, 0.8657747507095337, 0.872792661190033, 0.8539620637893677, 0.8621955513954163, 0.8939223885536194, 0.9069775938987732, 0.8777506351470947, 0.8601276278495789, 0.9346379041671753, 0.9006279706954956, 0.963677704334259, 0.8795167207717896, 0.9062240123748779, 0.8807650208473206, 0.8881875276565552, 0.9350603222846985, 0.9121062755584717, 0.9092005491256714, 0.9048842191696167, 0.9206650853157043, 0.9207098484039307, 0.9197458028793335, 0.9480863809585571], 'val_accuracy': [0.4881465435028076, 0.49461206793785095, 0.5323275923728943, 0.5678879022598267, 0.6336206793785095, 0.6433189511299133, 0.639008641242981, 0.6303879022598267, 0.6411637663841248, 0.6303879022598267, 0.6012930870056152, 0.5883620977401733, 0.5959051847457886, 0.5743534564971924, 0.5862069129943848, 0.6228448152542114, 0.5851293206214905, 0.5915948152542114, 0.6282327771186829, 0.600215494632721, 0.6411637663841248, 0.6885775923728943, 0.6821120977401733, 0.7241379022598267, 0.7176724076271057, 0.7349137663841248, 0.7392241358757019, 0.7456896305084229, 0.7521551847457886, 0.7607758641242981, 0.7521551847457886, 0.7607758641242981, 0.7521551847457886, 0.7553879022598267, 0.7392241358757019, 0.7586206793785095, 0.7704741358757019, 0.75, 0.7575430870056152, 0.7338362336158752, 0.7618534564971924, 0.7607758641242981, 0.7467672228813171, 0.767241358757019, 0.7629310488700867, 0.7381465435028076, 0.764008641242981, 0.7489224076271057, 0.7607758641242981, 0.7650862336158752, 0.7219827771186829, 0.7532327771186829, 0.7596982717514038, 0.7510775923728943, 0.7219827771186829, 0.743534505367279, 0.7424569129943848, 0.7230603694915771, 0.7683189511299133, 0.7349137663841248, 0.7532327771186829, 0.7532327771186829, 0.7661637663841248, 0.7176724076271057, 0.764008641242981, 0.7446120977401733, 0.732758641242981, 0.735991358757019, 0.7456896305084229, 0.7478448152542114, 0.7403017282485962, 0.7618534564971924, 0.7478448152542114, 0.7510775923728943, 0.7424569129943848, 0.732758641242981, 0.7424569129943848, 0.743534505367279, 0.7284482717514038, 0.7413793206214905, 0.7413793206214905, 0.735991358757019, 0.7241379022598267, 0.743534505367279, 0.7510775923728943, 0.7144396305084229, 0.7306034564971924, 0.7284482717514038, 0.7446120977401733, 0.7284482717514038, 0.7478448152542114, 0.732758641242981, 0.7295258641242981, 0.743534505367279, 0.7413793206214905, 0.7403017282485962, 0.7349137663841248, 0.7424569129943848, 0.735991358757019, 0.7413793206214905]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.5718 - accuracy: 0.8375"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 10s 57ms/step - loss: 0.5728 - accuracy: 0.8345 - val_loss: 0.8982 - val_accuracy: 0.4966\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5435 - accuracy: 0.8512 - val_loss: 0.8926 - val_accuracy: 0.5034\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5358 - accuracy: 0.8577 - val_loss: 0.8867 - val_accuracy: 0.5158\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5230 - accuracy: 0.8647 - val_loss: 0.8808 - val_accuracy: 0.5973\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5193 - accuracy: 0.8659 - val_loss: 0.8743 - val_accuracy: 0.6335\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5186 - accuracy: 0.8667 - val_loss: 0.8701 - val_accuracy: 0.6391\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5027 - accuracy: 0.8772 - val_loss: 0.8669 - val_accuracy: 0.6357\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5090 - accuracy: 0.8735 - val_loss: 0.8628 - val_accuracy: 0.6278\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4961 - accuracy: 0.8755 - val_loss: 0.8650 - val_accuracy: 0.6041\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5043 - accuracy: 0.8707 - val_loss: 0.8548 - val_accuracy: 0.6324\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5309 - accuracy: 0.8565 - val_loss: 0.8478 - val_accuracy: 0.6403\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5368 - accuracy: 0.8514 - val_loss: 0.8691 - val_accuracy: 0.5973\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5019 - accuracy: 0.8676 - val_loss: 0.8769 - val_accuracy: 0.5950\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4915 - accuracy: 0.8772 - val_loss: 0.8827 - val_accuracy: 0.5939\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4854 - accuracy: 0.8820 - val_loss: 0.8838 - val_accuracy: 0.6075\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4924 - accuracy: 0.8797 - val_loss: 0.8830 - val_accuracy: 0.6131\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4776 - accuracy: 0.8885 - val_loss: 0.8816 - val_accuracy: 0.6256\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4766 - accuracy: 0.8829 - val_loss: 0.9782 - val_accuracy: 0.5950\n","Epoch 19/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4886 - accuracy: 0.8786 - val_loss: 0.8804 - val_accuracy: 0.6538\n","Epoch 20/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4721 - accuracy: 0.8860 - val_loss: 0.9025 - val_accuracy: 0.6471\n","Epoch 21/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4691 - accuracy: 0.8840 - val_loss: 0.9080 - val_accuracy: 0.6618\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4730 - accuracy: 0.8899 - val_loss: 0.9163 - val_accuracy: 0.6686\n","Epoch 23/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4593 - accuracy: 0.8939 - val_loss: 0.8346 - val_accuracy: 0.7036\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4650 - accuracy: 0.8899 - val_loss: 0.8351 - val_accuracy: 0.7048\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4606 - accuracy: 0.8888 - val_loss: 0.8529 - val_accuracy: 0.7014\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4867 - accuracy: 0.8735 - val_loss: 0.8433 - val_accuracy: 0.7149\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4666 - accuracy: 0.8868 - val_loss: 0.8041 - val_accuracy: 0.7308\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4500 - accuracy: 0.8967 - val_loss: 0.8205 - val_accuracy: 0.7285\n","Epoch 29/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4625 - accuracy: 0.8905 - val_loss: 0.8055 - val_accuracy: 0.7432\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4474 - accuracy: 0.8981 - val_loss: 0.7688 - val_accuracy: 0.7624\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4703 - accuracy: 0.8800 - val_loss: 0.7707 - val_accuracy: 0.7557\n","Epoch 32/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4445 - accuracy: 0.8998 - val_loss: 0.7506 - val_accuracy: 0.7704\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4434 - accuracy: 0.9004 - val_loss: 0.7709 - val_accuracy: 0.7726\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4366 - accuracy: 0.9021 - val_loss: 0.7944 - val_accuracy: 0.7545\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4723 - accuracy: 0.8809 - val_loss: 0.7419 - val_accuracy: 0.7681\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4462 - accuracy: 0.9015 - val_loss: 0.7613 - val_accuracy: 0.7749\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4680 - accuracy: 0.8879 - val_loss: 0.7499 - val_accuracy: 0.7749\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4410 - accuracy: 0.9010 - val_loss: 0.7776 - val_accuracy: 0.7658\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4340 - accuracy: 0.9038 - val_loss: 0.8596 - val_accuracy: 0.7364\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4401 - accuracy: 0.8956 - val_loss: 0.7631 - val_accuracy: 0.7692\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4225 - accuracy: 0.9086 - val_loss: 0.7719 - val_accuracy: 0.7658\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4313 - accuracy: 0.9035 - val_loss: 0.7652 - val_accuracy: 0.7749\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4297 - accuracy: 0.9024 - val_loss: 0.7834 - val_accuracy: 0.7636\n","Epoch 44/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4305 - accuracy: 0.8995 - val_loss: 0.7745 - val_accuracy: 0.7670\n","Epoch 45/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4233 - accuracy: 0.9027 - val_loss: 0.7701 - val_accuracy: 0.7771\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4246 - accuracy: 0.9032 - val_loss: 0.7693 - val_accuracy: 0.7658\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4183 - accuracy: 0.9089 - val_loss: 0.7687 - val_accuracy: 0.7726\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4191 - accuracy: 0.9120 - val_loss: 0.7891 - val_accuracy: 0.7647\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4113 - accuracy: 0.9117 - val_loss: 0.7884 - val_accuracy: 0.7613\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4102 - accuracy: 0.9137 - val_loss: 0.7807 - val_accuracy: 0.7738\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4096 - accuracy: 0.9120 - val_loss: 0.7856 - val_accuracy: 0.7636\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4106 - accuracy: 0.9143 - val_loss: 0.8073 - val_accuracy: 0.7624\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4065 - accuracy: 0.9128 - val_loss: 0.7881 - val_accuracy: 0.7658\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4044 - accuracy: 0.9177 - val_loss: 0.7874 - val_accuracy: 0.7771\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.9194 - val_loss: 0.8060 - val_accuracy: 0.7613\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4037 - accuracy: 0.9154 - val_loss: 0.8028 - val_accuracy: 0.7681\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3980 - accuracy: 0.9188 - val_loss: 0.8459 - val_accuracy: 0.7602\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4008 - accuracy: 0.9134 - val_loss: 0.8128 - val_accuracy: 0.7613\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4044 - accuracy: 0.9069 - val_loss: 0.8658 - val_accuracy: 0.7319\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3883 - accuracy: 0.9196 - val_loss: 0.7965 - val_accuracy: 0.7704\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.9148 - val_loss: 0.8085 - val_accuracy: 0.7647\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3932 - accuracy: 0.9182 - val_loss: 0.8096 - val_accuracy: 0.7613\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3975 - accuracy: 0.9182 - val_loss: 0.8070 - val_accuracy: 0.7602\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4003 - accuracy: 0.9143 - val_loss: 0.8382 - val_accuracy: 0.7557\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3902 - accuracy: 0.9191 - val_loss: 0.8322 - val_accuracy: 0.7602\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4048 - accuracy: 0.9114 - val_loss: 0.8068 - val_accuracy: 0.7602\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4086 - accuracy: 0.9063 - val_loss: 0.8185 - val_accuracy: 0.7568\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3815 - accuracy: 0.9261 - val_loss: 0.8136 - val_accuracy: 0.7681\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3771 - accuracy: 0.9216 - val_loss: 0.8367 - val_accuracy: 0.7624\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3952 - accuracy: 0.9165 - val_loss: 0.8775 - val_accuracy: 0.7489\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3882 - accuracy: 0.9202 - val_loss: 0.8145 - val_accuracy: 0.7715\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3906 - accuracy: 0.9194 - val_loss: 0.8258 - val_accuracy: 0.7624\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3834 - accuracy: 0.9182 - val_loss: 0.8215 - val_accuracy: 0.7692\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3716 - accuracy: 0.9293 - val_loss: 0.8347 - val_accuracy: 0.7557\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3718 - accuracy: 0.9239 - val_loss: 0.8453 - val_accuracy: 0.7557\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3807 - accuracy: 0.9253 - val_loss: 0.8762 - val_accuracy: 0.7421\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3769 - accuracy: 0.9213 - val_loss: 0.8713 - val_accuracy: 0.7410\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3660 - accuracy: 0.9338 - val_loss: 0.8370 - val_accuracy: 0.7579\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3620 - accuracy: 0.9360 - val_loss: 0.8736 - val_accuracy: 0.7557\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3803 - accuracy: 0.9216 - val_loss: 0.9293 - val_accuracy: 0.7432\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3750 - accuracy: 0.9250 - val_loss: 0.8482 - val_accuracy: 0.7590\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3620 - accuracy: 0.9352 - val_loss: 0.8886 - val_accuracy: 0.7568\n","Epoch 83/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3580 - accuracy: 0.9329 - val_loss: 0.8612 - val_accuracy: 0.7658\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3636 - accuracy: 0.9304 - val_loss: 0.8570 - val_accuracy: 0.7579\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3648 - accuracy: 0.9287 - val_loss: 0.9033 - val_accuracy: 0.7410\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3843 - accuracy: 0.9109 - val_loss: 0.9357 - val_accuracy: 0.7500\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3567 - accuracy: 0.9315 - val_loss: 0.8680 - val_accuracy: 0.7590\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3628 - accuracy: 0.9355 - val_loss: 0.9643 - val_accuracy: 0.7455\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3632 - accuracy: 0.9304 - val_loss: 0.8679 - val_accuracy: 0.7579\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3442 - accuracy: 0.9406 - val_loss: 0.8662 - val_accuracy: 0.7602\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3481 - accuracy: 0.9403 - val_loss: 0.8720 - val_accuracy: 0.7681\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3380 - accuracy: 0.9403 - val_loss: 0.8793 - val_accuracy: 0.7511\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3489 - accuracy: 0.9352 - val_loss: 0.9320 - val_accuracy: 0.7398\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3377 - accuracy: 0.9445 - val_loss: 0.8983 - val_accuracy: 0.7624\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3452 - accuracy: 0.9392 - val_loss: 0.8850 - val_accuracy: 0.7545\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3620 - accuracy: 0.9293 - val_loss: 0.8863 - val_accuracy: 0.7579\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3542 - accuracy: 0.9324 - val_loss: 0.8805 - val_accuracy: 0.7647\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3545 - accuracy: 0.9383 - val_loss: 0.8785 - val_accuracy: 0.7602\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3464 - accuracy: 0.9377 - val_loss: 0.9194 - val_accuracy: 0.7387\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3374 - accuracy: 0.9406 - val_loss: 0.8927 - val_accuracy: 0.7523\n","{'loss': [0.5727716088294983, 0.5434601306915283, 0.5358392000198364, 0.5230101346969604, 0.519289493560791, 0.5185624361038208, 0.5026973485946655, 0.5089737772941589, 0.4961067736148834, 0.5042567253112793, 0.5309184789657593, 0.5368473529815674, 0.5018784999847412, 0.49145203828811646, 0.48537346720695496, 0.49241903424263, 0.47757187485694885, 0.47655850648880005, 0.4885703921318054, 0.47212064266204834, 0.46911948919296265, 0.47298741340637207, 0.45926639437675476, 0.4650319814682007, 0.4605511426925659, 0.48667487502098083, 0.4665924608707428, 0.4500250816345215, 0.4624656140804291, 0.4473879635334015, 0.47034597396850586, 0.4444737732410431, 0.4434460401535034, 0.4365696907043457, 0.472327321767807, 0.44618505239486694, 0.4680314064025879, 0.4409545958042145, 0.4340400695800781, 0.44005563855171204, 0.4224829077720642, 0.43126949667930603, 0.429680198431015, 0.4305408298969269, 0.4232988655567169, 0.42462509870529175, 0.4183448255062103, 0.41909128427505493, 0.41125836968421936, 0.41015782952308655, 0.4096466898918152, 0.41060495376586914, 0.4064798057079315, 0.40441572666168213, 0.3963741958141327, 0.4036770164966583, 0.3979634642601013, 0.40077245235443115, 0.40440356731414795, 0.38827377557754517, 0.4006786346435547, 0.39323481917381287, 0.3975452780723572, 0.4003276824951172, 0.39018088579177856, 0.40477102994918823, 0.4085755944252014, 0.38149380683898926, 0.377061665058136, 0.3952365219593048, 0.38816073536872864, 0.39060330390930176, 0.38344934582710266, 0.37162935733795166, 0.371834397315979, 0.3807116746902466, 0.37692004442214966, 0.36602336168289185, 0.36199086904525757, 0.3802625834941864, 0.3749893307685852, 0.36201000213623047, 0.35800403356552124, 0.36361071467399597, 0.36477896571159363, 0.38427871465682983, 0.3567192256450653, 0.3628462553024292, 0.36318859457969666, 0.3442360460758209, 0.3481175899505615, 0.3380122184753418, 0.3488710820674896, 0.3376709520816803, 0.34524664282798767, 0.3619982600212097, 0.3542291224002838, 0.3545072674751282, 0.3464277982711792, 0.33736154437065125], 'accuracy': [0.8344652056694031, 0.8511601686477661, 0.8576683402061462, 0.8647425174713135, 0.8658743500709534, 0.8667232394218445, 0.8771929740905762, 0.8735144138336182, 0.875495195388794, 0.870684802532196, 0.8565365076065063, 0.8514431118965149, 0.8675721287727356, 0.8771929740905762, 0.8820033669471741, 0.8797396421432495, 0.888511598110199, 0.88285231590271, 0.8786078095436096, 0.8859649300575256, 0.8839841485023499, 0.8899264335632324, 0.8938879370689392, 0.8899264335632324, 0.8887945413589478, 0.8735144138336182, 0.8868138194084167, 0.8967176079750061, 0.8904923796653748, 0.8981324434280396, 0.8800226449966431, 0.8998302221298218, 0.9003961682319641, 0.9020939469337463, 0.8808715343475342, 0.901528000831604, 0.8879456520080566, 0.9009620547294617, 0.9037917256355286, 0.8955857157707214, 0.9086021780967712, 0.9035087823867798, 0.9023768901824951, 0.899547278881073, 0.9026598930358887, 0.9032257795333862, 0.90888512134552, 0.9119977355003357, 0.9117147922515869, 0.9136955142021179, 0.9119977355003357, 0.9142614603042603, 0.9128466248512268, 0.9176570177078247, 0.9193548560142517, 0.9153932929039001, 0.9187889099121094, 0.9134125709533691, 0.9069043397903442, 0.9196377992630005, 0.9148274064064026, 0.918222963809967, 0.918222963809967, 0.9142614603042603, 0.9190718531608582, 0.9114317893981934, 0.9063384532928467, 0.9261460304260254, 0.9216185808181763, 0.9165251851081848, 0.9202037453651428, 0.9193548560142517, 0.918222963809967, 0.9292586445808411, 0.9238823056221008, 0.9252971410751343, 0.9213355779647827, 0.9337860941886902, 0.9360498189926147, 0.9216185808181763, 0.9250141382217407, 0.9352009296417236, 0.9329372048377991, 0.930390477180481, 0.9286926984786987, 0.9108659029006958, 0.9315223693847656, 0.9354838728904724, 0.930390477180481, 0.9405772686004639, 0.9402942657470703, 0.9402942657470703, 0.9352009296417236, 0.9445387721061707, 0.9391624331474304, 0.9292586445808411, 0.9323712587356567, 0.9383135437965393, 0.937747597694397, 0.9405772686004639], 'val_loss': [0.8982452750205994, 0.892581582069397, 0.8867378234863281, 0.8807728886604309, 0.8743053674697876, 0.8701238036155701, 0.86688232421875, 0.8628490567207336, 0.8649853467941284, 0.8548021912574768, 0.8477819561958313, 0.8690692186355591, 0.8769373893737793, 0.8827403783798218, 0.8837812542915344, 0.8830319046974182, 0.8816170692443848, 0.9781977534294128, 0.8803766965866089, 0.9025097489356995, 0.908015251159668, 0.916253387928009, 0.8346222043037415, 0.8351244926452637, 0.8528642654418945, 0.8433396816253662, 0.8040992617607117, 0.8204724192619324, 0.8055127263069153, 0.7687684297561646, 0.7707448601722717, 0.750622034072876, 0.7709445953369141, 0.7943997383117676, 0.7418981790542603, 0.7612696886062622, 0.7498769164085388, 0.7775766253471375, 0.859583854675293, 0.7630935311317444, 0.7719058394432068, 0.7651671767234802, 0.7834016680717468, 0.7745398879051208, 0.7700932025909424, 0.7693460583686829, 0.7687095403671265, 0.7891465425491333, 0.7884284257888794, 0.7806571125984192, 0.785605251789093, 0.8072500228881836, 0.7880882620811462, 0.7874435782432556, 0.8060499429702759, 0.8027701377868652, 0.845881462097168, 0.8127952218055725, 0.8658275604248047, 0.7964611649513245, 0.8084925413131714, 0.8095621466636658, 0.8069721460342407, 0.8382295370101929, 0.8322470784187317, 0.8068115711212158, 0.8184844255447388, 0.81363445520401, 0.8367384076118469, 0.877478301525116, 0.8145190477371216, 0.8258373737335205, 0.8214885592460632, 0.834719717502594, 0.8453049063682556, 0.8762279748916626, 0.8713209629058838, 0.8370406627655029, 0.8735818862915039, 0.9292821884155273, 0.8481850624084473, 0.8885535597801208, 0.8611811995506287, 0.8570395708084106, 0.9032689929008484, 0.9356933832168579, 0.8679797649383545, 0.9642673134803772, 0.8679348826408386, 0.8662128448486328, 0.8720105886459351, 0.8793443441390991, 0.9319618940353394, 0.8982948660850525, 0.8849726319313049, 0.8863273859024048, 0.8805133700370789, 0.8785132765769958, 0.9194183349609375, 0.8926905393600464], 'val_accuracy': [0.49660632014274597, 0.5033936500549316, 0.5158371329307556, 0.5972850918769836, 0.6334841847419739, 0.639140248298645, 0.6357465982437134, 0.627828061580658, 0.6040723919868469, 0.6323529481887817, 0.6402714848518372, 0.5972850918769836, 0.5950226187705994, 0.5938913822174072, 0.6074660420417786, 0.6131221652030945, 0.6255655884742737, 0.5950226187705994, 0.6538461446762085, 0.6470588445663452, 0.6617646813392639, 0.668552041053772, 0.7036198973655701, 0.7047511339187622, 0.7013574838638306, 0.7149321436882019, 0.7307692170143127, 0.7285068035125732, 0.7432126402854919, 0.7624434232711792, 0.7556561231613159, 0.7703620195388794, 0.7726244330406189, 0.7545248866081238, 0.7680995464324951, 0.7748869061470032, 0.7748869061470032, 0.7658371329307556, 0.7364253401756287, 0.7692307829856873, 0.7658371329307556, 0.7748869061470032, 0.7635746598243713, 0.766968309879303, 0.7771493196487427, 0.7658371329307556, 0.7726244330406189, 0.7647058963775635, 0.7613122463226318, 0.773755669593811, 0.7635746598243713, 0.7624434232711792, 0.7658371329307556, 0.7771493196487427, 0.7613122463226318, 0.7680995464324951, 0.7601810097694397, 0.7613122463226318, 0.7319004535675049, 0.7703620195388794, 0.7647058963775635, 0.7613122463226318, 0.7601810097694397, 0.7556561231613159, 0.7601810097694397, 0.7601810097694397, 0.7567873597145081, 0.7680995464324951, 0.7624434232711792, 0.7488687634468079, 0.7714931964874268, 0.7624434232711792, 0.7692307829856873, 0.7556561231613159, 0.7556561231613159, 0.7420814633369446, 0.7409502267837524, 0.7579185366630554, 0.7556561231613159, 0.7432126402854919, 0.7590497732162476, 0.7567873597145081, 0.7658371329307556, 0.7579185366630554, 0.7409502267837524, 0.75, 0.7590497732162476, 0.7454751133918762, 0.7579185366630554, 0.7601810097694397, 0.7680995464324951, 0.7511312365531921, 0.7398189902305603, 0.7624434232711792, 0.7545248866081238, 0.7579185366630554, 0.7647058963775635, 0.7601810097694397, 0.7386877536773682, 0.7522624731063843]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 48ms/step - loss: 0.6020 - accuracy: 0.8300 - val_loss: 0.8985 - val_accuracy: 0.4907\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5470 - accuracy: 0.8592 - val_loss: 0.8923 - val_accuracy: 0.4948\n","Epoch 3/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5467 - accuracy: 0.8514 - val_loss: 0.8813 - val_accuracy: 0.6240\n","Epoch 4/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5342 - accuracy: 0.8607 - val_loss: 0.8745 - val_accuracy: 0.6570\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5423 - accuracy: 0.8561 - val_loss: 0.8709 - val_accuracy: 0.6415\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5287 - accuracy: 0.8646 - val_loss: 0.8658 - val_accuracy: 0.6436\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5260 - accuracy: 0.8654 - val_loss: 0.8613 - val_accuracy: 0.6405\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5230 - accuracy: 0.8633 - val_loss: 0.8571 - val_accuracy: 0.6364\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5172 - accuracy: 0.8705 - val_loss: 0.8613 - val_accuracy: 0.6116\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5135 - accuracy: 0.8713 - val_loss: 0.8562 - val_accuracy: 0.6178\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5250 - accuracy: 0.8615 - val_loss: 0.8718 - val_accuracy: 0.5981\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5082 - accuracy: 0.8755 - val_loss: 0.8606 - val_accuracy: 0.6043\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5305 - accuracy: 0.8563 - val_loss: 0.8468 - val_accuracy: 0.6250\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5229 - accuracy: 0.8574 - val_loss: 0.8831 - val_accuracy: 0.5981\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5035 - accuracy: 0.8760 - val_loss: 0.8749 - val_accuracy: 0.6157\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5018 - accuracy: 0.8765 - val_loss: 0.9012 - val_accuracy: 0.6085\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4959 - accuracy: 0.8752 - val_loss: 1.0048 - val_accuracy: 0.5868\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5182 - accuracy: 0.8667 - val_loss: 0.9197 - val_accuracy: 0.6260\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4919 - accuracy: 0.8760 - val_loss: 0.9253 - val_accuracy: 0.6322\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4944 - accuracy: 0.8791 - val_loss: 0.8886 - val_accuracy: 0.6601\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4902 - accuracy: 0.8791 - val_loss: 0.8911 - val_accuracy: 0.6632\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4880 - accuracy: 0.8796 - val_loss: 0.8683 - val_accuracy: 0.6808\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4926 - accuracy: 0.8770 - val_loss: 0.7883 - val_accuracy: 0.7283\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4971 - accuracy: 0.8721 - val_loss: 0.7932 - val_accuracy: 0.7262\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4966 - accuracy: 0.8731 - val_loss: 0.8373 - val_accuracy: 0.7097\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4832 - accuracy: 0.8848 - val_loss: 0.7883 - val_accuracy: 0.7459\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4788 - accuracy: 0.8804 - val_loss: 0.8500 - val_accuracy: 0.7066\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4782 - accuracy: 0.8845 - val_loss: 0.8045 - val_accuracy: 0.7345\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4739 - accuracy: 0.8845 - val_loss: 0.8071 - val_accuracy: 0.7531\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4673 - accuracy: 0.8915 - val_loss: 0.8144 - val_accuracy: 0.7469\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4689 - accuracy: 0.8873 - val_loss: 0.8151 - val_accuracy: 0.7479\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4610 - accuracy: 0.8922 - val_loss: 0.8491 - val_accuracy: 0.7242\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4833 - accuracy: 0.8783 - val_loss: 0.8404 - val_accuracy: 0.7283\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4660 - accuracy: 0.8894 - val_loss: 0.8510 - val_accuracy: 0.7180\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4770 - accuracy: 0.8796 - val_loss: 0.8703 - val_accuracy: 0.7190\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4811 - accuracy: 0.8762 - val_loss: 0.8316 - val_accuracy: 0.7376\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4682 - accuracy: 0.8881 - val_loss: 0.8274 - val_accuracy: 0.7407\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4605 - accuracy: 0.8904 - val_loss: 0.8721 - val_accuracy: 0.7138\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4768 - accuracy: 0.8786 - val_loss: 0.8774 - val_accuracy: 0.7293\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4676 - accuracy: 0.8910 - val_loss: 0.8667 - val_accuracy: 0.7190\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4563 - accuracy: 0.8956 - val_loss: 0.8346 - val_accuracy: 0.7386\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4459 - accuracy: 0.8925 - val_loss: 0.8536 - val_accuracy: 0.7438\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4421 - accuracy: 0.9090 - val_loss: 0.8946 - val_accuracy: 0.7118\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4473 - accuracy: 0.9013 - val_loss: 0.8679 - val_accuracy: 0.7407\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4376 - accuracy: 0.9003 - val_loss: 0.8637 - val_accuracy: 0.7428\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4360 - accuracy: 0.9023 - val_loss: 0.8609 - val_accuracy: 0.7459\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4418 - accuracy: 0.8984 - val_loss: 0.8864 - val_accuracy: 0.7355\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4446 - accuracy: 0.8943 - val_loss: 0.8648 - val_accuracy: 0.7355\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4416 - accuracy: 0.9000 - val_loss: 0.8602 - val_accuracy: 0.7417\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4357 - accuracy: 0.8990 - val_loss: 0.8957 - val_accuracy: 0.7304\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4286 - accuracy: 0.9031 - val_loss: 0.9056 - val_accuracy: 0.7231\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4258 - accuracy: 0.9103 - val_loss: 0.9038 - val_accuracy: 0.7149\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4498 - accuracy: 0.8917 - val_loss: 0.9233 - val_accuracy: 0.7211\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4416 - accuracy: 0.8951 - val_loss: 0.9389 - val_accuracy: 0.7149\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4205 - accuracy: 0.9047 - val_loss: 0.8931 - val_accuracy: 0.7324\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4203 - accuracy: 0.9072 - val_loss: 0.9091 - val_accuracy: 0.7355\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4163 - accuracy: 0.9070 - val_loss: 0.9569 - val_accuracy: 0.7211\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4292 - accuracy: 0.8984 - val_loss: 0.8847 - val_accuracy: 0.7324\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4275 - accuracy: 0.9054 - val_loss: 0.9657 - val_accuracy: 0.7231\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4234 - accuracy: 0.9070 - val_loss: 0.8787 - val_accuracy: 0.7335\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4211 - accuracy: 0.9052 - val_loss: 0.8914 - val_accuracy: 0.7345\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4033 - accuracy: 0.9137 - val_loss: 0.9035 - val_accuracy: 0.7190\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4135 - accuracy: 0.9129 - val_loss: 0.8987 - val_accuracy: 0.7345\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4028 - accuracy: 0.9186 - val_loss: 0.9203 - val_accuracy: 0.7355\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4121 - accuracy: 0.9078 - val_loss: 0.9091 - val_accuracy: 0.7324\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4054 - accuracy: 0.9106 - val_loss: 0.9601 - val_accuracy: 0.7252\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4193 - accuracy: 0.9023 - val_loss: 0.9137 - val_accuracy: 0.7386\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4070 - accuracy: 0.9150 - val_loss: 0.9136 - val_accuracy: 0.7345\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4078 - accuracy: 0.9163 - val_loss: 0.9568 - val_accuracy: 0.7211\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4144 - accuracy: 0.9098 - val_loss: 0.9253 - val_accuracy: 0.7304\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4070 - accuracy: 0.9134 - val_loss: 0.9198 - val_accuracy: 0.7211\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4100 - accuracy: 0.9127 - val_loss: 0.9656 - val_accuracy: 0.7211\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4015 - accuracy: 0.9147 - val_loss: 0.9930 - val_accuracy: 0.7118\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4037 - accuracy: 0.9088 - val_loss: 0.9251 - val_accuracy: 0.7242\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4082 - accuracy: 0.9090 - val_loss: 0.9809 - val_accuracy: 0.7118\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3968 - accuracy: 0.9158 - val_loss: 0.9128 - val_accuracy: 0.7231\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3911 - accuracy: 0.9222 - val_loss: 0.9378 - val_accuracy: 0.7252\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3786 - accuracy: 0.9258 - val_loss: 0.9564 - val_accuracy: 0.7304\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3858 - accuracy: 0.9209 - val_loss: 0.9556 - val_accuracy: 0.7324\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3776 - accuracy: 0.9225 - val_loss: 0.9405 - val_accuracy: 0.7335\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3853 - accuracy: 0.9271 - val_loss: 0.9533 - val_accuracy: 0.7252\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3805 - accuracy: 0.9230 - val_loss: 0.9755 - val_accuracy: 0.7262\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4006 - accuracy: 0.9103 - val_loss: 0.9607 - val_accuracy: 0.7262\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3858 - accuracy: 0.9178 - val_loss: 0.9893 - val_accuracy: 0.7149\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3770 - accuracy: 0.9279 - val_loss: 0.9476 - val_accuracy: 0.7366\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3714 - accuracy: 0.9269 - val_loss: 0.9471 - val_accuracy: 0.7283\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3828 - accuracy: 0.9238 - val_loss: 0.9442 - val_accuracy: 0.7200\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3817 - accuracy: 0.9207 - val_loss: 1.0357 - val_accuracy: 0.7118\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3808 - accuracy: 0.9225 - val_loss: 1.0327 - val_accuracy: 0.7035\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3909 - accuracy: 0.9168 - val_loss: 0.9715 - val_accuracy: 0.7335\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3722 - accuracy: 0.9248 - val_loss: 0.9587 - val_accuracy: 0.7242\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3654 - accuracy: 0.9287 - val_loss: 0.9719 - val_accuracy: 0.7283\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3700 - accuracy: 0.9261 - val_loss: 0.9622 - val_accuracy: 0.7335\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3592 - accuracy: 0.9339 - val_loss: 0.9699 - val_accuracy: 0.7355\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3679 - accuracy: 0.9297 - val_loss: 0.9714 - val_accuracy: 0.7262\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3580 - accuracy: 0.9313 - val_loss: 0.9887 - val_accuracy: 0.7262\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3629 - accuracy: 0.9287 - val_loss: 1.0112 - val_accuracy: 0.7242\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3672 - accuracy: 0.9261 - val_loss: 0.9967 - val_accuracy: 0.7262\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3616 - accuracy: 0.9295 - val_loss: 0.9875 - val_accuracy: 0.7293\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3597 - accuracy: 0.9313 - val_loss: 0.9910 - val_accuracy: 0.7190\n","{'loss': [0.6019826531410217, 0.547034740447998, 0.5467413067817688, 0.5341718792915344, 0.5422818660736084, 0.5286900401115417, 0.5259962677955627, 0.5229976177215576, 0.51722651720047, 0.5135019421577454, 0.5249983668327332, 0.5081921219825745, 0.5304757356643677, 0.5228989124298096, 0.5034968852996826, 0.5017634034156799, 0.49586185812950134, 0.5182086229324341, 0.491906076669693, 0.49436068534851074, 0.4902498424053192, 0.48799020051956177, 0.4925859868526459, 0.4970770478248596, 0.49663347005844116, 0.4832020401954651, 0.4787946343421936, 0.47821977734565735, 0.47394832968711853, 0.46733543276786804, 0.4689129590988159, 0.4610303044319153, 0.48330825567245483, 0.4659629166126251, 0.47700658440589905, 0.481089323759079, 0.46815580129623413, 0.4604819118976593, 0.4767754077911377, 0.4676312208175659, 0.456339955329895, 0.4458584487438202, 0.4421215355396271, 0.4473080039024353, 0.4375856816768646, 0.43595191836357117, 0.44177767634391785, 0.4445818364620209, 0.4416414499282837, 0.4357120394706726, 0.42863714694976807, 0.4257744550704956, 0.44979602098464966, 0.44161713123321533, 0.42051705718040466, 0.42026805877685547, 0.41630077362060547, 0.42916861176490784, 0.4275173544883728, 0.4233715832233429, 0.4211394786834717, 0.4033200144767761, 0.41353240609169006, 0.40275436639785767, 0.41214343905448914, 0.4054168164730072, 0.4193178117275238, 0.4070125222206116, 0.4077852964401245, 0.41443052887916565, 0.4070160984992981, 0.40995433926582336, 0.40147966146469116, 0.40365636348724365, 0.4082155227661133, 0.3967819809913635, 0.391121506690979, 0.37858128547668457, 0.3858359754085541, 0.37755969166755676, 0.3852679431438446, 0.3804730474948883, 0.4005658030509949, 0.38582322001457214, 0.3769848346710205, 0.3714171051979065, 0.3828250765800476, 0.38166913390159607, 0.3807666003704071, 0.3908845782279968, 0.37216851115226746, 0.36540117859840393, 0.37000522017478943, 0.35921934247016907, 0.36788925528526306, 0.35804128646850586, 0.36290836334228516, 0.36719509959220886, 0.3615511357784271, 0.35973265767097473], 'accuracy': [0.8299741744995117, 0.8591731190681458, 0.8514211773872375, 0.8607234954833984, 0.8560723662376404, 0.8645994663238525, 0.8653746843338013, 0.8633074760437012, 0.8705426454544067, 0.8713178038597107, 0.8614987134933472, 0.8754522204399109, 0.8563307523727417, 0.8573643565177917, 0.8759689927101135, 0.8764857649803162, 0.8751937747001648, 0.8666666746139526, 0.8759689927101135, 0.8790697455406189, 0.8790697455406189, 0.8795865774154663, 0.8770025968551636, 0.8720930218696594, 0.8731266260147095, 0.8847545385360718, 0.8803617358207703, 0.8844961524009705, 0.8844961524009705, 0.8914728760719299, 0.8873385190963745, 0.8922480344772339, 0.8782945871353149, 0.8894056677818298, 0.8795865774154663, 0.8762273788452148, 0.8881136775016785, 0.8904392719268799, 0.8785529732704163, 0.8909560441970825, 0.8956072330474854, 0.89250648021698, 0.9090439081192017, 0.9012919664382935, 0.9002584218978882, 0.9023255705833435, 0.8984495997428894, 0.894315242767334, 0.8999999761581421, 0.8989664316177368, 0.9031007885932922, 0.910335898399353, 0.8917312622070312, 0.8950904607772827, 0.9046511650085449, 0.9072351455688477, 0.9069767594337463, 0.8984495997428894, 0.9054263830184937, 0.9069767594337463, 0.9051679372787476, 0.9136950969696045, 0.9129198789596558, 0.9186046719551086, 0.9077519178390503, 0.9105943441390991, 0.9023255705833435, 0.9149870872497559, 0.9162790775299072, 0.9098191261291504, 0.9134367108345032, 0.9126614928245544, 0.9147287011146545, 0.9087855219841003, 0.9090439081192017, 0.9157622456550598, 0.9222221970558167, 0.9258397817611694, 0.9209302067756653, 0.9224806427955627, 0.9271317720413208, 0.9229974150657654, 0.910335898399353, 0.9178294539451599, 0.9279069900512695, 0.9268733859062195, 0.9237726330757141, 0.920671820640564, 0.9224806427955627, 0.9167958498001099, 0.9248061776161194, 0.9286821484565735, 0.9260981678962708, 0.933850109577179, 0.9297157526016235, 0.9312661290168762, 0.9286821484565735, 0.9260981678962708, 0.9294573664665222, 0.9312661290168762], 'val_loss': [0.8984692096710205, 0.8923463821411133, 0.8813439607620239, 0.8745335340499878, 0.8709169626235962, 0.8658325672149658, 0.8612503409385681, 0.8570900559425354, 0.8612879514694214, 0.8561916351318359, 0.8718067407608032, 0.8606179356575012, 0.8468464016914368, 0.8830934762954712, 0.8749489784240723, 0.9011651873588562, 1.0047765970230103, 0.9197486042976379, 0.9252986907958984, 0.8885513544082642, 0.8911150693893433, 0.8682775497436523, 0.7882996797561646, 0.7931986451148987, 0.8373386263847351, 0.7883390784263611, 0.8500068187713623, 0.8044560551643372, 0.8070570230484009, 0.814383327960968, 0.8151138424873352, 0.8491213917732239, 0.8403998017311096, 0.8509688973426819, 0.870257556438446, 0.8315877318382263, 0.8274071216583252, 0.8721267580986023, 0.8774240016937256, 0.8666673302650452, 0.83464115858078, 0.8536407351493835, 0.8945883512496948, 0.867899477481842, 0.8637139797210693, 0.8608697652816772, 0.8863731622695923, 0.864833414554596, 0.8601958751678467, 0.8956683278083801, 0.905555009841919, 0.9038383364677429, 0.9233300089836121, 0.9389276504516602, 0.8930819034576416, 0.9090502858161926, 0.9568583369255066, 0.8846979141235352, 0.9656990766525269, 0.8786748647689819, 0.891392707824707, 0.9034580588340759, 0.8987430334091187, 0.9202553033828735, 0.9091209173202515, 0.9600719213485718, 0.9137062430381775, 0.9135528802871704, 0.9567991495132446, 0.9253473281860352, 0.9197625517845154, 0.9656175374984741, 0.9930486679077148, 0.9250515103340149, 0.9808792471885681, 0.9128110408782959, 0.9378288984298706, 0.956448495388031, 0.9556339979171753, 0.9404652118682861, 0.9532768726348877, 0.975493311882019, 0.96072918176651, 0.989303469657898, 0.9475874900817871, 0.947126030921936, 0.9442312717437744, 1.035745620727539, 1.0326757431030273, 0.9714516997337341, 0.9586879014968872, 0.9719054102897644, 0.9621601700782776, 0.9699293971061707, 0.9714071750640869, 0.9886630177497864, 1.0111829042434692, 0.9967491030693054, 0.9874795079231262, 0.9910387992858887], 'val_accuracy': [0.49070248007774353, 0.4948347210884094, 0.6239669322967529, 0.6570248007774353, 0.6415289044380188, 0.6435950398445129, 0.6404958963394165, 0.6363636255264282, 0.6115702390670776, 0.6177685856819153, 0.5981404781341553, 0.6043388247489929, 0.625, 0.5981404781341553, 0.6157024502754211, 0.6084710955619812, 0.586776852607727, 0.6260330677032471, 0.6322314143180847, 0.6601239442825317, 0.663223147392273, 0.6807851195335388, 0.7283057570457458, 0.7262396812438965, 0.7097107172012329, 0.7458677887916565, 0.7066115736961365, 0.7345041036605835, 0.7530992031097412, 0.7469007968902588, 0.7479338645935059, 0.7241735458374023, 0.7283057570457458, 0.7179751992225647, 0.7190082669258118, 0.7376033067703247, 0.7407024502754211, 0.7138429880142212, 0.7293388247489929, 0.7190082669258118, 0.7386363744735718, 0.7438016533851624, 0.711776852607727, 0.7407024502754211, 0.7427685856819153, 0.7458677887916565, 0.7355371713638306, 0.7355371713638306, 0.7417355179786682, 0.73037189245224, 0.7231404781341553, 0.7148760557174683, 0.7210744023323059, 0.7148760557174683, 0.7324380278587341, 0.7355371713638306, 0.7210744023323059, 0.7324380278587341, 0.7231404781341553, 0.7334710955619812, 0.7345041036605835, 0.7190082669258118, 0.7345041036605835, 0.7355371713638306, 0.7324380278587341, 0.7252066135406494, 0.7386363744735718, 0.7345041036605835, 0.7210744023323059, 0.73037189245224, 0.7210744023323059, 0.7210744023323059, 0.711776852607727, 0.7241735458374023, 0.711776852607727, 0.7231404781341553, 0.7252066135406494, 0.73037189245224, 0.7324380278587341, 0.7334710955619812, 0.7252066135406494, 0.7262396812438965, 0.7262396812438965, 0.7148760557174683, 0.7365702390670776, 0.7283057570457458, 0.7200413346290588, 0.711776852607727, 0.7035123705863953, 0.7334710955619812, 0.7241735458374023, 0.7283057570457458, 0.7334710955619812, 0.7355371713638306, 0.7262396812438965, 0.7262396812438965, 0.7241735458374023, 0.7262396812438965, 0.7293388247489929, 0.7190082669258118]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.4584 - accuracy: 0.8859"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 51ms/step - loss: 0.4555 - accuracy: 0.8879 - val_loss: 0.8966 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4352 - accuracy: 0.8944 - val_loss: 0.8815 - val_accuracy: 0.4925\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4041 - accuracy: 0.9106 - val_loss: 0.8678 - val_accuracy: 0.5259\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4113 - accuracy: 0.9089 - val_loss: 0.8600 - val_accuracy: 0.5442\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3941 - accuracy: 0.9146 - val_loss: 0.8467 - val_accuracy: 0.6024\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4054 - accuracy: 0.9098 - val_loss: 0.8399 - val_accuracy: 0.6261\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4034 - accuracy: 0.9103 - val_loss: 0.8352 - val_accuracy: 0.6401\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3851 - accuracy: 0.9213 - val_loss: 0.8372 - val_accuracy: 0.6336\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3860 - accuracy: 0.9184 - val_loss: 0.8385 - val_accuracy: 0.6272\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3928 - accuracy: 0.9135 - val_loss: 0.8381 - val_accuracy: 0.6293\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3875 - accuracy: 0.9149 - val_loss: 0.8555 - val_accuracy: 0.6099\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3998 - accuracy: 0.9119 - val_loss: 0.8552 - val_accuracy: 0.6142\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3850 - accuracy: 0.9178 - val_loss: 0.9109 - val_accuracy: 0.5841\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3728 - accuracy: 0.9240 - val_loss: 0.9087 - val_accuracy: 0.6088\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3726 - accuracy: 0.9219 - val_loss: 1.0352 - val_accuracy: 0.5711\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4079 - accuracy: 0.9081 - val_loss: 0.9679 - val_accuracy: 0.6078\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3730 - accuracy: 0.9278 - val_loss: 0.9166 - val_accuracy: 0.6379\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3677 - accuracy: 0.9300 - val_loss: 0.9544 - val_accuracy: 0.6379\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3637 - accuracy: 0.9300 - val_loss: 1.0880 - val_accuracy: 0.6099\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3680 - accuracy: 0.9318 - val_loss: 1.0521 - val_accuracy: 0.6358\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3707 - accuracy: 0.9243 - val_loss: 0.9257 - val_accuracy: 0.6670\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3626 - accuracy: 0.9278 - val_loss: 0.9203 - val_accuracy: 0.6907\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3626 - accuracy: 0.9302 - val_loss: 0.9377 - val_accuracy: 0.6875\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3621 - accuracy: 0.9286 - val_loss: 0.9461 - val_accuracy: 0.6983\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3496 - accuracy: 0.9370 - val_loss: 0.9190 - val_accuracy: 0.7123\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3881 - accuracy: 0.9151 - val_loss: 0.7109 - val_accuracy: 0.7769\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3810 - accuracy: 0.9151 - val_loss: 0.7098 - val_accuracy: 0.7823\n","Epoch 28/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3671 - accuracy: 0.9230 - val_loss: 0.7140 - val_accuracy: 0.7834\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3553 - accuracy: 0.9308 - val_loss: 0.7255 - val_accuracy: 0.7953\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3416 - accuracy: 0.9380 - val_loss: 0.7444 - val_accuracy: 0.7877\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3538 - accuracy: 0.9283 - val_loss: 0.7399 - val_accuracy: 0.7953\n","Epoch 32/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3490 - accuracy: 0.9340 - val_loss: 0.7464 - val_accuracy: 0.7974\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3518 - accuracy: 0.9318 - val_loss: 0.7375 - val_accuracy: 0.7953\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3418 - accuracy: 0.9397 - val_loss: 0.8270 - val_accuracy: 0.7683\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3468 - accuracy: 0.9364 - val_loss: 0.7500 - val_accuracy: 0.8039\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3426 - accuracy: 0.9367 - val_loss: 0.7633 - val_accuracy: 0.7920\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3497 - accuracy: 0.9329 - val_loss: 0.7882 - val_accuracy: 0.7834\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.9351 - val_loss: 0.8060 - val_accuracy: 0.7726\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3426 - accuracy: 0.9386 - val_loss: 0.7860 - val_accuracy: 0.7856\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3379 - accuracy: 0.9394 - val_loss: 0.7651 - val_accuracy: 0.7963\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3338 - accuracy: 0.9410 - val_loss: 0.7834 - val_accuracy: 0.7856\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3350 - accuracy: 0.9383 - val_loss: 0.7738 - val_accuracy: 0.7963\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3312 - accuracy: 0.9413 - val_loss: 0.7675 - val_accuracy: 0.7974\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3314 - accuracy: 0.9421 - val_loss: 0.8417 - val_accuracy: 0.7716\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3501 - accuracy: 0.9278 - val_loss: 0.7671 - val_accuracy: 0.7985\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3519 - accuracy: 0.9332 - val_loss: 0.7943 - val_accuracy: 0.7856\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3322 - accuracy: 0.9418 - val_loss: 0.7846 - val_accuracy: 0.7845\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3603 - accuracy: 0.9243 - val_loss: 0.8270 - val_accuracy: 0.7629\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3310 - accuracy: 0.9388 - val_loss: 0.7839 - val_accuracy: 0.7866\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3436 - accuracy: 0.9316 - val_loss: 0.9541 - val_accuracy: 0.7425\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3233 - accuracy: 0.9459 - val_loss: 0.8314 - val_accuracy: 0.7737\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3215 - accuracy: 0.9467 - val_loss: 0.8033 - val_accuracy: 0.7759\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3219 - accuracy: 0.9477 - val_loss: 0.8510 - val_accuracy: 0.7694\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3204 - accuracy: 0.9467 - val_loss: 0.8444 - val_accuracy: 0.7726\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3130 - accuracy: 0.9499 - val_loss: 0.7824 - val_accuracy: 0.7974\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3187 - accuracy: 0.9518 - val_loss: 0.8404 - val_accuracy: 0.7694\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3223 - accuracy: 0.9442 - val_loss: 0.8207 - val_accuracy: 0.7759\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3103 - accuracy: 0.9534 - val_loss: 0.8445 - val_accuracy: 0.7726\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3162 - accuracy: 0.9459 - val_loss: 0.7953 - val_accuracy: 0.7963\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3117 - accuracy: 0.9515 - val_loss: 0.8080 - val_accuracy: 0.7845\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3190 - accuracy: 0.9464 - val_loss: 0.8052 - val_accuracy: 0.7877\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3213 - accuracy: 0.9421 - val_loss: 0.8269 - val_accuracy: 0.7802\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3155 - accuracy: 0.9491 - val_loss: 0.8376 - val_accuracy: 0.7759\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3087 - accuracy: 0.9502 - val_loss: 0.8821 - val_accuracy: 0.7662\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3018 - accuracy: 0.9588 - val_loss: 0.8137 - val_accuracy: 0.7856\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3161 - accuracy: 0.9472 - val_loss: 0.9380 - val_accuracy: 0.7640\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3080 - accuracy: 0.9507 - val_loss: 0.8325 - val_accuracy: 0.7899\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.9518 - val_loss: 0.8236 - val_accuracy: 0.7812\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3062 - accuracy: 0.9512 - val_loss: 0.8192 - val_accuracy: 0.7856\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3107 - accuracy: 0.9464 - val_loss: 0.8260 - val_accuracy: 0.7802\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3028 - accuracy: 0.9512 - val_loss: 0.8744 - val_accuracy: 0.7672\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3117 - accuracy: 0.9467 - val_loss: 0.8477 - val_accuracy: 0.7748\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3130 - accuracy: 0.9488 - val_loss: 0.8525 - val_accuracy: 0.7812\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3127 - accuracy: 0.9437 - val_loss: 0.8384 - val_accuracy: 0.7769\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2978 - accuracy: 0.9572 - val_loss: 0.8155 - val_accuracy: 0.7812\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2991 - accuracy: 0.9542 - val_loss: 0.8969 - val_accuracy: 0.7726\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3019 - accuracy: 0.9502 - val_loss: 0.8491 - val_accuracy: 0.7802\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3005 - accuracy: 0.9529 - val_loss: 0.8379 - val_accuracy: 0.7985\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3000 - accuracy: 0.9507 - val_loss: 0.9141 - val_accuracy: 0.7629\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2962 - accuracy: 0.9547 - val_loss: 0.8402 - val_accuracy: 0.7942\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2984 - accuracy: 0.9561 - val_loss: 0.8446 - val_accuracy: 0.7877\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2943 - accuracy: 0.9553 - val_loss: 0.8520 - val_accuracy: 0.7769\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2823 - accuracy: 0.9634 - val_loss: 0.8591 - val_accuracy: 0.7737\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2866 - accuracy: 0.9582 - val_loss: 0.8634 - val_accuracy: 0.7780\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2853 - accuracy: 0.9580 - val_loss: 0.8780 - val_accuracy: 0.7780\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2800 - accuracy: 0.9634 - val_loss: 0.8981 - val_accuracy: 0.7672\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2921 - accuracy: 0.9534 - val_loss: 0.9573 - val_accuracy: 0.7565\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2805 - accuracy: 0.9601 - val_loss: 0.8862 - val_accuracy: 0.7705\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2812 - accuracy: 0.9604 - val_loss: 0.8978 - val_accuracy: 0.7716\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2903 - accuracy: 0.9561 - val_loss: 0.8984 - val_accuracy: 0.7737\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2798 - accuracy: 0.9620 - val_loss: 0.9134 - val_accuracy: 0.7651\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2860 - accuracy: 0.9585 - val_loss: 0.8690 - val_accuracy: 0.7748\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2823 - accuracy: 0.9601 - val_loss: 0.9187 - val_accuracy: 0.7640\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2783 - accuracy: 0.9642 - val_loss: 0.8861 - val_accuracy: 0.7769\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2899 - accuracy: 0.9566 - val_loss: 0.9349 - val_accuracy: 0.7651\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2774 - accuracy: 0.9615 - val_loss: 0.9249 - val_accuracy: 0.7694\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2765 - accuracy: 0.9623 - val_loss: 0.9556 - val_accuracy: 0.7586\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2899 - accuracy: 0.9558 - val_loss: 0.8862 - val_accuracy: 0.7802\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2768 - accuracy: 0.9599 - val_loss: 0.9380 - val_accuracy: 0.7608\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2747 - accuracy: 0.9626 - val_loss: 0.8860 - val_accuracy: 0.7791\n","{'loss': [0.45553481578826904, 0.4351983666419983, 0.40412482619285583, 0.411255806684494, 0.3940923511981964, 0.40544772148132324, 0.4034171998500824, 0.3850521445274353, 0.385995477437973, 0.39279845356941223, 0.3874755799770355, 0.39984333515167236, 0.3849528133869171, 0.37282636761665344, 0.3725837171077728, 0.40791523456573486, 0.37295711040496826, 0.3676605820655823, 0.36371955275535583, 0.36800429224967957, 0.3707284927368164, 0.36264756321907043, 0.36261364817619324, 0.3621390163898468, 0.34963080286979675, 0.38806846737861633, 0.38102591037750244, 0.3670530319213867, 0.3552931845188141, 0.3416116535663605, 0.35377389192581177, 0.34901517629623413, 0.3518286645412445, 0.34179186820983887, 0.3468433916568756, 0.34258124232292175, 0.3496769964694977, 0.3391338586807251, 0.34263837337493896, 0.33789995312690735, 0.33383968472480774, 0.33500930666923523, 0.3312360644340515, 0.33136290311813354, 0.3501025140285492, 0.3518924117088318, 0.33222728967666626, 0.36025193333625793, 0.3309905529022217, 0.3435900807380676, 0.32332557439804077, 0.3215121626853943, 0.32185834646224976, 0.3203698992729187, 0.31301289796829224, 0.31873342394828796, 0.32233133912086487, 0.3103388845920563, 0.31615889072418213, 0.31167951226234436, 0.31904345750808716, 0.3213491141796112, 0.31552696228027344, 0.3087199926376343, 0.30178046226501465, 0.3161379098892212, 0.3080008029937744, 0.30413368344306946, 0.3061656355857849, 0.31070515513420105, 0.30278217792510986, 0.3116695284843445, 0.3129548728466034, 0.31273800134658813, 0.2978244721889496, 0.2990882992744446, 0.30190160870552063, 0.30053022503852844, 0.3000375032424927, 0.2962028682231903, 0.2983691692352295, 0.2943248450756073, 0.28227391839027405, 0.2866499722003937, 0.28530555963516235, 0.2799797058105469, 0.29212287068367004, 0.2805078327655792, 0.2812080979347229, 0.2902776598930359, 0.2797973155975342, 0.28597381711006165, 0.2822783589363098, 0.2783066928386688, 0.28989389538764954, 0.2774476408958435, 0.2764947712421417, 0.28991127014160156, 0.2768145799636841, 0.27467429637908936], 'accuracy': [0.8879310488700867, 0.8943965435028076, 0.9105603694915771, 0.9089439511299133, 0.9146012663841248, 0.9097521305084229, 0.9102909564971924, 0.9213362336158752, 0.9183728694915771, 0.9135237336158752, 0.9148706793785095, 0.9119073152542114, 0.9178340435028076, 0.9240301847457886, 0.921875, 0.9081357717514038, 0.9278017282485962, 0.9299569129943848, 0.9299569129943848, 0.9318426847457886, 0.9242995977401733, 0.9278017282485962, 0.9302262663841248, 0.9286099076271057, 0.9369612336158752, 0.9151400923728943, 0.9151400923728943, 0.9229525923728943, 0.9307650923728943, 0.9380387663841248, 0.928340494632721, 0.9339978694915771, 0.9318426847457886, 0.9396551847457886, 0.9364224076271057, 0.9366918206214905, 0.9329202771186829, 0.9350754022598267, 0.9385775923728943, 0.9393857717514038, 0.9410021305084229, 0.9383081793785095, 0.9412715435028076, 0.9420797228813171, 0.9278017282485962, 0.9331896305084229, 0.9418103694915771, 0.9242995977401733, 0.938847005367279, 0.9315732717514038, 0.9458512663841248, 0.946659505367279, 0.9477370977401733, 0.946659505367279, 0.9498922228813171, 0.951777994632721, 0.9442349076271057, 0.9533944129943848, 0.9458512663841248, 0.951508641242981, 0.9463900923728943, 0.9420797228813171, 0.9490840435028076, 0.9501616358757019, 0.9587823152542114, 0.9471982717514038, 0.9507004022598267, 0.951777994632721, 0.9512392282485962, 0.9463900923728943, 0.9512392282485962, 0.946659505367279, 0.9488146305084229, 0.943696141242981, 0.9571659564971924, 0.9542025923728943, 0.9501616358757019, 0.9528555870056152, 0.9507004022598267, 0.954741358757019, 0.9560883641242981, 0.9552801847457886, 0.9633620977401733, 0.9582435488700867, 0.9579741358757019, 0.9633620977401733, 0.9533944129943848, 0.9601293206214905, 0.9603987336158752, 0.9560883641242981, 0.9620150923728943, 0.9585129022598267, 0.9601293206214905, 0.9641702771186829, 0.9566271305084229, 0.9614762663841248, 0.962284505367279, 0.9558189511299133, 0.9598599076271057, 0.962553858757019], 'val_loss': [0.8966469168663025, 0.8815218210220337, 0.8677710890769958, 0.8600302934646606, 0.8467331528663635, 0.8398944139480591, 0.8351666927337646, 0.8371642827987671, 0.8384827375411987, 0.8380578756332397, 0.8554501533508301, 0.8551629185676575, 0.9109297394752502, 0.9086654186248779, 1.0351593494415283, 0.967920184135437, 0.9165772795677185, 0.9543651342391968, 1.0880147218704224, 1.0520670413970947, 0.9256936311721802, 0.9202517867088318, 0.9376815557479858, 0.9461212754249573, 0.9190438985824585, 0.7108941674232483, 0.7098263502120972, 0.713996410369873, 0.7255376577377319, 0.7443511486053467, 0.7398576140403748, 0.7464148998260498, 0.7374706864356995, 0.8269546031951904, 0.7500042915344238, 0.7633073925971985, 0.7881709337234497, 0.8059820532798767, 0.7860110998153687, 0.7650725245475769, 0.7834168672561646, 0.7737916707992554, 0.7674666047096252, 0.8417117595672607, 0.767119824886322, 0.7943229675292969, 0.7845713496208191, 0.826979398727417, 0.7838819622993469, 0.9540933966636658, 0.8313621282577515, 0.8032527565956116, 0.8509615063667297, 0.8443955779075623, 0.7824450135231018, 0.8403856158256531, 0.8206979632377625, 0.8444808721542358, 0.7953255772590637, 0.8080093860626221, 0.8052396178245544, 0.826875627040863, 0.8376370072364807, 0.8820717930793762, 0.8137073516845703, 0.9379589557647705, 0.8324909210205078, 0.823618471622467, 0.8192201256752014, 0.8259631991386414, 0.8744392991065979, 0.8477156162261963, 0.85248863697052, 0.8384265303611755, 0.815451979637146, 0.8969351649284363, 0.8491340279579163, 0.8379402160644531, 0.9141480922698975, 0.8402431607246399, 0.8445753455162048, 0.8519529700279236, 0.8591411113739014, 0.8634324669837952, 0.8779522180557251, 0.8981378078460693, 0.9572554230690002, 0.886222243309021, 0.8978120684623718, 0.8983914852142334, 0.9133893847465515, 0.8690407872200012, 0.9187033176422119, 0.8860875368118286, 0.9349347352981567, 0.9249250292778015, 0.9555968046188354, 0.8861918449401855, 0.9379537105560303, 0.8860068917274475], 'val_accuracy': [0.48491379618644714, 0.4924568831920624, 0.5258620977401733, 0.5441810488700867, 0.6023706793785095, 0.6260775923728943, 0.6400862336158752, 0.6336206793785095, 0.6271551847457886, 0.6293103694915771, 0.6099137663841248, 0.6142241358757019, 0.5840517282485962, 0.6088362336158752, 0.5711206793785095, 0.607758641242981, 0.6379310488700867, 0.6379310488700867, 0.6099137663841248, 0.6357758641242981, 0.6670258641242981, 0.6907327771186829, 0.6875, 0.6982758641242981, 0.712284505367279, 0.7769396305084229, 0.7823275923728943, 0.7834051847457886, 0.795258641242981, 0.787715494632721, 0.795258641242981, 0.7974137663841248, 0.795258641242981, 0.7683189511299133, 0.8038793206214905, 0.7920258641242981, 0.7834051847457886, 0.7726293206214905, 0.7855603694915771, 0.7963362336158752, 0.7855603694915771, 0.7963362336158752, 0.7974137663841248, 0.7715517282485962, 0.798491358757019, 0.7855603694915771, 0.7844827771186829, 0.7629310488700867, 0.7866379022598267, 0.7424569129943848, 0.7737069129943848, 0.7758620977401733, 0.7693965435028076, 0.7726293206214905, 0.7974137663841248, 0.7693965435028076, 0.7758620977401733, 0.7726293206214905, 0.7963362336158752, 0.7844827771186829, 0.787715494632721, 0.7801724076271057, 0.7758620977401733, 0.7661637663841248, 0.7855603694915771, 0.764008641242981, 0.7898706793785095, 0.78125, 0.7855603694915771, 0.7801724076271057, 0.767241358757019, 0.774784505367279, 0.78125, 0.7769396305084229, 0.78125, 0.7726293206214905, 0.7801724076271057, 0.798491358757019, 0.7629310488700867, 0.7941810488700867, 0.787715494632721, 0.7769396305084229, 0.7737069129943848, 0.7780172228813171, 0.7780172228813171, 0.767241358757019, 0.756465494632721, 0.7704741358757019, 0.7715517282485962, 0.7737069129943848, 0.7650862336158752, 0.774784505367279, 0.764008641242981, 0.7769396305084229, 0.7650862336158752, 0.7693965435028076, 0.7586206793785095, 0.7801724076271057, 0.7607758641242981, 0.7790948152542114]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.4472 - accuracy: 0.8906"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 58ms/step - loss: 0.4489 - accuracy: 0.8899 - val_loss: 0.8870 - val_accuracy: 0.4966\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3916 - accuracy: 0.9177 - val_loss: 0.8795 - val_accuracy: 0.5023\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4095 - accuracy: 0.9012 - val_loss: 0.8676 - val_accuracy: 0.5170\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4040 - accuracy: 0.9095 - val_loss: 0.8571 - val_accuracy: 0.5781\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3902 - accuracy: 0.9205 - val_loss: 0.8513 - val_accuracy: 0.5928\n","Epoch 6/100\n","28/28 [==============================] - 4s 133ms/step - loss: 0.3929 - accuracy: 0.9143 - val_loss: 0.8433 - val_accuracy: 0.6176\n","Epoch 7/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4035 - accuracy: 0.9032 - val_loss: 0.8410 - val_accuracy: 0.6346\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3743 - accuracy: 0.9244 - val_loss: 0.8359 - val_accuracy: 0.6346\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3789 - accuracy: 0.9256 - val_loss: 0.8415 - val_accuracy: 0.6165\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3807 - accuracy: 0.9188 - val_loss: 0.8400 - val_accuracy: 0.6176\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3768 - accuracy: 0.9222 - val_loss: 0.8372 - val_accuracy: 0.6267\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3750 - accuracy: 0.9199 - val_loss: 0.8420 - val_accuracy: 0.6244\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3792 - accuracy: 0.9134 - val_loss: 0.8557 - val_accuracy: 0.6188\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3680 - accuracy: 0.9228 - val_loss: 0.8908 - val_accuracy: 0.6086\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3615 - accuracy: 0.9298 - val_loss: 0.8870 - val_accuracy: 0.6199\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3652 - accuracy: 0.9270 - val_loss: 1.0021 - val_accuracy: 0.5882\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3854 - accuracy: 0.9145 - val_loss: 0.9238 - val_accuracy: 0.6324\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3676 - accuracy: 0.9242 - val_loss: 0.9595 - val_accuracy: 0.6278\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3665 - accuracy: 0.9208 - val_loss: 1.0118 - val_accuracy: 0.6346\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3726 - accuracy: 0.9219 - val_loss: 0.9878 - val_accuracy: 0.6459\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3525 - accuracy: 0.9318 - val_loss: 0.8709 - val_accuracy: 0.6934\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3631 - accuracy: 0.9256 - val_loss: 0.9572 - val_accuracy: 0.6878\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3621 - accuracy: 0.9290 - val_loss: 0.9803 - val_accuracy: 0.6867\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3683 - accuracy: 0.9228 - val_loss: 0.8458 - val_accuracy: 0.7240\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3491 - accuracy: 0.9310 - val_loss: 0.8995 - val_accuracy: 0.7262\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3516 - accuracy: 0.9293 - val_loss: 0.8216 - val_accuracy: 0.7477\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3561 - accuracy: 0.9281 - val_loss: 0.7044 - val_accuracy: 0.7907\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3564 - accuracy: 0.9264 - val_loss: 0.6822 - val_accuracy: 0.8043\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3440 - accuracy: 0.9369 - val_loss: 0.7072 - val_accuracy: 0.7873\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3485 - accuracy: 0.9338 - val_loss: 0.7460 - val_accuracy: 0.7794\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3520 - accuracy: 0.9284 - val_loss: 0.6974 - val_accuracy: 0.8066\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3613 - accuracy: 0.9273 - val_loss: 0.6949 - val_accuracy: 0.7885\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3523 - accuracy: 0.9270 - val_loss: 0.7661 - val_accuracy: 0.7862\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3367 - accuracy: 0.9392 - val_loss: 0.7175 - val_accuracy: 0.7998\n","Epoch 35/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3350 - accuracy: 0.9392 - val_loss: 0.7218 - val_accuracy: 0.8145\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3344 - accuracy: 0.9386 - val_loss: 0.7229 - val_accuracy: 0.8043\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3392 - accuracy: 0.9358 - val_loss: 0.7222 - val_accuracy: 0.7941\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3304 - accuracy: 0.9423 - val_loss: 0.7152 - val_accuracy: 0.8111\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3362 - accuracy: 0.9386 - val_loss: 0.7230 - val_accuracy: 0.7952\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3301 - accuracy: 0.9443 - val_loss: 0.7342 - val_accuracy: 0.8043\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.9406 - val_loss: 0.7270 - val_accuracy: 0.7975\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3223 - accuracy: 0.9431 - val_loss: 0.8139 - val_accuracy: 0.7726\n","Epoch 43/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3386 - accuracy: 0.9318 - val_loss: 0.7422 - val_accuracy: 0.7998\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3272 - accuracy: 0.9457 - val_loss: 0.7515 - val_accuracy: 0.8009\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3247 - accuracy: 0.9431 - val_loss: 0.7687 - val_accuracy: 0.7952\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3462 - accuracy: 0.9284 - val_loss: 0.7591 - val_accuracy: 0.7964\n","Epoch 47/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3195 - accuracy: 0.9505 - val_loss: 0.7635 - val_accuracy: 0.7964\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3285 - accuracy: 0.9411 - val_loss: 0.7508 - val_accuracy: 0.7975\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3137 - accuracy: 0.9493 - val_loss: 0.7696 - val_accuracy: 0.7964\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3156 - accuracy: 0.9434 - val_loss: 0.7456 - val_accuracy: 0.8054\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3116 - accuracy: 0.9499 - val_loss: 0.7787 - val_accuracy: 0.7896\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3265 - accuracy: 0.9403 - val_loss: 0.7444 - val_accuracy: 0.8032\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3153 - accuracy: 0.9477 - val_loss: 0.7767 - val_accuracy: 0.8009\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3130 - accuracy: 0.9460 - val_loss: 0.7614 - val_accuracy: 0.8032\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3069 - accuracy: 0.9488 - val_loss: 0.7684 - val_accuracy: 0.7986\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3086 - accuracy: 0.9474 - val_loss: 0.7908 - val_accuracy: 0.7941\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3108 - accuracy: 0.9485 - val_loss: 0.7832 - val_accuracy: 0.7952\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3041 - accuracy: 0.9493 - val_loss: 0.7810 - val_accuracy: 0.7952\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3102 - accuracy: 0.9510 - val_loss: 0.7863 - val_accuracy: 0.7975\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3092 - accuracy: 0.9491 - val_loss: 0.7692 - val_accuracy: 0.7885\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3009 - accuracy: 0.9496 - val_loss: 0.8658 - val_accuracy: 0.7738\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3166 - accuracy: 0.9443 - val_loss: 0.7811 - val_accuracy: 0.7975\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3122 - accuracy: 0.9445 - val_loss: 0.7824 - val_accuracy: 0.8020\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3068 - accuracy: 0.9457 - val_loss: 0.8062 - val_accuracy: 0.7919\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3091 - accuracy: 0.9457 - val_loss: 0.8031 - val_accuracy: 0.7885\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3001 - accuracy: 0.9530 - val_loss: 0.8509 - val_accuracy: 0.7805\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3038 - accuracy: 0.9502 - val_loss: 0.7918 - val_accuracy: 0.7986\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2992 - accuracy: 0.9505 - val_loss: 0.8522 - val_accuracy: 0.7907\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3003 - accuracy: 0.9499 - val_loss: 0.7903 - val_accuracy: 0.7930\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2988 - accuracy: 0.9479 - val_loss: 0.7927 - val_accuracy: 0.7964\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2978 - accuracy: 0.9516 - val_loss: 0.9818 - val_accuracy: 0.7500\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3202 - accuracy: 0.9414 - val_loss: 0.7994 - val_accuracy: 0.7771\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2850 - accuracy: 0.9590 - val_loss: 0.8011 - val_accuracy: 0.7862\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2939 - accuracy: 0.9502 - val_loss: 0.8322 - val_accuracy: 0.7986\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2838 - accuracy: 0.9593 - val_loss: 0.8357 - val_accuracy: 0.7896\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3114 - accuracy: 0.9451 - val_loss: 0.9066 - val_accuracy: 0.7692\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3001 - accuracy: 0.9493 - val_loss: 0.8379 - val_accuracy: 0.7919\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2978 - accuracy: 0.9547 - val_loss: 0.8507 - val_accuracy: 0.7839\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2973 - accuracy: 0.9493 - val_loss: 1.0791 - val_accuracy: 0.7308\n","Epoch 80/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3262 - accuracy: 0.9335 - val_loss: 0.7957 - val_accuracy: 0.7952\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2932 - accuracy: 0.9536 - val_loss: 0.8269 - val_accuracy: 0.7941\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2874 - accuracy: 0.9578 - val_loss: 0.8110 - val_accuracy: 0.7885\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2754 - accuracy: 0.9595 - val_loss: 0.8260 - val_accuracy: 0.7851\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2887 - accuracy: 0.9536 - val_loss: 0.8378 - val_accuracy: 0.7919\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2813 - accuracy: 0.9559 - val_loss: 0.8210 - val_accuracy: 0.7964\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2763 - accuracy: 0.9618 - val_loss: 0.8492 - val_accuracy: 0.7873\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2869 - accuracy: 0.9567 - val_loss: 0.8404 - val_accuracy: 0.7873\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2747 - accuracy: 0.9652 - val_loss: 0.8263 - val_accuracy: 0.8009\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2724 - accuracy: 0.9660 - val_loss: 0.8397 - val_accuracy: 0.7930\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2780 - accuracy: 0.9578 - val_loss: 0.8466 - val_accuracy: 0.7998\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2746 - accuracy: 0.9590 - val_loss: 0.8687 - val_accuracy: 0.7828\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2833 - accuracy: 0.9539 - val_loss: 0.9864 - val_accuracy: 0.7658\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2911 - accuracy: 0.9550 - val_loss: 0.8453 - val_accuracy: 0.7828\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2774 - accuracy: 0.9607 - val_loss: 0.8681 - val_accuracy: 0.7862\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2783 - accuracy: 0.9612 - val_loss: 0.8609 - val_accuracy: 0.7919\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2734 - accuracy: 0.9624 - val_loss: 0.8887 - val_accuracy: 0.7839\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2690 - accuracy: 0.9618 - val_loss: 0.8640 - val_accuracy: 0.7885\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2708 - accuracy: 0.9615 - val_loss: 0.8661 - val_accuracy: 0.7851\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2690 - accuracy: 0.9658 - val_loss: 0.8815 - val_accuracy: 0.7862\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2722 - accuracy: 0.9607 - val_loss: 0.8800 - val_accuracy: 0.7862\n","{'loss': [0.448920875787735, 0.3915817141532898, 0.4094848036766052, 0.40399304032325745, 0.39016735553741455, 0.39291587471961975, 0.403470903635025, 0.37430161237716675, 0.3789120614528656, 0.38065147399902344, 0.3767777979373932, 0.37495550513267517, 0.3791597783565521, 0.3680271506309509, 0.3615201711654663, 0.3652157783508301, 0.38542601466178894, 0.3676096796989441, 0.3664856255054474, 0.37258777022361755, 0.35249266028404236, 0.36312371492385864, 0.36207878589630127, 0.368305504322052, 0.3490760624408722, 0.3516283631324768, 0.35609638690948486, 0.3564467430114746, 0.3439665734767914, 0.3485155403614044, 0.3520318865776062, 0.36128494143486023, 0.3523346483707428, 0.3367118537425995, 0.33500000834465027, 0.33437955379486084, 0.3391622304916382, 0.33036062121391296, 0.336184024810791, 0.33007970452308655, 0.33326026797294617, 0.32225319743156433, 0.3385780453681946, 0.3271910548210144, 0.3246666193008423, 0.3461858332157135, 0.3194642961025238, 0.328490287065506, 0.31374475359916687, 0.31557777523994446, 0.311600923538208, 0.3264598250389099, 0.31529396772384644, 0.3130013942718506, 0.30686548352241516, 0.3085755407810211, 0.3107858896255493, 0.30411258339881897, 0.3101949095726013, 0.30919671058654785, 0.3008638620376587, 0.31655821204185486, 0.3121671974658966, 0.30681049823760986, 0.3090670108795166, 0.3001389503479004, 0.30381467938423157, 0.29915088415145874, 0.3002883493900299, 0.2988256514072418, 0.2978149354457855, 0.32022300362586975, 0.2850281298160553, 0.2938559055328369, 0.283817857503891, 0.3114388585090637, 0.30012813210487366, 0.2978460490703583, 0.29726922512054443, 0.3262411653995514, 0.2931968867778778, 0.28744298219680786, 0.2754145562648773, 0.2886578142642975, 0.281254380941391, 0.27630895376205444, 0.286862850189209, 0.274664968252182, 0.2723567485809326, 0.27801358699798584, 0.27455803751945496, 0.2833481729030609, 0.2911108434200287, 0.2774491608142853, 0.2783361077308655, 0.2733858823776245, 0.2690178453922272, 0.27082595229148865, 0.2690296769142151, 0.2721559405326843], 'accuracy': [0.8899264335632324, 0.9176570177078247, 0.9012450575828552, 0.9094510674476624, 0.9204866886138916, 0.9142614603042603, 0.9032257795333862, 0.9244481921195984, 0.9255800843238831, 0.9187889099121094, 0.9221844673156738, 0.9199207425117493, 0.9134125709533691, 0.9227504134178162, 0.9298245906829834, 0.9269949197769165, 0.914544403553009, 0.9241652488708496, 0.9207696914672852, 0.921901524066925, 0.9318053126335144, 0.9255800843238831, 0.9289756417274475, 0.9227504134178162, 0.9309564232826233, 0.9292586445808411, 0.9281267523765564, 0.9264289736747742, 0.9368987083435059, 0.9337860941886902, 0.92840975522995, 0.9272778630256653, 0.9269949197769165, 0.9391624331474304, 0.9391624331474304, 0.9385964870452881, 0.9357668161392212, 0.9422750473022461, 0.9385964870452881, 0.9442558288574219, 0.9405772686004639, 0.9431239366531372, 0.9318053126335144, 0.9456706047058105, 0.9431239366531372, 0.92840975522995, 0.9504810571670532, 0.9411431550979614, 0.9493491649627686, 0.943406879901886, 0.9499151110649109, 0.9402942657470703, 0.9476513862609863, 0.9459536075592041, 0.9487832188606262, 0.9473684430122375, 0.9485002756118774, 0.9493491649627686, 0.9510469436645508, 0.9490662217140198, 0.9496321678161621, 0.9442558288574219, 0.9445387721061707, 0.9456706047058105, 0.9456706047058105, 0.9530277252197266, 0.9501980543136597, 0.9504810571670532, 0.9499151110649109, 0.9479343295097351, 0.9516128897666931, 0.941426157951355, 0.9589700102806091, 0.9501980543136597, 0.9592529535293579, 0.945104718208313, 0.9493491649627686, 0.9547255039215088, 0.9493491649627686, 0.9335030913352966, 0.9535936713218689, 0.9578381180763245, 0.9595359563827515, 0.9535936713218689, 0.9558573961257935, 0.961799681186676, 0.9567062854766846, 0.9651952385902405, 0.9660441279411316, 0.9578381180763245, 0.9589700102806091, 0.9538766145706177, 0.9550085067749023, 0.9606677889823914, 0.9612337350845337, 0.9623655676841736, 0.961799681186676, 0.9615166783332825, 0.9657611846923828, 0.9606677889823914], 'val_loss': [0.887020468711853, 0.8794909119606018, 0.8675811886787415, 0.8570694923400879, 0.8513205647468567, 0.8433200120925903, 0.840959370136261, 0.8359319567680359, 0.8414899110794067, 0.8399804830551147, 0.8371975421905518, 0.8420302271842957, 0.8557085394859314, 0.8908277153968811, 0.8870221972465515, 1.0020699501037598, 0.9237669706344604, 0.9594987034797668, 1.0117897987365723, 0.9877792000770569, 0.8708612322807312, 0.9572485089302063, 0.9802528619766235, 0.8457823395729065, 0.8994547128677368, 0.8215904235839844, 0.7044168710708618, 0.6822150945663452, 0.7072450518608093, 0.7459604740142822, 0.6973881721496582, 0.694937527179718, 0.766065239906311, 0.7175480723381042, 0.7218441367149353, 0.7228938937187195, 0.7221543788909912, 0.7151879072189331, 0.722976565361023, 0.7341669797897339, 0.7269782423973083, 0.8138949871063232, 0.7422026991844177, 0.7515245079994202, 0.768652617931366, 0.7591413259506226, 0.7635130882263184, 0.7507614493370056, 0.7695672512054443, 0.7456374764442444, 0.7787485122680664, 0.7444043755531311, 0.7766633629798889, 0.7614144086837769, 0.7684270739555359, 0.7907816171646118, 0.7832158803939819, 0.7809785008430481, 0.7862810492515564, 0.7692326903343201, 0.8658019304275513, 0.7810812592506409, 0.7824326157569885, 0.8061936497688293, 0.8031484484672546, 0.8509364128112793, 0.79175865650177, 0.8521950840950012, 0.7902657985687256, 0.7927408218383789, 0.9817723035812378, 0.7993839383125305, 0.8010852336883545, 0.8322173953056335, 0.8356677889823914, 0.9066254496574402, 0.8378859162330627, 0.8506634831428528, 1.079075574874878, 0.7957419753074646, 0.8268881440162659, 0.8109593391418457, 0.826007604598999, 0.8378187417984009, 0.8209934830665588, 0.8491653800010681, 0.8403602242469788, 0.8262645602226257, 0.8397111892700195, 0.8465632796287537, 0.8686608076095581, 0.9864048957824707, 0.8452516198158264, 0.8680721521377563, 0.8609212040901184, 0.8887059688568115, 0.8639733791351318, 0.866107165813446, 0.8815044164657593, 0.8800359964370728], 'val_accuracy': [0.49660632014274597, 0.5022624731063843, 0.516968309879303, 0.5780543088912964, 0.5927602052688599, 0.6176470518112183, 0.6346153616905212, 0.6346153616905212, 0.6165158152580261, 0.6176470518112183, 0.6266968250274658, 0.6244344115257263, 0.6187782883644104, 0.6085972785949707, 0.6199095249176025, 0.5882353186607361, 0.6323529481887817, 0.627828061580658, 0.6346153616905212, 0.6459276080131531, 0.6934388875961304, 0.6877828240394592, 0.6866515874862671, 0.7239819169044495, 0.726244330406189, 0.7477375268936157, 0.790723979473114, 0.8042986392974854, 0.7873303294181824, 0.779411792755127, 0.8065611124038696, 0.7884615659713745, 0.7861990928649902, 0.7997737526893616, 0.814479649066925, 0.8042986392974854, 0.7941176295280457, 0.8110859990119934, 0.7952488660812378, 0.8042986392974854, 0.7975113391876221, 0.7726244330406189, 0.7997737526893616, 0.8009049892425537, 0.7952488660812378, 0.7963801026344299, 0.7963801026344299, 0.7975113391876221, 0.7963801026344299, 0.8054298758506775, 0.7895927429199219, 0.8031674027442932, 0.8009049892425537, 0.8031674027442932, 0.7986425161361694, 0.7941176295280457, 0.7952488660812378, 0.7952488660812378, 0.7975113391876221, 0.7884615659713745, 0.773755669593811, 0.7975113391876221, 0.8020362257957458, 0.7918552160263062, 0.7884615659713745, 0.7805429697036743, 0.7986425161361694, 0.790723979473114, 0.7929864525794983, 0.7963801026344299, 0.75, 0.7771493196487427, 0.7861990928649902, 0.7986425161361694, 0.7895927429199219, 0.7692307829856873, 0.7918552160263062, 0.7839366793632507, 0.7307692170143127, 0.7952488660812378, 0.7941176295280457, 0.7884615659713745, 0.7850678563117981, 0.7918552160263062, 0.7963801026344299, 0.7873303294181824, 0.7873303294181824, 0.8009049892425537, 0.7929864525794983, 0.7997737526893616, 0.7828054428100586, 0.7658371329307556, 0.7828054428100586, 0.7861990928649902, 0.7918552160263062, 0.7839366793632507, 0.7884615659713745, 0.7850678563117981, 0.7861990928649902, 0.7861990928649902]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.8829"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 54ms/step - loss: 0.4620 - accuracy: 0.8829 - val_loss: 0.8900 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4313 - accuracy: 0.8995 - val_loss: 0.8791 - val_accuracy: 0.4959\n","Epoch 3/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4242 - accuracy: 0.8992 - val_loss: 0.8664 - val_accuracy: 0.5186\n","Epoch 4/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4185 - accuracy: 0.9023 - val_loss: 0.8554 - val_accuracy: 0.5640\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4151 - accuracy: 0.9003 - val_loss: 0.8421 - val_accuracy: 0.6250\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4083 - accuracy: 0.9109 - val_loss: 0.8323 - val_accuracy: 0.6539\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4075 - accuracy: 0.9031 - val_loss: 0.8253 - val_accuracy: 0.6467\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4027 - accuracy: 0.9103 - val_loss: 0.8323 - val_accuracy: 0.6364\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4157 - accuracy: 0.9072 - val_loss: 0.8236 - val_accuracy: 0.6353\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4036 - accuracy: 0.9093 - val_loss: 0.8453 - val_accuracy: 0.6147\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4004 - accuracy: 0.9052 - val_loss: 0.8531 - val_accuracy: 0.6136\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3892 - accuracy: 0.9116 - val_loss: 0.8418 - val_accuracy: 0.6364\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4051 - accuracy: 0.9044 - val_loss: 0.9123 - val_accuracy: 0.6002\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3932 - accuracy: 0.9158 - val_loss: 0.9230 - val_accuracy: 0.6054\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3949 - accuracy: 0.9158 - val_loss: 0.9034 - val_accuracy: 0.6157\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.9096 - val_loss: 0.9647 - val_accuracy: 0.6074\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4037 - accuracy: 0.9106 - val_loss: 0.8913 - val_accuracy: 0.6498\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3897 - accuracy: 0.9183 - val_loss: 0.9743 - val_accuracy: 0.6291\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3852 - accuracy: 0.9168 - val_loss: 1.0175 - val_accuracy: 0.6343\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3828 - accuracy: 0.9134 - val_loss: 0.9570 - val_accuracy: 0.6653\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3809 - accuracy: 0.9204 - val_loss: 0.9244 - val_accuracy: 0.6839\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3831 - accuracy: 0.9214 - val_loss: 0.9342 - val_accuracy: 0.6973\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3759 - accuracy: 0.9225 - val_loss: 0.8208 - val_accuracy: 0.7366\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4026 - accuracy: 0.9057 - val_loss: 0.7948 - val_accuracy: 0.7469\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3793 - accuracy: 0.9207 - val_loss: 0.7795 - val_accuracy: 0.7593\n","Epoch 26/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3670 - accuracy: 0.9227 - val_loss: 0.7885 - val_accuracy: 0.7665\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3656 - accuracy: 0.9307 - val_loss: 0.8061 - val_accuracy: 0.7603\n","Epoch 28/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3652 - accuracy: 0.9266 - val_loss: 0.8143 - val_accuracy: 0.7769\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3762 - accuracy: 0.9207 - val_loss: 0.8177 - val_accuracy: 0.7717\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3772 - accuracy: 0.9155 - val_loss: 0.8275 - val_accuracy: 0.7727\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3854 - accuracy: 0.9085 - val_loss: 0.9045 - val_accuracy: 0.7541\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3802 - accuracy: 0.9204 - val_loss: 0.8290 - val_accuracy: 0.7758\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3595 - accuracy: 0.9300 - val_loss: 0.8419 - val_accuracy: 0.7655\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3541 - accuracy: 0.9333 - val_loss: 0.8456 - val_accuracy: 0.7665\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.9300 - val_loss: 0.8822 - val_accuracy: 0.7552\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3623 - accuracy: 0.9245 - val_loss: 0.8516 - val_accuracy: 0.7665\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3630 - accuracy: 0.9251 - val_loss: 0.8320 - val_accuracy: 0.7748\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3500 - accuracy: 0.9297 - val_loss: 0.8293 - val_accuracy: 0.7727\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3610 - accuracy: 0.9251 - val_loss: 0.8594 - val_accuracy: 0.7707\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3609 - accuracy: 0.9276 - val_loss: 0.8613 - val_accuracy: 0.7665\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3509 - accuracy: 0.9297 - val_loss: 0.8828 - val_accuracy: 0.7624\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3676 - accuracy: 0.9212 - val_loss: 0.9520 - val_accuracy: 0.7500\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3527 - accuracy: 0.9282 - val_loss: 0.8350 - val_accuracy: 0.7789\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3539 - accuracy: 0.9310 - val_loss: 0.8335 - val_accuracy: 0.7748\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3433 - accuracy: 0.9377 - val_loss: 0.8924 - val_accuracy: 0.7562\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.9367 - val_loss: 0.8624 - val_accuracy: 0.7603\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3436 - accuracy: 0.9367 - val_loss: 0.8646 - val_accuracy: 0.7696\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3567 - accuracy: 0.9253 - val_loss: 0.8656 - val_accuracy: 0.7686\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3439 - accuracy: 0.9326 - val_loss: 0.9119 - val_accuracy: 0.7552\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3636 - accuracy: 0.9235 - val_loss: 0.8572 - val_accuracy: 0.7696\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3492 - accuracy: 0.9307 - val_loss: 0.8691 - val_accuracy: 0.7738\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3486 - accuracy: 0.9318 - val_loss: 0.9884 - val_accuracy: 0.7407\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3468 - accuracy: 0.9313 - val_loss: 0.8898 - val_accuracy: 0.7593\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3364 - accuracy: 0.9339 - val_loss: 0.8692 - val_accuracy: 0.7696\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3277 - accuracy: 0.9437 - val_loss: 0.8623 - val_accuracy: 0.7758\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3259 - accuracy: 0.9447 - val_loss: 0.9005 - val_accuracy: 0.7655\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3282 - accuracy: 0.9413 - val_loss: 0.8978 - val_accuracy: 0.7665\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3235 - accuracy: 0.9419 - val_loss: 0.8727 - val_accuracy: 0.7707\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3323 - accuracy: 0.9351 - val_loss: 0.9738 - val_accuracy: 0.7459\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3346 - accuracy: 0.9333 - val_loss: 0.8607 - val_accuracy: 0.7634\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3310 - accuracy: 0.9388 - val_loss: 0.9116 - val_accuracy: 0.7531\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3311 - accuracy: 0.9333 - val_loss: 0.9607 - val_accuracy: 0.7562\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3296 - accuracy: 0.9370 - val_loss: 0.9271 - val_accuracy: 0.7500\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3399 - accuracy: 0.9349 - val_loss: 0.9129 - val_accuracy: 0.7655\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3395 - accuracy: 0.9328 - val_loss: 0.9021 - val_accuracy: 0.7676\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3547 - accuracy: 0.9256 - val_loss: 0.9167 - val_accuracy: 0.7572\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3336 - accuracy: 0.9408 - val_loss: 0.9053 - val_accuracy: 0.7614\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3144 - accuracy: 0.9465 - val_loss: 0.9100 - val_accuracy: 0.7624\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3281 - accuracy: 0.9401 - val_loss: 0.8908 - val_accuracy: 0.7603\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3276 - accuracy: 0.9364 - val_loss: 0.9478 - val_accuracy: 0.7603\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3336 - accuracy: 0.9357 - val_loss: 0.9130 - val_accuracy: 0.7583\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3160 - accuracy: 0.9447 - val_loss: 0.9148 - val_accuracy: 0.7583\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3231 - accuracy: 0.9424 - val_loss: 0.9321 - val_accuracy: 0.7531\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3132 - accuracy: 0.9496 - val_loss: 1.0334 - val_accuracy: 0.7397\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3449 - accuracy: 0.9302 - val_loss: 0.8996 - val_accuracy: 0.7603\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3064 - accuracy: 0.9475 - val_loss: 0.9342 - val_accuracy: 0.7490\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3090 - accuracy: 0.9488 - val_loss: 0.9385 - val_accuracy: 0.7603\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3077 - accuracy: 0.9463 - val_loss: 0.9771 - val_accuracy: 0.7614\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3056 - accuracy: 0.9501 - val_loss: 0.9506 - val_accuracy: 0.7593\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3113 - accuracy: 0.9470 - val_loss: 0.9649 - val_accuracy: 0.7521\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3013 - accuracy: 0.9468 - val_loss: 0.9567 - val_accuracy: 0.7552\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2902 - accuracy: 0.9566 - val_loss: 0.9641 - val_accuracy: 0.7593\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3003 - accuracy: 0.9468 - val_loss: 0.9462 - val_accuracy: 0.7655\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3052 - accuracy: 0.9473 - val_loss: 1.0216 - val_accuracy: 0.7366\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3048 - accuracy: 0.9496 - val_loss: 0.9664 - val_accuracy: 0.7459\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3007 - accuracy: 0.9486 - val_loss: 1.0668 - val_accuracy: 0.7283\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2927 - accuracy: 0.9550 - val_loss: 0.9937 - val_accuracy: 0.7562\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3108 - accuracy: 0.9401 - val_loss: 1.1128 - val_accuracy: 0.7304\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3021 - accuracy: 0.9460 - val_loss: 0.9686 - val_accuracy: 0.7603\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3020 - accuracy: 0.9491 - val_loss: 0.9918 - val_accuracy: 0.7510\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2971 - accuracy: 0.9522 - val_loss: 1.0951 - val_accuracy: 0.7283\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2963 - accuracy: 0.9530 - val_loss: 1.0384 - val_accuracy: 0.7521\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3006 - accuracy: 0.9468 - val_loss: 0.9603 - val_accuracy: 0.7603\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2858 - accuracy: 0.9579 - val_loss: 1.0141 - val_accuracy: 0.7500\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2939 - accuracy: 0.9525 - val_loss: 0.9839 - val_accuracy: 0.7593\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2933 - accuracy: 0.9535 - val_loss: 0.9994 - val_accuracy: 0.7572\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2935 - accuracy: 0.9506 - val_loss: 0.9969 - val_accuracy: 0.7552\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2874 - accuracy: 0.9576 - val_loss: 1.0226 - val_accuracy: 0.7500\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2873 - accuracy: 0.9535 - val_loss: 0.9975 - val_accuracy: 0.7624\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3072 - accuracy: 0.9447 - val_loss: 1.2657 - val_accuracy: 0.7056\n","{'loss': [0.46203675866127014, 0.43132781982421875, 0.42422613501548767, 0.41845521330833435, 0.41510123014450073, 0.40827125310897827, 0.4074520170688629, 0.4026896357536316, 0.41571441292762756, 0.40361717343330383, 0.4003971517086029, 0.38921719789505005, 0.4050504267215729, 0.3932340741157532, 0.3949049711227417, 0.3924289643764496, 0.4037150740623474, 0.3897404372692108, 0.38521796464920044, 0.3827963173389435, 0.38092362880706787, 0.3830985724925995, 0.3759346604347229, 0.4025576710700989, 0.37927863001823425, 0.36697879433631897, 0.3655741512775421, 0.3652401566505432, 0.3762376010417938, 0.37722551822662354, 0.38538309931755066, 0.3801518976688385, 0.3594634234905243, 0.3541363775730133, 0.3581112325191498, 0.362305223941803, 0.3630002737045288, 0.34995409846305847, 0.3610256314277649, 0.3609066903591156, 0.3508877754211426, 0.36760783195495605, 0.3526969850063324, 0.35387086868286133, 0.34332844614982605, 0.34044185280799866, 0.3436335623264313, 0.35674092173576355, 0.343886137008667, 0.3636389970779419, 0.3491973876953125, 0.3486148416996002, 0.34676018357276917, 0.33643659949302673, 0.32766100764274597, 0.3258863687515259, 0.3281880021095276, 0.32347604632377625, 0.33234143257141113, 0.33457085490226746, 0.3310401141643524, 0.3311290144920349, 0.32961371541023254, 0.3398740589618683, 0.3395015299320221, 0.35474005341529846, 0.3335857093334198, 0.31440770626068115, 0.3281281292438507, 0.327580064535141, 0.3336361050605774, 0.3159857988357544, 0.32307150959968567, 0.3131859004497528, 0.34489622712135315, 0.30644118785858154, 0.3090116083621979, 0.3076881170272827, 0.30555862188339233, 0.3112635910511017, 0.30133843421936035, 0.2902348041534424, 0.3003403842449188, 0.3051721751689911, 0.3047826886177063, 0.30070197582244873, 0.29267528653144836, 0.3107922375202179, 0.3021318316459656, 0.30201590061187744, 0.2971058487892151, 0.29631590843200684, 0.3005640506744385, 0.28581857681274414, 0.2939450740814209, 0.2932971715927124, 0.2934597134590149, 0.28742459416389465, 0.28726330399513245, 0.3072379231452942], 'accuracy': [0.882945716381073, 0.8994832038879395, 0.8992248177528381, 0.9023255705833435, 0.9002584218978882, 0.9108527302742004, 0.9031007885932922, 0.910335898399353, 0.9072351455688477, 0.9093023538589478, 0.9051679372787476, 0.9116278886795044, 0.9043927788734436, 0.9157622456550598, 0.9157622456550598, 0.9095607399940491, 0.9105943441390991, 0.9183462262153625, 0.9167958498001099, 0.9134367108345032, 0.9204134345054626, 0.9214470386505127, 0.9224806427955627, 0.905684769153595, 0.920671820640564, 0.9227390289306641, 0.9307493567466736, 0.9266149997711182, 0.920671820640564, 0.9155038595199585, 0.908527135848999, 0.9204134345054626, 0.9299741387367249, 0.9333333373069763, 0.9299741387367249, 0.9245477914810181, 0.9250646233558655, 0.9297157526016235, 0.9250646233558655, 0.9276486039161682, 0.9297157526016235, 0.9211886525154114, 0.9281653761863708, 0.9310077428817749, 0.9377260804176331, 0.9366925358772278, 0.9366925358772278, 0.9253230094909668, 0.9325581192970276, 0.923514187335968, 0.9307493567466736, 0.9317829608917236, 0.9312661290168762, 0.933850109577179, 0.9436692595481873, 0.9447028636932373, 0.9413436651229858, 0.9418604373931885, 0.9351420998573303, 0.9333333373069763, 0.9387596845626831, 0.9333333373069763, 0.9369509220123291, 0.934883713722229, 0.9328165650367737, 0.9255813956260681, 0.9408268928527832, 0.9465116262435913, 0.9400516748428345, 0.9364340901374817, 0.9356589317321777, 0.9447028636932373, 0.9423772692680359, 0.9496123790740967, 0.930232584476471, 0.9475452303886414, 0.9488372206687927, 0.94625324010849, 0.9501292109489441, 0.947028398513794, 0.9467700123786926, 0.9565891623497009, 0.9467700123786926, 0.94728684425354, 0.9496123790740967, 0.9485788345336914, 0.9550387859344482, 0.9400516748428345, 0.9459948539733887, 0.949095606803894, 0.9521963596343994, 0.9529715776443481, 0.9467700123786926, 0.9578811526298523, 0.9524548053741455, 0.9534883499145508, 0.9506459832191467, 0.957622766494751, 0.9534883499145508, 0.9447028636932373], 'val_loss': [0.8899878859519958, 0.8791132569313049, 0.8664282560348511, 0.8553921580314636, 0.8421069979667664, 0.8322601914405823, 0.8253400921821594, 0.8323455452919006, 0.8236066102981567, 0.8452891111373901, 0.8530592322349548, 0.8417763710021973, 0.9122658371925354, 0.9230403304100037, 0.9034261107444763, 0.96473628282547, 0.8913185596466064, 0.9743392467498779, 1.0175108909606934, 0.9569838047027588, 0.9244435429573059, 0.9341766238212585, 0.8207774758338928, 0.7947637438774109, 0.7794867753982544, 0.7885488867759705, 0.8061379194259644, 0.814250648021698, 0.8177178502082825, 0.8274611234664917, 0.904516339302063, 0.8290227055549622, 0.8418887853622437, 0.8455561399459839, 0.8821955919265747, 0.851611316204071, 0.8319661617279053, 0.8292993307113647, 0.8594141602516174, 0.8612502813339233, 0.8828002214431763, 0.9519920945167542, 0.8350046277046204, 0.8335469961166382, 0.8924497365951538, 0.8623919486999512, 0.8645792603492737, 0.8655758500099182, 0.911902666091919, 0.8572345972061157, 0.8691393136978149, 0.9884030222892761, 0.8897534012794495, 0.869166910648346, 0.8622723817825317, 0.9004510641098022, 0.8978469371795654, 0.8726505041122437, 0.9737759232521057, 0.8607377409934998, 0.9115664958953857, 0.9607468247413635, 0.9271434545516968, 0.9128795862197876, 0.9020939469337463, 0.9166887998580933, 0.90526282787323, 0.9099526405334473, 0.8907936811447144, 0.9478312134742737, 0.913027286529541, 0.9147875308990479, 0.9321144819259644, 1.033440113067627, 0.8996412754058838, 0.9342172741889954, 0.9384526014328003, 0.9771214127540588, 0.9505940675735474, 0.9648516774177551, 0.9566968083381653, 0.964124858379364, 0.9462435245513916, 1.0216374397277832, 0.9664482474327087, 1.0668426752090454, 0.9937146306037903, 1.1127821207046509, 0.9686290621757507, 0.9917832612991333, 1.095077633857727, 1.0383707284927368, 0.9603359699249268, 1.0140899419784546, 0.9839098453521729, 0.9994285106658936, 0.9968668222427368, 1.022552728652954, 0.9975383877754211, 1.2656826972961426], 'val_accuracy': [0.48553720116615295, 0.4958677589893341, 0.5185950398445129, 0.5640496015548706, 0.625, 0.6539255976676941, 0.6466942429542542, 0.6363636255264282, 0.6353305578231812, 0.6146694421768188, 0.6136363744735718, 0.6363636255264282, 0.6002066135406494, 0.60537189245224, 0.6157024502754211, 0.6074380278587341, 0.6497933864593506, 0.6291322112083435, 0.6342975497245789, 0.6652892827987671, 0.68388432264328, 0.6973140239715576, 0.7365702390670776, 0.7469007968902588, 0.7592975497245789, 0.7665289044380188, 0.7603305578231812, 0.7768595218658447, 0.7716942429542542, 0.7727272510528564, 0.7541322112083435, 0.7758264541625977, 0.7654958963394165, 0.7665289044380188, 0.7551652789115906, 0.7665289044380188, 0.7747933864593506, 0.7727272510528564, 0.7706611752510071, 0.7665289044380188, 0.7623966932296753, 0.75, 0.7789255976676941, 0.7747933864593506, 0.7561983466148376, 0.7603305578231812, 0.76962810754776, 0.7685950398445129, 0.7551652789115906, 0.76962810754776, 0.7737603187561035, 0.7407024502754211, 0.7592975497245789, 0.76962810754776, 0.7758264541625977, 0.7654958963394165, 0.7665289044380188, 0.7706611752510071, 0.7458677887916565, 0.7634297609329224, 0.7530992031097412, 0.7561983466148376, 0.75, 0.7654958963394165, 0.7675619721412659, 0.7572314143180847, 0.7613636255264282, 0.7623966932296753, 0.7603305578231812, 0.7603305578231812, 0.7582644820213318, 0.7582644820213318, 0.7530992031097412, 0.7396694421768188, 0.7603305578231812, 0.7489669322967529, 0.7603305578231812, 0.7613636255264282, 0.7592975497245789, 0.7520661354064941, 0.7551652789115906, 0.7592975497245789, 0.7654958963394165, 0.7365702390670776, 0.7458677887916565, 0.7283057570457458, 0.7561983466148376, 0.73037189245224, 0.7603305578231812, 0.7510330677032471, 0.7283057570457458, 0.7520661354064941, 0.7603305578231812, 0.75, 0.7592975497245789, 0.7572314143180847, 0.7551652789115906, 0.75, 0.7623966932296753, 0.7055785059928894]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wylZACobKb2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"vUq_mraXKdzB","executionInfo":{"status":"ok","timestamp":1717439089512,"user_tz":-360,"elapsed":21,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"4bb7da00-a894-4a6d-8807-689c26cfabd2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.666667   0.711253  0.561139  0.627341     0.561139     0.772194   \n","1        1  0.672316   0.714035  0.574859  0.636933     0.574859     0.769774   \n","2        2  0.647590   0.623946  0.742972  0.678277     0.742972     0.552209   \n","3        0  0.681742   0.725572  0.584590  0.647495     0.584590     0.778894   \n","4        1  0.701977   0.730645  0.639831  0.682229     0.639831     0.764124   \n","5        2  0.650602   0.622150  0.767068  0.687050     0.767068     0.534137   \n","6        0  0.723618   0.761252  0.651591  0.702166     0.651591     0.795645   \n","7        1  0.716808   0.717730  0.714689  0.716207     0.714689     0.718927   \n","8        2  0.719880   0.692443  0.791165  0.738519     0.791165     0.648594   \n","9        0  0.746231   0.759717  0.720268  0.739467     0.720268     0.772194   \n","10       1  0.734463   0.746291  0.710452  0.727931     0.710452     0.758475   \n","11       2  0.768072   0.750469  0.803213  0.775946     0.803213     0.732932   \n","12       0  0.784757   0.798246  0.762144  0.779777     0.762144     0.807370   \n","13       1  0.771186   0.774286  0.765537  0.769886     0.765537     0.776836   \n","14       2  0.790161   0.766114  0.835341  0.799232     0.835341     0.744980   \n","\n","       Kappa  \n","0   0.333333  \n","1   0.344633  \n","2   0.295181  \n","3   0.363484  \n","4   0.403955  \n","5   0.301205  \n","6   0.447236  \n","7   0.433616  \n","8   0.439759  \n","9   0.492462  \n","10  0.468927  \n","11  0.536145  \n","12  0.569514  \n","13  0.542373  \n","14  0.580321  "],"text/html":["\n","  <div id=\"df-b8b61e6c-3011-48f9-9260-23c6f2b2255a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.666667</td>\n","      <td>0.711253</td>\n","      <td>0.561139</td>\n","      <td>0.627341</td>\n","      <td>0.561139</td>\n","      <td>0.772194</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.672316</td>\n","      <td>0.714035</td>\n","      <td>0.574859</td>\n","      <td>0.636933</td>\n","      <td>0.574859</td>\n","      <td>0.769774</td>\n","      <td>0.344633</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.647590</td>\n","      <td>0.623946</td>\n","      <td>0.742972</td>\n","      <td>0.678277</td>\n","      <td>0.742972</td>\n","      <td>0.552209</td>\n","      <td>0.295181</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.681742</td>\n","      <td>0.725572</td>\n","      <td>0.584590</td>\n","      <td>0.647495</td>\n","      <td>0.584590</td>\n","      <td>0.778894</td>\n","      <td>0.363484</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.701977</td>\n","      <td>0.730645</td>\n","      <td>0.639831</td>\n","      <td>0.682229</td>\n","      <td>0.639831</td>\n","      <td>0.764124</td>\n","      <td>0.403955</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.650602</td>\n","      <td>0.622150</td>\n","      <td>0.767068</td>\n","      <td>0.687050</td>\n","      <td>0.767068</td>\n","      <td>0.534137</td>\n","      <td>0.301205</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.723618</td>\n","      <td>0.761252</td>\n","      <td>0.651591</td>\n","      <td>0.702166</td>\n","      <td>0.651591</td>\n","      <td>0.795645</td>\n","      <td>0.447236</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.716808</td>\n","      <td>0.717730</td>\n","      <td>0.714689</td>\n","      <td>0.716207</td>\n","      <td>0.714689</td>\n","      <td>0.718927</td>\n","      <td>0.433616</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.719880</td>\n","      <td>0.692443</td>\n","      <td>0.791165</td>\n","      <td>0.738519</td>\n","      <td>0.791165</td>\n","      <td>0.648594</td>\n","      <td>0.439759</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.746231</td>\n","      <td>0.759717</td>\n","      <td>0.720268</td>\n","      <td>0.739467</td>\n","      <td>0.720268</td>\n","      <td>0.772194</td>\n","      <td>0.492462</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.734463</td>\n","      <td>0.746291</td>\n","      <td>0.710452</td>\n","      <td>0.727931</td>\n","      <td>0.710452</td>\n","      <td>0.758475</td>\n","      <td>0.468927</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.768072</td>\n","      <td>0.750469</td>\n","      <td>0.803213</td>\n","      <td>0.775946</td>\n","      <td>0.803213</td>\n","      <td>0.732932</td>\n","      <td>0.536145</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.784757</td>\n","      <td>0.798246</td>\n","      <td>0.762144</td>\n","      <td>0.779777</td>\n","      <td>0.762144</td>\n","      <td>0.807370</td>\n","      <td>0.569514</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.771186</td>\n","      <td>0.774286</td>\n","      <td>0.765537</td>\n","      <td>0.769886</td>\n","      <td>0.765537</td>\n","      <td>0.776836</td>\n","      <td>0.542373</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.790161</td>\n","      <td>0.766114</td>\n","      <td>0.835341</td>\n","      <td>0.799232</td>\n","      <td>0.835341</td>\n","      <td>0.744980</td>\n","      <td>0.580321</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b61e6c-3011-48f9-9260-23c6f2b2255a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b8b61e6c-3011-48f9-9260-23c6f2b2255a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b8b61e6c-3011-48f9-9260-23c6f2b2255a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f07062e5-1f7e-48b1-b27c-8dc88f6426da\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f07062e5-1f7e-48b1-b27c-8dc88f6426da')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f07062e5-1f7e-48b1-b27c-8dc88f6426da button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04773080672588271,\n        \"min\": 0.6475903614457831,\n        \"max\": 0.7901606425702812,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7462311557788944,\n          0.7680722891566265,\n          0.6666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.050232117326929934,\n        \"min\": 0.6221498371335505,\n        \"max\": 0.7982456140350878,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7597173144876325,\n          0.7504690431519699,\n          0.7112526539278131\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08689295037858409,\n        \"min\": 0.5611390284757118,\n        \"max\": 0.8353413654618473,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7202680067001676,\n          0.8032128514056225,\n          0.5611390284757118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054132146094205434,\n        \"min\": 0.6273408239700373,\n        \"max\": 0.7992315081652257,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7394668959587274,\n          0.7759456838021337,\n          0.6273408239700373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08689295037858409,\n        \"min\": 0.5611390284757118,\n        \"max\": 0.8353413654618473,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7202680067001676,\n          0.8032128514056225,\n          0.5611390284757118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08405692572351772,\n        \"min\": 0.5341365461847389,\n        \"max\": 0.8073701842546064,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7584745762711864,\n          0.8073701842546064,\n          0.7721943048576214\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09546161345176538,\n        \"min\": 0.29518072289156627,\n        \"max\": 0.5803212851405622,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.49246231155778897,\n          0.536144578313253,\n          0.33333333333333337\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_GRU/Theta_time_gru.csv', index = False)"],"metadata":{"id":"SMuQ_xYTKequ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-OoXW-WlLKix"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}