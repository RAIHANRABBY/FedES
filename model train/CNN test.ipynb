{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":30079,"status":"ok","timestamp":1710738770711,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"rBb4Qge7Jpji"},"outputs":[],"source":["%%capture\n","pip install mne"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3201,"status":"ok","timestamp":1710738773905,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"mECGGdpyHt5E"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import mne\n","import pywt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1997803,"status":"ok","timestamp":1710740771703,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"VjI7x3dkGTgC","outputId":"db2ea0b5-02bc-4ac6-b985-7a85b1d5386d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1143,"status":"ok","timestamp":1710741375667,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"9gslxn4FEE2V"},"outputs":[],"source":["%%capture\n","# folder = 'E:/Data WareHouse/1sec/Epileptic Seizure/equalized'\n","folder = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/equalized epoch'\n","epochs_path = [os.path.join(folder,i) for i in os.listdir(folder) if i[-3:]=='fif']"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":33473,"status":"ok","timestamp":1710741409138,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"0EPV0WFNKzcL"},"outputs":[],"source":["%%capture\n","# folder = 'E:/Data WareHouse/1sec/Epileptic Seizure/equalized'\n","# folder = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/equalized epoch'\n","# epochs_path = [os.path.join(folder,i) for i in os.listdir(folder) if i[-3:]=='fif']\n","\n","data= [mne.read_epochs(i).pick_types(eeg=True) for i in epochs_path]\n","labels = [mne.read_epochs(i).events[:,2] for i in epochs_path]\n","group = [[i]*len(j) for i,j in enumerate(data)]\n","X=np.vstack(data)\n","Y=np.hstack(labels)\n","group= np.hstack(group)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1710741409139,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"hQJA9euEEn6S","outputId":"7c8c13cb-1c67-413a-d195-cc17bac0a354"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5834, 29, 180) (5834,) (5834,)\n"]}],"source":["print(X.shape,Y.shape,group.shape)"]},{"cell_type":"markdown","metadata":{"id":"Li9z4hcFz53K"},"source":["# Feature Extraction methods"]},{"cell_type":"markdown","metadata":{"id":"EcluaJK1z9hw"},"source":["##Time-domain Features\n","\n","1. Mean (mean_val): The average value of the signal amplitude, representing the signal's central tendency.\n","\n","2. Median (median_val): The middle value of the signal amplitude when sorted, representing the central tendency of the signal, less sensitive to outliers than the mean.\n","\n","3. Variance (var_val): Measures the spread of the signal's amplitude.\n","\n","4. Standard Deviation (std_dev): The square root of the variance, representing the dispersion of the signal's amplitude.\n","\n","5. Skewness (skewness): Measures the asymmetry of the signal's amplitude distribution around the mean.\n","\n","6. Kurtosis (kurt): Measures the 'tailedness' of the signal's amplitude distribution, indicating the presence of outliers.\n","\n","7. Zero Crossing Rate (zcr): The rate at which the signal changes sign, indicating frequency content.\n","\n","8. Root Mean Square (rms_val): Represents the square root of the average of the squares of the signal, indicative of the signal's magnitude.\n","\n","9. Signal Energy (energy): The sum of the squares of the signal values, indicative of the signal's power.\n","\n","10. Crest Factor (crest_fact): The ratio of the peak amplitude of the waveform to the RMS value, indicating the extremeness of peaks.\n","\n","11. Shape Factor (shape_fact): The ratio of the RMS value to the mean absolute value, indicative of the waveform shape.\n","\n","12. Entropy (signal_entropy): Measures the unpredictability or complexity of the signal.\n","\n","13. Peak Amplitude (peak_amp): The difference between the maximum and minimum amplitude, indicating the signal's range.\n","\n","14. Number of Peaks (num_peaks): The count of local maxima, indicating the frequency of oscillations.\n","\n","15. Average Peak-to-Peak Distance (peak_to_peak_distance): The average distance between consecutive peaks, related to the periodicity of the signal.\n","\n","16. Hjorth Parameters:\n","\n","  Activity: Indicates the signal power.\n","\n","  Mobility: Indicates the mean frequency or the proportion of the standard deviation of the power spectrum.\n","  \n","  Complexity: Indicates the bandwidth of the signal or the change in frequency.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbNE0IwEJbPg"},"outputs":[],"source":["# import numpy as np\n","# from scipy.stats import skew, kurtosis\n","# from scipy.signal import find_peaks\n","\n","# def zero_crossing_rate(signal):\n","#     zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n","#     return len(zero_crossings) / len(signal)\n","\n","# def hjorth_parameters(signal):\n","#     diff_input = np.diff(signal)\n","#     diff_diff_input = np.diff(diff_input)\n","\n","#     activity = np.var(signal)\n","#     mobility = np.sqrt(np.var(diff_input)/activity)\n","#     complexity = np.sqrt(np.var(diff_diff_input)/np.var(diff_input)) / mobility\n","\n","#     return activity, mobility, complexity\n","\n","\n","\n","\n","# def extract_time_domain_features(epochs):\n","#     features = []\n","\n","#     for epoch in epochs:\n","#         epoch_features = []\n","\n","#         for channel_data in epoch:\n","#             # Flatten the channel data\n","#             flattened_data = channel_data.flatten()\n","\n","#             # Basic Time-Domain Features\n","#             mean_val = np.mean(flattened_data)\n","#             median_val = np.median(flattened_data)\n","#             var_val = np.var(flattened_data)\n","#             std_dev = np.std(flattened_data)\n","#             skewness = skew(flattened_data)\n","#             kurt = kurtosis(flattened_data)\n","#             zcr = zero_crossing_rate(flattened_data)\n","#             peak_amp = np.ptp(flattened_data)\n","\n","#             # Hjorth Parameters\n","#             activity, mobility, complexity = hjorth_parameters(flattened_data)\n","\n","#             # Additional Features\n","#             num_waves = len(find_peaks(flattened_data)[0])\n","#             wave_duration = len(flattened_data) / num_waves if num_waves > 0 else 0\n","\n","#             channel_features = [\n","#                 mean_val, median_val, var_val, std_dev, skewness, kurt, zcr, num_waves,\n","#                 wave_duration, peak_amp, activity, mobility, complexity\n","#             ]\n","#             epoch_features.append(channel_features)\n","\n","#         features.append(epoch_features)\n","\n","#     return np.array(features)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710741409139,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"-QMPhbvu0vAL"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import skew, kurtosis, entropy\n","from scipy.signal import find_peaks\n","\n","\n","def hjorth_parameters(signal):\n","    diff_input = np.diff(signal)\n","    diff_diff_input = np.diff(diff_input)\n","\n","    activity = np.var(signal)\n","    mobility = np.sqrt(np.var(diff_input)/activity)\n","    complexity = np.sqrt(np.var(diff_diff_input)/np.var(diff_input)) / mobility\n","\n","    return activity, mobility, complexity\n","\n","# def zero_crossing_rate(signal):\n","#     # Enhanced ZCR to handle noise\n","#     # Setting a threshold (eps) to consider as zero (to avoid detecting false crossings due to noise)\n","#     eps = 0.01 * np.std(signal)\n","#     zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n","#     close_to_zero = np.where(np.abs(signal) < eps)[0]\n","#     return (len(zero_crossings) + len(close_to_zero)) / len(signal)\n","\n","def zero_crossing_rate(signal):\n","    zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n","    return len(zero_crossings) / len(signal)\n","\n","def safe_divide(numerator, denominator, default=0.0):\n","    \"\"\"Safely divide two numbers, returning a default value if the denominator is zero.\"\"\"\n","    if denominator == 0:\n","        return default\n","    else:\n","        return numerator / denominator\n","\n","def signal_entropy(signal):\n","    # Calculate histogram of the signal\n","    hist, bin_edges = np.histogram(signal, bins='auto', density=True)\n","    # Ensure non-zero histogram values by adding a small constant\n","    hist += np.finfo(float).eps\n","    # Normalize the histogram to get a probability distribution\n","    prob_dist = hist / hist.sum()\n","    # Calculate the entropy\n","    return entropy(prob_dist)\n","\n","def rms(signal):\n","    return np.sqrt(np.mean(signal**2))\n","\n","def signal_energy(signal):\n","    return np.sum(signal**2)\n","\n","\n","\n","def crest_factor(signal, rms_val=None):\n","    if rms_val is None:\n","        rms_val = rms(signal)\n","    return np.max(np.abs(signal)) / rms_val\n","\n","def shape_factor(signal, rms_val=None):\n","    if rms_val is None:\n","        rms_val = rms(signal)\n","    mean_abs = np.mean(np.abs(signal))\n","    return rms_val / mean_abs if mean_abs != 0 else 0\n","\n","def extract_time_domain_features(epochs):\n","    features = []\n","\n","    for epoch in epochs:\n","        epoch_features = []\n","\n","        for channel_data in epoch:\n","            # Flatten the channel data if needed\n","            flattened_data = np.ravel(channel_data)\n","\n","            # Basic Time-Domain Features\n","            mean_val = np.mean(flattened_data)\n","            median_val = np.median(flattened_data)\n","            var_val = np.var(flattened_data)\n","            std_dev = np.std(flattened_data)\n","            skewness = skew(flattened_data)\n","            kurt = kurtosis(flattened_data)\n","            zcr = zero_crossing_rate(flattened_data)\n","            rms_val = rms(flattened_data)\n","            energy = signal_energy(flattened_data)\n","            crest_fact = crest_factor(flattened_data, rms_val)\n","            shape_fact = shape_factor(flattened_data, rms_val)\n","            signal_entropy_val = signal_entropy(flattened_data)  # Use the defined function\n","            peak_amp = np.ptp(flattened_data)\n","\n","            # Hjorth Parameters\n","            activity, mobility, complexity = hjorth_parameters(flattened_data)\n","\n","            # Additional Features\n","            num_peaks = len(find_peaks(flattened_data)[0])\n","            peak_to_peak_distance = np.mean(np.diff(find_peaks(flattened_data)[0])) if num_peaks > 1 else 0\n","\n","            channel_features = [\n","                mean_val, median_val, var_val, std_dev, skewness, kurt, zcr, rms_val, energy,\n","                 crest_fact, shape_fact, signal_entropy_val,\n","                peak_amp, num_peaks, peak_to_peak_distance,\n","                activity, mobility, complexity\n","            ]\n","            epoch_features.append(channel_features)\n","\n","        features.append(epoch_features)\n","\n","    return np.array(features)"]},{"cell_type":"markdown","metadata":{"id":"usMNds7p2CQY"},"source":["## Frequency Domain Features\n","\n","\n","1. Power Spectral Density (PSD) Calculation:\n","\n","Utilizes the welch method to compute the power spectral density of the signal, which forms the basis for many of the following features.\n","\n","2. Basic Statistical Features from PSD:\n","\n","  Mean (mean_val): The average power in the spectrum.\n","\n","*   Median (median_val): The middle value of the power spectrum.\n","*   Variance (var_val): The variance of the power spectrum.\n","*   Standard Deviation (std_dev): The standard deviation of the power spectrum.\n","*   Standard Deviation (std_dev): The standard deviation of the power spectrum.\n","* Skewness (skewness): A measure of the asymmetry of the power spectrum.\n","* Kurtosis (kurt): A measure of the tailedness of the power spectrum.\n","\n",".\n","\n","3. Wavelet Coefficients:\n","\n","* Wavelet Coefficients (wave_coeffs): Computed using the Discrete Wavelet\n","* Transform (DWT) to provide a multi-resolution analysis of the signal.\n","\n","* Mean of Wavelet Coefficients (wave_coeffs_mean): The mean of the wavelet coefficients, providing a summary of the wavelet-transformed data.\n","\n","4. Band Power Features:\n","\n","Computed by summing the PSD within specified frequency bands. The bands considered are delta, theta, alpha, beta, gamma, and sigma.\n","\n","\n","5. Band Power Ratios:\n","\n","* Theta/Alpha Ratio (theta_alpha_ratio): The ratio of power in the theta band to the power in the alpha band.\n","\n","* Beta/Alpha Ratio (beta_alpha_ratio): The ratio of power in the beta band to the power in the alpha band.\n","\n","* (Theta + Alpha)/Beta Ratio (theta_alpha_beta_ratio): The ratio of the sum of power in the theta and alpha bands to the power in the beta band.\n","\n","* Theta/Beta Ratio (theta_beta_ratio): The ratio of power in the theta band to the power in the beta band.\n","\n","* (Theta + Alpha)/(Alpha + Beta) Ratio (theta_alpha_beta_alpha_ratio): The ratio of the sum of power in the theta and alpha bands to the sum of power in the alpha and beta bands.\n","\n","* Gamma/Delta Ratio (gamma_delta_ratio): The ratio of power in the gamma band to the power in the delta band.\n","\n","* (Gamma + Beta)/(Delta + Alpha) Ratio (gamma_beta_delta_alpha_ratio): The ratio of the sum of power in the gamma and beta bands to the sum of power in the delta and alpha bands.\n","\n","6. Additional Frequency Domain Features:\n","\n","* Spectral Entropy (spectral_entropy_val): Measures the entropy of the power spectrum, providing an index of the complexity or disorder in the frequency domain.\n","\n","* Spectral Edge Frequency (spectral_edge_freq): The frequency below which a certain percentage (e.g., 95%) of the power of the signal is contained, providing a cutoff frequency that encloses most of the signal's power."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AE_0hytQJbH0"},"outputs":[],"source":["# import numpy as np\n","# from scipy.stats import skew, kurtosis\n","# from scipy.signal import welch\n","\n","\n","\n","# def get_wavelet_coeffs(channel_data, wavelet='db4', level=5):\n","#     coeffs = pywt.wavedec(channel_data, wavelet, level=level)\n","#     return coeffs\n","\n","\n","# def extract_frequency_domain_features(epochs, sfreq,wavelet='db4', bands={'delta': (1.59, 4), 'theta': (4, 8), 'alpha': (8, 12), 'beta': (12, 30), 'gamma': (30, 100), 'sigma': (11, 16)}):\n","#     features = []\n","\n","#     for epoch in epochs:\n","#         epoch_features = []\n","\n","#         for channel_data in epoch:\n","#             # Compute the Power Spectral Density (PSD)\n","#             freqs, psd = welch(channel_data, sfreq, nperseg=256)\n","\n","#             # Frequency domain features\n","#             mean_val = np.mean(psd)\n","#             median_val = np.median(psd)\n","#             var_val = np.var(psd)\n","#             std_dev = np.std(psd)\n","#             skewness = skew(psd)\n","#             kurt = kurtosis(psd)\n","\n","#             # Compute wavelet coefficients\n","#             wave_coeffs = get_wavelet_coeffs(channel_data, wavelet, level=5)\n","#             wave_coeffs_mean = np.mean(wave_coeffs[0])\n","\n","#             # Band Power Features\n","#             band_powers = {}\n","#             for band, freq_range in bands.items():\n","#                 freq_mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])\n","#                 band_power = np.sum(psd[freq_mask])\n","#                 band_powers[band] = band_power\n","\n","#             # Band Power Ratios\n","#             theta_alpha_ratio = band_powers['theta'] / band_powers['alpha']\n","#             beta_alpha_ratio = band_powers['beta'] / band_powers['alpha']\n","#             theta_alpha_beta_ratio = (band_powers['theta'] + band_powers['alpha']) / band_powers['beta']\n","\n","#             # Additional Band Power Ratios\n","#             theta_beta_ratio = band_powers['theta'] / band_powers['beta']\n","#             theta_alpha_beta_alpha_ratio = (band_powers['theta'] + band_powers['alpha']) / (band_powers['alpha'] + band_powers['beta'])\n","#             gamma_delta_ratio = band_powers['gamma'] / band_powers['delta']\n","#             gamma_beta_delta_alpha_ratio = (band_powers['gamma'] + band_powers['beta']) / (band_powers['delta'] + band_powers['alpha'])\n","\n","\n","#             channel_features = [\n","#                 mean_val, median_val, var_val, std_dev, skewness, kurt,\n","#                 band_powers['delta'], band_powers['theta'], band_powers['alpha'],\n","#                 band_powers['beta'], band_powers['gamma'], band_powers['sigma'],\n","#                 theta_alpha_ratio, beta_alpha_ratio, theta_alpha_beta_ratio,theta_beta_ratio,\n","#                 theta_alpha_beta_alpha_ratio, gamma_delta_ratio, gamma_beta_delta_alpha_ratio,\n","#                 wave_coeffs_mean\n","#             ]\n","#             epoch_features.append(channel_features)\n","\n","#         features.append(epoch_features)\n","\n","#     return np.array(features)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710741409139,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"bOdfEbDDLuCO"},"outputs":[],"source":["import numpy as np\n","import pywt\n","from scipy.stats import skew, kurtosis, entropy\n","from scipy.signal import welch\n","\n","def get_wavelet_coeffs(channel_data, wavelet='db4', level=5):\n","    coeffs = pywt.wavedec(channel_data, wavelet, level=level)\n","    return coeffs\n","\n","\n","def safe_divide(numerator, denominator, default_value=0.0):\n","    \"\"\"Safely divide two numbers, returning a default value if the denominator is zero.\"\"\"\n","    if denominator == 0:\n","        return default_value\n","    else:\n","        return numerator / denominator\n","\n","\n","\n","def spectral_entropy(psd, sfreq):\n","    # Adding a small constant to avoid division by zero when normalizing\n","    psd_sum = np.sum(psd) + np.finfo(float).eps\n","    psd_norm = psd / psd_sum\n","    # Normalizing PSD to a probability distribution\n","    psd_norm = psd_norm / np.sum(psd_norm)\n","    # Ensuring the normalized PSD values are positive\n","    psd_norm[psd_norm <= 0] = np.finfo(float).eps\n","    return entropy(psd_norm)\n","\n","\n","def spectral_edge_frequency(freqs, psd, edge_percent=0.95):\n","    psd_sum = np.sum(psd) + np.finfo(float).eps  # Add a small constant to ensure non-zero denominator\n","    psd_cumsum = np.cumsum(psd) / psd_sum\n","    idx = np.where(psd_cumsum <= edge_percent)[0][-1] if len(psd_cumsum) > 0 else 0\n","    spectral_edge_freq = freqs[idx] if idx < len(freqs) else 0\n","    return spectral_edge_freq\n","\n","def extract_frequency_domain_features(epochs, sfreq, wavelet='db4', bands={'delta': (1.59, 4), 'theta': (4, 8), 'alpha': (8, 12), 'beta': (12, 30), 'sigma': (11, 16)}):\n","    features = []\n","\n","    for epoch in epochs:\n","        epoch_features = []\n","\n","        for channel_data in epoch:\n","            # Compute the Power Spectral Density (PSD)\n","            freqs, psd = welch(channel_data, sfreq, nperseg=256)\n","\n","            # Frequency domain features\n","            mean_val = np.mean(psd)\n","            median_val = np.median(psd)\n","            var_val = np.var(psd)\n","            std_dev = np.std(psd)\n","            skewness = skew(psd)\n","            kurt = kurtosis(psd)\n","\n","            # Compute wavelet coefficients\n","            wave_coeffs = get_wavelet_coeffs(channel_data, wavelet, level=5)\n","            wave_coeffs_mean = np.mean(wave_coeffs[0])\n","\n","            # Band Power Features\n","            band_powers = {}\n","            for band, freq_range in bands.items():\n","                freq_mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])\n","                band_power = np.sum(psd[freq_mask])\n","                band_powers[band] = band_power\n","\n","            # Band Power Ratios\n","            # Band Power Ratios with safe division\n","            theta_alpha_ratio = safe_divide(band_powers['theta'], band_powers['alpha'])\n","            beta_alpha_ratio = safe_divide(band_powers['beta'], band_powers['alpha'])\n","            theta_alpha_beta_ratio = safe_divide(band_powers['theta'] + band_powers['alpha'], band_powers['beta'])\n","            theta_beta_ratio = safe_divide(band_powers['theta'], band_powers['beta'])\n","            theta_alpha_beta_alpha_ratio = safe_divide(band_powers['theta'] + band_powers['alpha'], band_powers['alpha'] + band_powers['beta'])\n","\n","            # gamma_delta_ratio = band_powers['gamma'] / band_powers['delta']\n","            # gamma_beta_delta_alpha_ratio = (band_powers['gamma'] + band_powers['beta']) / (band_powers['delta'] + band_powers['alpha'])\n","\n","            # Additional Features\n","            spectral_entropy_val = spectral_entropy(psd, sfreq)\n","            spectral_edge_freq = spectral_edge_frequency(freqs, psd)\n","\n","            channel_features = [\n","                mean_val, median_val, var_val, std_dev, skewness, kurt,\n","                band_powers['delta'], band_powers['theta'], band_powers['alpha'],\n","                band_powers['beta'], band_powers['sigma'],\n","                theta_alpha_ratio, beta_alpha_ratio, theta_alpha_beta_ratio, theta_beta_ratio,\n","                theta_alpha_beta_alpha_ratio,\n","                wave_coeffs_mean, spectral_entropy_val, spectral_edge_freq\n","            ]\n","            epoch_features.append(channel_features)\n","\n","        features.append(epoch_features)\n","\n","    return np.array(features)"]},{"cell_type":"markdown","source":["## Mel-frequency cepstrum coefficients (MFCCs)"],"metadata":{"id":"s8XACWQ2bcR8"}},{"cell_type":"code","source":["!pip install librosa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-3UCL2CbnXE","executionInfo":{"status":"ok","timestamp":1710746413259,"user_tz":-360,"elapsed":7937,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"8ecb2ec1-8501-48dd-ff4b-5a4cc4ac8852"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.10.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (24.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.3.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import librosa\n","\n","def extract_eeg_mfcc_features(eeg_epochs, sr, n_mfcc=13):\n","    \"\"\"\n","    Extract MFCC features from EEG signal epochs.\n","\n","    Parameters:\n","    - eeg_epochs: A list (or an array) of EEG epochs, where each epoch is a time series of signal data from one or more channels.\n","    - sr: Sampling rate of the EEG signal.\n","    - n_mfcc: Number of MFCC features to extract. Default is 13, but consider adjusting for EEG data.\n","\n","    Returns:\n","    - A numpy array of MFCC features. Shape: (number of epochs, number of channels, n_mfcc).\n","    \"\"\"\n","    mfcc_features = []\n","\n","    for epoch in eeg_epochs:\n","        epoch_features = []\n","        for channel_data in epoch:\n","            # Compute MFCCs from EEG channel data\n","            mfcc = librosa.feature.mfcc(y=channel_data, sr=sr, n_mfcc=n_mfcc)\n","\n","            # Compute mean and standard deviation as a simple way to summarize the MFCCs over time\n","            mfcc_mean = np.mean(mfcc, axis=1)\n","            mfcc_std = np.std(mfcc, axis=1)\n","\n","            # Combine mean and standard deviation into a single feature vector for the channel\n","            channel_features = np.concatenate([mfcc_mean, mfcc_std])\n","            epoch_features.append(channel_features)\n","\n","        mfcc_features.append(epoch_features)\n","\n","    return np.array(mfcc_features)"],"metadata":{"id":"RlRrKKRGbbmc","executionInfo":{"status":"ok","timestamp":1710746415654,"user_tz":-360,"elapsed":2,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["X_mfcc = extract_eeg_mfcc_features(X,256)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtQGsM21dT1s","executionInfo":{"status":"ok","timestamp":1710747932239,"user_tz":-360,"elapsed":998647,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"2d663e01-4754-452f-f896-5107ad7eb9df"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=180\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["X_mfcc.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"arYiJPUMiBYZ","executionInfo":{"status":"ok","timestamp":1710748092523,"user_tz":-360,"elapsed":407,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"c6d0cc4e-8a7f-41c3-9051-0a38a0822062"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5834, 29, 26)"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"9fc4LGGaWGnl"},"source":["#Apply Feature Extraction Methods"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":711328,"status":"ok","timestamp":1710742120464,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"O0hmbblbJbDA","outputId":"d964c0b1-7528-444b-effa-08c9f5638097"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 180, using nperseg = 180\n","  warnings.warn('nperseg = {0:d} is greater than input length '\n","/usr/local/lib/python3.10/dist-packages/pywt/_multilevel.py:43: UserWarning: Level value of 5 is too high: all coefficients will experience boundary effects.\n","  warnings.warn(\n"]}],"source":["X_time = extract_time_domain_features(X)\n","sfreq = 256  # Replace with the sampling frequency of your data\n","# epochs_data = [epoch.get_data() for epoch in epochs]  # Assuming epochs is a list of MNE Epochs objects\n","X_frequency = extract_frequency_domain_features(X, sfreq)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710742120465,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"7eGL289PKMJx"},"outputs":[],"source":["#merge the time and frequency features\n","X_merged_features = np.concatenate((X_time ,X_frequency), axis=2)\n","\n","X_reshape = X_merged_features.reshape(X_merged_features.shape[0], -1)\n","# X_reshape = DWT_data.reshape(DWT_data.shape[0], -1)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1099,"status":"ok","timestamp":1710742121558,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"fqHnVTIpKK6T"},"outputs":[],"source":["from sklearn.metrics import accuracy_score,confusion_matrix, precision_score, recall_score, f1_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GroupKFold, GridSearchCV\n","\n","\n","import xgboost as xgb\n","from sklearn.ensemble import RandomForestClassifier,HistGradientBoostingClassifier,\\\n","                                StackingClassifier,VotingClassifier,IsolationForest,\\\n","                                RandomForestRegressor\n","from sklearn.svm import SVC\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import GaussianNB,BernoulliNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.naive_bayes import CategoricalNB\n","from xgboost import XGBClassifier\n","# import lightgbm as lgb\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.model_selection import cross_val_predict, RandomizedSearchCV,GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score, matthews_corrcoef\n","from sklearn.model_selection import KFold\n","import pandas as pd\n","\n","\n","#Scale the data\n","SS1= StandardScaler()\n","X_scaled = SS1.fit_transform(X_reshape)\n","\n","\n","models = {\n","    'XGBoost': XGBClassifier(),\n","    'RandomForest': RandomForestClassifier(),\n","    'HistGradientBoosting': HistGradientBoostingClassifier(),\n","    'SVM': SVC(),\n","    'GradientBoosting': GradientBoostingClassifier(),\n","    'KNeighbors': KNeighborsClassifier(),\n","    'MLP': MLPClassifier(),\n","    'DecisionTree': DecisionTreeClassifier(),\n","    # 'MultinomialNB': MultinomialNB(),\n","    'GaussianNB': GaussianNB(),\n","    'BernoulliNB': BernoulliNB(),\n","    'LogisticRegression': LogisticRegression(),\n","    'AdaBoost': AdaBoostClassifier(),\n","    # 'Bagging': BaggingClassifier(),\n","    'ExtraTrees': ExtraTreesClassifier(),\n","\n","}\n","\n","\n","def predict_binary(model, X, threshold=0.5):\n","    \"\"\"\n","    Predicts binary labels for the given input X using the specified model.\n","    Predictions are determined based on the specified threshold.\n","\n","    Parameters:\n","    - model: Trained Keras model for prediction\n","    - X: Input data for prediction\n","    - threshold: Threshold for converting probabilities to binary labels\n","\n","    Returns:\n","    - Binary labels (0 or 1) for each input sample\n","    \"\"\"\n","    # Get the model's probability predictions for the input data\n","    prob_predictions = model.predict(X)\n","\n","    # Apply threshold to convert probabilities to binary labels\n","    binary_predictions = (prob_predictions > threshold).astype(int)\n","\n","    return binary_predictions\n","\n","\n","\n","\n","\n","def evaluate_model(model, X, y, n_splits):\n","    kf = KFold(n_splits=n_splits,shuffle=True,random_state=42)\n","    accuracies, precisions, recalls,f1s,cm,specificitys, sensitivitys,roc_aucs,kappas,mccs= [], [], [],[],[],[],[],[],[],[]\n","\n","    for train_idx, test_idx in kf.split(X):\n","      # take the location of the splited data and access it by the index\n","\n","      X_train, y_train = (X.iloc[train_idx], y.iloc[train_idx]) if isinstance(X, pd.DataFrame) else (X[train_idx], y[train_idx])\n","      X_test, y_test = (X.iloc[test_idx], y.iloc[test_idx]) if isinstance(X, pd.DataFrame) else (X[test_idx], y[test_idx])\n","      # train the model\n","      model = build_sequential_model(input_shape=scaled_data.shape[1:])\n","      model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data = (X_test, y_test), shuffle=True)\n","      # make prediction\n","      # Example of using the custom prediction function\n","      y_pred = predict_binary(model, X_test)\n","\n","      # evaluation scores\n","      accuracy = accuracy_score(y_test, y_pred)\n","      precision = precision_score(y_test, y_pred,zero_division=1)\n","      recall = recall_score(y_test, y_pred)\n","      f1= f1_score(y_test, y_pred)\n","      cms = confusion_matrix(y_test, y_pred)  # Calculate confusion matrix\n","      roc_auc=roc_auc_score(y_test, y_pred)\n","\n","      # calculate the specificity and sensitivity\n","      tn, fp, fn, tp = cms.ravel()\n","      specificity = tn / (tn + fp)\n","      sensitivity = tp / (tp + fn)\n","      # Calculate Cohen's Kappa\n","      kappa = cohen_kappa_score(y_test, y_pred)\n","      mcc = matthews_corrcoef(y_test, y_pred)\n","\n","\n","\n","\n","\n","      # append all the results\n","      accuracies.append(accuracy)\n","      precisions.append(precision)\n","      recalls.append(recall)\n","      f1s.append(f1)\n","      cm.append(cms)  # Add confusion matrix to list\n","      specificitys.append(specificity) #add specificity score\n","      sensitivitys.append(sensitivity) #add sensitivity scores to the list\n","      roc_aucs.append(roc_auc) #add roc_auc score to the list\n","      kappas.append(kappa)\n","      mccs.append(mcc)\n","\n","\n","    return (format(sum(accuracies)/n_splits, '.3f'), format(sum(precisions)/n_splits, '.3f'),\n","            format(sum(recalls)/n_splits, '.3f'),format(sum(f1s)/n_splits, '.3f'),format(sum(roc_aucs)/n_splits, '.3f'), sum(cm)/n_splits ,format(sum(specificitys)/n_splits, '.3f'),\n","            format(sum(sensitivitys)/n_splits, '.3f'),format(sum(kappas)/n_splits, '.3f'),format(sum(mccs)/n_splits, '.3f'))\n","\n","\n","\n","\n","def modelApplied(Model,X_train , y_train, n_splits=5,MN='model_name',model_result = pd.DataFrame()):\n","  accuracy, precision, recall,f1,roc_auc,cm,specificity,sensitivity,kappa,mcc = evaluate_model(Model,X_train , y_train, n_splits)\n","\n","  new_row=[MN,accuracy,precision,recall,f1,roc_auc,specificity, sensitivity,kappa,mcc]\n","\n","  model_result.loc[len(model_result)]=new_row\n","  print(new_row)\n","  print('DONE!!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYpAF6VLtU8I"},"outputs":[],"source":["# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>ALL band<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","# ['XGBoost', '0.957', '0.987', '0.926', '0.955', '0.957', '0.987', '0.926', '0.913', '0.915']\n","# DONE!!\n","# ['RandomForest', '0.937', '0.973', '0.898', '0.934', '0.937', '0.975', '0.898', '0.873', '0.876']\n","# DONE!!\n","# ['HistGradientBoosting', '0.958', '0.991', '0.925', '0.957', '0.958', '0.991', '0.925', '0.916', '0.919']\n","# DONE!!\n","# ['SVM', '0.916', '0.960', '0.868', '0.911', '0.916', '0.963', '0.868', '0.831', '0.835']\n","# DONE!!\n","# ['GradientBoosting', '0.942', '0.975', '0.907', '0.940', '0.942', '0.977', '0.907', '0.884', '0.886']\n","# DONE!!\n","# ['KNeighbors', '0.818', '0.988', '0.644', '0.778', '0.818', '0.992', '0.644', '0.636', '0.679']\n","# DONE!!\n","# ['MLP', '0.928', '0.953', '0.901', '0.926', '0.928', '0.955', '0.901', '0.856', '0.857']\n","# DONE!!\n","# ['DecisionTree', '0.891', '0.887', '0.897', '0.891', '0.891', '0.885', '0.897', '0.782', '0.782']\n","# DONE!!\n","# ['GaussianNB', '0.857', '0.985', '0.726', '0.836', '0.857', '0.989', '0.726', '0.714', '0.741']\n","# DONE!!\n","# ['BernoulliNB', '0.865', '0.933', '0.787', '0.854', '0.865', '0.943', '0.787', '0.731', '0.740']\n","# DONE!!\n","# ['LogisticRegression', '0.899', '0.911', '0.885', '0.897', '0.899', '0.913', '0.885', '0.798', '0.798']\n","# DONE!!\n","# ['AdaBoost', '0.923', '0.947', '0.897', '0.921', '0.923', '0.950', '0.897', '0.847', '0.848']\n","# DONE!!\n","# ['ExtraTrees', '0.929', '0.964', '0.892', '0.926', '0.929', '0.967', '0.892', '0.858', '0.861']\n","# DONE!!"]},{"cell_type":"markdown","metadata":{"id":"v9PMm15XGqaK"},"source":["#Optimization"]},{"cell_type":"code","source":["def signal_normalize(signal):\n","  X_merged_features_axis = np.moveaxis(signal,1,2)\n","  X_merged_features_reshaped = X_merged_features_axis.reshape(X_merged_features_axis.shape[0],-1)\n","  scaler= MinMaxScaler(feature_range=(0, 1))\n","  scaled_data_reshaped = scaler.fit_transform(X_merged_features_reshaped)\n","\n","# Reshape back to original shape if necessary\n","  scaled_data = scaled_data_reshaped.reshape(X_merged_features_axis.shape)\n","  return scaled_data"],"metadata":{"id":"hEf_87HiiXpD","executionInfo":{"status":"ok","timestamp":1710750095552,"user_tz":-360,"elapsed":830,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","import numpy as np\n","\n","\n","\n","X_merged_features_axis = np.moveaxis(X_merged_features,1,2)\n","X_merged_features_reshaped = X_merged_features_axis.reshape(X_merged_features_axis.shape[0],-1)\n","# scaler = StandardScaler()\n","scaler= MinMaxScaler(feature_range=(0, 1))\n","scaled_data_reshaped = scaler.fit_transform(X_merged_features_reshaped)\n","\n","# Reshape back to original shape if necessary\n","scaled_data = scaled_data_reshaped.reshape(X_merged_features_axis.shape)"],"metadata":{"id":"X_zOkIijrrSA","executionInfo":{"status":"ok","timestamp":1710742121558,"user_tz":-360,"elapsed":6,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["scaled_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsqBbkSes5SK","executionInfo":{"status":"ok","timestamp":1710742121558,"user_tz":-360,"elapsed":5,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"fb2203d0-349f-404a-bf97-8d9b1bcd8b8e"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5834, 37, 29)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#for MFCC features\n","X_scaled_mfcc = signal_normalize(X_mfcc)"],"metadata":{"id":"9clk7FQtvjm5","executionInfo":{"status":"ok","timestamp":1710751682354,"user_tz":-360,"elapsed":522,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","xtrian_mfcc,xtest_mfcc, ytrain_mfcc, ytest_mfcc = train_test_split(X_scaled_mfcc,Y,test_size= 0.2,shuffle= True, random_state=42)"],"metadata":{"id":"HalpBWRtcDwK","executionInfo":{"status":"ok","timestamp":1710751735396,"user_tz":-360,"elapsed":3,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","xtrian,xtest, ytrain, ytest = train_test_split(scaled_data,Y,test_size= 0.2,shuffle= True, random_state=42)"],"metadata":{"id":"oDaI_Oytvziy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from wandb.keras import WandbCallback\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras import callbacks\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.layers import  Conv1D,Conv1DTranspose,BatchNormalization,LeakyReLU,MaxPool1D,Flatten,\\\n","GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D,ReLU,MaxPooling1D,Conv2D,MaxPool2D,GlobalAveragePooling2D,\\\n","AveragePooling2D,Bidirectional, LSTM, concatenate,Reshape\n","from tensorflow.keras.regularizers import l2\n","from keras.layers import ConvLSTM1D, LSTM\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.backend import clear_session\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM"],"metadata":{"id":"5zqXyTPmsxWH","executionInfo":{"status":"ok","timestamp":1710742128375,"user_tz":-360,"elapsed":6820,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"UhKbMnbetEoo","executionInfo":{"status":"ok","timestamp":1710742136385,"user_tz":-360,"elapsed":8014,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"id":"e2xYREzG3Ih9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710753597409,"user_tz":-360,"elapsed":387330,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"28d2987a-fa85-4e75-80d3-1e6cd6057107"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 22, 256)           37376     \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 18, 128)           163968    \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 14, 64)            41024     \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 10, 128)           41088     \n","                                                                 \n"," conv1d_4 (Conv1D)           (None, 6, 256)            164096    \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 2, 256)            0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 2, 256)            0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 32)                16416     \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 464001 (1.77 MB)\n","Trainable params: 464001 (1.77 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/50\n","73/73 [==============================] - 12s 103ms/step - loss: 0.6770 - accuracy: 0.5738 - val_loss: 0.6376 - val_accuracy: 0.5844\n","Epoch 2/50\n","73/73 [==============================] - 6s 79ms/step - loss: 0.5890 - accuracy: 0.6919 - val_loss: 0.5345 - val_accuracy: 0.7207\n","Epoch 3/50\n","73/73 [==============================] - 7s 102ms/step - loss: 0.5389 - accuracy: 0.7328 - val_loss: 0.5352 - val_accuracy: 0.7429\n","Epoch 4/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.5239 - accuracy: 0.7450 - val_loss: 0.5470 - val_accuracy: 0.7035\n","Epoch 5/50\n","73/73 [==============================] - 7s 99ms/step - loss: 0.4562 - accuracy: 0.7947 - val_loss: 0.4838 - val_accuracy: 0.7909\n","Epoch 6/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.3807 - accuracy: 0.8350 - val_loss: 0.4615 - val_accuracy: 0.8003\n","Epoch 7/50\n","73/73 [==============================] - 7s 101ms/step - loss: 0.3401 - accuracy: 0.8599 - val_loss: 0.3155 - val_accuracy: 0.8715\n","Epoch 8/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.3238 - accuracy: 0.8648 - val_loss: 0.4224 - val_accuracy: 0.8329\n","Epoch 9/50\n","73/73 [==============================] - 7s 101ms/step - loss: 0.3054 - accuracy: 0.8751 - val_loss: 0.3063 - val_accuracy: 0.8732\n","Epoch 10/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.2953 - accuracy: 0.8819 - val_loss: 0.2922 - val_accuracy: 0.8886\n","Epoch 11/50\n","73/73 [==============================] - 7s 102ms/step - loss: 0.2632 - accuracy: 0.8999 - val_loss: 0.2775 - val_accuracy: 0.8929\n","Epoch 12/50\n","73/73 [==============================] - 6s 81ms/step - loss: 0.2801 - accuracy: 0.8899 - val_loss: 0.2799 - val_accuracy: 0.8792\n","Epoch 13/50\n","73/73 [==============================] - 7s 97ms/step - loss: 0.2882 - accuracy: 0.8830 - val_loss: 0.3067 - val_accuracy: 0.8749\n","Epoch 14/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.2605 - accuracy: 0.9010 - val_loss: 0.3015 - val_accuracy: 0.8757\n","Epoch 15/50\n","73/73 [==============================] - 7s 94ms/step - loss: 0.2656 - accuracy: 0.8961 - val_loss: 0.2660 - val_accuracy: 0.8877\n","Epoch 16/50\n","73/73 [==============================] - 6s 86ms/step - loss: 0.2518 - accuracy: 0.9036 - val_loss: 0.3399 - val_accuracy: 0.8680\n","Epoch 17/50\n","73/73 [==============================] - 7s 94ms/step - loss: 0.2556 - accuracy: 0.8974 - val_loss: 0.3390 - val_accuracy: 0.8740\n","Epoch 18/50\n","73/73 [==============================] - 6s 88ms/step - loss: 0.2531 - accuracy: 0.9055 - val_loss: 0.2795 - val_accuracy: 0.8826\n","Epoch 19/50\n","73/73 [==============================] - 7s 94ms/step - loss: 0.2640 - accuracy: 0.8984 - val_loss: 0.2620 - val_accuracy: 0.8920\n","Epoch 20/50\n","73/73 [==============================] - 7s 92ms/step - loss: 0.2364 - accuracy: 0.9100 - val_loss: 0.3189 - val_accuracy: 0.8852\n","Epoch 21/50\n","73/73 [==============================] - 7s 90ms/step - loss: 0.2500 - accuracy: 0.9016 - val_loss: 0.2960 - val_accuracy: 0.8740\n","Epoch 22/50\n","73/73 [==============================] - 7s 92ms/step - loss: 0.2425 - accuracy: 0.9094 - val_loss: 0.2541 - val_accuracy: 0.9006\n","Epoch 23/50\n","73/73 [==============================] - 6s 85ms/step - loss: 0.2313 - accuracy: 0.9136 - val_loss: 0.2759 - val_accuracy: 0.8946\n","Epoch 24/50\n","73/73 [==============================] - 7s 95ms/step - loss: 0.2271 - accuracy: 0.9149 - val_loss: 0.2776 - val_accuracy: 0.8972\n","Epoch 25/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.2384 - accuracy: 0.9117 - val_loss: 0.2930 - val_accuracy: 0.8800\n","Epoch 26/50\n","73/73 [==============================] - 7s 98ms/step - loss: 0.2428 - accuracy: 0.9079 - val_loss: 0.2787 - val_accuracy: 0.8877\n","Epoch 27/50\n","73/73 [==============================] - 6s 78ms/step - loss: 0.2225 - accuracy: 0.9149 - val_loss: 0.2643 - val_accuracy: 0.8955\n","Epoch 28/50\n","73/73 [==============================] - 7s 101ms/step - loss: 0.2227 - accuracy: 0.9171 - val_loss: 0.2701 - val_accuracy: 0.8895\n","Epoch 29/50\n","73/73 [==============================] - 6s 84ms/step - loss: 0.2131 - accuracy: 0.9188 - val_loss: 0.2576 - val_accuracy: 0.8869\n","Epoch 30/50\n","73/73 [==============================] - 7s 98ms/step - loss: 0.2059 - accuracy: 0.9244 - val_loss: 0.3037 - val_accuracy: 0.8869\n","Epoch 31/50\n","73/73 [==============================] - 6s 83ms/step - loss: 0.2092 - accuracy: 0.9216 - val_loss: 0.2923 - val_accuracy: 0.9006\n","Epoch 32/50\n","73/73 [==============================] - 7s 102ms/step - loss: 0.2083 - accuracy: 0.9201 - val_loss: 0.2666 - val_accuracy: 0.8955\n","Epoch 33/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.2100 - accuracy: 0.9214 - val_loss: 0.2990 - val_accuracy: 0.8749\n","Epoch 34/50\n","73/73 [==============================] - 7s 101ms/step - loss: 0.1976 - accuracy: 0.9280 - val_loss: 0.2689 - val_accuracy: 0.9015\n","Epoch 35/50\n","73/73 [==============================] - 6s 83ms/step - loss: 0.2026 - accuracy: 0.9237 - val_loss: 0.2538 - val_accuracy: 0.8963\n","Epoch 36/50\n","73/73 [==============================] - 7s 102ms/step - loss: 0.1979 - accuracy: 0.9261 - val_loss: 0.3994 - val_accuracy: 0.8595\n","Epoch 37/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.2003 - accuracy: 0.9278 - val_loss: 0.2570 - val_accuracy: 0.9006\n","Epoch 38/50\n","73/73 [==============================] - 7s 103ms/step - loss: 0.1919 - accuracy: 0.9254 - val_loss: 0.2681 - val_accuracy: 0.8972\n","Epoch 39/50\n","73/73 [==============================] - 6s 83ms/step - loss: 0.1909 - accuracy: 0.9289 - val_loss: 0.2884 - val_accuracy: 0.8997\n","Epoch 40/50\n","73/73 [==============================] - 7s 103ms/step - loss: 0.1777 - accuracy: 0.9387 - val_loss: 0.2991 - val_accuracy: 0.8946\n","Epoch 41/50\n","73/73 [==============================] - 6s 83ms/step - loss: 0.1980 - accuracy: 0.9271 - val_loss: 0.2797 - val_accuracy: 0.8980\n","Epoch 42/50\n","73/73 [==============================] - 8s 103ms/step - loss: 0.1812 - accuracy: 0.9346 - val_loss: 0.2760 - val_accuracy: 0.8877\n","Epoch 43/50\n","73/73 [==============================] - 6s 84ms/step - loss: 0.1728 - accuracy: 0.9368 - val_loss: 0.2459 - val_accuracy: 0.9023\n","Epoch 44/50\n","73/73 [==============================] - 7s 102ms/step - loss: 0.1685 - accuracy: 0.9424 - val_loss: 0.2923 - val_accuracy: 0.9040\n","Epoch 45/50\n","73/73 [==============================] - 6s 83ms/step - loss: 0.2028 - accuracy: 0.9233 - val_loss: 0.2676 - val_accuracy: 0.9015\n","Epoch 46/50\n","73/73 [==============================] - 8s 104ms/step - loss: 0.1836 - accuracy: 0.9310 - val_loss: 0.2744 - val_accuracy: 0.8997\n","Epoch 47/50\n","73/73 [==============================] - 6s 83ms/step - loss: 0.1692 - accuracy: 0.9359 - val_loss: 0.3037 - val_accuracy: 0.8946\n","Epoch 48/50\n","73/73 [==============================] - 7s 100ms/step - loss: 0.1693 - accuracy: 0.9374 - val_loss: 0.3218 - val_accuracy: 0.8997\n","Epoch 49/50\n","73/73 [==============================] - 6s 84ms/step - loss: 0.1843 - accuracy: 0.9304 - val_loss: 0.2579 - val_accuracy: 0.9040\n","Epoch 50/50\n","73/73 [==============================] - 7s 99ms/step - loss: 0.1831 - accuracy: 0.9301 - val_loss: 0.2924 - val_accuracy: 0.9092\n","CPU times: user 8min 23s, sys: 15.5 s, total: 8min 39s\n","Wall time: 6min 26s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a2e001c7ee0>"]},"metadata":{},"execution_count":33}],"source":["%%time\n","import tensorflow_addons as tfa\n","from keras.optimizers import RMSprop, Adam\n","def build_sequential_model(input_shape):\n","\n","    clear_session()\n","    model = Sequential()\n","\n","\n","    model.add(Conv1D(filters=256, kernel_size=5,strides =1, activation='relu',input_shape=input_shape))\n","    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n","    model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n","    # model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n","    # model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n","    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n","    model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n","\n","\n","\n","\n","    # model.add(MaxPool1D(pool_size=4,padding = 'same'))\n","    # model.add(MaxPool1D(pool_size=4,padding = 'same'))\n","    model.add(MaxPool1D(pool_size=4,padding = 'same'))\n","    model.add(Dropout(0.25))\n","\n","\n","    # Flatten for Dense layers after Conv1D/LSTM processing\n","\n","    model.add(Flatten())\n","    # model.add(Dense(1024, activation='relu'))\n","    # model.add(Dense(256, activation='relu'))\n","    # model.add(Dense(64, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    # opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.001)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer = opt,\n","        # loss=focal_loss(),\n","                  loss= 'binary_crossentropy',\n","        metrics=['accuracy'])\n","    model.summary()\n","    return model\n","latent_dim = 29\n","Model = build_sequential_model(input_shape=xtrian_mfcc.shape[1:])\n","Model.fit(xtrian_mfcc,ytrain_mfcc, epochs=50, batch_size=64, validation_data = (xtest_mfcc, ytest_mfcc\n","                                                                      ), shuffle=True)#"]},{"cell_type":"code","source":["Model.fit(xtrian,ytrain, epochs=50, batch_size=64, validation_data = (xtest, ytest\n","                                                                      ), shuffle=True)#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TzKBX92qJ9z","outputId":"3b0fb431-4587-4589-e1a2-cd5e0fb18721","executionInfo":{"status":"ok","timestamp":1710746225966,"user_tz":-360,"elapsed":322048,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","73/73 [==============================] - 6s 87ms/step - loss: 0.0540 - accuracy: 0.9816 - val_loss: 0.2099 - val_accuracy: 0.9374\n","Epoch 2/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0500 - accuracy: 0.9835 - val_loss: 0.2256 - val_accuracy: 0.9212\n","Epoch 3/50\n","73/73 [==============================] - 5s 66ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.2294 - val_accuracy: 0.9400\n","Epoch 4/50\n","73/73 [==============================] - 6s 86ms/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.2384 - val_accuracy: 0.9434\n","Epoch 5/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.2226 - val_accuracy: 0.9434\n","Epoch 6/50\n","73/73 [==============================] - 6s 85ms/step - loss: 0.0508 - accuracy: 0.9820 - val_loss: 0.2283 - val_accuracy: 0.9272\n","Epoch 7/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0369 - accuracy: 0.9865 - val_loss: 0.2430 - val_accuracy: 0.9469\n","Epoch 8/50\n","73/73 [==============================] - 5s 64ms/step - loss: 0.0422 - accuracy: 0.9850 - val_loss: 0.2126 - val_accuracy: 0.9409\n","Epoch 9/50\n","73/73 [==============================] - 6s 85ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.2824 - val_accuracy: 0.9203\n","Epoch 10/50\n","73/73 [==============================] - 5s 65ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 0.2605 - val_accuracy: 0.9229\n","Epoch 11/50\n","73/73 [==============================] - 6s 80ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 0.3248 - val_accuracy: 0.9169\n","Epoch 12/50\n","73/73 [==============================] - 5s 72ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 0.2360 - val_accuracy: 0.9297\n","Epoch 13/50\n","73/73 [==============================] - 5s 65ms/step - loss: 0.0318 - accuracy: 0.9889 - val_loss: 0.3318 - val_accuracy: 0.8997\n","Epoch 14/50\n","73/73 [==============================] - 6s 87ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.2424 - val_accuracy: 0.9392\n","Epoch 15/50\n","73/73 [==============================] - 5s 68ms/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.2674 - val_accuracy: 0.9280\n","Epoch 16/50\n","73/73 [==============================] - 5s 74ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.2281 - val_accuracy: 0.9349\n","Epoch 17/50\n","73/73 [==============================] - 5s 73ms/step - loss: 0.0437 - accuracy: 0.9844 - val_loss: 0.2756 - val_accuracy: 0.9263\n","Epoch 18/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0380 - accuracy: 0.9852 - val_loss: 0.2437 - val_accuracy: 0.9400\n","Epoch 19/50\n","73/73 [==============================] - 6s 86ms/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 0.2776 - val_accuracy: 0.9340\n","Epoch 20/50\n","73/73 [==============================] - 5s 65ms/step - loss: 0.0405 - accuracy: 0.9854 - val_loss: 0.3568 - val_accuracy: 0.9032\n","Epoch 21/50\n","73/73 [==============================] - 5s 69ms/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.2522 - val_accuracy: 0.9400\n","Epoch 22/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.2746 - val_accuracy: 0.9314\n","Epoch 23/50\n","73/73 [==============================] - 5s 65ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.2841 - val_accuracy: 0.9280\n","Epoch 24/50\n","73/73 [==============================] - 6s 85ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.2611 - val_accuracy: 0.9357\n","Epoch 25/50\n","73/73 [==============================] - 5s 66ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.2838 - val_accuracy: 0.9400\n","Epoch 26/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 0.2932 - val_accuracy: 0.9332\n","Epoch 27/50\n","73/73 [==============================] - 6s 84ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.3970 - val_accuracy: 0.9143\n","Epoch 28/50\n","73/73 [==============================] - 5s 65ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.3185 - val_accuracy: 0.9357\n","Epoch 29/50\n","73/73 [==============================] - 6s 88ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.3180 - val_accuracy: 0.9237\n","Epoch 30/50\n","73/73 [==============================] - 5s 66ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.2934 - val_accuracy: 0.9280\n","Epoch 31/50\n","73/73 [==============================] - 5s 68ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.2887 - val_accuracy: 0.9357\n","Epoch 32/50\n","73/73 [==============================] - 6s 84ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.2545 - val_accuracy: 0.9400\n","Epoch 33/50\n","73/73 [==============================] - 5s 68ms/step - loss: 0.0546 - accuracy: 0.9786 - val_loss: 0.2207 - val_accuracy: 0.9434\n","Epoch 34/50\n","73/73 [==============================] - 6s 86ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.3010 - val_accuracy: 0.9254\n","Epoch 35/50\n","73/73 [==============================] - 5s 64ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.3176 - val_accuracy: 0.9169\n","Epoch 36/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.3276 - val_accuracy: 0.9332\n","Epoch 37/50\n","73/73 [==============================] - 6s 86ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.3336 - val_accuracy: 0.9400\n","Epoch 38/50\n","73/73 [==============================] - 5s 65ms/step - loss: 0.0232 - accuracy: 0.9914 - val_loss: 0.3119 - val_accuracy: 0.9392\n","Epoch 39/50\n","73/73 [==============================] - 6s 81ms/step - loss: 0.0245 - accuracy: 0.9904 - val_loss: 0.3620 - val_accuracy: 0.9135\n","Epoch 40/50\n","73/73 [==============================] - 5s 71ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.3297 - val_accuracy: 0.9263\n","Epoch 41/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.3295 - val_accuracy: 0.9417\n","Epoch 42/50\n","73/73 [==============================] - 6s 86ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.3542 - val_accuracy: 0.9314\n","Epoch 43/50\n","73/73 [==============================] - 5s 63ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.2977 - val_accuracy: 0.9392\n","Epoch 44/50\n","73/73 [==============================] - 5s 75ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.2861 - val_accuracy: 0.9306\n","Epoch 45/50\n","73/73 [==============================] - 6s 76ms/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.2814 - val_accuracy: 0.9332\n","Epoch 46/50\n","73/73 [==============================] - 5s 66ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.3069 - val_accuracy: 0.9289\n","Epoch 47/50\n","73/73 [==============================] - 6s 83ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.3365 - val_accuracy: 0.9297\n","Epoch 48/50\n","73/73 [==============================] - 5s 67ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.3247 - val_accuracy: 0.9332\n","Epoch 49/50\n","73/73 [==============================] - 5s 68ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.2722 - val_accuracy: 0.9289\n","Epoch 50/50\n","73/73 [==============================] - 6s 82ms/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 0.2893 - val_accuracy: 0.9400\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a2e9282a7d0>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["\n","all_band_result = pd.DataFrame(columns=['Models', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Roc_Auc', 'Specificity', 'Sensitivity', 'Kappa', 'MCC'])\n","\n","print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>ALL band<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n","\n","modelApplied(Model, scaled_data, Y, MN='CNN',model_result= all_band_result)"],"metadata":{"id":"n37uUA8WxleH","executionInfo":{"status":"aborted","timestamp":1710745215542,"user_tz":-360,"elapsed":7,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" ['CNN', '0.965', '0.977', '0.952', '0.964', '0.965', '0.977', '0.952', '0.929', '0.930']\n","DONE!!\n","['CNN', '0.922', '0.950', '0.891', '0.919', '0.921', '0.952', '0.891', '0.843', '0.846']\n","DONE!!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"wP5e-hcIWSY8","executionInfo":{"status":"error","timestamp":1710530147451,"user_tz":-360,"elapsed":435,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"a7a1a20d-a38d-41a2-dc26-4c771b7c1e9c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-46-48cce0cbbba1>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-48cce0cbbba1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    DONE!!\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import numpy as np\n","\n","# Configuration\n","n_splits = 5  # Number of folds\n","random_state = 42\n","shuffle = True\n","\n","# Initialize KFold\n","\n","kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n","\n","# Create a placeholder array for fold assignments\n","fold_assignments = np.empty(len(Y), dtype=int)\n","\n","# Split the data using kf.split. Note: kf.split does not need Y for splitting, but it's kept here for consistency\n","for fold, (train_idx, test_idx) in enumerate(kf.split(scaled_data, Y)):\n","    # Assign fold number\n","    fold_assignments[test_idx] = fold\n","\n","# Example: To get the train and test sets for the first fold\n","fold_number = 0  # Choose which fold to use (0 to n_splits-1)\n","train_idx = np.where(fold_assignments != fold_number)[0]\n","test_idx = np.where(fold_assignments == fold_number)[0]\n","\n","X_train, X_test = scaled_data[train_idx], scaled_data[test_idx]\n","y_train, y_test = Y[train_idx], Y[test_idx]"],"metadata":{"id":"JHKSZLg84em-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Model.fit(X_train, y_train, epochs=1, batch_size=128, validation_data = (X_test, y_test), shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lznj0ZkM46oy","executionInfo":{"status":"ok","timestamp":1710519446296,"user_tz":-360,"elapsed":21549,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"96d9132a-b547-4083-a59e-642e43609b2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["73/73 [==============================] - 15s 208ms/step - loss: 0.0292 - accuracy: 0.9891 - val_loss: 0.3378 - val_accuracy: 0.9306\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b7a883fa7d0>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["\n","# make prediction\n","y_pred = Model.predict(X_test)\n","def predict_binary(model, X, threshold=0.5):\n","    \"\"\"\n","    Predicts binary labels for the given input X using the specified model.\n","    Predictions are determined based on the specified threshold.\n","\n","    Parameters:\n","    - model: Trained Keras model for prediction\n","    - X: Input data for prediction\n","    - threshold: Threshold for converting probabilities to binary labels\n","\n","    Returns:\n","    - Binary labels (0 or 1) for each input sample\n","    \"\"\"\n","    # Get the model's probability predictions for the input data\n","    prob_predictions = model.predict(X)\n","\n","    # Apply threshold to convert probabilities to binary labels\n","    binary_predictions = (prob_predictions > threshold).astype(int)\n","\n","    return binary_predictions\n","\n","# Example of using the custom prediction function\n","y_pred_binary = predict_binary(Model, X_test)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred_binary)\n","precision = precision_score(y_test, y_pred_binary, zero_division=1)\n","recall = recall_score(y_test, y_pred_binary)\n","f1 = f1_score(y_test, y_pred_binary)\n","roc_auc = roc_auc_score(y_test, y_pred_binary)\n","conf_matrix = confusion_matrix(y_test, y_pred_binary)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","specificity = tn / (tn+fp)\n","sensitivity = tp / (tp+fn)\n","kappa = cohen_kappa_score(y_test, y_pred_binary)\n","mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","# Print the results\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"ROC AUC Score: {roc_auc:.4f}\")\n","print(f\"Confusion Matrix:\\n {conf_matrix}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Sensitivity: {sensitivity:.4f}\")\n","print(f\"Cohen's Kappa: {kappa:.4f}\")\n","print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6AKNJ7r4iVI","executionInfo":{"status":"ok","timestamp":1710519711713,"user_tz":-360,"elapsed":4796,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"25570087-f8c3-4998-82a8-eab63e1c14a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["37/37 [==============================] - 1s 32ms/step\n","37/37 [==============================] - 1s 35ms/step\n","Accuracy: 0.9306\n","Precision: 0.9922\n","Recall: 0.8688\n","F1 Score: 0.9264\n","ROC AUC Score: 0.9310\n","Confusion Matrix:\n"," [[576   4]\n"," [ 77 510]]\n","Specificity: 0.9931\n","Sensitivity: 0.8688\n","Cohen's Kappa: 0.8613\n","Matthews Correlation Coefficient: 0.8681\n"]}]},{"cell_type":"markdown","metadata":{"id":"IVz-RFOiLzEw"},"source":["#Final Model Exicuition"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1710172264565,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"tM2k_LHINXMM","outputId":"17da8b95-082a-4e62-a2a2-7539f017c76b"},"outputs":[{"data":{"text/plain":["((5834, 29, 18), (5834, 29, 19), (5834, 29, 37))"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["X_time.shape, X_frequency.shape, X_merged_features.shape #3 different data is available for analysis"]},{"cell_type":"markdown","metadata":{"id":"vtqS4TrtM8JO"},"source":["##Model run without data normalization"]},{"cell_type":"markdown","metadata":{"id":"ZHngiihpZpTc"},"source":["###time domain data"]},{"cell_type":"markdown","metadata":{"id":"hBvyLN6wNJ9V"},"source":["data : X_time, X_frequecy, X_merged_features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710172854185,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"es90H7UnORAS","outputId":"6dd87964-3ccc-4ee2-d8c2-116ce296cc9b"},"outputs":[{"data":{"text/plain":["((4667, 522), (1167, 522), (4667,), (1167,))"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","X_time = X_time.reshape(X_time.shape[0],-1)\n","X_train, X_test, Y_train,Y_test = train_test_split(X_time,Y, random_state= 42, shuffle = True,test_size=0.20)\n","X_train.shape, X_test.shape, Y_train.shape,Y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710172911521,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"4a7v6BrhPKoC","outputId":"ff0ae3f9-5902-49f4-98a0-f03171266e97"},"outputs":[{"data":{"text/plain":["1    587\n","0    580\n","dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(Y_test).value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":692814,"status":"ok","timestamp":1710175175488,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"XePGSOt1L2Fg","outputId":"122af3b6-aa02-4aae-db44-95aa94385ffe"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                          Classifier  Accuracy       mcc  \\\n","0  RandomForestClassifier(max_depth=9, n_estimato...  0.930065  0.864236   \n","1                DecisionTreeClassifier(max_depth=5)  0.902811  0.809774   \n","2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.897326  0.797470   \n","3                             KNeighborsClassifier()  0.775283  0.556909   \n","4  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.926980  0.856534   \n","5  XGBClassifier(base_score=0.5, booster=None, ca...  0.945149  0.893378   \n","\n","      Kappa  precision    recall        f1  sensitivity  specificity  \n","0  0.860130   0.976453  0.881385  0.926486     0.978745     0.881385  \n","1  0.805622   0.948131  0.852245  0.897635     0.953377     0.852245  \n","2  0.794652   0.933757  0.855331  0.892825     0.939321     0.855331  \n","3  0.550566   0.824052  0.700034  0.756997     0.850531     0.700034  \n","4  0.853960   0.962839  0.888241  0.924037     0.965718     0.888241  \n","5  0.890298   0.985421  0.903668  0.942775     0.986630     0.903668  \n"]}],"source":["# total_Metics = []\n","# total_Metics = pd.DataFrame(total_Metics)\n","# total_Metics['Classifier'] = 'Classifier'\n","# total_Metics['Accuracy'] = 'Accuracy'\n","# total_Metics['mcc'] = 'mcc'\n","# # total_Metics['auc'] = 'auc'\n","# total_Metics['Kappa'] = 'Kappa'\n","# total_Metics['precision'] = 'precision'\n","# total_Metics['recall'] = 'recall'\n","# total_Metics['f1'] = 'f1'\n","# total_Metics['sensitivity'] = 'sensitivity'\n","# total_Metics['specificity'] = 'specificity'\n","\n","# cv = KFold(n_splits=5, random_state=42, shuffle=True)\n","\n","# # create model\n","# models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n","#           DecisionTreeClassifier(max_depth = 5),\n","#           ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n","#           KNeighborsClassifier(n_neighbors=5),\n","#           AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n","#           XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n","#           # LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50)\n","#           ]\n","# for model in models:\n","#   from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n","#   # evaluate model\n","#   # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n","#   # model.fit(xtrain, ytrain)\n","#   # pred = model.predict(xtest)\n","#   pred = cross_val_predict(model, X_time, Y, cv=cv, n_jobs=-1)\n","\n","#   # cm1 = confusion_matrix(y, y_pred)\n","#   # report performance\n","#   Accuracy = accuracy_score(Y, pred)\n","#   mcc = matthews_corrcoef(Y, pred)\n","#   cm1 = confusion_matrix(Y, pred)\n","#   kappa = cohen_kappa_score(Y, pred)\n","#   f1 = f1_score(Y, pred)\n","#   precision_score = precision_score(Y, pred)\n","#   recall_score = recall_score(Y, pred)\n","#   sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n","#   specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n","#   # y_pred = np.argmax(y_pred, axis=0)\n","#   # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n","#   total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n","\n","# print(total_Metics)\n","# # total_Metics.to_csv(\"total metrics(FT-CV).csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":807051,"status":"ok","timestamp":1710176711396,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"Phl50Z8rVwxz","outputId":"4c3e0f05-ca15-4c94-f27a-ad45736e1c69"},"outputs":[{"name":"stdout","output_type":"stream","text":["['XGBoost', '0.942', '0.980', '0.903', '0.940', '0.942', '0.981', '0.903', '0.884', '0.887']\n","DONE!!\n","['RandomForest', '0.935', '0.974', '0.895', '0.933', '0.935', '0.976', '0.895', '0.871', '0.874']\n","DONE!!\n","['HistGradientBoosting', '0.943', '0.986', '0.899', '0.940', '0.943', '0.987', '0.899', '0.886', '0.889']\n","DONE!!\n","['SVM', '0.791', '0.864', '0.691', '0.768', '0.791', '0.891', '0.691', '0.582', '0.594']\n","DONE!!\n","['GradientBoosting', '0.926', '0.962', '0.888', '0.923', '0.926', '0.964', '0.888', '0.853', '0.855']\n","DONE!!\n","['KNeighbors', '0.775', '0.825', '0.700', '0.756', '0.775', '0.851', '0.700', '0.551', '0.558']\n","DONE!!\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["['MLP', '0.832', '0.843', '0.825', '0.831', '0.831', '0.837', '0.825', '0.663', '0.669']\n","DONE!!\n","['DecisionTree', '0.889', '0.888', '0.889', '0.889', '0.889', '0.888', '0.889', '0.777', '0.777']\n","DONE!!\n","['GaussianNB', '0.771', '0.877', '0.630', '0.733', '0.771', '0.912', '0.630', '0.542', '0.565']\n","DONE!!\n","['BernoulliNB', '0.578', '0.577', '0.581', '0.579', '0.578', '0.575', '0.581', '0.156', '0.156']\n","DONE!!\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"name":"stdout","output_type":"stream","text":["['LogisticRegression', '0.811', '0.828', '0.787', '0.806', '0.811', '0.836', '0.787', '0.623', '0.624']\n","DONE!!\n","['AdaBoost', '0.914', '0.941', '0.883', '0.911', '0.914', '0.944', '0.883', '0.828', '0.829']\n","DONE!!\n","['ExtraTrees', '0.932', '0.968', '0.892', '0.929', '0.932', '0.971', '0.892', '0.863', '0.866']\n","DONE!!\n"]}],"source":["time_domain_result = pd.DataFrame(columns=['Models', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Roc_Auc', 'Specificity', 'Sensitivity', 'Kappa', 'MCC'])\n","for k,v in models.items():\n","  modelApplied(v,X_time , Y, n_splits=5,MN=k,model_result = time_domain_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"executionInfo":{"elapsed":2077197,"status":"error","timestamp":1710183603643,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"XXETc9gRab_H","outputId":"5561629e-3f78-4006-c888-3e2f120d9470"},"outputs":[{"name":"stdout","output_type":"stream","text":["['XGBoost', '0.944', '0.982', '0.905', '0.942', '0.944', '0.983', '0.905', '0.888', '0.891']\n","DONE!!\n","['RandomForest', '0.933', '0.970', '0.894', '0.930', '0.933', '0.972', '0.894', '0.866', '0.869']\n","DONE!!\n","['HistGradientBoosting', '0.943', '0.985', '0.900', '0.940', '0.943', '0.986', '0.900', '0.886', '0.890']\n","DONE!!\n","['SVM', '0.791', '0.864', '0.691', '0.768', '0.791', '0.891', '0.691', '0.582', '0.594']\n","DONE!!\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-14de47490d64>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtime_domain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Models'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1-Score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Roc_Auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Specificity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sensitivity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Kappa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MCC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mmodelApplied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_time\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_domain_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-52a9f675a7fc>\u001b[0m in \u001b[0;36mmodelApplied\u001b[0;34m(Model, X_train, y_train, n_splits, MN, model_result)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodelApplied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m   \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0mnew_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-52a9f675a7fc>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X, y, n_splits)\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m       \u001b[0;31m# make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","\n","\n","\n","\n","\n","Classifier = {\n","    'XGBoost': XGBClassifier(n_estimators=500, learning_rate=.1, max_depth=5,base_score = 0.5),\n","    'RandomForest': RandomForestClassifier(n_estimators=150,criterion = 'gini',max_features= 'sqrt'),\n","    'HistGradientBoosting': HistGradientBoostingClassifier( max_leaf_nodes=20,max_iter=300,max_depth=17),\n","    'SVM': SVC(),\n","    'GradientBoosting': GradientBoostingClassifier(learning_rate= .2,n_estimators=450,),\n","    'KNeighbors': KNeighborsClassifier(),\n","    'MLP': MLPClassifier(),\n","    'DecisionTree': DecisionTreeClassifier(),\n","    # 'MultinomialNB': MultinomialNB(),\n","    'GaussianNB': GaussianNB(),\n","    'BernoulliNB': BernoulliNB(),\n","    'LogisticRegression': LogisticRegression(),\n","    'AdaBoost': AdaBoostClassifier(estimator = RandomForestClassifier(n_estimators=150,criterion = 'gini',max_features= 'sqrt')),\n","    # 'Bagging': BaggingClassifier(),\n","    'ExtraTrees': ExtraTreesClassifier(n_estimators=150),\n","\n","}\n","\n","time_domain_result = pd.DataFrame(columns=['Models', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Roc_Auc', 'Specificity', 'Sensitivity', 'Kappa', 'MCC'])\n","for k,v in Classifier.items():\n","  modelApplied(v,X_time , Y, n_splits=5,MN=k,model_result = time_domain_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EuGLQOfwyks"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}